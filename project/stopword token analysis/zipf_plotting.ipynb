{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine sim for all datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df:pd.DataFrame, exclude=None):\n",
    "    subset_columns = ['Job Title', 'Company Name', 'Location', 'Salary Estimate', 'Rating', 'Job Description']\n",
    "    if exclude:\n",
    "        if isinstance(exclude, list):\n",
    "            subset_columns = [a for a in subset_columns if a not in exclude]\n",
    "        else:\n",
    "            subset_columns.remove(exclude)\n",
    "    \n",
    "    df.sort_values(subset_columns, inplace=True)\n",
    "\n",
    "    df['Duplicate Count'] = df.groupby(subset_columns)['Job Title'].transform('count')\n",
    "    print(df['Duplicate Count'].value_counts())\n",
    "    df.drop_duplicates(subset=subset_columns, inplace=True, keep='last')\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Count\n",
      "1.0     15855\n",
      "2.0      7490\n",
      "3.0       513\n",
      "4.0       288\n",
      "6.0       168\n",
      "5.0       145\n",
      "10.0      120\n",
      "50.0      100\n",
      "7.0        98\n",
      "97.0       97\n",
      "31.0       93\n",
      "42.0       84\n",
      "8.0        80\n",
      "26.0       78\n",
      "37.0       74\n",
      "24.0       72\n",
      "71.0       71\n",
      "33.0       66\n",
      "16.0       64\n",
      "9.0        63\n",
      "60.0       60\n",
      "15.0       60\n",
      "12.0       48\n",
      "47.0       47\n",
      "40.0       40\n",
      "39.0       39\n",
      "17.0       34\n",
      "11.0       33\n",
      "30.0       30\n",
      "29.0       29\n",
      "28.0       28\n",
      "27.0       27\n",
      "13.0       26\n",
      "22.0       22\n",
      "20.0       20\n",
      "19.0       19\n",
      "14.0       14\n",
      "Name: count, dtype: int64\n",
      "role\n",
      "Data Analyst        8702\n",
      "Business Analyst    6511\n",
      "Data Scientist      4626\n",
      "Data Engineer       2217\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Sector</th>\n",
       "      <th>...</th>\n",
       "      <th>Duplicate Count</th>\n",
       "      <th>Salary Type</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>State</th>\n",
       "      <th>job_description_cleaned</th>\n",
       "      <th>Job Title clean</th>\n",
       "      <th>Years Experience</th>\n",
       "      <th>role</th>\n",
       "      <th>Job Title clean underscored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#11598 - Data Collection Moderator</td>\n",
       "      <td>Qualitest</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>50-70</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Q Analysts - A Qualitest Company is looking fo...</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>q analyst a qualitest company is looking for a...</td>\n",
       "      <td>data collection moderator</td>\n",
       "      <td>2+</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>data_collection_moderator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#11885 - Data Collection Technician</td>\n",
       "      <td>Qualitest</td>\n",
       "      <td>Burlingame, CA</td>\n",
       "      <td>20.00-22.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Q Analysts, a Qualitest Company, is looking fo...</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Per Hour</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>q analyst a qualitest company is looking for a...</td>\n",
       "      <td>data collection technician</td>\n",
       "      <td>2+</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>data_collection_technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2) Sr Business Analyst/s</td>\n",
       "      <td>RiseIT Solutions</td>\n",
       "      <td>Des Moines, IA</td>\n",
       "      <td>63.00</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Title: (2) Sr Business Analyst/s\\nLocation: De...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Per Hour</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>IA</td>\n",
       "      <td>title senior business analyst s location de mo...</td>\n",
       "      <td>senior business analyst s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>senior_business_analyst_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Associate) Director, Manufacturing Operations</td>\n",
       "      <td>Novavax, Inc.</td>\n",
       "      <td>Gaithersburg, MD</td>\n",
       "      <td>109-159</td>\n",
       "      <td>3.3</td>\n",
       "      <td>(Nasdaq:NVAX) is a late-stage biotechnology co...</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Biotech &amp; Pharmaceuticals</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "      <td>Pharmaceutical &amp; Biotechnology</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>109.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>MD</td>\n",
       "      <td>nasdaq nvax is a late stage biotechnology comp...</td>\n",
       "      <td>director manufacturing operation</td>\n",
       "      <td>7-10</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>director_manufacturing_operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Bid) Pricing Analyst</td>\n",
       "      <td>Daikin Comfort Technologies</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>67-93</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Overview:\\n\\n(Bid) Pricing Analyst -Remote\\n\\n...</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>Machinery Manufacturing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>67.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>overview bid pricing analyst remote about moti...</td>\n",
       "      <td>pricing analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>pricing_analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22051</th>\n",
       "      <td>senior data engineer</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Saint Louis, MO</td>\n",
       "      <td>100-134</td>\n",
       "      <td>3.7</td>\n",
       "      <td>JOB DESCRIPTION\\n\\nHaving experience with AWS ...</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>MO</td>\n",
       "      <td>job description having experience with aws ser...</td>\n",
       "      <td>senior data engineer</td>\n",
       "      <td>7-10</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>senior_data_engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22052</th>\n",
       "      <td>senior performance measures analyst , HR Share...</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>78-133</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Final compensation range is determined by cand...</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>Restaurants &amp; Cafes</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>Restaurants &amp; Food Service</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>78.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>final compensation range is determined by cand...</td>\n",
       "      <td>senior performance measure analyst hr shared s...</td>\n",
       "      <td>5+</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>senior_performance_measure_analyst_hr_shared_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22053</th>\n",
       "      <td>systems Analyst with to fraud mitigation on w2</td>\n",
       "      <td>Formac Inc</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>34.00-48.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Systems analyst on w2\\n\\nHybrid Houston TX\\n\\n...</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Per Hour</td>\n",
       "      <td>34.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>system analyst on hybrid houston tx hr on work...</td>\n",
       "      <td>system analyst to fraud mitigation on</td>\n",
       "      <td>5</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>system_analyst_to_fraud_mitigation_on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22054</th>\n",
       "      <td>vCIO</td>\n",
       "      <td>CITOC, Inc.</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>80-100</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Primary Role and Responsibilities\\n\\nBusiness ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>$1 to $5 million (USD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>primary role and responsibility business strat...</td>\n",
       "      <td>vcio</td>\n",
       "      <td>3</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>vcio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22055</th>\n",
       "      <td>DHS Business Systems Analyst</td>\n",
       "      <td>SILLC</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>87-121</td>\n",
       "      <td>2.9</td>\n",
       "      <td>you can email your resume to Email:resumes@sil...</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>$5 to $25 million (USD)</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>87.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>DC</td>\n",
       "      <td>you can email your resume to email resume sill...</td>\n",
       "      <td>dhs business system analyst</td>\n",
       "      <td>6-10</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>dhs_business_system_analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22056 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Job Title  \\\n",
       "0                     #11598 - Data Collection Moderator   \n",
       "1                    #11885 - Data Collection Technician   \n",
       "2                              (2) Sr Business Analyst/s   \n",
       "3         (Associate) Director, Manufacturing Operations   \n",
       "4                                  (Bid) Pricing Analyst   \n",
       "...                                                  ...   \n",
       "22051                               senior data engineer   \n",
       "22052  senior performance measures analyst , HR Share...   \n",
       "22053     systems Analyst with to fraud mitigation on w2   \n",
       "22054                                               vCIO   \n",
       "22055                       DHS Business Systems Analyst   \n",
       "\n",
       "                      Company Name           Location Salary Estimate  Rating  \\\n",
       "0                        Qualitest  Mountain View, CA           50-70     3.5   \n",
       "1                        Qualitest     Burlingame, CA     20.00-22.00     3.5   \n",
       "2                 RiseIT Solutions     Des Moines, IA           63.00     3.7   \n",
       "3                    Novavax, Inc.   Gaithersburg, MD         109-159     3.3   \n",
       "4      Daikin Comfort Technologies         Denver, CO           67-93     3.3   \n",
       "...                            ...                ...             ...     ...   \n",
       "22051                    Capgemini    Saint Louis, MO         100-134     3.7   \n",
       "22052                    Starbucks        Seattle, WA          78-133     3.7   \n",
       "22053                   Formac Inc        Houston, TX     34.00-48.00     4.2   \n",
       "22054                  CITOC, Inc.        Houston, TX          80-100     3.2   \n",
       "22055                        SILLC     Washington, DC          87-121     2.9   \n",
       "\n",
       "                                         Job Description  Founded  \\\n",
       "0      Q Analysts - A Qualitest Company is looking fo...   1997.0   \n",
       "1      Q Analysts, a Qualitest Company, is looking fo...   1997.0   \n",
       "2      Title: (2) Sr Business Analyst/s\\nLocation: De...      NaN   \n",
       "3      (Nasdaq:NVAX) is a late-stage biotechnology co...   1987.0   \n",
       "4      Overview:\\n\\n(Bid) Pricing Analyst -Remote\\n\\n...   1924.0   \n",
       "...                                                  ...      ...   \n",
       "22051  JOB DESCRIPTION\\n\\nHaving experience with AWS ...   1967.0   \n",
       "22052  Final compensation range is determined by cand...   1971.0   \n",
       "22053  Systems analyst on w2\\n\\nHybrid Houston TX\\n\\n...   2013.0   \n",
       "22054  Primary Role and Responsibilities\\n\\nBusiness ...      NaN   \n",
       "22055  you can email your resume to Email:resumes@sil...   1992.0   \n",
       "\n",
       "                                      Industry                     Revenue  \\\n",
       "0      Information Technology Support Services                         NaN   \n",
       "1      Information Technology Support Services                         NaN   \n",
       "2      Enterprise Software & Network Solutions                         NaN   \n",
       "3                    Biotech & Pharmaceuticals  $100 to $500 million (USD)   \n",
       "4                      Machinery Manufacturing                         NaN   \n",
       "...                                        ...                         ...   \n",
       "22051  Enterprise Software & Network Solutions          $10+ billion (USD)   \n",
       "22052                      Restaurants & Cafes          $10+ billion (USD)   \n",
       "22053  Information Technology Support Services                         NaN   \n",
       "22054                                       -1      $1 to $5 million (USD)   \n",
       "22055  Information Technology Support Services     $5 to $25 million (USD)   \n",
       "\n",
       "                               Sector  ... Duplicate Count Salary Type  \\\n",
       "0              Information Technology  ...             1.0  Annual (K)   \n",
       "1              Information Technology  ...             1.0    Per Hour   \n",
       "2              Information Technology  ...             2.0    Per Hour   \n",
       "3      Pharmaceutical & Biotechnology  ...             1.0  Annual (K)   \n",
       "4                       Manufacturing  ...             1.0  Annual (K)   \n",
       "...                               ...  ...             ...         ...   \n",
       "22051          Information Technology  ...             1.0  Annual (K)   \n",
       "22052      Restaurants & Food Service  ...             1.0  Annual (K)   \n",
       "22053          Information Technology  ...             1.0    Per Hour   \n",
       "22054                             NaN  ...             1.0  Annual (K)   \n",
       "22055          Information Technology  ...             2.0  Annual (K)   \n",
       "\n",
       "       min_salary  max_salary State  \\\n",
       "0            50.0        70.0    CA   \n",
       "1            20.0        22.0    CA   \n",
       "2            63.0        63.0    IA   \n",
       "3           109.0       159.0    MD   \n",
       "4            67.0        93.0    CO   \n",
       "...           ...         ...   ...   \n",
       "22051       100.0       134.0    MO   \n",
       "22052        78.0       133.0    WA   \n",
       "22053        34.0        48.0    TX   \n",
       "22054        80.0       100.0    TX   \n",
       "22055        87.0       121.0    DC   \n",
       "\n",
       "                                 job_description_cleaned  \\\n",
       "0      q analyst a qualitest company is looking for a...   \n",
       "1      q analyst a qualitest company is looking for a...   \n",
       "2      title senior business analyst s location de mo...   \n",
       "3      nasdaq nvax is a late stage biotechnology comp...   \n",
       "4      overview bid pricing analyst remote about moti...   \n",
       "...                                                  ...   \n",
       "22051  job description having experience with aws ser...   \n",
       "22052  final compensation range is determined by cand...   \n",
       "22053  system analyst on hybrid houston tx hr on work...   \n",
       "22054  primary role and responsibility business strat...   \n",
       "22055  you can email your resume to email resume sill...   \n",
       "\n",
       "                                         Job Title clean Years Experience  \\\n",
       "0                              data collection moderator               2+   \n",
       "1                             data collection technician               2+   \n",
       "2                              senior business analyst s              NaN   \n",
       "3                       director manufacturing operation             7-10   \n",
       "4                                        pricing analyst              NaN   \n",
       "...                                                  ...              ...   \n",
       "22051                               senior data engineer             7-10   \n",
       "22052  senior performance measure analyst hr shared s...               5+   \n",
       "22053              system analyst to fraud mitigation on                5   \n",
       "22054                                               vcio                3   \n",
       "22055                        dhs business system analyst             6-10   \n",
       "\n",
       "                   role                        Job Title clean underscored  \n",
       "0        Data Scientist                          data_collection_moderator  \n",
       "1        Data Scientist                         data_collection_technician  \n",
       "2          Data Analyst                          senior_business_analyst_s  \n",
       "3      Business Analyst                   director_manufacturing_operation  \n",
       "4          Data Analyst                                    pricing_analyst  \n",
       "...                 ...                                                ...  \n",
       "22051     Data Engineer                               senior_data_engineer  \n",
       "22052      Data Analyst  senior_performance_measure_analyst_hr_shared_s...  \n",
       "22053  Business Analyst              system_analyst_to_fraud_mitigation_on  \n",
       "22054  Business Analyst                                               vcio  \n",
       "22055      Data Analyst                        dhs_business_system_analyst  \n",
       "\n",
       "[22056 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_business_analyst = pd.read_csv('../combined scraper results/business analyst clean.csv')\n",
    "df_data_analyst = pd.read_csv('../combined scraper results/data analyst clean.csv')\n",
    "df_data_engineer = pd.read_csv('../combined scraper results/data engineer clean.csv')\n",
    "df_data_scientist = pd.read_csv('../combined scraper results/data scientist clean.csv')\n",
    "\n",
    "# Combine data for TF-IDF analysis\n",
    "combined_data = pd.concat([\n",
    "    df_business_analyst.assign(role=\"Business Analyst\"),\n",
    "    df_data_analyst.assign(role=\"Data Analyst\"),\n",
    "    df_data_scientist.assign(role=\"Data Scientist\"),\n",
    "    df_data_engineer.assign(role=\"Data Engineer\"),\n",
    "])\n",
    "# print(combined_data.role.value_counts())\n",
    "# combined_data\n",
    "remove_duplicates(combined_data, exclude=['Location','Salary Estimate']) # sometimes salary is location-dependent. we are only analyzing job descriptions so this is fine.\n",
    "print(combined_data.role.value_counts())\n",
    "\n",
    "# Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply,Duplicate Count,\n",
    "# Job Title clean,Salary Type,min_salary,max_salary,job_description_cleaned,Years Experience\n",
    "combined_data['Job Title clean underscored'] = combined_data['Job Title clean'].apply(lambda x: str(x).replace(' ','_'))\n",
    "\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zipf(df, column, vectorizer, stopwords_name, ax=None, rank_lim=1e7, count_lim=1e6):\n",
    "    # Fit and transform the data\n",
    "    if vectorizer.stop_words is not None and isinstance(vectorizer.stop_words, list):\n",
    "        print(f'removing {len(vectorizer.stop_words)} stopwords')\n",
    "    count_matrix = vectorizer.fit_transform(df[column].fillna(''))\n",
    "    ng_ = vectorizer.ngram_range\n",
    "    print(ng_, '-', count_matrix.shape[1], 'tokens detected')\n",
    "\n",
    "    # Sum the counts for each term in the corpus\n",
    "    count_sum = np.array(count_matrix.sum(axis=0)).flatten()\n",
    "\n",
    "    # Sort the counts in descending order\n",
    "    sorted_count_sum = np.sort(count_sum)[::-1]\n",
    "\n",
    "    # Check if axes are provided, if not, create new ones\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(7 * 1.4, 6 * 1.4))\n",
    "\n",
    "    # Plotting on the provided or new axes\n",
    "    ax.loglog(sorted_count_sum, label=f'{ng_[0]}-{ng_[1]} grams stopwords {stopwords_name}', lw=2)\n",
    "\n",
    "    # Setting labels, limits, and title only if new axes were created\n",
    "    if ax is None:\n",
    "        ax.set_xlabel('Rank')\n",
    "        ax.set_ylabel('Counts')\n",
    "        ax.set_xlim([0, rank_lim])\n",
    "        ax.set_ylim([0, count_lim])\n",
    "        ax.set_title(f'{column}: Word Freq, {count_matrix.shape[1]} tokens, {stopwords_name} stopwords removed')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        plt.show()\n",
    "# Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply,Duplicate Count,\n",
    "# Job Title clean,Salary Type,min_salary,max_salary,job_description_cleaned,Years Experience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
    "\n",
    "# Counting the number of stopwords in each set\n",
    "nltk_stopwords = set(nltk_stopwords.words('english'))\n",
    "sklearn_stopwords = set(sklearn_stop_words)\n",
    "\n",
    "nltk_stopwords_count = len(nltk_stopwords)\n",
    "sklearn_stopwords_count = len(sklearn_stopwords)\n",
    "\n",
    "stopword_sets = dict()\n",
    "stopword_sets['no'] = None\n",
    "stopword_sets['nltk sklearn intersect'] = list(nltk_stopwords.intersection(sklearn_stopwords))\n",
    "stopword_sets['nltk'] = list(nltk_stopwords)\n",
    "stopword_sets['sklearn'] = list(sklearn_stopwords)\n",
    "stopword_sets['nltk sklearn union'] = list(nltk_stopwords.union(sklearn_stopwords))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_data = {}\n",
    "# for col in ['job_description_cleaned']:\n",
    "#     for sw in stopword_sets:\n",
    "#         for j in range(1, 4):\n",
    "#             vectorizer = CountVectorizer(ngram_range=(1, j), stop_words=stopword_sets[sw])\n",
    "#             count_matrix = vectorizer.fit_transform(combined_data[col].fillna(''))\n",
    "#             count_sum = np.array(count_matrix.sum(axis=0)).flatten()\n",
    "#             sorted_count_sum = np.sort(count_sum)[::-1]\n",
    "#             count_data[(col, sw, j)] = sorted_count_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['job_description_cleaned']:\n",
    "    for sw in stopword_sets:\n",
    "        fig, ax = plt.subplots(figsize=(6*1.4, 6*1.4))\n",
    "        for j in range(1, 4):\n",
    "            sorted_count_sum = count_data[(col, sw, j)]\n",
    "            # print()\n",
    "            ax.loglog(sorted_count_sum, label=f'N-gram (1, {j})\\n{len(sorted_count_sum)} tokens')\n",
    "\n",
    "        ax.set_xlabel('Rank')\n",
    "        ax.set_ylabel('Counts')\n",
    "        ax.set_xlim([0, 1e7])\n",
    "        ax.set_ylim([0, 1e6])\n",
    "        ax.set_title(f'{col}: Word Freq, {len(stopword_sets[sw]) if stopword_sets[sw] else 0} stopwords ({sw})')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'zipf plots combined/zipf {col} stopwords {sw}.png', dpi=300)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['no', 'nltk sklearn intersect', 'nltk', 'sklearn', 'nltk sklearn union'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_sets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[119, 179, 318, 378]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(stopword_sets[a]) for a in stopword_sets if stopword_sets[a]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['job_description_cleaned']:\n",
    "    for j in range(1, 4):\n",
    "        fig, ax = plt.subplots(figsize=(6*1.4, 6*1.4))\n",
    "        for sw in stopword_sets:\n",
    "            sorted_count_sum = count_data[(col, sw, j)]\n",
    "            ax.loglog(sorted_count_sum, label=f'{len(stopword_sets[sw]) if stopword_sets[sw] else 0} stopwords ({sw})\\n{len(sorted_count_sum)} tokens')\n",
    "\n",
    "        ax.set_xlabel('Rank')\n",
    "        ax.set_ylabel('Counts')\n",
    "        ax.set_xlim([0, 1e7])\n",
    "        ax.set_ylim([0, 1e6])\n",
    "        ax.set_title(f'{col}: Word Freq, ngram range (1, {j})')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'zipf plots combined/zipf {col} ngrams 1-{j}.png', dpi=300)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['job_description_cleaned']:\n",
    "    fig, ax = plt.subplots(figsize=(8*1.4, 8*1.4))\n",
    "    for j in range(1, 4):\n",
    "        for sw in ['no','nltk sklearn intersect']:    \n",
    "        # for sw in ['no', 'nltk sklearn intersect', 'nltk sklearn union']:\n",
    "            sorted_count_sum = count_data[(col, sw, j)]\n",
    "            ax.loglog(sorted_count_sum, label=f'{len(stopword_sets[sw]) if stopword_sets[sw] else 0} stopwords ({sw})\\nN-gram (1, {j})\\n{len(sorted_count_sum)} tokens')\n",
    "\n",
    "    ax.set_xlabel('Rank')\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.set_xlim([0, 1e7])\n",
    "    ax.set_ylim([0, 1e6])\n",
    "    ax.set_title(f'{col}: Combined Word Freq Analysis')\n",
    "    ax.legend()\n",
    "    # ax.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    ax.grid(True)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'zipf plots combined/zipf {col} combined.png', dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43masdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'asdf' is not defined"
     ]
    }
   ],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Job Description','job_description_cleaned','Job Title','Job Title clean']:\n",
    "    for i in range(1,4):\n",
    "        for j in range(i,4):\n",
    "            for sw in stopword_sets:\n",
    "                print(col, (i,j), '- stopwords:', sw)\n",
    "                plot_zipf(combined_data, col, CountVectorizer(ngram_range=(i,j), stop_words=stopword_sets[sw]), stopwords_name=sw)\n",
    "                plt.savefig(f'zipf plots/zipf {col} ngrams {i}-{j} stopwords {sw}', dpi=300)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Job Title','Job Title clean']:\n",
    "    for i in range(1,4):\n",
    "        for j in range(i,4):\n",
    "            for sw in stopword_sets:\n",
    "                print(col, (i,j), '- stopwords:', sw)\n",
    "                plot_zipf(combined_data, col, CountVectorizer(ngram_range=(i,j), stop_words=stopword_sets[sw]), stopwords_name=sw)\n",
    "                plt.savefig(f'zipf plots/zipf {col} ngrams {i}-{j} stopwords {sw}', dpi=300)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for col in ['Job Description','job_description_cleaned','Job Title','Job Title clean']:\n",
    "    with open(f'{col}.txt', 'r') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    lines = file_content.split('\\n')\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "\n",
    "        if col in line:\n",
    "            # Extracting the N-gram and stopwords information\n",
    "            n_gram_info, stopwords_info = line.split(' - ')\n",
    "            n_gram = n_gram_info.split('(')[-1].split(')')[0]  # Extracting the N-gram range\n",
    "            n0,n1 = n_gram.split(', ')\n",
    "            stopwords = stopwords_info.split(': ')[-1]\n",
    "\n",
    "            if stopwords == 'no':\n",
    "                # If stopwords are 'no', the token count is in the next line\n",
    "                token_count = int(lines[i + 1].split(' - ')[-1].split()[0])\n",
    "                i += 2  # Incrementing by 2 to skip the next line\n",
    "            else:\n",
    "                # If stopwords are specified, the token count is in the line after the next\n",
    "                token_count = int(lines[i + 2].split(' - ')[-1].split()[0])\n",
    "                i += 3  # Incrementing by 3 to skip the next two lines\n",
    "\n",
    "            temp_df = pd.DataFrame({'ngram range': [n_gram], 'ngram min': [int(n0)], 'ngram max': [int(n1)], 'stopwords': [stopwords], 'num tokens': [token_count]})\n",
    "            df = pd.concat([df, temp_df], ignore_index=True)\n",
    "        else:\n",
    "            i += 1  # Incrementing to check the next line\n",
    "\n",
    "    # print(df)\n",
    "    df['column'] = col\n",
    "    df = df[['column','ngram range','ngram min', 'ngram max', 'stopwords', 'num tokens']]\n",
    "    dfs.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>ngram range</th>\n",
       "      <th>ngram min</th>\n",
       "      <th>ngram max</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>num tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>67695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk</td>\n",
       "      <td>67557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>67400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>67378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>67579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>1586888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk</td>\n",
       "      <td>1924770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1885504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>1881728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>1928322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>6233896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk</td>\n",
       "      <td>6603039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>6435895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>6423429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>6614995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>1519193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk</td>\n",
       "      <td>1857213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1818104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>1814350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>1860743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>6166201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk</td>\n",
       "      <td>6535482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>6368495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>6356051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>6547416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>4647008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk</td>\n",
       "      <td>4678269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>4550391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>4541701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>4686673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column ngram range  ngram min  ngram max               stopwords  \\\n",
       "0   Job Description        1, 1          1          1                      no   \n",
       "1   Job Description        1, 1          1          1                    nltk   \n",
       "2   Job Description        1, 1          1          1                 sklearn   \n",
       "3   Job Description        1, 1          1          1      nltk sklearn union   \n",
       "4   Job Description        1, 1          1          1  nltk sklearn intersect   \n",
       "5   Job Description        1, 2          1          2                      no   \n",
       "6   Job Description        1, 2          1          2                    nltk   \n",
       "7   Job Description        1, 2          1          2                 sklearn   \n",
       "8   Job Description        1, 2          1          2      nltk sklearn union   \n",
       "9   Job Description        1, 2          1          2  nltk sklearn intersect   \n",
       "10  Job Description        1, 3          1          3                      no   \n",
       "11  Job Description        1, 3          1          3                    nltk   \n",
       "12  Job Description        1, 3          1          3                 sklearn   \n",
       "13  Job Description        1, 3          1          3      nltk sklearn union   \n",
       "14  Job Description        1, 3          1          3  nltk sklearn intersect   \n",
       "15  Job Description        2, 2          2          2                      no   \n",
       "16  Job Description        2, 2          2          2                    nltk   \n",
       "17  Job Description        2, 2          2          2                 sklearn   \n",
       "18  Job Description        2, 2          2          2      nltk sklearn union   \n",
       "19  Job Description        2, 2          2          2  nltk sklearn intersect   \n",
       "20  Job Description        2, 3          2          3                      no   \n",
       "21  Job Description        2, 3          2          3                    nltk   \n",
       "22  Job Description        2, 3          2          3                 sklearn   \n",
       "23  Job Description        2, 3          2          3      nltk sklearn union   \n",
       "24  Job Description        2, 3          2          3  nltk sklearn intersect   \n",
       "25  Job Description        3, 3          3          3                      no   \n",
       "26  Job Description        3, 3          3          3                    nltk   \n",
       "27  Job Description        3, 3          3          3                 sklearn   \n",
       "28  Job Description        3, 3          3          3      nltk sklearn union   \n",
       "29  Job Description        3, 3          3          3  nltk sklearn intersect   \n",
       "\n",
       "    num tokens  \n",
       "0        67695  \n",
       "1        67557  \n",
       "2        67400  \n",
       "3        67378  \n",
       "4        67579  \n",
       "5      1586888  \n",
       "6      1924770  \n",
       "7      1885504  \n",
       "8      1881728  \n",
       "9      1928322  \n",
       "10     6233896  \n",
       "11     6603039  \n",
       "12     6435895  \n",
       "13     6423429  \n",
       "14     6614995  \n",
       "15     1519193  \n",
       "16     1857213  \n",
       "17     1818104  \n",
       "18     1814350  \n",
       "19     1860743  \n",
       "20     6166201  \n",
       "21     6535482  \n",
       "22     6368495  \n",
       "23     6356051  \n",
       "24     6547416  \n",
       "25     4647008  \n",
       "26     4678269  \n",
       "27     4550391  \n",
       "28     4541701  \n",
       "29     4686673  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>ngram range</th>\n",
       "      <th>ngram min</th>\n",
       "      <th>ngram max</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>num tokens detected by vectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>67695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk</td>\n",
       "      <td>67557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>67400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>67378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>67579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>23952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk</td>\n",
       "      <td>22413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>21753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>21742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>22424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             column ngram range  ngram min  ngram max               stopwords  \\\n",
       "0   Job Description        1, 1          1          1                      no   \n",
       "1   Job Description        1, 1          1          1                    nltk   \n",
       "2   Job Description        1, 1          1          1                 sklearn   \n",
       "3   Job Description        1, 1          1          1      nltk sklearn union   \n",
       "4   Job Description        1, 1          1          1  nltk sklearn intersect   \n",
       "..              ...         ...        ...        ...                     ...   \n",
       "25  Job Title clean        3, 3          3          3                      no   \n",
       "26  Job Title clean        3, 3          3          3                    nltk   \n",
       "27  Job Title clean        3, 3          3          3                 sklearn   \n",
       "28  Job Title clean        3, 3          3          3      nltk sklearn union   \n",
       "29  Job Title clean        3, 3          3          3  nltk sklearn intersect   \n",
       "\n",
       "    num tokens detected by vectorizer  \n",
       "0                               67695  \n",
       "1                               67557  \n",
       "2                               67400  \n",
       "3                               67378  \n",
       "4                               67579  \n",
       "..                                ...  \n",
       "25                              23952  \n",
       "26                              22413  \n",
       "27                              21753  \n",
       "28                              21742  \n",
       "29                              22424  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = pd.concat(dfs)\n",
    "ret.rename(columns={'num tokens':'num tokens detected by vectorizer'},inplace=True)\n",
    "ret.to_csv('stopword token analysis.csv',index=False)\n",
    "ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si671",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
