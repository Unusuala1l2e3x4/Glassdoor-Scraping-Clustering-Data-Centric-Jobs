Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply
Sr. Data Engineer,"MedWatchers Inc
","San Diego, CA",$95K - $145K (Employer est.),2.7,"About MedWatchers

We specialize in culturally senstive pharmacy services to improve patient health. The technology we leverage and platforms we build make it possible for amazing pharmacists to assist people in their own language, and to help people manage their medications for diseases including diabetes, asthma, hypertension, and many others.

If you are motived to help build platforms that make it possible to provide quality healthcare services for patients, we’d love to have you on the team!

About this Opportunity

Data Engineer / Experienced Python programmer position full-time permanent hire. Successful applicants will work on data and applications to support pharmacists and automating systems to optimize medication therapy services.

You will have an opportunity to experience working with highly experienced pharmacists as you delve into projects and services that help improve lives. Along the way, you will interact with and leverage multiple technologies, develop secure data pipelines, and help patients that our clients entrust us to support. The main goal is that solutions we put into action improve the outcome of the care, and our measurement of the effectiveness of the efforts is whether the patient was able to get the support they needed.

Future projects include developing secure applications to support the to provide context-based assistance for pharmacist and patient interactions, building secure infrastructure, optimizing outreach efforts. and improving predictions or finding indicators in the historical data that will facilitate better healthcare services.

Required:

Degree in Computer Science, Data Science and Engineering, Business Analytics, Information Systems or related fields
Programming proficiency: Python required
Solid knowledge of Linux, Comfortable working in a hybrid Linux / Windows environment
SQL / Database Knowledge
Statistical Analysis / Machine learning
Understanding of secure programming and computing practices
Ability to manage and work with data that involves some complex transformations
Ability to effectively communicate data insights to stakeholders, coordinate with management, and prioritize your efforts

Other Education, Skills, or Experience:

Formal education/courses/certificates in computer security related topics highly preferred
Understanding of AWS Cloud Services

Job Type: Full-time

Pay: $95,000.00 - $145,000.00 per year

Benefits:

401(k)
401(k) matching
Dental insurance
Flexible schedule
Health insurance
Paid time off
Referral program
Tuition reimbursement
Vision insurance

Compensation package:

Performance bonus
Signing bonus
Yearly pay

Experience level:

5 years

Schedule:

8 hour shift
Monday to Friday

Experience:

SQL: 1 year (Required)
Linux: 3 years (Required)
Python: 5 years (Required)

License/Certification:

AWS Certification (Required)

Work Location: Hybrid remote in San Diego, CA 92130",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,True
Data Engineer III (Hybrid Work Schedule),"Inland Empire Health Plans
","Rancho Cucamonga, CA",$118K - $151K (Employer est.),3.6,"A reasonable salary expectation is between $118,248.00 and $150,779.20, based upon experience and internal equity.

This position is on a Hybrid work schedule. (Mon & Fri - remote, Tues - Thurs Onsite in Rancho Cucamonga, CA)

Position Summary/Position

Under the direction of the Department Leadership, the Data Engineer III is responsible for the design, planning and development of IEHP data solutions. The Data Engineer III will lead the design and development of data transformation. This position will be involved in data architecture. The
Data Engineer III is expected to lead by example. In this role the Data Engineer III will follow coding standards throughout all aspects of the solution development to produce efficient and high-quality solutions.

Major Functions (Duties and Responsibilities)

1. Design, develop and implement reliable and effective data solutions based on business requirements.
2. Maintain process design artifacts like data flow diagrams, end user process maps and technical design documents.
3. Find trends in data sets and develop algorithms to help make raw data more useful to IEHP.
4. Create and maintain optimal data pipeline architecture that meet security standards.
5. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
6. Develop best practices for database design and development activities.
7. Create complex functions, scripts, and services to support the Data Services team.
8. Ensure all data solutions meet company and performance requirements.
9. Work under minimal supervision with wide latitude for independent judgment.
10. Conduct code reviews.
11. Direct and mentor some level I and II engineers.
12. Serve as a subject matter expert in key business projects.
13. Recommend improvements to existing Data Services processes as necessary.
14. Provide detailed analysis of data issues; data mapping; and the process for automation and enhancement of data quality.
15. Analyze and integrate new technologies with existing applications to improve the design and functionality of applications.
16. Maintain proficient programming skills in REST web services, C#.NET, TSQL, XML, JSON, and other relevant languages and/or frameworks.
17. Develop and automate solutions to consume data from multiple data sources, including external
API
18. Program and modify code in languages like Java, Json, Python, and Spark to support and implement Data Warehouse solutions.
19. Design and deploy enterprise-scale cloud infrastructure solutions.
20. Research, analyze, recommend and select technical approaches for solving difficult and meaningful development and integration problems.
21. Work closely with the Data and Engineering teams to design best in class Azure implementations.
22. Clearly and regularly communicate with management, colleagues, and domain units.

Supervisory Responsibilities
Leading: Guides Others

Experience Qualifications

Minimum of eight (8) years of experience in provisioning, configuring, and developing solutions in
Azure Data Lake, Azure Data Factory, Azure SQL Data Warehouse, Azure Synapse and Cosmos
DB. Eight (8) years implementing software development methodologies. Eight (8) years working with relational databases. Experience building and optimizing big data pipelines, architectures, and data sets. Experience performing root cause analysis on internal and external data and processes.
Experience using Source Control and management tools such as Azure DevOps and Gitlab/GitHub.
Experience transforming requirements into Design Concepts and ERDs using Visio and similar tools. Of the total eight, a minimum of five (5) years of hands-on experience with cloud orchestration and automation tools and CI/CD pipeline creation is required.

Education Qualifications

Bachelor’s degree in a quantitative discipline such as Computer Science, Statistics, Mathematics or
Engineering from an accredited institution required.

Preferred Education

Master's degree from an accredited institution preferred.

Professional Certification

MS Azure Certification in Data Engineering is a plus.

Knowledge Requirement

Strong knowledge and understanding in the following areas:
- DevOps, Python or Java or Json, (HL7/ FHIR is a plus)
- Applicable data privacy practices and laws
- common SDLC models (Waterfall, Agile - Scrum and Kanban)
- Practice of DevOps
- Non-relational database (NoSQL) designs using MongoDB and others
- Relational databases like MS SQL Server
- Fluency with at least one scripting or programming language such as Python.
- Message queuing, stream processing, and highly scalable ‘big data’ data stores.

Skills Requirement

Excellent communication skills. Excellent analytical and problem-solving skills. Strong logical reasoning skills and business intelligence. Ability to analyze technical specifications.

Abilities Requirement

Ability to work to work in a collaborative and inclusive environment. Ability to effectively communicate. Desire to work independently in a fast-paced, collaborative, and team-based support environment. Ability to demonstrate excellent organizational skills, with the ability to prioritize workload, meet deadlines, and multi-task while maintaining attention to detail.

Commitment to Team Culture

The IEHP Team environment requires a Team Member to participate in the IEHP Team Culture. A
Team Member demonstrates support of the Culture by developing professional and effective working relationships that include elements of respect and cooperation with Team Members,
Members and associates outside of our organization.

Work Model Location
Hybrid

Job Type: Full-time

Pay: $118,248.00 - $150,779.20 per year

Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Professional development assistance
Referral program
Tuition reimbursement
Vision insurance

Compensation package:

Bonus opportunities
Performance bonus

Experience level:

8 years

Schedule:

8 hour shift
Monday to Friday
No weekends

Education:

Bachelor's (Required)

Experience:

Azure: 8 years (Required)
implementing software: 8 years (Required)
automation tools: 5 years (Required)
cloud orchestration: 5 years (Required)
CI/CD: 5 years (Preferred)

Work Location: Hybrid remote in Rancho Cucamonga, CA 91730",1996,Health Care Services & Hospitals,$1 to $5 billion (USD),Healthcare,1001 to 5000 Employees,Company - Public,True
Engineer III - Test Data Management (Hybrid Work Schedule),"Inland Empire Health Plan
","Rancho Cucamonga, CA",$66K - $92K (Glassdoor est.),3.6,"Job Requisition ID: 7759




Position Summary/Position




The Engineer III - Test Data Management is the lead position assisting the Manager, Technical Test Data & Environment in leading the enterprise-level test data Management (ensuring the protection of PHI data) on several Test environments. It consists of using procedures, data masking tools, and resources to manage multiple components like software, hardware, test data, and applications. This position works in collaboration with TEM Engineers to ensure Test Environments are ready with necessary test data for Test execution and Delivery teams on all IT projects. This is a senior position and trains and guides Engineer I/IIs in the Test Data management area.

Major Functions (Duties and Responsibilities)




1. Analyze existing Test data in several environments and identify test data and security gaps.
2. Develop and execute Test Data Management Strategy and plans based on the assessment.
3. Lead enterprise-level Test Data management across several applications and test environments.
4. Provision On-demand, self-service test data.
5. Perform in-flight data masking, also for unstructured data, while ensuring referential integrity.
6. Set test data based on user-defined criteria on various projects.
7. Synthesize test data based on production data.
8. Integrate TDM into CI/CD pipelines with an open API.
9. Set up integrated test data in multiple test environments of integrated applications.
10. Use APIs to refresh to the latest data, rewind for cleanup, branch datasets, and version data alongside code.
11. Research and implement automatic test data generation tools .
12. Find then mask sensitive data value automatically.
13. Resolve application team/business team queries related to obfuscated data for all non-prod databases.
14. Deliver virtual data to environments for development, testing, integration, and UAT automatically.
15. Store and version control virtual datasets efficiently. Bookmark data and pair with specific test cases.
16. Create test data generation templates for QE Engineers to generate test data files in several formats (HL7/ CCDA/X12 etc.) based on various test scenarios
17. Build complex data reconciliation scripts for volume data validation in ETL and Data integration testing processes
18. Collaborate with Test Environment Management team, Application support team, Product vendors, internal database, and Data integration teams to support the Test Delivery on several projects in a timely manner.
19. Train and guide Engineer I/IIs in the Test Data management.

Supervisory Responsibilities
Leading: Guides Others
Experience Qualifications




A minimum of eight (8) years of Information systems and Quality Engineering experiences. Minimum five (5) years of experience working in Test Data Management. Demonstrated ability in the creation of data quality standards and methodologies. Demonstrated ability in Design and developing test Data Management Strategies and plans. Experience in data masking and setting up test data in integrated test environments of multiple applications. Experience writing and executing complex SQL query commands. Experience in coordination with external vendor teams. Test Automation and CI/CD experience. Experience in Test Automation tools. Experience communicating with management on topics related to Test Data roadblocks and risks. Strong technical background. A demonstrated track record of organizing test data at various stages of test life cycle and on multiple integrated systems across multiple projects. Proven experience with Data Masking.

Education Qualifications




Bachelor’s degree in Computer Science, Information Management or similar technical field from an accredited institution required.

Drivers License Required
Yes, must have a valid California Driver's License.
Knowledge Requirement



Thorough understanding of Test Data Management tools
knowledge of TDM, data Obfuscation and Test Lifecycle
knowledge of Agile, SDLC, and ITIL
Understanding of Agile environment and DevOps
Extensive familiarity with quality assurance processes and procedures, and the ability to devise methods to enforce data quality standards
Should have an overall grasp of the work effort involved to set up Test data for end-to-end testing environments.
Skills Requirement



The ability to use Test Data Management tools
Strong planning, organization, critical thinking, decision-making and communication (verbal and written) skills.
Strong interpersonal skills
Robust analytical skills for both existing processes and identifying areas of opportunity
Excellent decision-making, problem-solving, team and time management skills
Good interpersonal, communication and organizational skills
Abilities Requirement



Ability to clearly articulate both problems and proposed solutions
Ability to prioritize personal and team workloads to best meet organizational objectives
Ability to work effectively on a high-performing team
Analytical and process skills
Effective problem resolution
Resiliency and Ability to adapt in a dynamic environment
Present issues and challenges in senior management forums.
Work with a team of professionals from various disciplines.
Express action-oriented and creative approaches to IT system issues and problems.
Ability to lead, guide and train other resources
Motivated by delivery and speed to outcome
Ability to effectively prioritize and execute tasks in a high-pressure environment
Commitment to Team Culture




The IEHP Team environment requires a Team Member to participate in the IEHP Team Culture. A Team Member demonstrates support of the Culture by developing professional and effective working relationships that include elements of respect and cooperation with Team Members, Members and associates outside of our organization.

Working Conditions




Makes necessary adjustments to work shift ensure completion of projects and to meet deadlines, e.g., system releases, critical milestones

A reasonable salary expectation is between $103,708.80 - $132,225.60, based upon experience and internal equity




Inland Empire Health Plan (IEHP) is the largest not-for-profit Medi-Cal and Medicare health plan in the Inland Empire. We are also one of the largest employers in the region. With a provider network of more than 7,000 and a team of more than 2,500 employees, IEHP provides quality, accessible healthcare services to more than 1.5 million members. And our Mission, Vision, and Values help guide us in the development of innovative programs and the creation of an award winning workplace. As the healthcare landscape is transformed, we’re ready to make a difference today and in the years to come. Join our Team and make a difference with us! IEHP offers a competitive salary and a benefit package with a value estimated at 35% of the annual salary, including medical, dental, vision, team bonus, and state pension plan.",1996,Health Care Services & Hospitals,$1 to $5 billion (USD),Healthcare,1001 to 5000 Employees,Company - Public,False
Principal / Sr Principal Instrumentation and Data Acquisition Hardware Engineer,"Northrop Grumman
","Palmdale, CA",$95K - $142K (Employer est.),4.0,"Requisition ID: R10135180
Category: Engineering
Location: Palmdale, California, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: Any (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 7
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.

Northrop Grumman Aeronautics Systems has an opening for an Instrumentation and Data Acquisition Hardware Engineer to join our team of qualified, diverse individuals. This position is located in Palmdale, CA.

As an Instrumentation and Data Acquisition Engineer you’ll be part of the design, development, integration, configuration and test of a real-time, hardware in the loop (HITL), Data Acquisition Systems (DAS). Tasking will include design, development, verification and acceptance testing of data builds and real time Mission Control Room configuration files using Symvionics IADS software.

This position will require occasionally work shift work and overtime and travel.

“This requisition may be filled at a higher grade based on qualifications listed below.”

Basic Qualifications:




“This requisition may be filled at either a principal or a Sr. Principal Level)

Basic Qualifications for Principal Instrumentation Data Hardware Engineer:

Bachelor’s degree within a science, technical, engineering or mathematics (STEM Degree) discipline with 5 years of test experience, Masters with (STEM Degree) 0 years of experience.
Basic understanding of troubleshooting systems to identify and assist in the correct the root cause.
Assist with creating, editing and executing procedures.
Assist in data acquisition and data collection.
Experience with Microsoft Window Family, AutoCAD, MatLab.
Requires active DoD Secret Clearance
Ability to obtain and maintain PAR (Program Special Access)

Basic Qualification for Sr Principal Instrumentation Data Hardware Engineer:

Bachelor’s degree within a science, technical, engineering or mathematics (STEM Degree) discipline with 9 years of test experience, master's with (STEM Degree) 7 years of experience.
Basic understanding of troubleshooting systems to identify and assist in the correct the root cause.
Assist with creating, editing and executing procedures.
Assist in data acquisition and data collection.
Experience with Microsoft Window Family, AutoCAD, MatLab.
Requires active DoD Secret Clearance
Ability to obtain and maintain PAR (Program Special Access)

Preferred Qualifications:

Electronics, Analog and Digital Communications, Digital Signal Processes, Computer Communication Networks, Embedded Systems
Experience working in Flight Test or Lab Test environments
Experience using oscilloscopes and waveform generators.
Experience working with Strain Gages, Accelerometers, Pressure Transducers and other commonly used instrumentation sensors
Basic knowledge of data bus architecture MIL-STD-1553, IEE-1394, ARINC-429, RS232 an RS422.
Experience using Symvionics IADS software and working in a Mission Control Room
Experience post-test processing data from a IRIG-106 CH10 recording
Experience using TTCWare Application Software
Experience working Curtiss-Wright TTC Data Acquisitions Systems
Ability to write scripts GUIs or small scale applications a plus.
Degree in Electrical or a Bachelor’s of Science degree with Instrumentation data experience.
Salary Range: $95,000 - $142,000
Salary Range 2: $117,700 - $176,500
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.

Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",1939,Aerospace & Defense,$10+ billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
Senior Data Engineer,"Pacific Life
","Newport Beach, CA",$115K - $152K (Glassdoor est.),4.1,"Job Description:
Pacific Life is investing in bright, agile and diverse talent to contribute to our mission of innovating our business and creating a superior customer experience. We’re actively seeking a talented Senior Data Engineer to join our Workforce Benefits Technology team in Newport Beach, CA. This role can be on-site, hybrid or 100% remote.

This position will be responsible for the requirement gathering, design and delivery of integrated data marts, data translations, and data models in the newly formed Workforce Benefits Division. These data solutions will capture, manage, store and utilize structured and unstructured data from internal and external sources and provide integrated data for Sales, Actuarial, Pricing, Underwriting, Operations, Claims and other functions. The role will establish and build processes and structures based on business and technical requirements to channel data from multiple inputs, apply appropriate security, and create data products. The position will work with functional data stewards to implement data governance and data management principles across Workforce Benefits, and may work with solution providers to ensure the integrity and automated flow of data to PL. This role will serve as a valued partner across Workforce Benefits functions to create a single-source of trusted data with fast, scalable access to data assets, to satisfy the analytical data needs of the division.

How you will make an impact:
Become a domain expert in WBD data by understanding complex data relationship between internal and external data sources, user interface source data and event data.
Act as a key liaison to Workforce Benefits Division stakeholders on data needs by translating business requirements to design, and develop efficient and reliable data products for business analytics.
Document requirements, link requirements to integrate common data elements, expand the WBD data model with new data elements, and create source to target mappings for destination tables.
Identify the appropriate microservice events from the policy admin system to capture required data, and transform source data into an operational data store by building third normal form tables.
Develop Workforce Benefit’s division integrated data layer by constructing data schemas for functional business analysis and reporting. Recommend best practices for data-driven reporting and analytics.
Build data products that are used to drive business growth, operational effectiveness, customer success, and manage expenses, like prospect and sales, pricing, enrollment, onboarding, and claims data schemas.
Build data management solutions to feed real-time data back to customer portals and vendor data exchanges.
Conduct proof-of-concepts, ideate options, and embrace new technologies to support business goals and align with division strategies.
Working with the Data Governance team, contribute to data governance standards, profiling, and glossaries using a data catalog and working with business data stewards. Utilize and maintain metadata related to Workforce Benefits data domains.

The experience you will bring:
6+ years of experience using T-SQL, PL/SQL, or Hive to analyze and manipulate large volumes of data
6+ years of experience in analysis, design, development, and delivery of relational databases, data marts, data load processes and data wrangling in support of business analytics
5+ years using dbt to transform source data into operational data stores and data warehouse layers
5+ years working with a microservices event data infrastructure, including Kafka, Amazon Kinesis, or other event orchestration tools
5+ years of experience building data warehouses using Snowflake, Redshift or comparable tools
Strong ability to build relationships across the organization and communicate and manage stakeholders at all levels
Ability to work with ambiguity, and drive efforts forward without fully complete information. Strong execution focused mindset.
Bachelor’s degree in Computer Science, Mathematics, Analytics or related field. Master’s degree preferred.

What will make you stand out:
Knowledge of EIS administration system, including events and data structures
5+ years of experience designing and building data products in Group Benefits insurance data domains, including Sales, Actuarial, Operations, and Claims
Experience with cloud technologies such as AWS
Hands on experience using ETL/ELT tools like dbt or Matillion and analytics tools like Dataiku and Alteryx

You belong at Pacific Life
At Pacific Life we are committed to a culture of belonging, a space where all employees are empowered to be authentic. One way we cultivate an inclusive culture is through our employee connection groups. The purpose of these employee-led groups is to offer a place to build community, connection, camaraderie, and a sense of belonging. Each group can be active in education, advocacy, recruitment, and community building throughout our organization. Learn more about our employee connection groups at www.pacificlife.com.

Want to learn more about life at Pacific Life? Take an inside look at our company culture: Instagram.com/lifeatpacificlife.

Base Pay Range:
The base pay range noted provides a basis to determine the appropriate offer dependent upon several factors including but not limited to geographic location, experience, skills, education and pay equity. Also, most employees are eligible for additional incentive pay.
$127,890.00 - $156,310.00

Your Benefits Start Day 1

Your wellbeing is important to Pacific Life, and we’re committed to providing you with flexible benefits that you can tailor to meet your needs. Whether you are focusing on your physical, financial, emotional, or social wellbeing, we’ve got you covered.

Prioritization of your health and well-being including Medical, Dental, Vision, and Wellbeing Reimbursement Account that can be used on yourself or your eligible dependents

Generous paid time off options including: Paid Time Off, Holiday Schedules, and Financial Planning Time Off

Paid Parental Leave as well as an Adoption Assistance Program

Competitive 401k savings plan with company match and an additional contribution regardless of participation

EEO Statement:
Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.",1868,Insurance Carriers,$5 to $10 billion (USD),Insurance,1001 to 5000 Employees,Subsidiary or Business Segment,False
Senior Data Engineer,"KARL STORZ Endoscopy - America
","El Segundo, CA",$95K - $152K (Employer est.),3.4,"I. Job Purpose

The Sr. Data Engineer is responsible for the design, full life cycle development, and implementation of BW and HANA models, reporting and analytical solutions, and support the integration of Data Warehouse and HANA database with other applications. Candidates must have strong HANA and BW development and modeling skills to be part of our agile development team.

II. Job Duties



Work closely with business and SAP Analysts to analyze complex business scenarios & impacted business processes.
Work closely with development teams to provide guidance on functional design and translate requirements into technical specifications for implementation within the SAP BI environment.
To apply analytic skills for developing BI models in different BI tools of BW, HANA, frontend SAC, Business Objects, Analysis office, Query Designer and Tableau.
Must describe Data Provisioning concepts, HANA migration processes, and BW development in HANA Studio via the BW Modelling Tools.
Leverage analytics skills to understand and analyze SAP business processes, extracting meaningful data from SAP systems for reporting and analysis.
Design, develop, code, test, enhance and debug existing and new HANA and BW data sets/flows in compliance with the organization's architectural standards.
Extract, clean, and analyze data from various sources to ensure quality and accuracy.
Provide expert guidance on leverage SDI, SDA, and SLT for creating robust data models and efficient data extraction processes.
Utilize SAP standard and Generic extractors to extract data from SAP modules (e.g., FI, CO, MM, SD) and load it into data warehouses for reporting and analytics.
Design and develop efficient and scalable data models based on Layered Scalable Architecture (LSA++) approach, Implement Hybrid/Mixed models by combining the strengths of various data modeling approaches.
Execute testing activities related to SAP BI projects, including testing SAP BW data models, BEx queries, SAP BO reports, and other SAP BI components.
Collaborate with stakeholders to gather, analyze, and document business requirements for BI projects, ensuring a clear and comprehensive understanding of business needs and objectives.
Implement end-to-end business intelligence solutions, ensuring alignment with data warehousing concepts and principles.



III. Minimum Knowledge, Education and Skill Requirements

Required:

Minimum years of relevant work experience:
Minimum of 5+ years of hands-on experience in business analysis, proficient in requirements definition, and adept at constructing SAP BW and HANA system solutions.



Minimum education, certifications and/or credentials:
Minimum of bachelor's degree in computer science, Computer Information Systems, or relevant field



Minimum hard skill requirements (including computer and application proficiency):

Advanced knowledge and experience in SAP BW (Business Warehouse) architecture, data modeling, extraction, transformation, loading (ETL) processes, and administration.
In-depth understanding and proficiency in SAP HANA database architecture, data provisioning, and modeling.
Proficiency in integrating data from various sources into SAP BW and SAP HANA, utilizing technologies like SAP Data Services, SLT (SAP Landscape Transformation), and Smart Data Integration (SDI).
Proficiency in SQL scripting and optimization within SAP HANA for efficient data retrieval, manipulation, and reporting.



Minimum soft skill requirements:

Effective collaboration and engagement with business & technical stakeholders are vital for project success.
Excellent verbal & written communication skills. Demonstrable ability to work on large cross-functional teams.



Preferred

Preferred years of relevant work experience:

Knowledge and understanding of Enterprise applications like SAP ECC and SAP CRM etc.
Knowledge and functional understanding of SAP SD module
Knowledge and functional understanding of Finance and COPA module
Understanding of relational database concepts required
Working knowledge on ABAP concepts required for BW user exits



Preferred education, certifications and/or credentials:
Certification in SAP BI and HANA.



Preferred hard skill requirements:
Experience in utilizing version control systems and managing deployment strategies for SAP BW and HANA artifacts to maintain code integrity and collaboration within development teams.



Preferred soft skill requirements:

IV. Essential Function

Must be able to maintain productive working relationships and treat fellow employees with respect.
Must be a self-motivated, energetic, detail-oriented team player passionate about producing high quality BI & Analytics deliverables.
Ability to work independently with very little supervision and as a member of a team.
Must be able to travel domestically and internationally (as needed)
Mental requirements/ Emotional Demands:
Must be able to drive safely for frequent business travel.
Emotional Intelligence
Interpersonal and communication skills: Excellent verbal & written communication skills. Demonstrable ability to work on large cross-functional teams.



V. Core Requirements



Degree of accountability: High
Degree of decision making: Low
Financial/Budgetary: Low
Safety: Medium
Quality: High
Travel: Must be able to travel with in USA (10 - 15% of travel is expected)



Your Benefits

Medical / Dental / Vision including a state-of-the-art wellness program and pet insurance, too!*
3 weeks vacation, 11 holidays plus paid sick time*
Up to 8 weeks of 100% paid company parental leave**
401(k) retirement savings plan providing a match of 60% of the employee's first 6% contribution (up to IRS limits)
Section 125 Flexible Spending Accounts
Life, STD, LTD & LTC Insurance
We prepay your tuition up to $5,250 per year! - Tuition pre-imbursement
Fitness reimbursement of up to $200 annually
Employee referral program of up to $2,000 per hire
And much more!


Field sales, internships, and part-time employees are not eligible except where required by state law.
Non-employees, including temporary workers and consultants, are not eligible to participate in the KARL STORZ benefits program.
**To include, maternal/paternal leave, adoption, and fostering of a child.

KARL STORZ reserves the right to change or modify the employee's job description whether orally or in writing, at any time during the employment relationship. Additionally, KARL STORZ, through its supervisors, may require an employee to perform duties outside their normal description within the sole discretion of the supervisor. Employees must comply will all applicable KARL STORZ policies and procedures.

Credentialing requirements at KARL STORZ

KARL STORZ is committed to maintaining a safe work environment for our employees and customers. Most field-based roles at KARL STORZ require hospital credentialing/health screens as a condition of employment. Credentialing can include required vaccinations, health screens & other requirements as outlined by our customers. During the interview process, we encourage you to ask how credentialing/health screens may impact the role you are seeking and if you require any reasonable accommodations regarding these requirements.

Pay Transparency

The pay range and/or hourly pay rate listed is a good faith determination of potential base compensation that may be offered to a successful applicant for this position at the time of this job posting and may be modified in the future. When determining a specific team member's base salary and/or hourly pay rate, several factors will be considered including such things as location, specialty, service line, years of relevant experience, education, professional credentials, internal equity, and the amount budgeted for the role.

Equal Employment Opportunity & Reasonable Accommodation Statement

KARL STORZ is committed to creating an inclusive space where employees are valued for their skills and unique experiences. To achieve this goal, we are committed to diverse voices, and all applicants will receive consideration without regard to race, color, sex, national origin, disability, veteran status, or any other protected characteristic. KARL STORZ is also committed to providing reasonable accommodations during our recruitment process. Should you need assistance or accommodation please email us at taoperations@karlstorz.com.

Get in Contact

Name:

Contact Details:",1945,Health Care Products Manufacturing,Unknown / Non-Applicable,Manufacturing,1001 to 5000 Employees,Company - Private,False
Principal/Sr. Engineer Systems Test (Data Acquisition Engineer),"Northrop Grumman
","Palmdale, CA",$95K - $142K (Employer est.),4.0,"Requisition ID: R10127943
Category: Engineering
Location: Palmdale, California, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.

This role may be selected at the higher grade based on requirements listed below.

Northrop Grumman Aeronautics Systems has an opening for a Principal or Senior Principal Electronics Engineer (Data Acquisition) to join our team of qualified, diverse individuals within our Test and Evaluation organization. This role is located in Palmdale.

The primary job responsibilities are, but not limited, to the following:

Responsible for turning engineer requirement into data acquisition.
Provide mission load files to Curtiss Wright KSM-500, Omega Next, System 550, MCS, and IADS.
Develop software application for instrumentation.
Performs a variety of duties, including development, testing, and procedure writing.

This role may be selected at the higher grade based on requirements listed below.

Essential Functions

Responsible for turning engineer requirement into data acquisition.
Provide mission load files to Curtiss Wright KSM-500, Omega Next, System 550, MCS, and IADS.
Develop software application for instrumentation.
Performs a variety of duties, including development, testing, and procedure writing.

Basic Qualifications for a Principal level 3:

BS in STEM (Science, Technology, Engineering or Mathematics) and 5 years equivalent experience In Instrumentation / Data Acquisition career field or 3 years with a Master's degree and 0 years with a Ph D.
DOD Secret clearance is required to be considered
Ability to obtain Special Program Access prior to start
Familiar with ACRA Airborne Data Acquisition System KSM-500 series or industry equivalent.
Experience with ground telemetry frontends and IADS
IT working experience, candidate must have solid understanding of client and server applications
Experience with software development and maintenance
Overtime, odd shifts, and weekend work will occasionally be required

Basic Qualifications for a Sr. Principal level 4:

BS in STEM (Science, Technology, Engineering or Mathematics) and 9 years equivalent experience In Instrumentation / Data Acquisition career field or 7 years with a Master's degree and 4 years with a Ph D
DOD Secret clearance is required to be considered
Ability to obtain Special Program Access prior to start
Familiar with ACRA Airborne Data Acquisition System KSM-500 series or industry equivalent.
Experience with ground telemetry frontends and IADS
IT working experience, candidate must have solid understanding of client and server applications
Experience with software development and maintenance
Overtime, odd shifts, and weekend work will occasionally be required

Preferred Qualifications:

Active DOD Top Secret
Experience working with IRIG-106 standard, particularly chapters 4, 7, and 10
Experience working with SQL, XML, and C#, and is willing to adapt to special software projects
Active Security+ certification
9+ years of data acquisition experience working with over-the-air RF telemetry transmission and onboard recording systems
9+ experience working with ground station mission control room and test ranges
9+ years of experience working with various ICDs written for various digital bus mediums such as Ethernet, Mil-Std-1553, Arinc-429, Serial, 1394, etc
Ideal candidate must have an ability to digest different data formats and apply best filtering criteria for capturing data
5+ years of experience working with RT Station IENA data format
Experience in supporting test activities, anomaly resolution and process improvement initiatives
Familiar with the engineering development cycle, along with engineering configuration management concepts


The selected candidate will work in a dynamic people-focused environment while interacting with customers and other design engineers.
The position will be based out of Palmdale, CA.

Salary Range: $95,000 - $142,400
Salary Range 2: $117,700 - $176,500
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.

Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",1939,Aerospace & Defense,$10+ billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
Senior Data Engineer (Snowflake) - Contractor,"EY
",United States,$90.00 - $130.00 Per Hour (Employer est.),3.9,"The primary responsibility for the Sr. Data Engineer / Tech Lead is to ensure data accessibility, quality, and reliability within the client's data platform ecosystem.

RESPONSIBILITIES

Design and develop end-to-end data pipelines and ETL processes using Snowflake, Denodo, DBT Cloud, Fivetran, and AWS Glue, ensuring seamless data integration, transformation, and loading.
Collaborate with cross-functional teams to gather data requirements and implement scalable data models and schemas within Snowflake and Denodo, ensuring optimal performance and data consistency.
Implement and maintain data orchestration workflows using Stonebranch, ensuring efficient and reliable scheduling and automation of data processes.
Work with EnterpriseDataLake for ingestion and storage of data from various sources, ensuring the availability and accessibility of data for analytics and reporting purposes.
Utilize Azure DevOps and Teraform to implement and manage infrastructure as code, ensuring streamlined deployment and scalability of data engineering solutions.
Skills

snowflake

denodo

dbt cloud

fivetran

Qualifications

REQUIREMENTS

Proficiency in Snowflake and Denodo: Strong understanding and hands-on experience in working with Snowflake and Denodo for data integration, transformation, and analysis.
Knowledge of DBT Cloud: Familiarity with DBT Cloud, including experience in building and maintaining efficient data transformation workflows and deploying reliable data pipelines.
Experience with Fivetran: Demonstrated experience in utilizing Fivetran for data ingestion, source connectivity, and ensuring data accuracy and completeness.
Understanding of EnterpriseDataLake: Knowledge of EnterpriseDataLake principles and practices, including data ingestion, storage, and organization for analytics and reporting purposes.
Familiarity with Stonebranch: Proficiency in using Stonebranch for data orchestration and scheduling, ensuring efficient and reliable execution of data pipelines and workflows.
Proficiency in Azure DevOps and Teraform: Experience in leveraging Azure DevOps and Teraform for infrastructure as code, enabling streamlined deployment and scalability of data engineering solutions.

The expected pay rate range for this contract assignment is $90 to $130 per hour. The exact pay rate will vary based on skills, experience, and location. The position is approximately 65-70% remote and 30-35% travel to the client as needed.

#GigNowTechOpportunities

GigNowOpportunities

Equal Employment Opportunity Information
EY provides equal opportunities to applicants, employees, contractors, vendors, and stakeholders without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. If you are an individual with a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please email gignow.recruiting@ey.com.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,False
Data Engineer,Intellipro Group,"Sunnyvale, CA",$40.00 - $60.00 Per Hour (Employer est.),-1.0,"DATA ENGINEER

Contract: 6 months with potential extension

Location: Sunnyvale, CA; hybrid 4 days in office

Responsibilities:

Collaborate with project teams to understand business requirements, data sources, and integration needs.
Design and develop ETL solutions that meet business requirements, ensuring data accuracy, completeness, and timeliness.
Develop and maintain ETL processes using tools such as Hadoop, Hive, or similar ETL platforms/framework.
Create and maintain technical documentation for ETL solutions, including data mapping, data lineage, and data validation.
Optimize ETL performance by identifying and addressing bottlenecks and tuning ETL processes.
Perform data profiling and data quality analysis to ensure the accuracy and integrity of data.
Work with database administrators and other IT teams to troubleshoot issues and resolve problems related to ETL processes.

Requirements:

Bachelor's degree in computer science, engineering, or a related field.
1+ years of experience in ETL development using Hadoop, Hive, or a similar ETL platform.
Strong SQL skills, including proficiency in writing complex SQL queries.
Experience with data modeling, data warehousing, and data integration.
Ability to work independently and in a team environment.
Excellent communication skills and ability to work with cross-functional teams.

Job Type: Contract

Salary: $40.00 - $60.00 per hour

Experience level:

2 years

Schedule:

8 hour shift

Ability to commute/relocate:

Sunnyvale, CA: Reliably commute or planning to relocate before starting work (Required)

Experience:

SQL: 1 year (Required)
ETL: 1 year (Required)

Work Location: In person",-1,-1,Unknown / Non-Applicable,-1,Unknown,Company - Public,True
Junior Data Engineer,"University of California, Riverside
","Riverside, CA",$59K - $103K (Employer est.),4.2,"Position Information
The Junior Data Engineer position is part of the Information Technology Solutions (ITS) Data and Analytics Team. Tasked with imperative responsibilities, this role encompasses meticulous data management processes, which include the establishment and sustainment of intricate data systems. Collaborating closely with senior data engineers and other integral members of the ITS team, the incumbent is responsible for designing and orchestrating data pipelines. These critical pipelines systematically extract information from comprehensive systems, such as the Student Information System, Financial System, and Human Resource System, and subsequently transform this data into structured, business-focused data models. These refined data structures are instrumental, serving as the underpinning for sophisticated reports and analytic frameworks that are essential for the university's strategic decision-making processes. In the course of executing their duties, the Junior Data Engineer must exhibit an unwavering commitment to continuous learning and adaptation. This involves a proactive approach to staying abreast of current information requirements, standards, and best practices, ensuring that the data systems they oversee remain cutting-edge and efficacious.

This position is classified as predominantly remote with occasional visits to campus as needed. Working hours will be based on Pacific Standard Time (PST).

The full salary range for the Junior Database Engineer is $28.26 - $49.52 per hour. However, the expected pay scale for this position is UP TO $42.78 per hour. UCR bases salary offers on a variety of considerations, such as education, licensure and certifications, experience, and other business and organizational needs.”

Applicants must have current work authorization when accepting a UCR staff position. Currently, UCR is unable to sponsor or take over sponsorship of an employment Visa for staff.

As a university employee, you will be required to comply with all applicable University policies and/or collective bargaining agreements, as may be amended from time to time. Federal, state, or local government directives may impose additional requirements.
Education
Education Requirements
Degree
Requirement


Bachelor's degree in related area and/or equivalent experience/training.
Required





Experience
Experience
Requirement


0 - 1 years of related experience.
Required





Special Conditions
Special Condition
Requirement


Must pass a background check.
Required


Occasional travel for university related business meetings, conferences and/or professional development.
Required


Travel Outside of Normal Business Hours
Required





Minimum Requirements
Demonstrated effective communication and interpersonal skills.
Strong organizational skills.
Demonstrated ability to work with others from diverse backgrounds.
Self-motivated and works independently and as part of a team.
Demonstrated ability to communicate technical information to technical and non-technical personnel at various levels in the organization.
Understanding of data management operations and database administration, including data modeling, data definition, data conversion and management of content or unstructured information.
Strong analytical and design skills, including the ability to abstract information requirements from real-world processes to understand information flows in computer systems.
Demonstrated problem-solving skills. Able to learn effectively and meet deadlines.
Demonstrated service orientation skills.
Knowledge of relevant rules and regulations.
Ability to represent relevant information in abstract models. Critical thinking skills and attention to detail.
Familiarity with programming languages such as Python and SQL, essential for developing and managing data processes.
Understanding of automation techniques and an ability to work in a command line environment.

Preferred Qualifications
Familiarity with cloud computing platforms like Amazon AWS, Google Cloud, or Microsoft Azure to leverage scalable resources for data processing and storage.

Exposure to big data frameworks like Hadoop or Spark, enabling the handling and analysis of large datasets.

A commitment to keeping up with emerging data engineering trends, tools, and best practices.

An understanding of data governance principles, including ensuring the accuracy, consistency, and security of stored data.

Ability to effectively collaborate with other departments and stakeholders to gather requirements, understand data sources, and deliver on data-driven projects.

Additional Information
In the Heart of Inland Southern California, UC Riverside is located on nearly 1,200 acres near Box Springs Mountain in Southern California; the park-like campus provides convenient access to the vibrant and growing Inland region. The campus is a living laboratory for the exploration of issues critical to growing communities' air, water, energy, transportation, politics, the arts, history, and culture. UCR gives every student, faculty and staff member the resources to explore, engage, imagine and excel.

UC Riverside is recognized as one of the most ethnically diverse research universities in the country boasting several key rankings of which we are extremely proud.


UC Riverside is proud to be ranked No. 12 among all U.S. universities, according to Money Magazine's 2020 rankings, and among the top 1 percent of universities worldwide, according to the 2019-20 Center for World University rankings.


UC Riverside is the top university in the United States for social mobility. - U.S. News 2020


UCR is a member of the University Innovation Alliance, the leading national coalition of public research universities committed to improving student success for low-income, first-generation, and students of color.


Among top-tier universities, UC Riverside ranks No. 2 in financial aid. - Business Insider 2019


Ranked No. 2 in the world for research, UCR's Department of Entomology maintains one of the largest collections of insect specimens the nation. - Center for World University Rankings


UCR's distinguished faculty boasts 2 Nobel Laureates, and 13 members of the National Academies of Science and Medicine.






The University of California is an Equal Opportunity/Affirmative Action Employer with a strong institutional commitment to the achievement of excellence and diversity among its faculty and staff. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or any other characteristic protected by law.",-1,Colleges & Universities,$100 to $500 million (USD),Education,1001 to 5000 Employees,College / University,False
Junior Data Engineer,"Los Angeles Dodgers LLC
","Los Angeles, CA",$34.00 - $37.00 Per Hour (Employer est.),3.9,"Title: Junior Data Engineer

Department: Baseball Operations – Baseball Systems

Status: Full-Time

Pay Rate: $34.00-$37.00/hour*

Reports to: Director, Baseball Systems Platform

Compensation rates vary based on job-related factors, including experience, job skills, education, and training.

The Los Angeles Dodgers Baseball Systems team is committed to building and maintaining the technological platforms for baseball data, analysis, and decision-making for the Dodgers, and to providing technical expertise and advice across Dodger Baseball Operations. We focus on both the tools needed to put a winning team on the field today and those we need to ensure a winning future. The data engineering group within Baseball Systems operates the data platform used throughout Baseball Operations. We design, implement, and maintain the processes that bring in game, tracking, and scouting data, make them available to the rest of the Dodgers, and in turn re-ingest output from analytics to make that available as well.

The Junior Data Engineer will join the data engineering group within Baseball Systems to support our data operations. You will be responsible for implementing new ETL services and working with combining baseball data sources to create a cohesive view of games and plays. You will support the health of our data platform across relational databases, non-relational stores, and cloud file storage. You will collaborate with the rest of Baseball Operations to make sure that the data we provide them is complete, accurate, and meets their needs.

We work together to build and maintain a winning, industry-leading team. If you are also enthusiastic about baseball and want to see your work reflected on the field and in the box score, please contact us!

Essential Duties/Responsibilities:

Implement and document Dodgers R&D database schema and ETL layer
Design, implement, and test data collection, storage, and mapping procedures
Maintain computational environments to support analytical modeling (statistics, machine learning, and optimization)
Apply statistical models for data quality testing and missing data imputation
Write, optimize, and automate data processing tasks
Deploy and maintain system and database monitoring tools
Perform other related duties as assigned

Basic Requirements/Qualifications:

S. or M.S. in Computer Science, Computer Engineering, or a related field
SQL development skills and an understanding of database technologies (PostgreSQL preferred)
Experience with Python, Bash, and other scripting languages
Experience using Linux servers in a virtualized environment
Familiarity with cloud-based and distributed computing concepts (AWS and Kubernetes preferred)
Excellent analytical and problem-solving skills

Current Los Angeles Dodgers employees should apply via the internal job board in UltiPro by following these prompts:

MENU > MYSELF > MY COMPANY > VIEW OPPORTUNITIES > select the position > CONSENT > APPLY NOW

LOS ANGELES DODGERS LLC is firmly committed to providing equal opportunity for all qualified applicants from every race, creed, and background. The Organization is also firmly committed to complying with all applicable laws and governmental regulations at the state and local levels which prohibit discrimination.

LOS ANGELES DODGERS LLC considers all applicants without regard to national origin, race, color, religion, age, sex, sexual orientation, disability, military status, citizenship status, pregnancy or related medical conditions, marital status, ancestry-ethnicity, or any other characteristic protected by applicable state or federal civil rights law. The Immigration Reform and Control Act require that the Organization obtain documentation from every individual who is employed which verifies identity and authorizes their right to work in the United States.",2004,Sports & Recreation,$100 to $500 million (USD),"Arts, Entertainment & Recreation",201 to 500 Employees,Company - Private,True
Data Engineer,"Heineken
","Petaluma, CA",$91K - $145K (Glassdoor est.),4.2,"There’s Always a Seat at Our Bar

The Lagunitas Brewing Company began on a kitchen stove in Northern California in 1993 and has always looked to the future – whether supporting local communities by turning beer into money for the cause, or fueling stories, songs, and experiences with our IPA. Wherever you go: Beer Speaks, People Mumble.




What You’ll Get

Benefits – Awesome coverage for: Medical, Dental & Vision
Time off - Approx 33 days off in your first year (combo of vacay, holidays and personal days)
Retirement – up to 5% contribution on 401K plan
BEER – and non-alcoholic Lagunitas beverages
Schwag – 50% off food and merch
Gym Membership – $50 monthly reimbursement for that beer belly (or at least to prevent it)
Pet Insurance – keep your fur babies covered with pet insurance options
Skills to Pay the Bills – professional development, 24/7 operation
Opportunities – Expand your horizons in CA, Chicago . . . the world!
It’s Friday, Ya’ll – Get Paid every other Friday, starting at: $95,894-$107,881



The Gist

The mission of the Data & Analytics team is to lead Lagunitas into becoming a data-driven company and the best-connected brewer. As a team, we cultivate a data-driven entrepreneurial culture to the rest of the organization. We act as an incubator for smart data products and problem-solving business intelligence in all areas of business – from sales to logistics, and from marketing to finance. The Data & Analytics team is a multi-disciplined team that works pro-actively and solution-oriented to not only resolve issues, but more importantly to identify business opportunities.




Our team consists of Data Engineers, PowerBI developers and an Architect. As Data Engineer, you will have the following key responsibilities:




What You’ll Do

About the Role:

Team coordination: Coordinate a team of (external) data engineers and PowerBI developers, fostering a collaborative and high-performance culture.
The D&A team is a multi-disciplined team, which means that you support the team where needed in every aspect of the team responsibilities.
Work in an agile team with full responsibility to develop, maintain and support data products and applications in production environment.
Deliver against Lagunitas data & analytics roadmap in alignment with Lagunitas strategic business plan.
Keep up to date with Heineken, industry, and competitor trends.
Support with data quality, data audit and data security activities that include routine reviews and reporting of technology policies and security compliance while sharing with data stewards to ensure implementation in the business functions.
Provide input for architectural design and best practices for the implementation and data integration and data presentation layers throughout business units and across the organization.
Actively support the business solutions managers in partnering with key / leadership-level stakeholders in identifying business opportunities with data.



Data Engineering:

Design, implement and manage data solutions on the Microsoft Azure cloud platform. You will own the creation and maintenance of the data warehouse, data pipelines, data processing, and data integration to enable data-driven decision-making.
Create, adjust, and propose SQL queries for new or changed reporting needs.
Evaluate and optimize data models to meet performance and scalability requirements.
Perform data modeling sessions with subject-matter experts from regional and global hubs.
Coordinate functional and technical discussions and communicate effectively with a variety of audiences, moving between providing functional/technical design details and sharing how an information and data design would enhance business capabilities, stability, and supportability.
Analyze, transform, and organize large and complex datasets ingested from different data sources.
Maintain a secure data platform in collaboration with infrastructure and (regional or global) security teams.
Responsible for upholding a high standard of documentation.



Business Intelligence

Make a difference by helping the business towards a state-of-the-art self-service BI data products to overcome their business challenges.
Own and embed the standardized Lagunitas reporting lay-out throughout the community of functional data owners.
Optimize data delivery processes and improve data quality in developed data products.
Design and build user-friendly repository to boost organized self-service BI.
Develop Power BI reports, Custom Visuals, group creation, and effective dashboards after gathering and translating end-user requirements.
Implement role-based security as part of security in Power BI.



What We’re Lookin’ For

Basic Qualifications/Requirements:

Bachelor / Master degree in computer science, engineering or relevant field.
3-5 years leading data engineering and BI capability, with experience of coordinating a team of (external) developers.
Proven track record of developing and driving a company’s BI capability, including PowerBI.
Proven understanding of data management, data warehouse models, data ingestion and data pipelines.
Proven understanding of Microsoft Azure Cloud Platform (DataBricks, Data Factory, functions, Logic Apps, etc.)
Experience with agile way of working.
Deep understanding of descriptive & diagnostic analytics use cases within FMCG industry
Familiarity with data visualization, datasets and data flows in PowerBI.
Proficient in writing complex SQL.
Experience with Python development.
Strong project and time management skills.
Strong communication skills at all levels of the company.
Ability to work with stakeholders and team members located in different geographies.



Preferred Qualifications

Familiarity with SAP is also a plus.

Knowledge of basic components and functionalities of Azure ML workspace.
Knowledge of one or more functional areas such as Commercial Effectiveness, Sales or Supply Chain would be additional benefits.



Come as You Are

At Lagunitas, we welcome people (and dogs) from all walks of life. Anyone, regardless of their race, creed, nation of origin, sexual orientation, gender identity or expression, disability status, veteran status, marital status, or age, has a home here. Love, progress, and acceptance will always have a seat at our bar.",1864,Food & Beverage Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Private,False
DATA ENGINEER,"STAND 8
","Los Angeles, CA",$90K - $141K (Glassdoor est.),4.4,"STAND 8 provides end to end IT solutions to enterprise partners across the United States and with offices in Los Angeles, New York, New Jersey, Atlanta, and more including internationally in Mexico and India.

We are seeking a Data Engineer to work on various projects for a large school district client.

Qualifications and Duties
Set up R Studio Workbench, Connect, and Package Manager on a Linux server.
Manage libraries and versions.
Write required security plan.
Work with security to connect the server to Snowflake and other data sources.
Provision server access to data scientists, including R Studio Server, sftp, and command line.
Provide training and support to data scientists, including training on visualization packages like ggplot2, Quatro, and Shiny.
Guide data scientists on how to use version control with GIT/Azure Devops.
The US pay range for this contract position is $75 - 80 /year. Our pay ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training.",-1,-1,Less than $1 million (USD),-1,1 to 50 Employees,Company - Private,False
Data Engineer,"Itility US
","San Diego, CA",$100K - $150K (Employer est.),3.8,"Role: Data Engineer

Location: San Diego, CA


Who We Are

We believe in merging technology and data to drive our customers one step beyond. Itility digital consultants are experts in data, cloud, software, and IT infrastructure. Acting as the ‘digital twin’ of customers, we work shoulder-to-shoulder to exceed business goals and push the boundaries of what you thought was possible. We combine an agile way of working with proven methods and building blocks. This enables teams to act quickly and shape, deliver, and run innovative digital solutions. With a continuous focus on implementing your strategy and generating results.

About the Role

Are you adept at coding to capture data? Are you thrilled when you dig into various data sources and transform them into valuable, user-friendly information? Are your skills at the intersection of data and software? Is your day made when data flows flawlessly based on the carefully constructed code you've created? Then we have the perfect opportunity for you!

For numerous enterprise clients, we develop data connectors to streamline data flow from multiple sources to analytics platforms, such as Splunk, Databricks, Hadoop, or others. One thing these systems share is that the data will be utilized in a production environment, which means it must flow consistently and monitored for any interruptions. Ensuring data validity and quality is also crucial.


What you do:

Developing data connectors with Python or other programming languages.

Setting up data validation tests within the data pipeline.

Establishing monitoring and alert systems for data flow interruptions or corruption.

Leading incident resolution efforts to minimize impact on end users.

Teaming up to build, deploy, maintain, and optimize data ingestion and connectors for data flow to the data storage system.

Creating and managing distributed systems for data extraction, ingestion, and processing of large, diverse data sets.

Developing data products in stages, integrating and managing data from various sources.

Collaborating with software engineers and data scientists to design data sets for diverse applications, from proof-of-concept to production.

Partnering with Business Analysts for requirement collection, pipeline implementation decisions, data identification, and tooling selection.

Working with ETL/data services and application teams to support data solution development.

Collaborating with software engineers and data scientists to design data sets for diverse applications, from proof-of-concept to production.

Qualifications

Possess a bachelor’s or master’s degree.

Experience in creating data ingestion scripts.

Exhibit team spirit and good communication skills.

Good understanding of SQL and Python.

Experience with data platforms and data lakes in an enterprise setting is a plus.

Demonstrate a hands-on approach, strong customer focus, problem-solving skills, and quick results.

Prior experience with Linux is necessary.

Familiarity with continuous integration & delivery tools, e.g. Jira, Git, Jenkins, Bamboo.

3+ years’ experience with analytics platforms and tools, such as Databricks, Snowflake, Teradata, Spark, Kafka.

3+ years’ cloud experience and demonstrated proficiency working with AWS, GCP, and/or Azure Cloud DevOps Services is preferred.

Belief in scrum/agile work methodologies and software practices for professional data flow.


What we offer:

Salary range: $100k-$150k

Factors in determining the appropriate compensation for a role include experience, skills, knowledge, abilities, education, licensure and certifications, and other business and organizational needs. The Hiring Pay Scale referenced in the job posting is the budgeted salary or hourly range that Itility reasonably expects to pay for this position. The Annual Full Pay Range may be broader than what Itility anticipates paying for this position, based on internal equity, level and budget.

Additional Benefits:

100% employer paid medical, dental and vision insurance
401k with up to 4% employer match
Paid vacation and sick time
Paid company holidays
HAS Accounts
Flexible Spending Accounts
Life Insurance
Professional Training and Development Programs


This is a hybrid position, so it is a requirement that you are based within the San Diego Metro area.

eghfH9ZbWP",2006,Information Technology Support Services,$25 to $100 million (USD),Information Technology,201 to 500 Employees,Company - Private,True
ETL Developer/Data Engineer contractor,"Intellipro Group Inc
","San Francisco, CA",$35.00 Per Hour (Employer est.),3.9,"Responsibilities:

Collaborate with project teams to understand business requirements, data sources, and integration needs.
Design and develop ETL solutions that meet business requirements, ensuring data accuracy, completeness, and timeliness.
Develop and maintain ETL processes using tools such as Hadoop, Hive, or similar ETL platforms/frameworks.
Create and maintain technical documentation for ETL solutions, including data mapping, data lineage, and data validation.
Optimize ETL performance by identifying and addressing bottlenecks and tuning ETL processes.
Perform data profiling and data quality analysis to ensure the accuracy and integrity of data.
Work with database administrators and other IT teams to troubleshoot issues and resolve problems related to ETL processes.

Requirements:

Bachelor's degree in computer science, engineering, or a related field.
1+ years of experience in ETL development using Hadoop, Hive, or a similar ETL platform.
Strong SQL skills, including proficiency in writing complex SQL queries.
Experience with data modeling, data warehousing, and data integration.
Ability to work independently and in a team environment.
Excellent communication skills and ability to work with cross-functional teams.

Pay rate: Open to Discussion

Job Type: Contract

Pay: From $35.00 per hour

Benefits:

401(k)
Dental insurance
Health insurance

Experience level:

1 year

Work Location: In person",-1,-1,$5 to $25 million (USD),-1,201 to 500 Employees,Company - Private,True
QA Data Engineer G5377,"Nisum
","Pleasanton, CA",$115K - $120K (Employer est.),3.8,"Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto “Building Success Together®,” Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels.
What You'll Do
A QA Data Engineer ensures reliable, high-quality data is delivered to internal and external stakeholders and applications.
Data quality engineers will need to gather data quality requirements from relevant stakeholders.
Engage with product owners and development leads to create testing strategies
Document data quality issues, testing procedures, and resolutions for future reference and knowledge sharing.
What You Know
Should have a minimum of 7+ years of relevant professional experience.
Hands-on experience in engaging with product owners and development leads to create testing strategies
Strong experience in documenting data quality issues, testing procedures, and resolutions for future reference and knowledge sharing.
Experience with data processing concepts like mapping documents and complex data relationships.
Experience with requirement analysis, defect tracking, coordinating with team members in different locations, and test reporting and signoff.
Strong analytical and technical skills to address sophisticated issues.
Ability to perform root cause analysis on defects.
Design, monitor, and maintain QA reports, KPIs & quality trends for the internal data systems
Education
Bachelor’s degree in Computer Science, Information Systems, Engineering, Computer Applications, or a related field
Benefits
In addition to competitive salaries and benefits packages, Nisum US offers its employees some unique and fun extras:
Professional Development - We offer in-house technical training and professional learning programs aimed at developing skills across a broad spectrum of topics such as technology, leadership, role-based training, and process expertise. We also offer an annual stipend for employees to attend external courses in order to maintain professional certifications
Health & Wellness Benefits - We believe that your health and welfare are important, and we strive to ensure that you have affordable options available to you, including some plans that are subsidized for employees and their families up to 90%. We also have dental and vision plans in the US where Nisum pays 100% of premiums for employees
Volunteerism Pay - We believe in giving back and in the US, our employees are eligible for up to 40 hours of paid time off each year to volunteer towards the causes that they are most passionate about. This is in addition to personal PTO and paid holidays
Additional Benefits - We offer all the other important benefits to keep employees and their families healthy and financially secure, such as 401(k) retirement savings with a company match, pre-tax parking and transit programs, disability insurance, and Basic Life/AD&D, alongside exclusive employee discounts on a wide variety of products and services
Compensation Band
$115-120k per year
Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace.",2000,Information Technology Support Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,True
Data Engineer only W2,"IDC
","South San Francisco, CA",$65.00 Per Hour (Employer est.),4.3,"6 months Data Engineering Skillset : my-SQL (advanced), SQL (advanced), Python (advanced), build Dataswarm pipelines (advanced), Hive (advanced)

- Data requirements definition

- Design backend architecture and queries for Dashboards

- Can facilitate requirements and design sessions with client Front End Skills: Tableau( Nice to have) Additional must haves: Experience working with very large data volume and optimize code.

Functional skills: Finance business knowledge

Job Type: Contract

Salary: From $65.00 per hour

Schedule:

Monday to Friday

Ability to commute/relocate:

South San Francisco, CA 94080: Reliably commute or planning to relocate before starting work (Preferred)

Experience:

MySQL: 5 years (Preferred)
SQL: 4 years (Preferred)
Python: 4 years (Preferred)
Dataswarm: 4 years (Preferred)
Hive: 4 years (Preferred)

Work Location: In person",1972,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,True
Data Engineer (L5) - Playback (Device),"Netflix
","Los Gatos, CA",$136K - $220K (Glassdoor est.),4.2,"Los Gatos, California

Data Science and Engineering
At Netflix, our mission is to entertain the world. With 200+ million paid members in over 190 countries on millions of devices, enjoying TV series, documentaries, and feature films across a wide variety of genres and languages, Netflix is reinventing entertainment from end to end. We are revolutionizing how shows and movies are produced, pushing technological boundaries to efficiently deliver streaming video at a massive scale over the internet, and continuously improving the end-to-end user experience with Netflix across their member journey.

The Device pod within the Streaming Data Engineering team partners with multiple engineering teams, producing high-quality and large-scale datasets, a source of truth for how Netflix services operate on the vast landscape of devices that support Netflix. This team helps to create datasets used to certify and retire devices, categorize them, and identify changes in this constantly changing environment.

This role is focused on supporting Netflix’s core data assets, delivering high-quality business datasets and metrics, and building systems to process batch and real-time data at a large scale. Additionally, a candidate should have a rich understanding of large distributed systems, modern big data technologies, and software development techniques. Since data engineers are responsible for their pipelines at Netflix, this role requires engineers to take ownership of the operational excellence in their domain. In addition, the ideal candidate will have excellent data intuition and share our passion for continuously improving how we handle streaming data at Netflix.
Who are you?
You strive to write elegant code and are comfortable with independently picking up new technologies.
You have mastery over at least one major programming language (e.g., Java, Scala, Python) and are comfortable working with SQL.
You enjoy helping teams push the boundaries of analytical insights, creating new product features using data, and powering machine-learning models.
You have a strong background in at least one of the following: distributed data processing or software engineering of data services.
You are familiar with big data technologies like Spark and Flink and comfortable working with web-scale datasets.
You are passionate about the end-to-end software development lifecycle, focusing on automation, testing, CI/CD, and documentation.
At Netflix, you own your code, services, and pipelines. You have practical, solid DevOps and Operation fundamentals, and you enjoy total ownership of your domain.
You have a solid understanding of the device lifecycle. You have an eye for detail, good data intuition, and a passion for data quality.
You relate to and embody many of the aspects of the Netflix Culture.
You love working independently while also collaborating and giving/receiving candid feedback.
You are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risks.
What you will do:
Help Netflix support and evolve the device data model by improving data excellence and quality, supporting analytics, developing and maintaining metrics, and partnering with engineering to deliver the next generation of Netflix experiences.
Engineer efficient, adaptable, and scalable data pipelines to process structured and unstructured data
Partner with numerous engineering teams, analytics engineers, and data scientists to enhance playback-related datasets. Maintain and rethink existing pipelines to improve scalability and maintainability.
Here are a few more things to know:
Our culture is unique, and we live by our values, so it's worth learning more about Netflix at jobs.netflix.com/culture. We regularly share examples of our work on our tech blog. You will need to be comfortable working in the most agile of environments. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks.
At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location. The overall market range for this role is typically $150,000 - $750,000. This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.

We are an equal opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.",1997,Internet & Web Services,$5 to $10 billion (USD),Information Technology,5001 to 10000 Employees,Company - Public,False
"Snowflake Data Engineer--Cupertino, CA (onsite)",i2vision,"Cupertino, CA",$50.00 Per Hour (Employer est.),-1.0,"Position: Snowflake Data Engineer

Location: Cupertino, CA (onsite-Need Locals)

Duration: 12+ Months Contract

JD:

12+ years of experience in Data Engineering
Experienced in Snowflake Database
Good with Python programming and experience with Data pipeline creation
Good knowledge of Airflow
Experience with SQL

Job Type: Contract

Salary: $50.00 per hour

Expected hours: 40 per week

Experience level:

11+ years

Schedule:

Monday to Friday

Experience:

Snowflake: 8 years (Preferred)
Data Engineer: 9 years (Preferred)

Work Location: In person",2014,-1,$1 to $5 million (USD),-1,1 to 50 Employees,Company - Public,True
Data Engineer,"Orange County's Credit Union
","Santa Ana, CA",$79K - $125K (Glassdoor est.),4.0,"Great Opportunity At Orange County's Credit Union
Are you looking to join a dynamic, fast-paced team environment with a culture of collaboration and belonging? If so, let’s talk.

Orange County's Credit Union is now seeking a talented and driven individual to accelerate our efforts and be a major part of our team and culture.

Our team members are grounded in core values, have a strong capacity to learn, the energy to get things done, and bring real world experiences to help us think in new ways. Orange County's Credit Union actively invest in our team members to support their long-term growth so they can continue to advance our mission and achieve their highest potential.

Are you passionate about the future? Are you a data engineer who specializes in wrangling a wide range of data into versatile, accessible sources of knowledge? If yes, PLEASE APPLY IMMEDATELY!

More about Orange County's Credit Union:

Workplace Excellence. Through our associates' opinions and voices, Orange County's Credit Union is proud to be recognized year over year as one of the best places to work in Orange County and is a recipient of the Peter Barron Stark Best of the Best Award for highest associate satisfaction in the workplace.

As a leading financial service provider with over 80 years of experience serving 117,000+ members, Orange County's Credit Union is currently over $2 billion in assets & growing. Generous benefits include paid health insurance, time-off benefits, 401(k), and a professional, friendly work environment (with remote and hybrid options) focused on achieving goals, recognizing successes and excelling at member service.

Putting People First: Connect, Discover, Deliver & Wow is Orange County’s Credit Union mantra. If you’re passionate about serving people, this role is rewarding, brings purpose, and the opportunity to make a difference!

Overview:

Are you our next Data Engineer? With your strong understanding of financial services operations (e.g., banking, asset management, insurance, mortgage, consumer & business lending) you will be part of an innovative team that will architect, design and implement data analytics solutions to further advance the organization’s strategic goals. In collaboration with Business and IT partners, you will support our efforts in re-engineering, optimizing and advancing the organization’s data platform with modern cloud-based analytics technologies that will address near-term and future business needs. Be part of our vision to advance data-driven insights and decision making for our mission driven organization.

Essential Functions:

Collaborate with delivery team and engage with organizational stakeholders (Business and IT) to design, develop and deliver end-to-end enterprise data analytics solutions to enable data-driven insights and decision making.
Translate business requirements to technical solutions by applying technical knowledge and strong business acumen.
Solve business problems and complex data requirements/challenges by incorporating standards and best practices into engineering solutions, and leveraging modern data science programming languages (e.g., SQL, Python, R, Scala, SAS) and Azure data and analytics services.
Develop and implement database designs (logical and physical) and data models (normalized and dimensional) to support the new analytics platform.
Design, implement and maintain data ingestion/integration and end-to-end data pipeline processes using Azure technologies for a wide variety of traditional and non-traditional data sources/formats (structured, unstructured, and semi-structured) through various protocols (e.g., REST, SOAP, SFTP, MQ, etc).

Technical Must Haves for this Role:

5+ years of experience in Information Technology within a medium to large enterprise with complex business and IT environment.
3+ years of experience as a Data Engineer working with cross-functional teams (within IT and/or Business) on enterprise level business intelligence/data analytics implementations using Azure cloud-based analytics platforms/technologies (including hands-on experience with Microsoft/Azure stack, e.g., Synapse, Data Factory, Data Bricks, Data Lake, Data Catalog, SSIS, SQL, etc., and NoSQL databases).
3+ years of hands-on experience in designing, implementing and maintaining data ingestion /integration and end-to-end data pipeline using Azure technologies for a wide variety of traditional and non-traditional data sources/formats (structured, unstructured, and semi-structured) through various protocols (e.g., REST, SOAP, SFTP, MQ, etc.).
2+ years of experience working with and developing database designs (logical and physical) and data models (normalized and dimensional) for data warehouse, data marts and operational data stores.
2+ years of hands-on experience working with data science programming languages (e.g., SQL, Python, R, Scala, SAS).
Experience working in an agile delivery environment with working knowledge of continuous integration/continuous delivery (CI/CD) and DevOps practices.


The targeted hourly range is $36.55 - $54.83. Final offer will be determined based on experience, education, training/certifications and specialized skills.


We perform thorough background checks and credit checks. EOE.",1938,Banking & Lending,$25 to $100 million (USD),Financial Services,201 to 500 Employees,Nonprofit Organization,True
Senior Data Engineer,Data Capital inc,"Sunnyvale, CA",$55.00 Per Hour (Employer est.),-1.0,"looking for a highly energetic and collaborative Senior Data Engineer(10+ yrs) for a 12-month engagement. Responsibilities: As a Senior Data Engineer, you will • Design and develop big data applications using the latest open source technologies. • Desired working in offshore model and Managed outcome • Develop logical and physical data models for big data platforms. • Automate workflows using Apache Airflow. • Create data pipelines using Apache Hive, Apache Spark, Scala, Apache Kafka. • Provide ongoing maintenance and enhancements to existing systems and participate in rotational on-call support. • Learn our business domain and technology infrastructure quickly and share your knowledge freely and actively with others in the team. • Mentor junior engineers on the team • Lead daily standups and design reviews • Groom and prioritize backlog using JIRA • Act as the point of contact for your assigned business domain Requirements: • 8+ years of hands-on experience with developing data warehouse solutions and data products. • 4+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive,Scala, Airflow or a workflow orchestration solution are required . 4 + years of experience in GCP,GCS Data proc, BIG Query • 2+ years of hands-on experience in modeling(Erwin) and designing schema for data lakes or for RDBMS platforms. • Experience with programming languages: Python, Java, Scala, etc. • Experience with scripting languages: Perl, Shell, etc. • Practice working with, processing, and managing large data sets (multi TB/PB scale). • Exposure to test driven development and automated testing frameworks. • Background in Scrum/Agile development methodologies. • Capable of delivering on multiple competing priorities with little supervision. • Excellent verbal and written communication skills. • Bachelor's Degree in computer science or equivalent experience. The most successful candidates will also have experience in the following: • Gitflow • Atlassian products - BitBucket, JIRA, Confluence etc. • Continuous Integration tools such as Bamboo, Jenkins, or TFS Location: This position will be based in sunnyvale ca

Job Type: Full-time

Salary: From $55.00 per hour

Experience level:

10 years
11+ years

Experience:

Google Cloud Platform: 4 years (Preferred)
SQL: 8 years (Preferred)
Data warehouse: 8 years (Preferred)

Work Location: On the road",-1,-1,-1,-1,-1,-1,True
CAMPUS: Data Engineer (2024),"Capital Group Companies
","Irvine, CA",$82K - $132K (Employer est.),4.1,"Data Engineer:
“I can succeed as an EDGE Early Career Associate at Capital Group.”
As an IT Early Career Associate, you’ll be placed in a selected team and your manager will assign you to work on different technology, systems and projects as needed. As a Data Engineer Associate, you’ll be part of an engaging cohort experience that focuses on learning and development along with making connections through social events and networking during your first year at Capital Group. You’ll learn directly from our leaders through a speaker series, take on interesting business problems in sprint challenges and engage in activities to strengthen your technical skills and business acumen. You will be well supported and will learn how information technology elevates our ability to provide the best technology platforms for our internal customers and how the Capital System has sustained superior results over time.
You will build cloud-based solutions for enterprise data pipelines on AWS and/or Azure using the latest technologies, including but not limited to Cloudera/Hadoop, Databricks, Synapse, Hive, and Spark.
You will build skills in collaboration, requirements gathering, testing, managing ambiguity in a fast-paced environment, and influencing outcomes.
You will lead end-to-end delivery of select features in our data platforms.
“I am the person Capital Group is looking for.”
You are currently pursuing a bachelor’s degree with a major or minor in Computer Science, Engineering, Math, Statistics, cognitive science or equivalent with an anticipated graduation date of Spring 2024.
You have a cumulative GPA of 3.0 or above.
You have practical experience with one or more of these technologies: SQL, Python, Alteryx, and/or reporting/visualization tools such as Tableau, PowerBI
You have a passion for data and its possibilities, along with a propensity for analysis and logical/critical thinking
You have basic understanding of SDLC and agile methodologies
You express ideas effectively and interact professionally with others
You are not intimidated by the new and unfamiliar and embrace a continuous learning mindset
You are solution driven, accountable for results, and comfortable socializing your thought process
You are highly collaborative and willing to share your point of view

#LI-DNI
‎
‎
‎
‎
‎
‎
Orange County Base Salary Range: $82,308-$131,693
‎
‎
‎
‎
‎
‎
‎
‎
In addition to a highly competitive base salary, per plan guidelines, restrictions and vesting requirements, you also will be eligible for an individual annual performance bonus, plus Capital’s annual profitability bonus plus a retirement plan where Capital contributes 15% of your eligible earnings.
You can learn more about our compensation and benefits
here
.

We are an equal opportunity employer, which means we comply with all federal, state and local laws that prohibit discrimination when making all decisions about employment. As equal opportunity employers, our policies prohibit unlawful discrimination on the basis of race, religion, color, national origin, ancestry, sex (including gender and gender identity), pregnancy, childbirth and related medical conditions, age, physical or mental disability, medical condition, genetic information, marital status, sexual orientation, citizenship status, AIDS/HIV status, political activities or affiliations, military or veteran status, status as a victim of domestic violence, assault or stalking or any other characteristic protected by federal, state or local law.",1931,Investment & Asset Management,$1 to $5 billion (USD),Financial Services,5001 to 10000 Employees,Company - Private,False
AI/ML Engineer-Data Scientist,Noralogic Inc,"Woodland Hills, CA",$50.00 - $70.00 Per Hour (Employer est.),-1.0,"1. Experience in LLM and Generative AI

2. Experience in Document extraction/chat

3. Strong experience in Python, NLP

4. Experience working in a cloud-native environment such as AWS

5. Should have hands on experience with AWS Neptune or Neo4J graph database

6. Experience in building and maintaining open-domain or health care domain-specific ontologies

7. Understanding of knowledge graphs

8. Have experience in building graph-based ontology from scratch and working with structured and unstructured data

9. Experience supporting ML models development on big data infrastructure (on knowledge graph would be a bonus)

10. Hands on python to build knowledge Graph/ontologies.

11. Experience with AWS Textract, Comprehend Medical (nice to have

Job Type: Contract

Salary: $50.00 - $70.00 per hour

Schedule:

8 hour shift

Experience:

Python: 1 year (Preferred)
SQL: 1 year (Preferred)

Ability to Commute:

Woodland Hills, CA 91303 (Required)

Ability to Relocate:

Woodland Hills, CA 91303: Relocate before starting work (Required)

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Data Engineer,"Honda Center
","Anaheim, CA",$110K - $134K (Employer est.),4.0,"A great experience starts with you!
Honda Center welcomes fans, performers, and athletes from around the globe. Our team members are an integral part of the event experience through their interactions with guests. Whether you’re looking to create a great guest experience at a concert, support business growth and development, work behind-the-scenes during an Anaheim Ducks game, or anything in-between, this is your opportunity to start the next chapter of your career story and help create a one-of-a-kind fan experience at Honda Center.
Once you've had a chance to explore our current open positions, apply to the ones you feel best suit you, as an applicant, you can always see your application status in your profile.
Job Title:
Data Engineer
Pay Details:
The annual base salary range for this position in California is $109,550 to $133,895 per year. The starting pay for the successful candidate depends on various job-related factors, including but not limited to the candidate’s geographic location, job-related knowledge, skills, experience, education/training, internal value, peer equity, external market demands, and organizational considerations.
ocV!BE, a premier mixed-use community and live entertainment district, is coming to Anaheim in 2026! This $4+ billion, 100-acre, mixed-use community will surround its anchor, Honda Center, with new live entertainment venues, dining and retail offerings, and public amenities. From intimate clubs to a new 6K-capacity concert venue, ocV!BE will provide a full range of entertainment, activating the District daily for the enjoyment of its guests.
ocV!BE’s District Insights Group (DIG) is a holistic data practice that initiates and conducts activities across existing business units (primarily the Anaheim Ducks and Honda Center). Overtime, the DIG’s scope will expand to encompass all phases of the ocV!BE district, building upon learnings, platforms, standards, and practices developed between now, the ocV!BE’ District Phase 1 opening and beyond. The DIG represents hybrid expertise between both Business Intelligence (BI) and Consumer Intelligence (CI) practices. DIG’s team will evolve to represent fully dedicated resources for both BI and CI while remaining organized within the single, holistic Insights practice inclusive of data enrichment and predictive analytics enabled by Machine Learning and Generative AI.
The Data Engineer will be responsible for designing and delivering data platform solutions to support all aspects of data analytics practice and software engineering projects. Responsible for participating in the core data engineering work associated with the design and implementation of Data Strategy, Information Architecture and Governance projects to ensure the security, integrity, and availability of information with appropriate technical documentation and QA activities. Conduct data modeling and associated research, development, deployment, monitoring, and ongoing maintenance to ensure efficient, stable, scalable, and highly secure cloud data infrastructures for the enablement of data-driven business decision making. Manage the data engineering requirements associated with third party technology integrations. Lead the implementation of all data engineering projects, designing and communicating/translating business requirements into data engineering solutions across departments and operating entities. Responsible for implementing data transformation pipelines and data ingestion points to collect data from external data sources according to specifications provided by technical and business leadership. Serve as the organization’s primary Database Administrator (DBA), providing associated support and oversight of the organization’s Database Administration priorities.
Responsibilities
Design and implement data engineering facets of Data Strategy, Information Architecture and Governance projects to ensure the security, integrity, and availability of information with appropriate technical documentation and QA activities in accordance with organizational systems, standards, specifications, and requirements
Lead the implementation of data engineering projects
Design and communicate data engineering solutions based on business requirements
Implement data transformation pipelines and data ingestion points to collect data from external data sources
Motivate and communicate data engineering considerations across multiple levels of the department, including non-technical, non-data savvy audience (ability to translate data engineering technical communication into highly relatable, non-technical terms)
Develop strategies, refine/evolve existing, and develop new, initiatives with your team to advance on an organizational and technical levels across the core focus areas of the DIG and the operations it supports
Provide a consistent/successful interface between Engineering Development and Product Management
Develop leadership skills within the organization and mentor other leaders
Development, measurement, and management of key metrics for group's performance
Drive high throughput and all connected key metrics on a strategic level
Standardize the development process where needed, allow local differences where advantageous
Perform other duties and projects as assigned

Requirements
Proven track record of designing and delivering data management solutions in complex cloud environments
Experience in setting up and maintaining/evolving data platforms in cloud environments such as AWS, Azure, GCP (Azure being a requirement)
Experience with Snowflake
Foundational understanding of Data & Analytics Architectures, definition of KPIs/metrics and insight requirements
Proficient in Python and system-level languages like Go, Rust, Java
Strong technical knowledge of distributed data processing frameworks such as Spark, Flink, Arrow and similar (PySpark being a requirement)
Knowledge of workflow tools such as Airflow, Kubeflow, Jira and similar
Proficient in SQL and Document DBs, and performance tuning of queries: ensuring solutions are both scalable and maintainable
Skills
Minimum of 5 years of experience as a Data Engineer and Database Administrator
Graduate degree in Computer Science, Mathematics, Engineering, or other STEM
Experience with enterprise-scale, multi-application (platform) systems
Experience with data and software engineering direction within the ML/AI space
Experience synthesizing data and creativity to deliver transformation business results
Excellent written and verbal communication skills
Understanding of, and interest in expanding expertise around, Large Language Models (MML)/ Generative AI and its emerging role in data, analytics, prediction and the future of broader insights platforms and practices
Able to understand business requirements and translate them into data engineering and related analytics projects that deliver solutions to business challenges and/or support capitalizing on business opportunities
Knowledge, Skills, and Experience
Education - Bachelors Degree
Certifications Required – NA
Experience Required – 5+ Years
JM2023
Company:
ocV!BE Sports & Entertainment, LLC
Our Commitment:
We are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, parental status, military service, medical condition or any protected category prohibited by local, state or federal laws. We are firm believers that diversity and inclusion among our team members are critical to our success, and we seek to recruit, develop, and retain the most talented people from a diverse candidate pool.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",1948,Transportation Equipment Manufacturing,Unknown / Non-Applicable,Manufacturing,10000+ Employees,Company - Public,False
Data Engineer,"Natron Energy
","Santa Clara, CA",$119K (Employer est.),3.7,"The data team at Natron Energy is responsible for the collection, management, analysis, and distribution of all the battery manufacturing and test data. The data team drives one of the core principles of Natron Energy, rational decision-making, by providing data for every critical decision. As a data engineer on the data team, you will:

Be part of a small team with ownership of data infrastructure for the entire company
Work closely with many positions and teams across Natron Energy such as Analysts, Test Engineers, Process Engineers, Reliability, R&D etc.
Own and develop robust and scalable solutions
Contribute to the mission of building a company and a product to be proud of

Tech Stack: SQL, Python, Dagster, Fivetran, DBT, Big Query, Tableau, JMP
Experience and Skills:
2+ years of experience as a Data Engineer or other data/software-related role
Fluent in SQL and familiar with dimensional modeling
Fluent in Python
Fluent with version control software such as Git
Has a do-whatever-it-takes attitude, thrives in a fast-paced start-up environment and can deliver project deliverables on time
A bachelor’s degree or higher in a science or engineering field.
Desired Skills:
Experience with building data infrastructure to support high-volume manufacturing
Experience with statistical analysis relevant to product development and/or manufacturing
Familiar with dbt (data build tool)
Familiar with Dagster, AirFlow or other similar data orchestration tools
Familiar with cloud-based technologies like Big Query, Redshift, Snowflake etc.
Familiar with BI tools such as Tableau, Looker, Power BI etc.
Logistics:
Compensation: competitive with other data engineer positions at pre-revenue Bay Area startup companies
Hours and duration: permanent position, full time
Location: Hybrid (Santa Clara, CA) or Remote
Compensation/Pay Transparency:
Disclaimer: The actual salary of a successful applicant may vary from posted ranges based on the candidate’s experience, knowledge, skills, and abilities, internal equity and alignment with market data, and other legitimate business reasons, including, but not limited to, compliance with applicable immigration law prevailing wages.
In addition, Natron Energy has a strong benefits package including Medical, Dental, Vision, 401k Plan with Match, Life Insurance, Parental Leave Benefits, Discretionary Time Off (DTO) and Paid Time Off (PTO) for Exempt and Non-Exempt employees respectively, and 11 paid holidays.
The salary range for this position is a minimum of $119,000 and a maximum of $161,000.
About Us:
Natron Energy (natron.energy) is the future of energy storage. Natron Energy’s battery products solve operations performance and reliability problems for the world’s biggest electricity customers. Natron Energy’s initial products target markets exceeding $25B including data centers, oil & gas, EV fast charging, and commercial aviation. Natron Energy has additional products in development for >$50B markets including commercial and residential grid storage. Its products are based on sodium-ion cells containing Prussian blue electrodes that deliver unique power, cycle life, and safety: full discharge and recharge in just minutes and up to 50,000 deep discharge cycles from a nonflammable, fault-tolerant system. Natron Energy’s current production is sold out for the next 12 months. The company has signed over $225M/year in master sales agreements and LOIs, and scale-up to mass production is now underway. Natron Energy has raised over $155M in venture capital investment to date, as well as $35M in non-dilutive funding to support its supply chain scale up.




Unsolicited Resume Policy
Natron Energy, Inc. (“Natron Energy” or the “Company”) does not accept unsolicited resumes from professional recruiters, third-party recruiting or staffing agencies, placement services, or any other source other than directly from a candidate. Any unsolicited resumes, including partial resumes, candidate profiles, and candidate details or information, sent to Natron Energy or its personnel will be treated as public information provided free of any charges or fees.

Natron Energy will not pay a fee for any placement resulting from the receipt of an unsolicited resume, unless in connection with a written agreement with the Company then in effect. Such agreement must be pre-approved by Natron Energy and executed by an authorized representative of the Company. Natron Energy specifically rejects, and denies any liability under, any agreement purporting to be accepted based on negative consent, negotiation with a candidate, performance, or any means other than the signature of an authorized representative of the Company.


Natron Energy is proud to be an equal-opportunity employer. We value diversity. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

If you need assistance or an accommodation due to a disability, you may contact us at: jobs@natron.energy",-1,-1,Less than $1 million (USD),-1,1 to 50 Employees,Company - Private,True
Data Engineer - Remote,Vestis,"Burbank, CA",$95K - $115K (Employer est.),-1.0,"The Data Engineer will work within Aramark Uniform Services IT department and is responsible for supporting the data integration needs of Enterprise Data Warehouse, Data Lakes, and other integration solutions. The role of the Data Engineer is responsible for building and maintaining optimized and highly available data and analytics layer that facilitates deeper analysis and reporting to business consumers. Data Engineer will design robust and scalable data integration solutions based on industry best practices. The candidate must have a strong hands-on experience working in big data, and data warehouse environment.




Responsibilities/Essential Functions:

-Design, implement, and continuously improve data analytics platform
-Implement optimized and simplify data query and analysis capabilities of the data platform
-Develop and improve the current architecture, emphasizing data security, data quality and timeliness, scalability, and extensibility
-Deploy and apply big data solution and run pilots to design highly performing and low latency data architectures to scale
-Collaborate with cross functional team and develop, implement, and validate KPIs, statistical analyses, data profiling, prediction, forecasting, clustering, and machine learning algorithms
-Leverage best practices, disciplined approaches, and standards to solving technical problems.
-Perform ongoing monitoring, optimization, and refinement of reports and BI solutions
-The role entails 100% hands-on development using MS SQL / Python on MS Azure Synapse Platform

-Build data solutions with efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.

-Develop big data analytics solutions sourcing data from distributed systems and applications
-Ensuring accurate and efficient governance policy development and adherence
-Report on statuses when requested
-Submit all time and expense reporting procedures accurately and timely
-Maintain good standing and completion on all compliance related matters (i.e., assigned mandatory trainings, actions required from audits, corporate policies, etc.)
-Perform all additional duties and responsibilities based on the direction and guidance of supervisor



Knowledge/Skills/Abilities:

-Expertise in ELT optimization, designing, coding, and tuning big data processes using Microsoft Azure Synapse or similar technologies.
-Experience with building data pipelines and analytics solution to stream and process datasets at low latencies.
-Knowledge of Data Engineering and Data Operational Excellence using standard methodologies.
-Hands on level skills coding and optimizing complex SQL and Python
-Strong Knowledge of data warehousing frameworks and methodologies.
-Proven ability to foresee opportunities to innovate and leads the way
-Excellent verbal and written communication
-Proven interpersonal skills and ability to convey key insights from complex analyses in summarized business terms
-Ability to effectively communicate with technical and non-technical teams
-Ability to work with shifting deadlines in a fast-paced environment Skilled and proficient in MS Office O365 suite (i.e. Word, PowerPoint, Excel, SharePoint, Teams, Communications Tools, etc.)
-Ability to operate with a customer-centric service approach



Working Environment/Safety Requirements:

-Ensure necessary working environment and capabilities to effectively carry out responsibilities if working from a non-AUS location (remote work)
-Ability and willingness to handle work related issues during all hours of the day, every day of the week, understanding the responsibility of our organization’s requirement for 24/7 production support
-Ability, willingness, and flexibility to travel as needed for approved work purposes in accordance with project and management schedules



Experience/Qualifications:

-Bachelor’s degree in Computer Science, Mathematics, Statistics or related field or 6+ years relevant experience
-Experience in data mining, profiling, and analysis
-Experience in Azure Data Factory
-Experience with complex data modelling, ELT design, and using large databases in a business environment
-5+ years experience with languages like SQL, Python, Java, or similar language
-Must have at least three years of work experience in Big Data projects such as Microsoft Azure Synapse or similar Big Data platform a must



License Requirements/Certifications:

-Valid U.S. driver license (for rental cars when applicable)
-Be legally able to work in the United States: U.S. Citizen or Legal Resident

Benefits: Aramark offers a wide array of comprehensive benefit programs and services including medical, dental, vision, short and long-term disability, basic life insurance, and paid parental leave. Employees are able to enroll in the company’s 401k plan. Employees are eligible for 120 hours of vacation, 16 hours of floating holidays, and paid sick time every year. Employees will also receive 9 paid holidays throughout the calendar year.

Compensation: The salary rate for this position ranges from $95K-115K, depending on circumstances including an applicant’s skills and qualifications, certain degrees and certifications, prior job experience, market data, and other relevant factors.

Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities

The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)",-1,-1,Unknown / Non-Applicable,-1,201 to 500 Employees,Company - Private,True
"Data Engineer, Quality Data Analytics & Systems","Tesla
","Fremont, CA",$108K - $158K (Glassdoor est.),3.6,"What to Expect
The Quality Engineering team plays a key role in ensuring safety of our customers by providing world class Quality of our products. Quality Systems and Analytics team is looking for a key player on the team who can help drive Quality data analytics and help cross-functional engineering organizations to provide opportunities in product quality improvements. Candidate should have experience working with large data sets, finding best ways to engineer the data to help create critical KPI metrics, building innovative visualizations and dashboards all the while keeping in mind what improvements can be driven in underlying data systems.

Tesla's mission is to accelerate the world's transition to sustainable energy. We are committed to hiring the world's best and brightest people to help make this future a reality. Every Tesla is designed to be the safest, quickest car in its class—with industry-leading safety, range, and performance.
What You’ll Do
Collaborate with cross-functional problem-solving teams to drive process systems, analytics, data engineering improvements; use of effective QA methodologies to manage and facilitate issue resolution including root cause investigations and the development, implementation and monitoring of effective corrective and preventive actions

Establish and maintain guidelines for analytics/data engineering, QA, change management and metric/project documentation best practices and ensure team adheres to those standards
Design and implement metrics, applications and tools that will enable engineers by allowing them to self-serve their data insights

Analyze manufacturing, equipment, and vehicle data to extract useful statistics and insights about failures in order to drive meaningful improvements to production quality and customer experience
Interpret trends in manufacturing, equipment, and vehicle data, analyzing results using statistical techniques and depicting the story via dashboards and reports
Automate analyses and author pipelines using SQL, Python, Airflow, and Kubernetes based ETL frameworks
Monitor key product metrics, understanding root causes of changes in metrics
Drive underlying data systems improvement by working with key cross-functional stakeholders
Work effectively with engineers and conduct end-to-end analyses, from data requirement gathering to data processing and modeling
Contribute to all stages of the factory and service quality data modeling including but not limited to problem formulation, data pre-processing, feature engineering, sample design, algorithm selection and evaluation, hyper-parameter tuning, deployment, implementation, and monitoring
What You’ll Bring
Bachelor's Degree in Management Information Systems, Computer Science, Math, Physics, Engineering, Statistics or another technical field, or equivalent experience
1-2+ years of work experience in data analytics or engineering related field
Knowledge of SQL and experience with multiple data architecture paradigms (MySQL, MicrosoftSQL, Vertica, Oracle, kafka, Spark) with proficiency in Python, text processing, and python data analysis packages (eg. pandas, numpy)
Knowledge of data visualization techniques and tools using Tableau, Power BI, Superset, Matplotlib, Plotly etc

Understanding of various statistical techniques to effectively summarize data findings with strong knowledge of data warehousing concepts as well as data mining tools and techniques
Proficiency in using open-source ML toolkits (eg. Pytorch, Tensorflow) and building NLP applications, with Strong ML and NLP fundamentals
Knowledge of manipulating big data with Apache Spark (Python or Scale APIs)
Able to work under pressure while collaborating with cross-functional teams and managing competing demands with tight deadlines
Excellent communication skills and ability to work with different business stakeholders to understand, identify, and translate business challenges into data projects
A passion and curiosity for data and data-driven decision making",2003,Transportation Equipment Manufacturing,$1 to $5 billion (USD),Manufacturing,10000+ Employees,Company - Public,False
BI Data Engineer,"Spartan Technologies
","Palo Alto, CA",$115K - $155K (Glassdoor est.),3.4,"Spartan Technologies, Inc. - Palo Alto, CA

3 month contract

Fully remote

West Coast

We are seeking a a BI Data Engineer with a strong Tableau development background and has done Tableau implementations. You will also need solid experience with Snowflake and AWS. In this role you will be working with the Data Science and Security teams along with Stakeholders.",2007,Information Technology Support Services,$5 to $25 million (USD),Information Technology,1 to 50 Employees,Company - Private,False
Data Engineer,"Atlassian
","San Francisco, CA",$112K - $158K (Glassdoor est.),4.1,"Overview:

Atlassian is looking for a Data Engineer to join our Data Engineering Team. You will build top-notch data solutions and applications that inspire important decisions across the organization. You will be reporting to the Senior Data Engineering Manager.

You'll have flexibility in where you work – whether in an office, from home (remote), or a combination of the two.

Compensation

At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:

Zone A: $147,500 - $196,600

Zone B: $132,700 - $177,000

Zone C: $122,400 - $163,200

This role may also be eligible for benefits, bonuses, commissions, and equity.

Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.

Responsibilities:

A typical day may involve collaborating with partners, you will design data models, acquisition processes, and applications to address needs. With experience in large-scale data processing systems (batch and streaming), you will lead business growth and enhance product experiences. And will collaborate with Technology Teams, Global Analytical Teams, and Data Scientists across programs.

You'll take ownership of problems from end-to-end: extracting/cleaning data, and understanding generating systems. Improving the quality of data by adding sources, coding rules, and producing metrics is crucial as requirements evolve. Agility and smart risk-taking are important qualities in this industry where digital innovation meets partner/customer needs over time.

Qualifications:

On your first day, we'll expect you to have:

BS in Computer Science or equivalent experience with 3+ years as a Data Engineer or a similar role

Programming skills in Python & Java (good to have)

Design data models for storage and retrieval to meet product and requirements

Build scalable data pipelines using Spark, Airflow, AWS data services (Redshift, Athena, EMR), Apache projects (Spark, Flink, Hive, and Kafka)

Familiar with modern software development practices (Agile, TDD, CICD) applied to data engineering

Enhance data quality through internal tools/frameworks detecting DQ issues. Working knowledge of relational databases and SQL query authoring

We’d be super excited if you have:

Followed a Kappa architecture with any of your previous deployments and domain knowledge of Financial and People System",2002,Software Development,Unknown / Non-Applicable,Information Technology,5001 to 10000 Employees,Company - Public,False
Data Center Engineer,"Zoox
","Foster City, CA",$105K - $145K (Employer est.),3.9,"Zoox is looking for a Data Center Engineer to join our Platform Operations team. In this role, you will be responsible for Zoox's application, compute, and storage infrastructure. This individual will work closely with other engineers to install and maintain Zoox's internal infrastructure. This position will primarily be based at our Sunnyvale data center with periodic travel to other San Francisco Bay area locations.
Responsibilities
Maintain and repair CPU and GPU based compute clusters and storage.
Run cabling and fiber within the data centers.
Independently troubleshoot and repair complex hardware issues.
Deploy, integrate and rack new equipment. Includes planning and managing rack elevations.
Contribute to documentation.
Update inventory tracking, cable runs, and hardware deployments in DCIM tooling.
Handle Vendor RMAs.


Qualifications
Understanding of data center concepts including power consumption, power sizing, and cooling requirements.
Meaningful experience in installing and maintaining enterprise compute hardware.
Skilled with running fiber and cabling in a data center environment.
Skilled with troubleshooting and repair of Intel-based server hardware.
Competency to work independently with minimal supervision to maintain and repair servers in enterprise data center environments.
Familiarity with ticket management processes.
Familiarity with DCIM tools such as Device42.
Can lift 50 lbs to waist height, 25 lbs to shoulder height.
Understanding and respect for the importance of “production” environments.
Excellent verbal and written communication skills in English.
Ability and willingness to use personal vehicle to travel to data centers in Sunnyvale, CA and surrounding areas. (Expenses reimbursed)
There are three major components to compensation for this position: salary, Amazon Restricted Stock Units (RSUs), and Zoox Stock Appreciation Rights. The salary range for this position is $105,000 to $145,000. A sign-on bonus may be offered as part of the compensation package. Compensation will vary based on geographic location and level. Leveling, as well as positioning within a level, is determined by a range of factors, including, but not limited to, a candidate's relevant years of experience, domain knowledge, and interview performance. The salary range listed in this posting is representative of the range of levels Zoox is considering for this position.
Zoox also offers a comprehensive package of benefits including paid time off (e.g. sick leave, vacation, bereavement), unpaid time off, Zoox Stock Appreciation Rights, Amazon RSUs, health insurance, long-term care insurance, long-term and short-term disability insurance, and life insurance.

About Zoox
Zoox is developing the first ground-up, fully autonomous vehicle fleet and the supporting ecosystem required to bring this technology to market. Sitting at the intersection of robotics, machine learning, and design, Zoox aims to provide the next generation of mobility-as-a-service in urban environments. We’re looking for top talent that shares our passion and wants to be part of a fast-moving and highly execution-oriented team.

Follow us on LinkedIn

A Final Note:
You do not need to match every listed expectation to apply for this position. Here at Zoox, we know that diverse perspectives foster the innovation we need to be successful, and we are committed to building a team that encompasses a variety of backgrounds, experiences, and skills.",2014,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Principal / Senior Principal Instrumentation and Data Acquisition Hardware Engineer,"Northrop Grumman
","Edwards AFB, CA",$95K - $142K (Employer est.),4.0,"Requisition ID: R10134780
Category: Engineering
Location: Edwards AFB, California, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: Any (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 2
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.

Northrop Grumman Aeronautics Systems has an opening for a Principal / Senior Principal Instrumentation and Data Acquisition Hardware Engineer to join our team of qualified, diverse individuals within our Test and Evaluation organization. This position will be located in EAFB, CA.

The selected candidate will join the Instrumentation and Data Acquisition Engineering team be part of the design, development, integration, configuration and test of a real-time, hardware in the loop (HITL), Data Acquisition Systems (DAS). They will perform a variety of duties in the electronic, mechanical, electromechanical, or software areas. Tasking will include design, development, verification and acceptance testing of data builds and real time Mission Control Room configuration files using Symvionics IADS software. The selected candidate will be responsible for coordinating integrated testing activities; reviewing and evaluating test requirements to ensure compliance with policies and procedures. Compilation of data and definition of changes required in testing procedures or new testing requirements will be necessary as well to help define automated test strategies. The selected candidate should be pro-active and self-motivated; ask not only “what”, but also “how” and “why.” Overtime, odd shifts, and weekend work will occasionally be required.

Key Responsibilities:

Promptly respond to technical issues that arise on the production floor utilizing work instructions, design models, and specifications.
Establish on article long term planning for installations.
Compile data and define changes required in testing procedures or new testing requirements.
Help define automated test strategies.
Clarify work instructions to operations staff; modifying as needed.
Drafting, opening, tracking, and closing Prep Items.
Creation of test Concept of Operations (ConOps) flows that maximizes the utility of test resources while meeting schedule and technical requirements and/or constraints.
Coordinate integrated testing activities; review and evaluate test requirements to ensure compliance with policies and procedures.
Identify process improvements, capture feedback from operations staff, and incorporate into the installation process.
Resolve issues by collaborating with other resource groups as needed.
Perform technical impact, planning, and strategy assessments for change implementation.

The selected Candidate must be willing to work various shifts depending on the business needs: 4x10 schedule (Mon-Thurs) 1st shift; 4x10 (Mon-Thurs) 2nd shift; 3x10 schedule (Fri, Sat, Sun) 1st shift; 3x10 schedule Fri, Sat, Sun) 2nd shift. Candidate must also be willing to accept work assignments that may include the Palmdale, CA location dependent on business needs.

Basic Qualifications:

This requisition may be filled at either a Principal or a Sr. Principal level.

Basic Qualifications for Principal:

A Bachelors in Science, Technology, Engineering or Math (STEM Degree).
A minimum of 5 years of applicable experience with a BS Degree or 3 years with a MS degree in STEM Field

Basic Qualifications for Sr Principal:

A Bachelors in Science, Technology, Engineering or Math (STEM Degree).
A minimum of 9 years of applicable experience with a BS Degree or 7 years with a MS degree in STEM Field

Basic Qualifications for Both Principal and Sr Principal Engineer

Must have the ability to obtain and maintain DoD Secret Clearance.
Must have ability to obtain and maintain Program Access (PAR) within a reasonable period, as determined by the company to meet its business needs.
Basic understanding of troubleshooting systems to identify and assist in the correct the root cause.
Experience assisting with the creation, editing and execution of procedures.
Experience assisting with data acquisition and data collection.
Experience with Microsoft Windows family of products, AutoCAD, MatLab.

Preferred Qualifications:

Electronics, Analog and Digital Communications, Digital Signal Processes, Computer Communication Networks, Embedded Systems
Experience working in Flight Test or Lab Test environments
Experience using oscilloscopes and waveform generators.
Experience working with Strain Gages, Accelerometers, Pressure Transducers and other commonly used instrumentation sensors
Basic knowledge of data bus architecture MIL-STD-1553, IEE-1394, ARINC-429, RS232 an RS422.
Experience using Symvionics IADS software and working in a Mission Control Room
Experience post-test processing data from a IRIG-106 CH10 recording
Experience using TTCWare Application Software
Experience working Curtiss-Wright TTC Data Acquisitions Systems
Ability to write scripts GUIs or small scale applications a plus.
Bachelor of Science degree in Electrical Engineering or a degree with Instrumentation data experience.
Salary Range: $95,000 - $142,400
Salary Range 2: $117,700 - $176,500
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.

Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",1939,Aerospace & Defense,$10+ billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
Data Engineer (Flex Hybrid),"UCLA Health
","Los Angeles, CA",$96K - $222K (Employer est.),3.9,"Description

As a Data Engineer on the Data Architecture team, you will play a key role in technology initiatives to advance health informatics and analytics in the health sciences by advancing the usability, performance, and overall architecture of the Data Infrastructure. You will develop fastest, reliable, and large-scale data processing pipelines to ingest data from multiple data sources into Enterprise Data warehouse and Data Lake. Involves technical acumen for planning, designing, developing, implementing, and administering data-based systems that acquire, prepare, store, and provide access to data and metadata. Maintains and optimizes systems and migrates data and systems as needed. Ensures integrity and completeness of data and workflow, manages and / or develops data practices, databases, and information systems as well as guidelines, dictionaries, registries and / or services. May include interpretation of scientific research data artifacts as well as mediation across science and technology domains and long-term data care. As information architect and data steward, designs systems, data products and / or data production processes while focusing on data curation, data exchange, data security, data integrity and information environments. (Re)evaluates frameworks, strategies, standards, and standards-making activities. May involve work with a project-level data repository, a center, or an archive. You will be part of the team building UCLA Health’s Data Platform and products and is a unique opportunity to be part of advancing analytics for one of the nation’s leading Healthcare organizations where Big Data will be used as a platform to build solutions. You must be willing and able to be on-site at least once a month.

Qualifications

• Minimum five years of software development experience. • Development experience on the data processing side of the software development. • Experience with Orchestration tools like Airflow or SSIS is required. • Strong experience with Relational like SQL Server or Oracle is required. • Strong background in Data warehousing and ETL principles, architecture, and its implementation in large environments. • Strong industry experience in programming languages such as Python or C#, with the ability to pick up new languages and technologies quickly. • Working knowledge on leading cloud platforms like Azure, AWS, GCP; Microsoft Azure experience is preferred. • Healthcare experience (using claims and EHR data) strongly preferred. • Bachelor’s degree in computer science, Computer Engineering, or related field from an accredited college or university; Master’s Degree preferred.",1919,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,5001 to 10000 Employees,Company - Public,False
Senior Data Engineer,"Spokeo
","Pasadena, CA",$136K - $167K (Employer est.),4.0,"Note: Contractors (C2C, C2H) that directly apply will not be considered. Individual applicants only


Spokeo is a people search engine and identity platform that enlightens and empowers our customers. With nearly 15 billion records and 18 million monthly visitors, we reconnect friends, reunite families, prevent fraud, and more.


As a Senior Data Engineer at Spokeo, you will develop, optimize, and maintain the ETL data pipeline. This involves working with infrastructure built in AWS, including Airflow, PySpark, EMR, S3, DynamoDB, and more. This role will help build and improve automation platform features, analytical software packages, and data pipeline orchestration tools.


What You'll Do: This includes an estimate of where time will be spent. This is subject to change:

40% - Build infrastructure and data automation pipeline for extracting, preparing, and loading data from various sources. Automate and integrate new components into the data pipeline.

30% - Implement robust ETL processes to efficiently execute product vision and strategy in alignment with organizational goals and priorities.

10% - Create unit and stress test components to monitor technical performance and ensure identified issues are resolved.

10% - Develop data analysis tools to provide data insights and capture key metrics.

10% - Research solutions and maintain technical documentation.

Follow best practices for data governance, quality, cleansing, and ETL-related activities.


Requirements:

7+ years of development experience in data engineering.

5+ years of hands-on programming experience with Python.

5+ years of professional experience working in big data ecosystems, preferably with Spark

3+ years experience with SQL, schema design, and dimensional data modeling.

2+ years of professional experience working with dataflow management tools, such as Airflow

2+ years of development experience in highly scalable, distributed systems and cluster architectures using AWS.

2+ years experience with non-relational databases (e.g., DynamoDB, Elasticsearch, etc.)

Prior experience working with large data sets (>100M+ records)

B.S. in Computer Science, Information Systems, or related fields


Named Best Company for 2023 by Comparably in the areas of Perks & Benefits, Happiness, Compensation, and Work-Life Balance.


Spokeo offers a bonus program, equity plans, and 401K matching for qualified roles. Twice a year, we do discretionary, merit-based salary increases. Additional benefits include 100% medical/dental/vision coverage for all employees and unlimited PTO.


Spokeo extends written offers to candidates who successfully complete their selection process. Spokeo’s offers include a base salary, participation in a company bonus program, stock options, and comprehensive benefits. A final offer will depend on several factors, including, but not limited to, marketplace competition, job leveling, the candidate’s experience, skills, etc.


Privacy Notice for Candidates: https://www.spokeo.com/recruiting-policy


Spokeo is an equal opportunity employer. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, or protected veteran status. Spokeo fosters a business culture where ideas and decisions from all people help us grow, innovate, create the best products, and be relevant in a rapidly changing world.


Recruiters or staffing agencies: Spokeo is not obligated to compensate any external recruiter or search firm who presents a candidate or their resume or profile to a Spokeo employee without 1) a current, fully-executed agreement on file, and 2) being assigned to the open position (as a search) via our applicant tracking solution.


#LI-Remote


This is a remote position.",2006,Internet & Web Services,Unknown / Non-Applicable,Information Technology,201 to 500 Employees,Company - Private,True
Data Engineer (Contract),"Aputure
","Glendale, CA",$90K - $130K (Employer est.),4.0,"Aputure is one of the fastest-growing cinema technology companies. Our equipment has emerged a global newcomer to watch for with hundreds of thousands of Aputure lights now being used on film sets worldwide. Beyond just products, our marketing team also works in a way that is equally visionary. Electing to create communities and content for filmmakers rather than advertisements, the Aputure A-Team is composed of like-minded creatives that genuinely enjoy working with filmmakers every day.

The Data Engineer will be instrumental in delivering and maintaining the data pipelines and infrastructure, as well as building dashboards needed for business metrics as per Aputure's needs. As one of the early hires of this team, you will get to shape the project's direction and success.
The Role:

Contribute to the data collection/data cleaning process
Validate the metrics set out by Aputure's executive team
Architect, build, monitor and maintain data ETL pipelines that support Aputure's business domains
Implement the data dashboards needed for business metrics delivery and interpretation.
Integrate seamlessly with the existing Aputure's data workflow and legacy systems.
Implement deployment workflows to take prototype data systems to production.

Required Qualifications:

At least Bachelor's in Computer Science or relevant fields
Strong knowledge of data structures, ETL pipelines and data processing/cleaning
Strong experience with data visualization libraries such as Tableau and Plotly
2+ years of experience building production grade data platforms using AWS or GCP, and be willing to ramp up quickly on Aliyun
Advanced knowledge of SQL and NoSQL database technologies (SQL, Postgres, Cassandra, Mongo etc.)
Proficiency in Python, Spark, Kafka, RabbitMQ and related data engineering tools
Proficiency in working with/implementing REST and GraphQL APIs
Working knowledge of Git, Docker, and associated deployment tools
Aware of CI/CD best practices
Aware of modern data offerings such as Databricks and Snowflake
Experience in participating in on-call rotations and dealing with hot fixes

Specifications:

6 months contract with potential for renewal or conversion to full time
40 hours/week working hours
Remote eligible (Los Angeles presence strongly preferred for some in-person sync ups)
Work authorization: US citizen or permanent resident
Direct hire only - no agencies

Our mission is to make filmmaking better, more creative and more accessible for all. Ensuring a diverse and inclusive workplace where we learn from each other is core to Aputure's values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and strive to be the most supportive place to work.
Salary: $50-$70/hour depending on experience

Job Types: Full-time, Contract

Pay: $90,000.00 - $130,000.00 per year",2005,Film Production,Unknown / Non-Applicable,Media & Communication,1 to 50 Employees,Company - Private,True
Data Engineer,"Crossover Health Management Services, Inc.
","San Clemente, CA",$91K - $105K (Employer est.),3.8,"About Crossover Health

Crossover Health is creating the future of health as it should be. A national, team-based medical group with a focus on wellbeing and prevention that extends beyond traditional sick care, the company delivers an entirely new model of healthcare—Primary Health—built on the foundation of trusted relationships, an interdisciplinary care team approach, and outcomes-based payment. Crossover’s Primary Health model integrates primary care, physical medicine, mental health, health coaching, care navigation and more, and delivers care in surround-sound—in-person, virtually and via asynchronous messaging. Together we are building a community of members that embraces healthcare as a proactive part of their lifestyle.

Job Summary


Crossover’s Data Engineer is responsible for managing and developing data sources for analytics at scale. This is a critical role for supporting Crossover’s growing analytics team, and serves as the connection between Crossover’s Product and Technology teams, Data Science team, and data infrastructure vendors. In this role, the successful candidate will build out new data sources within the enterprise data warehouse, guide data modeling efforts for new and existing projects, and manage data ingress and egress between Crossover teams, clients, partners, and vendors. The ideal candidate will have experience with both clinical healthcare data as well as healthcare claims data.

About Crossover Health

Crossover makes remarkable health possible by bringing people, their doctors, data, and benefits together under one connected system of health. We’ve built an entirely new category of primary care providing one simple place to go for trusted care—in person, online, anytime. We are working with the most innovative employer partners to integrate disconnected health and wellness benefits with tech-enabled services which allows our partners to increase access to care, decrease spend, and deliver an unrivaled experience for employees near and far.

Job Responsibilities

Crossover’s Data Engineer is responsible for managing and developing data sources for analytics at scale. This is a critical role for supporting Crossover’s growing analytics team, and serves as the connection between Crossover’s Product and Technology teams, Data Science team, and data infrastructure vendors. In this role, the successful candidate will build out new data sources within the enterprise data warehouse, guide data modeling efforts for new and existing projects, and manage data ingress and egress between Crossover teams, clients, partners, and vendors. The ideal candidate will have experience with both clinical healthcare data as well as healthcare claims data.

Develop and maintain data sources within Crossover’s enterprise data warehouse (inclusive of our current vendor and/or future data infrastructure)

Assist with recommendations for data architecture, data storage, data integration, data quality, and data models

Contribute to design sessions based on technical requirements, and build data models to clean and transform datasets for use by Crossover’s Data Science and Analytics teams

Assist with ETL, ELT, and reverse-ETL design and development initiatives including data analysis, source-target mapping, data profiling, change data capture, QA testing, and performance tuning to guarantee quality and repeatability of data model results

Create and maintain data model standards, including MDM (Master Data Management) and codebase standardization

Migrate Enterprise Workloads to Snowflake using industry standard methodologies

Automate and deploy as well as build CI/CD pipelines to support cloud based workload

Design, deliver cloud native, hybrid, and multi-cloud Workloads

Invest in documentation, including all system design, architecture and ongoing changes

Design and support production job schedules, including alerting, monitoring, break fixes, and performance tuning

Build solutions that are automated, scalable, and sustainable while minimizing defects and technical debt

Assist stakeholders including analytics, design, product, and executive teams with data-related technical issues

Ability to work independently with little instruction or direct oversight

Perform other duties as assigned

Minimum Qualifications

Bachelors in Computer Science or Data Engineering, related degree, or equivalent professional experience

3+ years relevant work experience within a complex, dynamic environment, with preference for experience with clinical healthcare data

3+ years architecting , implementing, and supporting data infrastructure and topologies

Experience building and operating highly available, distributed systems of extraction, ingestion, and processing of large data sets across a variety of applications (OLTP, OLAP and DSS)

3+ years Experience with Data warehousing, methodologies, modeling techniques, design patterns, and technologies.

Experience with data migration tools and deploying cloudbase solutions

Experience in writing advanced SQL (DML & DDL), including Stored Procedures, Indexes, user defined functions, windows functions, correlated subqueries and CTE's, and related data query and management technology

Coding ability in R, Python, and Shell Scripting to build and deploy Pipelines

Working knowledge of Git, or similar collaborative code management software

Experience with data integration tools such as Matillion, FiveTran, DBT, or similar ETL/ELT tools

Experience with Snowflake’s data platform

Preferred Qualifications

Masters in Computer Science, Data Engineering, or related degree

Healthcare data acquisition, ingestion, processing, and analytics knowledge highly preferred

Previous experience with health informatics, taxonomies, terminologies, and code sets

Knowledge and understanding of product features: IAAS, PAAS and SAAS solutions

Experience with healthcare claims data, formats, and analytics

Experience with Health Catalyst’s data and analytics platform

Experience with Tableau Cloud administration

Experience with Master Data Management

Understand Cloud Ecosystem

The base pay range for this position is $91,428.00 to $105,143.00 per year. Pay range may vary depending on work location, applicable knowledge, skills, and experience. This position will be eligible for an annual bonus opportunity and comprehensive benefits package that includes Medical Insurance, Dental Insurance, Vision Insurance, Short- and Long-Term Disability, Life Insurance, Paid Time Off and 401K.

Crossover Health is committed to Equal Employment Opportunity regardless of race, color, national origin, gender, sexual orientation, age, religion, veteran status, disability, history of disability or perceived disability. If you need assistance or an accommodation due to a disability, you may email us at careers@crossoverhealth.com.

To all recruitment agencies: We do not accept unsolicited agency resumes and are not responsible for any fees related to unsolicited resumes.

#LI-Remote",2010,Health Care Services & Hospitals,$100 to $500 million (USD),Healthcare,1001 to 5000 Employees,Company - Private,True
Data Engineer,"Lynx Analytics
","San Francisco, CA",$109K - $154K (Glassdoor est.),4.0,"COMPANY OVERVIEW

Lynx Analytics was founded in 2010 by a group of INSEAD students and professors with a strong research background in graph analytics. Several of our founders since then became professors and faculty directors of analytics centers at leading US universities. Our founding purpose? To apply graph theory to simplify and solve complex, real-world business problems.

Our mission has evolved over the years, and we currently offer a range of cutting edge data analytics and AI solutions to help companies transform their operations and optimise their commercial performance. Back then, graph theory was mostly the purview of social networking sites. We wanted to expand this technology and help companies leverage their communities to unlock greater growth.

Lynx has offices in Singapore, US, Hong Kong, Hungary, and operations in several other countries such as Canada, Germany, Indonesia. We work with some of the world's largest companies and are constantly looking to expand our knowledge base and geographical footprint. Lynx Analytics' technology is deployed with various Clients internationally and has significant growth potential.

We have a diverse and inclusive global team comprising Professors, PhDs, MSc's, and MBAs from Ivy Leagues, INSEAD and NUS with a broad spectrum of experience in start-ups and blue-chip companies (Google, Databricks, ZS, Abbvie, Amgen, Vodafone, Morgan Stanley, Palantir, Katana Graph to name but a few). It is the combination of our industry insight and experience, scalable proprietary technology, and highly qualified people that drives our compelling value proposition.

We are looking for ambitious, innovative, empathetic and relentless team players to explore the career opportunities that we offer as we continue to scale our operations.

KEY RESPONSIBILITIES

A Data Engineer's responsibility is to implement and deploy data analysis pipelines at various clients of Lynx Analytics. This includes participating in the activities below:

Understand deeply the business problem that we are trying to solve by our analytical solution
Through continuous consultations with employees of our client, discover the client's existing data sources that are relevant to the problem we try to solve. This includes discussions with client IT, data owners, future business users, etc.
Working together with the IT teams of the client, define the technical architecture for the analytical solution that we are to deploy for the client.
Implement the data ingestion subsystem: this is the system responsible for moving all the necessary data sources to a single location where the actual analysis will happen.
Implement the data analysis pipelines.
Integrate the results into business UIs developed by Lynx or pre-existing client software systems

REQUIREMENTS

Relevant tertiary qualification, preferably at Masters level or above, in Engineering or another relevant discipline with strong academic results
Strong programming skills
Experience in GCP, Airflow and Spark
Solid experience in Python and SQL
Good problem-solving skills
Good communication skills

DESIRABLE

Experience in Big Data
A minimum of 3 years of experience in Data Science or Analytics
Industry experience in working for a big enterprise (like our clients)

WHAT WE OFFER

Opportunity to work on creating innovative, leading-edge data science pipelines using our state of the art, in-house built big graph tool
Work closely with the developers of the (big graph) tool you will be building upon
Be a member of a very strong team with mathematicians, ex-Googlers, Ivy League professors, MBA alumni and telecommunications industry experts
Startup atmosphere",2010,Enterprise Software & Network Solutions,$5 to $25 million (USD),Information Technology,51 to 200 Employees,Company - Private,True
Data Engineer,"Own Company
","San Diego, CA",$102K - $152K (Employer est.),3.5,"Own is the leading data platform trusted by thousands of organizations to protect and activate SaaS data to transform their businesses. Own empowers customers to ensure the availability, security and compliance of mission-critical data, while unlocking new ways to gain deeper insights faster. By partnering with some of the world's largest SaaS ecosystems such as Salesforce, ServiceNow and Microsoft Dynamics 365, Own enables customers around the world to truly own the data that powers their business.

It's their platform. It's your data. Own it.

The Job

As a Data Engineer, you will collaborate closely with Analytics Engineering, Business Intelligence, and other cross-functional teams to craft business critical data assets and build strong relationships with key data consumers. In this role, you will report to the head of Data Engineering and play a critical part in maintaining and expanding Own's internal database.

Your Day-to-Day Role
Develop Data Engineering Pipelines and Assets with your Data Engineering peers.
Document and communicate the complexities of your work to the users and the team.
Identify areas of improvement within the database and code that powers it.
Troubleshoot data issues as they arise.
Define and promote DB management tools consolidation.
Your Work Experience
Generally 4 year Mathematics, Data Science, Statistics, CS or Finance degree with 1-2 years of professional experience.
Clear Verbal and Written Communicator.
Customer-centric focus for Internal Staff.
Able to write complex SQL; previous experience with dbt would be desirable.
Hands on experience working within Relational Databases (Snowflake, Amazon Redshift, Microsoft SQL) to deploy code and administer the platform.
Experience writing Python scripts to perform ELT/ETL and Reverse ETL.
Experience with Airflow, Dagster, or other orchestration tools.
Experience working with Scrum\Agile methodology is a plus.
Important Details

This is a full-time position. The ideal candidate will work out of our San Diego, CA office a minimum of 3 days per week to maximize collaboration and interaction with the business. Travel may be required.

The base salary hiring range for this position is $101,600 to $152,400. The actual amount to be offered to the successful candidate will be dependent upon various factors such as education, training, skills, qualifications, competencies, years of experience, job-related knowledge, scope of the role, and location.

Own is dedicated to creating an environment where employees thrive, which is why base pay is only one part of the total compensation package that is provided to compensate and recognize employees for their work. This role may also be eligible for unlimited PTO, generous medical benefits, a 401(k) savings plan with a 4% employer match, discretionary bonuses/incentives, and stock options. We also offer catered lunches in the office five days a week.

Creating an environment where employees thrive also means making sure every employee feels accepted. As we scale to help all types of companies protect precious data, our team must reflect the diversity we serve. Own is an Equal Opportunity Employer and we believe that every employee in the company brings a unique perspective that they can and should contribute in order to make an impact every day. We strive to be one team and one culture that builds trust through transparency. We do not discriminate based on race, color, religion, sex, sexual orientation, gender identity, age, national origin, protected veteran status or disability status.

Learn more at owndata.com.

#LI-Onsite",2015,Enterprise Software & Network Solutions,$100 to $500 million (USD),Information Technology,501 to 1000 Employees,Company - Private,True
Senior Data Engineer,"Tencent
","Palo Alto, CA",$124K - $228K (Employer est.),4.0,"Work Mode:
Onsite
Responsibilities:
Tencent is a world-leading internet and technology company that develops innovative products and services to improve the quality of life of people around the world. Founded in 1998 with its headquarters in Shenzhen China, our guiding principle is to use technology for good.

We are not only a major video game publisher in the world, we also produce other high-quality digital content, enriching interactive entertainment experiences for people around the globe. We offer a range of services such as cloud computing, advertising, FinTech, and other enterprise services to support our clients' digital transformation and business growth.

Interactive Entertainment Group (IEG) is responsible for the R&D, operation, and development of the company's interactive entertainment business including games and eSports. Through online gaming, live broadcasts, and offline eSports, IEG assists the company in leading the global interactive entertainment market to create better interactive entertainment content experiences for users.
1. You will be responsible for the raw data pipeline for all Tencent overseas games.
2. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers.
Requirements:
1. Minimal 2-3 years of technical experience designing, building, and maintaining distributed data processing platforms.
2. Minimal 2-3 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines.
3. Minimal 2-3 years years of data modeling experience designing data warehouse table schemas and logging schemas.
4. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent).
5. Experience with large, complex, highly dimensional data sets; hands-on experience with SQL.
6. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations.
7. You are self-directed and capable of operating amidst ambiguity.
8. You are humble, continually growing in self-awareness, and possessing a growth mindset.
9. You are curious and have excellent written and verbal communication as well as problem-solving skills.

Location State(s)
California

The base pay range for this position in the state(s) above is $124,420 to $227,770 per year. Actual pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign on payment, relocation package, and restricted stock units may be provided as part of the compensation package, as well as other medical, financial, and/or other benefits, dependent on the specific position offered.",1998,Internet & Web Services,Unknown / Non-Applicable,Information Technology,10000+ Employees,Company - Public,False
Senior Data Engineer,"Snackpass
","San Francisco, CA",$153K - $210K (Employer est.),3.4,"Who we are ✨
Snackpass's mission is to unify the physical and digital world for local commerce.

We power mobile order pickup and social commerce for restaurants, modernizing the customer experience while making restaurant operators successful.

Opportunity ✨

Snackpass is one of the fastest growing marketplaces (a16z top marketplaces), and a top 100 YC company. We are backed by Andreeson Horowitz, Y Combinator, General Catalyst, First Round Capital, Craft Ventures and many others. We are hiring people who are humble and hungry to join us in any of our hubs (NYC, SF, LA) or remotely.

Our vision is to be the dominant platform for pickup, a $750B market globally.

About the Role

We are seeking a talented and experienced Senior Data Engineer to join our dynamic team. As a Senior Data Engineer, you will play a crucial role in building and maintaining data pipelines, developing and managing dashboards, and contributing to tool development. Your expertise will enable us to efficiently process and analyze large volumes of data, providing valuable insights to drive business decisions.

What we're looking for

4+ years of proven experience as a Data Engineer, with a focus on building robust data pipelines and maintaining data infrastructure.
Strong programming skills in languages like Python, Scala or Javascript, with a solid understanding of software engineering principles.
Hands-on Experience building or maintaining data pipelines with a modern orchestration tools like Airflorw/Prefect/Dagster
Strong expertise with SQL and non-SQL DBs, cloud-based data platforms (e.g., AWS, GCP) and their related services (S3, BigQuery, etc.).
Expert level writing of SQL for data manipulation, transformation and for analytics.
Experience building and maintaining interactive and intuitive dashboards using tools like Looker.
Comfortable with tool development, including building and enhancing internal data tools and frameworks.
Excellent problem-solving and analytical skills, with a strong attention to detail.
Effective communication skills, with the ability to collaborate with cross-functional teams and present complex ideas to both technical and non-technical stakeholders.

What you'll be working on

Build scalable and efficient data pipelines to collect, process, and transform large volumes of data from diverse sources.
Develop and maintain data models, ensuring data integrity and optimizing query performance.
Collaborate with stakeholders to understand their data requirements and provide the necessary infrastructure and support.
Build and maintain interactive dashboards and visualizations to enable data-driven decision-making across the organization.
Contribute to the development of internal data tools and frameworks, automating repetitive tasks and improving data accessibility and usability.
Stay up to date with the latest advancements in data engineering technologies and best practices, and proactively recommend improvements to our data infrastructure.
Mentor and provide guidance to junior data engineers, fostering a culture of learning and growth.

Cash Compensation for this role: $153,000 - $210,000

Please note: Final offer amounts are determined by multiple factors, including prior experience, expertise, and leveling. The final offer amount may vary from the amount above. Please note that this range does not represent additional compensation benefits (such as equity, 401K or medical, dental, or vision insurance).



What You Will Get From Us:

You will receive competitive compensation, a generous equity grant in a high-growth start-up, and benefits like healthcare, medical & dental coverage, unlimited PTO, a home office budget, wellness budget and more.

Importantly, you will also receive an unparalleled amount of ownership over the work you do here. We are a small team, so the opportunity to make a large impact, work on a broad spectrum of challenges and grow your personal skill-set awaits you here.

Finally, you will get a diverse and inclusive work environment where you will be surrounded by hungry and humble colleagues.

Snackpass is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. In fact, we are confident that the most inclusive and diverse teams accomplish the most extraordinary results.",-1,-1,$5 to $25 million (USD),-1,1 to 50 Employees,Unknown,True
Data Engineer,"Robinhood
","Menlo Park, CA",$122K - $144K (Employer est.),3.4,"Join a leading fintech company that's democratizing finance for all.

Robinhood was founded on a simple idea: that our financial markets should be accessible to all. With customers at the heart of our decisions, Robinhood is lowering barriers and providing greater access to financial information. Together, we are building products and services that help create a financial system everyone can participate in.

As we continue to build...

We're seeking curious, growth minded thinkers to help shape our vision, structures and systems; playing a key-role as we launch into our ambitious future. If you're invigorated by our mission, values, and drive to change the world — we'd love to have you apply.

About the team:

The preferred location for this position is in or around Robinhood's offices in Menlo Park, CA or New York, NY with in-office work capabilities, as may be required by management.

Robinhood is a metrics driven company and data is foundational to all key decisions from growth strategy to product optimization to our day-to-day operations. We are looking for a Data Engineer to build and maintain foundational datasets that will allow us to reliably and efficiently power decision making at Robinhood. These datasets include application events, database snapshots, and the derived datasets that describe and track Robinhood's key metrics across all products. You'll partner closely with engineers, data scientists and business teams to power analytics, experimentation, and machine learning use cases. We are a fast-paced team in a fast growing company and this is a unique opportunity to help lay the foundation for reliable, impactful, data-driven decisions across the company for years to come.

The role is located in the office location(s) listed on this job description which will align with our in-office working environment. Please connect with your recruiter for more information regarding our in-office philosophy and expectations.

What you'll do day-to-day:
Help define and build key datasets across all Robinhood product areas. Lead the evolution of these datasets as use cases grow.
Build scalable data pipelines using Python, Spark and Airflow to move data from different applications into our data lake.
Partner with upstream engineering teams to enhance data generation patterns.
Partner with data consumers across Robinhood to understand consumption patterns and design intuitive data models.
Ideate and contribute to shared data engineering tooling and standards.
Define and promote data engineering best practices across the company.
About you:
4+ years of professional experience building end-to-end data pipelines
Proven ability to implement software engineering-caliber code (preferably Python)
Expert at building and maintaining large-scale data pipelines using open source frameworks (Spark, Flink, etc)
Strong SQL (Presto, Spark SQL, etc) skills.
Experience solving problems across the data stack (Data Infrastructure, Analytics and Visualization platforms)
Expert collaborator with the ability to democratize data through actionable insights and solutions.
Bonus points:
Passion for working and learning in a fast-growing company.

The expected salary range for this role is based on the location where the work will be performed and is aligned to one of 3 compensation zones. This role is also eligible to participate in a Robinhood bonus plan and Robinhood's equity plan.

US Zone 1: $157000 - $185000
US Zone 2: $139000 - $163000
US Zone 3: $122000 - $144000

Base pay for the successful applicant will depend on a variety of job-related factors, which may include education, training, experience, location, business needs, or market demands. You can view comp zones for our US office locations in the table below. For other locations not listed, compensation can be discussed with your recruiter during the interview process.

Office locations (by comp zone)
US Zone 1: Menlo Park, CA; New York, NY; Seattle, WA; Washington, D.C.
US Zone 2: Denver, CO; Westlake (Dallas), TX; Chicago, IL
US Zone 3: Lake Mary, FL

Click here to learn more about Robinhood's Benefits.

Robinhood promotes diversity and provides equal opportunity for all applicants and employees. We are dedicated to building a company that represents a variety of backgrounds, perspectives, and skills. We believe that the more inclusive we are, the better our work (and work environment) will be for everyone. Additionally, Robinhood provides reasonable accommodations for candidates on request and respects applicants' privacy rights. To review Robinhood's Privacy Policy please visit Robinhood - US Applicant Privacy Policy. If you are an applicant located in the UK or EEA, please visit the Robinhood - UK/EEA Applicant Privacy Policy.",2013,Investment & Asset Management,Unknown / Non-Applicable,Financial Services,1001 to 5000 Employees,Company - Public,True
Data Engineer,"Jade Global
","San Jose, CA",$116K - $167K (Glassdoor est.),3.7,"ID: 6439 | 8-12 yrs | San Jose | careers

We are looking for a skilled Data Engineer with expertise in Salesforce and BigQuery to join our data team. The ideal candidate will be responsible for designing, developing, and maintaining data pipelines, ETL processes, and data integration solutions that leverage Salesforce and Google BigQuery. You will work closely with cross-functional teams to ensure the efficient flow of data, data transformation, and the availability of high-quality data for analytics and reporting.

Key Responsibilities:

Data Integration and ETL: Develop and maintain data integration solutions using Salesforce APIs and BigQuery for the extraction, transformation, and loading of data from various sources into a structured data warehouse.
Data Modeling: Create and optimize data models, data mappings, and data dictionaries to support ETL processes and ensure data integration aligns with business requirements.
ETL Pipeline Development: Design, build, and maintain ETL pipelines to move, transform, and load data from source systems into BigQuery, ensuring data consistency and accuracy.
Data Quality Assurance: Implement data quality checks, data validation, and error handling mechanisms to maintain the integrity of data during the ETL process.
Performance Optimization: Identify and resolve performance issues in ETL processes and data pipelines, working closely with database administrators to enhance data efficiency.
Collaboration: Collaborate with business analysts, data analysts, and stakeholders to understand data requirements and deliver solutions that meet business needs.
Documentation: Maintain comprehensive documentation of data pipelines, ETL processes, data models, and integration workflows, ensuring ease of understanding and future maintenance.
Monitoring and Support: Monitor data pipelines, diagnose and resolve issues, and provide support for production data integration systems.
Security and Compliance: Ensure data security and compliance with data governance policies, especially in the handling of sensitive Salesforce data.

Qualifications and Skills:

Bachelor's degree in Computer Science, Information Technology, or related field.
Proven experience as a Data Engineer with a focus on Salesforce and BigQuery.
Strong proficiency in Salesforce data integration, data modeling, and ETL development.
Expertise in Google BigQuery, SQL, and data warehousing concepts.
Problem-solving skills and attention to detail.
Excellent communication and teamwork abilities.
Ability to work independently and in a team.

Preferred Qualifications:

Salesforce certifications related to data and integration.
Google Cloud Platform (GCP) or BigQuery certification.
Familiarity with other data integration tools and cloud services.
Knowledge of business intelligence and reporting tools.
Experience with data governance and compliance practices.",2003,Information Technology Support Services,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,False
Data Engineer,Candid Health,"San Francisco, CA",$150K - $200K (Employer est.),-1.0,"The Role

At Candid Health, we’re searching for our first Data Engineer to design, build, and support our next generation of data infrastructure. As a key strategic investment for the company and product, you will be working on highly impactful and visible outcomes. This is an opportunity to get in at the ground floor of designing and building something exciting and new in a secure, durable, performant, and maintainable way with other top-tier talent. As the first Data Engineer at Candid Health, you will report to the Head of Engineering and will help to build out a world-class Data Team.


What You’ll Do

Collaborate with leadership, delivery, engineering, product, and customers: Collaborate with leadership and other stakeholders to understand Candid’s data needs. Work with product and engineering to understand the long-term product strategy and broader technical architecture. Work with customers to understand their needs and how best to address them in a scalable way.

Expansively own Data Engineering team outcomes: Deliver on Data Team outcomes for both internal teams and external customers, which include both operational and analytics workflows.

Lead design of new data infrastructure: Research and identify industry best practices and state-of-the-art tools to leverage. Design new systems to support the necessary outcomes in a secure, durable, performant, and maintainable way.

Build and support new data products: Build datasets, pipelines, and other solutions to support operational and product outcomes. Develop support systems to scale the team and achievable outcomes.

Who You Are

You have Bachelors of Science or Bachelors of Art in Computer Science, Computer Engineering, Math or other similar degree.

You have 4+ years of experience working with data pipelines, products, and tools.

You’ve built and maintained complex data integrations or pipelines.

You have well-developed opinions on modern data warehouse architecture, tools, and patterns.

You have excellent technical vision; you know the right architecture and patterns to build functional, durable, and maintainable product.

You have a customer-first and learner’s mindset, and value teaching others.

You make the right trade-offs when considering project scope, which corners are worth cutting, and which are not.

You’re a clear and concise communicator; you enjoy the challenge of explaining complicated ideas in simple terms, both in-person and in writing.

Experience with the technologies we currently use is a plus, but by no means required: Google Cloud Platform, BigQuery, PostgreSQL, Metabase, Terraform, Python.

What we do

We’re fixing one of the most broken and costly pieces of the US healthcare system: medical billing.

Today, healthcare providers spend over $250B each year on administrative overhead just to get paid by insurance. Medical billing is expensive because it’s nuanced and hard - maybe ~100x harder than credit card payment processing - and because it’s traditionally done by armies of humans who track and manage complex rules and processes specific to individual insurance companies with little or no supporting software. We’re rethinking medical billing from the ground up, building software backed by best-in-class data science (and, soon, a dash of machine learning) to automate much of this complexity so healthcare providers can get paid dramatically more easily and inexpensively.

We were in the Y Combinator W20 batch and have since been well funded by a world-class group of funds (8VC, First Round Capital, BoxGroup) + angel investors. We're now helping our customers treat opioid addiction, provide holistic care for women, lose weight, increase access to mental health care, and much more. This is such important and gratifying work; we can't wait for you to join our team and help support some of the most important innovation happening in healthcare today!

Our Values

We spend at least as much time with our coworkers as we do with our closest friends + family - if we intend to do the most important + challenging work of our lives, it’s important that these folks energize us, support us, inspire us, and push us to do our best work. This is what you can expect of your teammates at Candid (in no particular order):

We put our customers first

We take care of each other and ourselves

We anchor on outcomes and work relentlessly and creatively to achieve them

We collectively prioritize building a diverse and inclusive workspace

We believe humility is our greatest strength

We are candid, kind, and committed

We strive to be the most prepared person in the room

We are truth seekers

Pay Transparency

The estimated starting annual salary range for this position is $150,000 to $200,000 USD. The listed range is a guideline from Pave data, and the actual base salary may be modified based on factors including job-related skills, experience/qualifications, interview performance, market data, etc. Total compensation for this position may also include equity, sales incentives (for sales roles), and employee benefits. Given Candid Health’s funding and size, we heavily value the potential upside from equity in our compensation package. Further note that Candid Health has minimal hierarchy and titles, but has broad ranges of experience represented within roles.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Company - Public,True
"Software Engineer, Data","Parafin
","San Francisco, CA",$160K - $190K (Employer est.),4.7,"About Us:

At Parafin, our mission is to grow small businesses. Small businesses are the backbone of our economy, yet banks do not have their back. Parafin is a technology company that builds infrastructure which enables small businesses to get easy access to financial services via platforms they sell on.


Parafin's first product offers capital-as-a-service for online platforms. Parafin currently powers the capital programs of platforms ranging from Series B to post-IPO companies such as DoorDash, Amazon, and Worldpay. We are a tight-knit team of engineers and designers, coming from organizations such as Stripe, Square, Plaid, Coinbase, Robinhood, Affirm, Uber, and CERN, and are excited both about helping hundreds of thousands of small businesses grow and thrive, and building products that leaders at top companies have started to use every day.

We are backed by prominent venture capitalists such as Ribbit Capital, Thrive Capital, GIC, Index Ventures, Green Oaks Capital, and SV Angel.

About the Position:

We are looking for a software engineer to join our data platform team and help us set the foundations for the company. You will be responsible for designing, building, and maintaining our data platform, enabling data-driven decision-making across the company. You will also work with stakeholders to develop core data assets and workflows.

What You’ll Be Doing:

Design, build, and maintain scalable and reliable data pipelines, infrastructure, and services

Develop and maintain data models and data warehouses

Work with stakeholders (Data Science, Accounting, Product Eng) to understand their data needs and develop data solutions including ML models

Troubleshoot and resolve data platform issues.

Stay up-to-date on the latest data technologies and best practices.

What We’re Searching For:

2+ years of experience in data/ML development with a strong grasp of engineering fundamentals.

Experience with big data systems like Hadoop, Spark, Flink, and OLAP.

Experience with ETL, data warehouse, and data product development.

Experience with data governance and security best practices.

Experience with MLOps toolsets

Excellent problem-solving and analytical skills

Strong communication and collaboration skills

Passion for leveraging data/ML infrastructure to power product development

What We Offer

Salary Range: $160k - $190k

Equity grant

Medical, dental & vision insurance

Unlimited PTO & work from home flexibility

Commuter benefits

Free lunches

Paid parental leave

401(k)

Employee assistance program

If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please contact us.",2020,Financial Transaction Processing,Unknown / Non-Applicable,Financial Services,51 to 200 Employees,Company - Private,True
Data Engineer,"Sia Partners
","San Francisco, CA",$95K - $122K (Employer est.),3.9,"Company Description


Sia Partners is a next-generation consulting firm dedicated to creating state-of-the-art narratives for transformation and innovation and deploying them at scale. Our goal is to deliver superior value and tangible results to our clients as they navigate the digital revolution and achieve transformations which generate a positive impact. Our global footprint and expertise in more than 40 sectors and services allow us to enhance our clients’ businesses worldwide. We guide their projects and initiatives in strategy, business transformation, IT & digital strategy, and Data Science.


Why Join The Sia Village?

Excellence | Entrepreneurship | Innovation | Teamwork | Care & Support | Employee Wellbeing

These are the six core values that guide all our actions. As an expression of our values, our Sia Village concept describes our commitment to fostering a sense of community within and among our offices. We believe that knowledge sharing is the key, not only to innovation, but to the growth and development of our people.

Your experience at Sia Partners will be enriched by a(n):

Entrepreneurial journey
Career advocacy program that supports achieving professional development goals through guidance, and real-time feedback
Continuous learning & development opportunities
Diversity, equity, and inclusion programs with an ever-growing list of global affinity initiatives


Job Description


Sia Partners is looking for a talented Data Engineer to support our activities within the Data Science Business Unit. You will be working alongside with our Data Science consultants and our clients on Data Engineering topics, including creating relevant data models, developing powerful data pipelines, exposing them through various mechanisms including APIs, and using data visualization tools to efficiently present data.

You will also contribute to internal Data Science projects posted on Heka, our internal accelerator for Data Science projects. As part of the global Data Science team you will contribute to the development of various solutions designed to address our clients' needs.

Key Responsibilities

Partner with our client’s leadership teams, engineers, program managers and data analysts to understand data needs.
Design, build and launch efficient and reliable data pipelines transforming data into useful report ready datasets.
Communicate at scale, through multiple mediums: presentations, dashboards, client-wide datasets, bots and more.
Use your data and analytics experience to ‘see what’s missing,’ identifying and addressing data gaps, build monitors to detect data quality issues and partner to establish a self-serve environment.
Broad range of partners equates to a broad range of projects and deliverables, including ML Models, datasets, measurements, services, tools and process.
Leverage data and business principles to automate data flow, detect business exceptions, build diagnostic capabilities, and improve both business and data knowledge base.
Build data expertise and own data quality for your areas.


Qualifications

At least 4+ years' of advanced SQL experience (including at least one SQL DBMS and one noSQL).
4+ years' of Python development experience.
3+ years' of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).
3+ years' experience with Data Modeling.
Experience analyzing data to discover opportunities and address gaps.
4+ years' experience in custom ETL design, implementation and maintenance.
Experience working with cloud or on-prem Big Data/MPP analytics platform (i.e. SnowFlake, Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).
BSc/BA in Data Science, Computer Science, Engineering.

Additional Information


Compensation & Benefits

Salary + Annual Discretionary Bonus
Healthcare coverage that includes medical, dental, vision and life insurance policies
Generous time off
Parental leave paid at 100% of base pay for all new parents regardless of gender
Future Moms Program
9 Company Holidays + 1 Floating Holiday
401(k) matching
College save-up plan & college loan repayment plan
Monthly cell phone stipend
Commuter Benefits
Gym Reimbursement through firm medical plan

Compensation Information:

California compensation for this role is between $94,500 to $122,000 per year. Actual compensation within that range will be dependent upon the individual’s skills, experience, qualifications, and market location.

Work Authorization & Sponsorship

At this time, Sia Partners does not intend to pursue employment with applicants who require/will require sponsorship for work authorization in the United States (i.e., H1-B visa, F-1 visa (OPT), TN visa, or any other non-immigrant status). Applicants for employment must have work authorization that does not now or in the future require sponsorship of a visa for work authorization.

Hybrid Workplace Guidelines

Sia Partners maintains its hybrid workplace arrangements and provides a flexible workplace environment that is driven by client and business/market needs. At this time, in person requirements are issued by departments (Business Unit/Business Line) and vary by office location. Consultants are expected to have the ability to be flexible with work location depending on business needs and live within a reasonable distance to the office.

Our Commitment To Diversity

Diversity, equity, inclusion, and belonging (DEIB) are part of Sia Partners’ DNA. Thanks to our expertise in several sectors and our international growth, our teams include a variety of experiences and cultures. We’re confident that promoting DEIB creates an environment in which everyone can reach their full potential.

Our global network, DEIB@Sia Partners, brings together our people worldwide to facilitate local and global progress, focused on the following areas:

Gender equality (global Gender Equality Index score of 91/100 for FY19-20)
LGBTQ+
Race & Ethnicity
Working Parents
Disabilities

Sia Partners is an equal opportunity employer. All aspects of employment, including hiring, promotion, remuneration, or discipline, are based solely on performance, competence, conduct, or business needs.


To learn more about our mission, values, and business sectors, please visit our website.

Sia Partners is an equal opportunity employer. All aspects of employment, including hiring, promotion, remuneration, or discipline, are based solely on performance, competence, conduct, or business needs.",1999,Business Consulting,$100 to $500 million (USD),Management & Consulting,1001 to 5000 Employees,Company - Private,True
Data Engineer,Probably Genetic,"San Francisco, CA",$127K - $195K (Employer est.),-1.0,"About Probably Genetic

Probably Genetic is changing the lives of patients living with severe, complex diseases. Our data platform is used by drug developers and patient advocacy groups to develop and launch treatments for these patients. Our technology discovers undiagnosed patients online, analyzes their disease state using machine learning and at-home testing, and enables compliant communication with patients. In doing so, we help patients access diagnoses, clinical trials, and treatments as early as possible.

We are a tight-knit group of hard-working, ambitious problem solvers united by a mission greater than ourselves.

We do well by doing right by patients. Our annually recurring revenue is growing >6x year over year, we’re profitable, and our roadmap is packed with innovations in bioinformatics, machine learning, and drug development. We are building an all-star team to help us bring our vision to life, and we want you to be a part of it.

Probably Genetic has raised multiple rounds of funding from Silicon Valley’s best investors, including Threshold, Khosla, and Y Combinator, giving us the ability to pay competitive salaries, offer great benefits, and provide meaningful equity. We’re dedicated to ensuring your journey with us is unforgettable, with incredible team retreats to places like Barbados, the Alps, Mexico, Costa Rica, and Portugal, just to name a few.

About the role

We are looking for a Data Engineer to build data pipelines and visualizations for key business metrics, machine learning (ML) models, and growth metrics to enable our data-driven organization.

What you will do

In this role, you will have the unique opportunity to use data to provide life-changing services, including genetic tests, to patients living with severe, complex diseases. This involves building data infrastructure to assess patient acquisition channel quality, ML training pipelines, and dashboards for business metrics driving all company decisions. You will own pipelines end-to-end while building beautiful visualizations and dashboards. You will play a pivotal role in enabling Probably Genetic to use our data to grow the business.

You will drive the Probably Genetic data infrastructure by:

Collaborating with stakeholders in Business Development, Growth, Product, ML and Finance to design data visualizations and pipelines

Developing ETL pipelines from a PostreSQL database using Python Django and AWS services such as S3, Glue, and Athena

Integrating with external data sources such as Meta and Google Ad platforms, product analytics platforms, and financial platforms to extract valuable data and insights

Developing visualizations in a business intelligence (BI) tool of your choice to create reports and dashboards

You will collaborate internally to achieve data and company goals by:

Collaborating directly with the CEO and executive team on investor updates using data from BI reports and dashboards

Identifying missing data points which should be collected and working with the engineering team to collect all valuable data

Writing documentation to onboard team members to BI tooling and ensuring that datasets are available for ad-hoc analysis

Who you are

What will help you succeed in this role:

5+ years of relevant experience in data engineering

Experience using Python and SQL for ETL pipelines and data analysis

Experience in data reporting and dashboarding using variety of BI tools

Track-record of solving extremely difficult, ambiguous problems

Some things that are not required, but you will learn on the job:

Experience in contributing to a Python Django backend

Expertise with healthcare data, bioinformatics, ML infrastructure, or growth marketing

As with all new hires at Probably Genetic, you will also need to be:

A good person. We work with some of the most marginalized populations on the planet and empathy is key

Patient-focused and motivated to have a lasting, positive impact on humanity

Comfortable in a fast-paced, often ambiguous environment with rapid change

Action-oriented and excited to build a company from the ground up

The salary range for this role is $127,000-$195,000 annually. Actual compensation offered will depend on several factors including but not limited to: work experience, education, skill level, and/or other business and organizational needs.

What we offer at Probably Genetic:

An engaging and supportive team

30 days of vacation a year

Hybrid, flexible work

A “work from anywhere” policy, up to 4 weeks a year

Competitive equity grants

All-expenses paid quarterly team retreats

Benefits including medical and vision

This is a hybrid role that will require working on-site 3 days a week in San Francisco. Local candidates only. Relocation is not offered for this role.

Probably Genetic is committed to fostering a welcoming and inclusive work environment for people of all genders, sexuality, ethnicity, socioeconomic background and life experiences. We urge candidates of all backgrounds to apply. If you require specific accommodations as you interview or consider working with us, please let us know.

Compensation Range: $127K - $195K",-1,-1,-1,-1,-1,-1,True
Senior Data Engineer,"Skechers
","Manhattan Beach, CA",$130K - $175K (Employer est.),3.5,"Company Description


Headquartered in Southern California, Skechers has spent nearly 30 years helping men, women and kids everywhere look and feel good. Developing comfort technologies is at the foundation of all that we do—delivering stylish, innovative, and quality products at a reasonable price. From our diverse footwear offering to a growing range of apparel and accessories, Skechers is a complete lifestyle brand.

With international business representing over half of our total sales, we have product available in more than 170 countries and significant opportunities for continued expansion worldwide. We sell our collections direct to consumers through more than 4,000 Skechers stores around the globe and Skechers e-commerce sites, as well as through a network of third-party partners.



Job Description


Are you excited about high performance Big Data environments? Then great! The Data Engineering team is growing, and we need Data Engineers who are thorough and agile, capable of breaking down and solving problems, and have a strong will to get things done. In the Data Engineering team, you will work on real-world problems working on-premise or multi cloud tech stack where reliability, accuracy and speed are paramount, take responsibility for your systems end-to-end and influence the direction of our technology that impacts customers around the world. We are looking for a Senior Data Engineer with both conceptual and hands-on experience working on structured/semi structured/complex data processing and streaming frameworks, RDBMS, and NoSQL data stores. As a member of our Data Services team, you will be a member of a service group responsible for continuing organizational expansion of our data processing projects. Ideal candidate must be enthused about all spectrum of data development, including data transport, data processing, data warehouse/ETL integration, quick learning, and self-starting. This position includes 24x7 production support.

Responsibilities

Collaborate with data stewards, data architects, and data engineers to design, implement and deliver successful data solutions.
Drive engineering best practices, set standards and propose larger projects which may require cross-team collaboration.
Define technical requirements and implementation details for the underlying data lake, data warehouse and data marts involved in the design and implementation of full cycle of data services, from data ingestion, data processing, ETL to data delivery for reporting.
Identify, troubleshoot, and resolve production data integrity and performance issues.
Design, develop and support various data platform applications.
Design and develop applications to process large amounts of critical information in batch and near real-time to power business insights.
Demonstrate ability to mentor junior engineers.
Proficiency in leading meetings and facilitating discussions.
Strong self-starter with capability to drive initiatives independently with minimal oversight.


Qualifications

Experience in managed services for data ingestion/processing with hands on experience working in AWS environment and operational experience of Kinesis/Kafka, S3, Glue and Athena.
Experience with the following data processing technologies: Spark, Kafka, Kinesis
A solid understanding of NoSQL data stores with extensive experience in working with SQL, script languages (Python, shell etc.)
Proven experience of distributed systems driving large-scale data processing and analytics Expertise with RDMS and Data Warehousing (Strong SQL)
Experience working with BI and data warehousing tools building data pipelines and real-time data streams.
Experience with Linux KSH/bash scripting and java
Experience working with any one of ETL toolsets: Talend, Informatica
Experience with any of the following message / file formats: Parquet, Avro, ORC Protobuf
Excellent communication and presentation skills (verbal, written, presentation) across all levels of the organization.
Ability to translate ambiguous concepts into tangible ideas.
Experience with version control systems like Git
Proficient in writing technical specifications and documentation.

Plus

Experience with Presto, Hive, Impala or similar SQL based engine for Big Data
Experience with Cassandra, MongoDB, or similar NoSQL databases.
Experience with Scala, Nodejs

Work Experience

10+ years of experience defining, designing, and delivering data pipelines and solutions.
8+ years of experience working with Linux based operating systems.
6+ years relevant experience developing and integrating frameworks and database technologies that support highly scalable data processing.
5+ years of programming experience with Python
3+ years documented experience in a data engineering role on a variety of big data projects.
3+ year experience with cloud-based data warehousing systems (e.g., AWS Redshift, Snowflake, Google Big Query)
Proficient in any flavor of SQL
Demonstrable ability in data modeling, ETL development, data warehousing, batch, and real time data processing
Demonstrable experience with Stream Processing and workload management for data transformation, augmentation, analysis, etc.

Job-Related Education

B.S. in Computer Science, Computer Information Systems, Engineering, or another technical field, or equivalent work experience.


Additional Information


To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The skills, abilities and physical demands described are representative of those duties that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodation may be made to enable individuals with disabilities, who are otherwise qualified for the job position, to perform the essential functions.

PHYSICAL DEMANDS-

While performing the duties of this job, the employee is regularly required to stand; use hands to finger, handle, or feel, and talk or hear. The employee frequently is required to walk; sit, reach with hands and arms, and stoop, kneel. The employee is occasionally required to sit for long period of times.

All your information will be kept confidential according to EEO guidelines.

The salary range for this position is $130,000-$175,000.",1992,"Department, Clothing & Shoe Stores",$5 to $10 billion (USD),Retail & Wholesale,5001 to 10000 Employees,Company - Public,False
Data Engineer,"Retool
","San Francisco, CA",$104K - $164K (Glassdoor est.),3.7,"ABOUT RETOOL:

Nearly every company in the world runs on custom business software: Gartner estimates that up to 50% of all code is written for internal usage. This is the operational software for refunding orders, underwriting loans, moderating content, managing marketplaces, rolling out new features, onboarding employees, analyzing transactions, providing customer support…the list is nearly endless. For most companies, building and maintaining all of these tools demands a lot of engineering time—scarce, expensive resources better put to use on customer-facing products.


At Retool, we're designing a new type of development environment that makes it dramatically faster and easier to build all of this software. Retool unifies the ease of visual programming with the power of code, while abstracting away the tedious and repetitive tasks of development. We believe that the future of software development lies in being a force multiplier for developers and technical builders, helping them move considerably faster and build a lot more software. It's akin to a new version of Visual Basic, HyperCard, or Flash—with a bit of Figma and some future-of-programming vibes thrown on top. Today, our customers span from small startups building their first operational tools, to Fortune 500 companies building mission-critical apps for thousands of users across their business.

WHY WE'RE LOOKING FOR YOU:

Retool is a fast-growing company with quickly evolving business needs. We're looking to hire engineers to help us build out our data ecosystem to serve the needs of our business today and for broader scale years from now. We're looking for someone who is ready to get their hands dirty, is motivated by having an impact on the business, and is constantly curious. This is the right role for someone who thrives while making sense of the blurry space that is data at a high growth startup.

WHAT YOU'LL DO:

You'll design and build a foundation that strengthens Retool's data culture at scale. You'll take on projects that solidify Retool's reporting capabilities and help the company remain data-driven. You'll develop and scale ingestion infrastructure, optimize our ETLs, and design our data architecture for scale, with a keen eye for data warehouse management and tooling. You'll also take on ownership of our data stack to ensure that your teammates are able to access the data they need to make decisions and technical teams are able to quickly implement events. We've already built out a solid stack on top of Segment, Databricks, DBT, and of course, Retool, but we need your help to ensure it scales with the company as our user base grows.

WHO YOU'LL WORK WITH:

You'll work with stakeholders across the business, including data scientists, finance, marketing, engineering, product, operations, and support. You'll be joining a broader team of Retools who are passionate about serving our customers, enjoy collaborating to build an incredibly innovative product, and enjoy swapping stories. If this sounds like you, we'd love to hear from you!

IN THIS ROLE, YOU'LL:

Architect and scale a modern data platform that will be used internally by all of Retool
Build and maintain scalable ETL pipelines to efficiently process and transform large volumes of data from source systems into our data warehouse
Work with our engineering teams to ensure robust instrumentation across areas of the product
Partner with business stakeholders to synthesize and develop requirements for core tables
Implement monitoring and observability to guarantee data quality and consistency
Articulate and implement best practices around ingestion frameworks and data pipeline development

THE SKILLSET YOU'll BRING:

Background in Data Engineering, 5+ years of experience building and maintaining scalable data infrastructure, including distributed processing solutions (e.g. Spark), cloud-based data lakes and warehouses (e.g. Databricks, Snowflake, BigQuery), workflow management (e.g. Airflow, Luigi), and data transformation tools (e.g. DBT)
Experience using Infrastructure as Code (IaC) to automate data infrastructure provisioning and management (i.e. Terraform)
Experience implementing and defining best data practices at scale
Experience proactively identifying opportunities to improve ETL & dashboard performance and cost
Excellent business acumen with the ability to translate stakeholder requirements into data models
Proficiency with common git workflows and at least one programming language (e.g. Python, Scala, Java)
A solution-oriented growth mindset. You'll need to be a self-starter and thrive in a dynamic environment
A bias towards communication and collaboration with business and technical stakeholders
Quantitative rigor and systems thinking

Retool offers generous benefits to all employees. For more information, please visit the benefits and perks section of our careers page!

At this time, Retool is only set up to employ in the US and UK.",2017,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,201 to 500 Employees,Company - Private,True
Senior Data Engineer,Second Dinner,California,$130K - $210K (Employer est.),-1.0,"Who We Are

Second Dinner is an award-winning independent game development studio that is here to make the most fun games in the world. Not super fun games. Not SUPER DUPER fun games. We mean the MOST fun games. In fact, our game MARVEL SNAP has earned multiple Mobile Game of the Year Awards (Game Awards, DICE), Best Strategy Game (IGN), and the Apple Design Award for Innovation!

Second Dinner is a remote-first studio, so while we are headquartered in Irvine, California, most of our team is fully remote across the United States. We want the most talented teammates wherever they call home. A diverse team with varied perspectives makes us a better company and will help us make better games. If you can bring something new to the table and expand our point of view, that's a huge upside.

Our Data Team

At Second Dinner, data plays a crucial role in conveying the voices of our players and informing our decisions, which leads us to great games and player experiences. Our team enables decision-making with scientific and methodological rigor for Marvel SNAP and our new projects. We partner with teams across the studio to build data-powered player experiences directly into the games. We innovate in analytics tooling and data engineering capabilities to redefine what is possible in game development and operations.

Your Role

You will report to the Data Engineering Lead. You will play a critical role in shaping data-driven insights across our organization. You will develop and operate data pipelines to empower analytics, data science, marketing, product management, and design teams to create incredible player experiences. You will build and operate large-scale cloud data infrastructure. You will collaborate with cross-functional teams to ensure the collection and serving of timely high-quality data. Moreover, you will partner with the AI team to innovate in self-service analytics tools. If you are passionate about building high-impact core capabilities to help craft world-class game experiences and are excited to influence millions of players by leveraging your expertise in data engineering, then APPLY!!!


What You'll Do:

Develop and operate data infrastructure and pipelines to enable robust data for analytics and reporting in Marvel SNAP

Empower the SNAP Marketing team with high-quality data to improve user acquisition (UA)

Enable SNAP Product Management, Analytics, Design, Engineering, and Production teams to gain insights from analytics quickly

Partner with data scientists, analysts, and software engineers to ensure high-quality and relevant data collection

Partner with the AI team to innovate, develop, and operate self-service analytics tooling


What You’ll Need:

Extensive expertise with data infrastructure and data engineering

Demonstrated experience in large-scale distributed data systems (Spark, Flink)

Deep expertise in analytical database technologies (SQL and NoSQL)

Proficiency in SQL and Python

Experience with database technologies and ETL/ELT

Experience with orchestration and automation tools (Airflow, Beam)

Experience with Looker or Tableau

Familiarity with Databricks and data/analytics solutions on AWS

Experience with marketing platforms and data tools (Braze, AppsFlyer)

Demonstrated success in a highly collaborative cross-functional work environment

Passionate player of mobile games

Mindset for serving a diverse and global player base

Nice to Have But Not Necessary:

Experience working in online video games, preferably mobile free-to-play games

Experience in .NET/C# and backend software development

Experience in building and integrating data pipelines for customer-facing live services (e.g., recommenders)

Experience in operational database and storage technologies (e.g., DynamoDB, Cassandra, and Redis)

The total compensation for this position includes a new hire offer base salary range of $130,000 - $210,000 USD + equity + comprehensive benefits + potential for discretionary performance bonuses.


Individual pay within this salary range may span multiple levels within the discipline and is determined by assessed job-related skills, experience, relevant education or training. It also factors in market demands and business needs. The disclosed range is not adjusted based on location and may be subject to change or modification based on business needs in the future. Your recruiter can answer any questions about new hire total compensation during the hiring process.


An overview of the benefits and perks at Second Dinner:

Medical, Dental, and Vision insurance plans with Second Dinner paying 100% of premiums for employees and 75% for dependents for many plans

401(k) contribution with no waiting period

16 weeks paid parental leave with no waiting period

Home office improvement bonus

Paid Vacation & Sick time

Remote-first with core overlap hours between 10AM and 4PM PT

Company Winter Holiday shutdown (Dec 25-Jan 1)

Company Summer Holiday shutdown (week of July 4)

Company Events - In-person Summer all-hands gathering, in-person holiday party, annual camping event, and virtual events throughout the year


We are an equal opportunity employer that places high value on diversity and inclusion. We do not discriminate on the basis of race, color, ancestry, national origin, religion, age, disability status, sex (including pregnancy), gender, gender identity, gender expression, sexual orientation, medical condition, genetic information, marital status, military status, or veteran status.


You must be eligible to work in the United States to be considered for this position.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,False
Senior Data Platform Engineer,"Mendel
","San Jose, CA",$126K - $178K (Glassdoor est.),4.3,"At Mendel, we harness AI to revolutionize healthcare. Our ambition is to ensure every patient's journey informs healthcare decisions, optimizing treatment plans and promoting drug discoveries. Through comprehensive analysis of patient health records, we aspire to deliver timely and precise care. If you share our zeal for healthcare advancement through technology, let's reshape the future together.

About Mendel:

At Mendel, we are enabling different stakeholders in healthcare to make better decisions by learning from every patient's journey— from a physician deciding on the best treatment for a patient to a pharma company discovering the next blockbuster drug. In creating depth and breadth for a patient's health record journey, Mendel enables the right care to be delivered at the right time to the right person. This is an incredible opportunity to join a unique vision to improve healthcare using AI technology.

About the Role:

We seek a highly skilled and experienced Data Platform Engineer to join our dynamic team. The ideal candidate will have a strong background in designing, building and maintaining AI/ML platforms for scale and resiliency.

Responsibilities:

Design, develop, and maintain an AI/ML platform to enable the AI to build LLM, Bert, and other models.
Build robust ML training and inference pipelines using MLFlow, Kubeflow, Ray, and Spark.
Ensure the performance, quality, and responsiveness of the models.
Collaborate with cross-functional teams to define, design, and ship new features.
Continuously discover, evaluate, and implement new technologies to maximize development efficiency.

Qualifications:

Bachelor's degree in Computer Science, Statistics, Mathematics, or a related field. Advanced degrees are preferred.
Minimum of 5 years of experience in building and maintaining AI/ML platforms using Kubernetes, MLFlow, Kubeflow, Ray, and Spark.
Strong knowledge of machine learning frameworks, libraries, data structures, data modeling, and software architecture.
Good understanding of machine learning algorithms, processes, tools, and platforms.
Experience with cloud services (GCP, AWS, Azure). Cloud-agnostic deployment experience is highly encouraged.
Excellent problem-solving skills and ability to work in a team environment.

Preferred Skills:

Experience with startup environments and agile development methodologies.
Strong communication skills with the ability to explain technical concepts to non-technical audiences.
Knowledge of data streaming technologies (e.g., Apache Kafka).
Experience with data visualization tools (e.g., Tableau, Power BI).
Certification in relevant data engineering technologies.

In this role, you will play a critical part in shaping our data infrastructure and ensuring that data is available, reliable, and ready for analysis. Your expertise in data engineering will contribute to our organization's data-driven decision-making and overall success.

Why should you join our team:

Benjamin Franklin once said: ""If you would not be forgotten as soon as you are dead, either write something worth reading, or do something worth writing."" — at Mendel you can do the latter. There are two things more devastating than learning that you or your loved ones have a terminal illness; getting the wrong treatment or not finding any. At Mendel, we are on a sincere mission to solve many never-solved-before technology challenges that can enable prescribers and drug makers to do their best

Mendel is a very collaborative environment. You will be taking ownership of your work and collaborate directly with different teams to see it going into production and used by customers. At the same time, you will be mentored by world class AI scientists, software engineers, and clinical and business leaders.

Why should you join our team:

At Mendel, we believe in the transformative potential of technology. We offer a dynamic and rewarding work environment, competitive compensation, and comprehensive benefits. If you share our passion for innovation and making a difference in healthcare, Mendel could be the place for you. Join us as we work to improve the future of healthcare.

Mendel is a very collaborative environment. You will be taking ownership of your work and collaborate directly with different teams to see it going into production and used by customers. At the same time, you will be mentored by world class AI scientists, software engineers, and clinical and business leaders. Hear from our team here.",2017,Internet & Web Services,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,True
Data Engineer,"Crimson Wine Group LTD
","Napa, CA",$90K - $95K (Employer est.),4.1,"At Crimson Wine Group, we are the guardians of 1,000 acres of pristine vineyards, iconic estates, forests, and wildlife habitats along the West Coast. Our enviable portfolio of brands includes Pine Ridge Vineyards (Napa, Calif.), Seghesio Family Vineyards (Healdsburg, Calif.), Archery Summit (Dayton, Ore.), Chamisal Vineyards (San Luis Obispo, Calif.), Double Canyon (West Richland, Wash.), Seven Hills Winery (Walla Walla, Wash.) and Malene Wines (Santa Barbara County, Calif.).

We are committed to creating a workplace and culture that celebrates diversity, equity, and inclusion as part of what makes us a little different and a lot better. Our success is informed by the wide range of experiences and perspectives that our team brings to each of our wines – from vine to bottle and beyond. We encourage all applicants with a vision for creating a more equitable, inclusive, and diverse wine industry to apply to join our team. For more information, please visit www.crimsonwinegroup.com.

Position Summary

As a member of the IT team, the Data Engineer will take the lead role in designing, implementing, and maintaining data systems and data-related processes that support internal business teams, customers, and partners. Your realm includes data warehouses, databases, integrations, analytics/reporting tools, data wrangling/remediation, and associated processes. The right individual has experience in all stages of database project work (requirements gathering, logical and physical design, implementation, testing, and deployment) and expertise in the technologies needed to implement robust data warehouse and business intelligence solutions. We are seeking someone who is passionate about answering questions with data and has the ambition to help take our team and the company to the next level. Because CWG is in a regulated environment, a strong understanding of compliance and security controls is key.

Essential Duties & Responsibilities

The following reflects management’s definition of essential functions for this job but does not restrict the tasks that may be assigned. Management may assign or reassign duties and responsibilities to this job at any time due to reasonable accommodations or other reasons.

Collaborates with IT and business stakeholders to design and implement data warehouse, reporting/analytics, and integration solutions that align with the technology roadmap and data architecture.
Defines, documents, and socializes procedures and standards to ensure data handling meets objectives for data quality, business process enablement, and compliance. Designs and builds workflows, tools, integrations, and data structures to improve data accuracy, availability, and usability.
Identifies, designs, and implements internal process improvements such as automating manual processes and optimizing data delivery.
Leverages integration platforms and services to assemble complex data sets that meet end user and business requirements. Builds analytical tools to provide actionable insights from key business performance metrics.
Designs, implements, and maintains integrations with internal and 3rd party systems. Monitors and ensures timely data flows related to business facing solutions, CRM, ERP, and other SOX applications in CWG’s environment.
Establishes and maintains procedures, FAQs, SOPs, and other documentation required for internal/external audits and end user support.

Qualifications

Bachelor’s degree in business, finance, economics, technology, computer science, statistics, analytics, data science, or mathematics preferred; equivalent work experience will be considered.
3+ years of experience in a similar role
The ability to be well organized and to perform with minimal supervision in a remote work environment while maintaining high attention to detail is essential.
Demonstrated ability to successfully manage multiple projects and workflows.
Hands on experience with:
Microsoft Azure data, storage, and integration services, including Azure Data Lake, Azure SQL Database, SSIS, PowerBI
Modern data warehouse platforms (e.g., Azure, Snowflake)
Integration platforms (e.g., MuleSoft, WebMethods, Celigo, Informatica)
Programming languages (e.g., Python, R, SQL)
Web APIs (e.g., SOAP, REST, OData)
Service-oriented personality, positive attitude, a passion for data and delivering creative solutions.
Excellent interpersonal and communication skills and the ability to work well with all levels of personnel.
Experience working in a regulated (e.g., SOX) environment preferred.


All applicants will receive consideration for employment without regard to all federally and state protected classes. If you require assistance to participate in the application process, please contact us at HR@Crimsonwinegroup.com.

The projected (base) pay range for this position is $90k to $95k per year in addition to the annual bonus. This is the projected compensation for the position however the actual compensation offered may vary based on job-related factors such as (but not limited to) candidate qualifications, related experience and education, candidate work location and market data. Crimson Wine Group reserves the right to modify the pay range/rate at any time in the future.",-1,Food & Beverage Manufacturing,$25 to $100 million (USD),Manufacturing,51 to 200 Employees,Company - Public,True
Senior Data Engineer,"Adobe
","San Jose, CA",$119K - $233K (Employer est.),4.4,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

We are looking for a senior data engineer who can design, build, and maintain scalable and reliable data pipelines and solutions using Databricks lakehouse platform and web data sources. You will work closely with our data scientists, analysts, and marketers to deliver data-driven insights and recommendations that drive our business growth and customer satisfaction.

Responsibilities:
Develop, test, and deploy data pipelines and ETL processes using Databricks, Spark, SQL, Python, and other tools
Extract, transform, and load web data from various sources such as Google Analytics, Google Ads, Facebook Ads, etc. using APIs, web scraping, or other methods
Design and implement data models and schemas that support our analytical and reporting needs
Optimize and monitor the performance, reliability, and quality of our data lakehouse architecture and solutions
Troubleshoot and resolve data issues and ensure data integrity and security
Collaborate with cross-functional teams to understand their data requirements and provide technical guidance and support
Research and evaluate new technologies and best practices to improve our data engineering capabilities

Qualifications:
Bachelor’s degree in Computer Science, Engineering, or related field
7+ years of experience in data engineering or related roles
Proficient in Databricks, Spark, SQL, Python, and other data engineering tools and frameworks
Experience in working with web data sources such as Adobe Analytics, Google Analytics etc.
Experience in designing and building data lakehouse architectures and solutions using cloud platforms such as AWS, Azure, or GCP
Experience in applying data quality, governance, and security standards and practices
Strong analytical and problem-solving skills
Excellent communication and collaboration skills
Our compensation reflects the cost of labor across several U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $119,000 -- $232,700 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.

At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).

In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.

Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.

Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees.",1982,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Network Data Engineer,"eTeam Inc.
","Los Angeles, CA",$45.00 - $50.00 Per Hour (Employer est.),4.1,"Job Description:
Certified in Networking CCNA, CCNP (A MUST)
Experience in Cisco, Aruba wireless, Palo Alto
Primary skills in Networking, Routing & Switching.
Arista Experience- Experience with Multicas t, VRF, BGP-EVPN, VXLAN and Spine & leaf architecture
Experience working on Cisco ASA firewalls
Experience in Infoblox -DNS, DHCP related
Palo Alto firewalls experience is required
Aruba Clearpass knowledge (good to have)
Should have experience working in datacenter environment",1999,Staffing & Subcontracting,$100 to $500 million (USD),Human Resources & Staffing,5001 to 10000 Employees,Company - Private,True
Data Engineer 4,"NextDeavor, Inc.
","San Jose, CA",$80.00 - $84.50 Per Hour (Employer est.),4.5,"Data Engineer 4
12+ Month W2 Contract
San Jose, CA, Open to remote candidates in PST & CST timezone

Benefits You’ll Love:
NextDeavor offers health, vision and dental benefits for contract employees.
You’ll be eligible to receive Paid Sick Leave (Amount varies per state).
Own the opportunity to get your foot in the door at a well-established corporation, with the likelihood of extension or conversion to full time employment (NextDeavor’s conversion rate is approximately 70%!)

Become a key player as a Data Engineer:
We are seeking a highly skilled Senior Data Engineer to join our dynamic team at Adobe. The ideal candidate will be responsible for designing and implementing data solutions, ensuring their scalability, availability, and maintainability. The Senior Data Engineer will play a crucial role in building and optimizing data pipelines and architectures for our cutting-edge products and services.


Here’s how you’ll make an impact on the team:

Build and continuously optimize data architecture to address the evolving data needs of our rapidly growing business.
Own the data mapping, business logic, transformations, and data quality in collaboration with business partners such as Sales Operations, Finance, Field Sales, Data Engineering teams.
Continuously architect, build, and launch new data models (single source Sales Operations
Design and implement data pipelines to ETL/ELT data from multiple sources into a central data warehouse/repository.
Write sophisticated and efficient code to transform raw data sources into easily accessible models by coding across several languages and tools such as SQL, Python, Spark, Databricks, Airflow, Azure, AWS, etc.
Partner closely with data analysts, data scientists, data engineering, product marketing & Sales Operations teams across B2B to anticipate the next steps in evolving data architecture.
Become the go-to person for data expertise in the broader B2B Field Analytics Team and own data quality for the pipelines and data models we create.
Provide thought leadership to B2B Team by actively mentoring teammates in standard methodologies to self-serve using the most efficient code and techniques.
Develop and implement data governance procedures to ensure data security, privacy, and compliance.
Participate in architecture discussions, influence the data solution roadmap, and take ownership and responsibility over new projects.
Design, architect and build data insight dashboards and visualizations.

Here’s what you’ll need to be successful in this role:

B.S. or M.Sc. or Ph.D. in an analytical field: statistics, applied mathematics, computer science, engineering, economics, physics, etc., or equivalent practical experience
5+ years of proficiency in Python and SQL
3+ years of expertise with modern data science workflows on the cloud (Git, Jupyter, Python, AWS, Azure)
Strong proficiency in writing complex queries and manipulating large datasets using SQL-like languages on the cloud - SQL, Python, Spark, Databricks, Airflow, Azure, AWS, etc.
Proficiency in ML/Data Science/Statistical Modeling languages such as Python, R to build Propensity Models, Customer Segmentation, Churn Scores, Forecast Models etc.
Proficiency in ETL/ELT
Experience with design, development, and implementation of highly scalable, high-volume data architectures, source of truth systems for different business areas, developing and maintaining in an agile environment
Strong fundamentals in Quantitative and Statistical methods as well as demonstrated proficiencies in data visualizations like Power BI / Tableau
Strong Project Management, Communication, Leadership skills to support multiple ongoing projects in a fast-paced environment

Here’s what else might help you out:

Experience crafting dashboards in Power BI and/or Tableau
Expert in one or more data science tools such as Pandas, NumPy, etc.
Experience with Databricks
Experience with building effective Presentations for all levels
Experience building data processing machine learning models in a production environment
Familiarity with ML for propensity estimation and causal inference with observational data or experimental designs

Pay Range:
$80.00 - $84.50/hour

Ready to make your mark? Take the leap and apply directly here: <https://j.brt.mv/jb.do?reqGK=27715319&refresh=true> – your application is in good hands.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,True
Experienced Data Engineer - Data Engineering,"Plaid
","San Francisco, CA",$187K - $281K (Employer est.),4.2,"We believe that the way people interact with their finances will drastically improve in the next few years. We’re dedicated to empowering this transformation by building the tools and experiences that thousands of developers use to create their own products. Plaid powers the tools millions of people rely on to live a healthier financial life. We work with thousands of companies like Venmo, SoFi, several of the Fortune 500, and many of the largest banks to make it easy for people to connect their financial accounts to the apps and services they want to use. Plaid’s network covers 12,000 financial institutions across the US, Canada, UK and Europe. Founded in 2013, the company is headquartered in San Francisco with offices in New York, Washington D.C., London and Amsterdam. #LI-Hybrid

Making data-driven decisions is key to Plaid's culture. To support that, we need to scale our data systems while maintaining correct and complete data. We provide tooling and guidance to teams across engineering, product, and business and help them explore our data quickly and safely to get the data insights they need, which ultimately helps Plaid serve our customers more effectively. In addition, Plaid will not be successful if we can't move quickly. We build the data systems and tools that enable everyone at Plaid to be data-driven, making analytics easy, obvious, and proactive across the company.

Data Engineers heavily leverage SQL and Python to build data workflows that integrate with our Golang and Typescript applications. We use tools like DBT, Airflow, Redshift, ElasticSearch, Atlan, and Retool to orchestrate data pipelines and define workflows. We work with engineers, product managers, business intelligence, data analysts, and many other teams to build Plaid's data strategy and a data-first mindset. Our engineering culture is IC-driven - we favor bottom-up ideation and empowerment of our incredibly talented team. We are looking for engineers who are motivated by creating impact for our consumers and customers, growing together as a team, shipping the MVP, and leaving things better than we found them.

You will be in a high impact role that will drive and define data standards and data culture across Plaid. You will have the opportunity to transition into the Tech Lead role on the team which will come with higher visibility and more stakeholder collaboration. You will collaborate with and have strong and cross functional partnerships with literally all teams at Plaid from Engineering to Product to Marketing/Finance. You will be responsible for mentoring junior engineers on the team and being closely involved in their design and implementations. You will be able to provide guidance and build the technical culture on the team in the form of design reviews and PRs.
Responsibilities
Defining the long-term technical roadmap for building a data-driven culture at Plaid.
Focus on data quality and privacy.
Leading key data engineering projects that drive collaboration across the company.
Mentoring engineers, operations, and data analysts on best practices for data organization and query performance.
Advocating for adopting industry tools and practices at the right time.
Owning core SQL and python data pipelines that power our data lake and data warehouse.
Well-documented data with defined dataset quality, uptime, and usefulness.
Qualifications
6+ years of dedicated data engineering experience, solving complex data pipelines issues at scale.
You value SQL as a flexible and extensible tool, and are comfortable with modern SQL data orchestration tools like DBT, Mode, Hightouch, and Airflow.
Experience working both real-time systems like Kinesis, Kafka, Flink, and batch data pipelines in Redshift, Presto, and Data Lakes.
You appreciate the importance of schema design, and can evolve an analytics schema on top of unstructured data.
You are excited to try out new technologies. You like to produce proof-of-concepts that balance technical advancement and user experience and adoption.
You like to get deep in the weeds to manage, deploy, and improve low level data infrastructure.
You are empathetic working with stakeholders. You listen to them, ask the right questions, and collaboratively come up with the best solutions for their needs.
You are a champion for data privacy and integrity, and always act in the best interest of consumers.
$187,200 - $280,800 a year
Target base Salary for this role is $187,200- $280,800 per year. Additional compensation in the form(s) of equity and/or commission are dependent on the position offered. Plaid provides a comprehensive benefit plan, including medical, dental, vision, and 401(k). Pay is based on factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience and skillset, and location. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans.
Our mission at Plaid is to unlock financial freedom for everyone. To support that mission, we seek to build a diverse team of driven individuals who care deeply about making the financial ecosystem more equitable. We recognize that strong qualifications can come from both prior work experiences and lived experiences. We encourage you to apply to a role even if your experience doesn't fully match the job description. We are always looking for team members that will bring something unique to Plaid!

Plaid is proud to be an equal opportunity employer and values diversity at our company. We do not discriminate based on race, color, national origin, ethnicity, religion or religious belief, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, military or veteran status, disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state, and local laws. Plaid is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance with your application or interviews due to a disability, please let us know at accommodations@plaid.com.

Please review our Candidate Privacy Notice here.",2012,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Senior Data Engineer,"Disney Entertainment & ESPN Technology
","San Francisco, CA",$139K - $174K (Employer est.),3.8,"Team’s Vision

The Machine Learning (ML) Engineering team at Disney drives and enables ML usage across several domains in heterogeneous language environments and at all stages of a project’s life cycle, including ad-hoc exploration, preparing training data, model development, and robust production deployment. The team is invested in continual innovation of the ML infrastructure itself to carefully orchestrate a continuous cycle of learning, inference, and observation while also maintaining high system availability and reliability. We seek to find new ways to scale with our guest and partner base as well as the ever-growing need for ML and experiments.

Role

In this role you will partner with the ML Engineers and Data Scientists to help create and manage the datasets, contribute to the ML infrastructure by building and managing services that support and simplify ML development. You will conduct data exploration, feature engineering and build services. You will work on cross-functional projects and push the envelope on data and ML infrastructure.

Responsibilities:

Design and develop data discovery tools, data quality and feature libraries

Collaborate with ML practitioners to design and build data-forward solutions

Deploy scalable streaming and batch data pipelines support petabyte scale datasets

Build and maintain dimensional data, feature and model stores

Ability to work on multi-faceted projects with engineers from diverse backgrounds, heterogenous skills and across teams.

Drive and maintain a culture of quality, innovation and experimentation

Work in an Agile environment that focuses on collaboration and teamwork

Basic Qualifications:

5+ years of software experience, with 3+ years of relevant data and software experience

Experience in building large datasets and scalable services

Experience deploying and running services in AWS, and engineering big-data solutions using technologies like Databricks, EMR, S3, Spark

Experience loading and querying cloud-hosted databases such as Redshift and Snowflake

Experience designing and developing backend microservices for large scale distributed systems using gRPC or REST.

Experience with large-scale distributed data processing systems, cloud infrastructure such as AWS or GCP, and container systems such as Docker or Kubernetes.

Preferred Qualifications:

Knowledge of the Python/Scala/Java data ecosystem

Experience building streaming pipelines using Kafka, Spark, Flink, or Samza

Excellent communication and people engagement skills

Drive and maintain a culture of quality, innovation and experimentation

Mentor colleagues on best practices and technical concepts of building large scale solutions




The hiring range for this position in California is $145,400 - $181,700 per year, in New York is $139,040 - $173,800 per year and Washington is $139,040 - $173,800 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",1901,Culture & Entertainment,$1 to $5 billion (USD),"Arts, Entertainment & Recreation",10000+ Employees,Subsidiary or Business Segment,False
Senior Data Engineer,"Electric Hydrogen
","San Carlos, CA",$128K - $174K (Glassdoor est.),4.5,"Electric Hydrogen's mission is to make molecules to decarbonize our world! Our outstanding people are our most important asset and will allow us to deliver hydrogen from renewable electrolysis for heavy industry, at prices below fossil fuels.

We are searching for an accomplished and motivated Senior Data Engineer to build and maintain mission-critical data infrastructure for the world's most powerful electrolyzer. As a Data Engineer, you will develop services to ingest, analyze, and store plant data and key performance metrics. Tools you build will monitor our electrolyzer fleet, assessing their operation and detecting issues before they lead to unplanned downtime.

You will be based in San Carlos, CA [and can work on a hybrid basis], reporting to the Director of Software Engineering.

Role and Responsibilities

Ensure data availability to internal and external stakeholders from internal devices and deployed plants
Architect streaming pipelines, analysis triggers, and notifications
Building data models and develop schemas for relational databases (PostgreSQL, MySQL, MS SQL Server)
Work with data from industrial PLCs and other connected devices
Coalesce data from manufacturing and deployed plant data for use in analysis
Design data systems for machine learning applications

Qualifications

Bachelor's degree in Computer Science, Engineering, or related field
6+ years working with data pipelines and industrial networks
Significant experience with relational databases (PostgreSQL, MySQL, MS SQL Server)
Familiarity with industrial streaming protocols such as MQTT and Kafka
Familiarity with OPC servers, OPC UA, and PLC communication
Experience using git and git-based workflows for version control.
Experience working with time series data and time series databases
Knowledge of process historians (OSI PI, FactoryTalk Historian)
Experience building data pipelines in AWS, using tools such as IoT Core and Kinesis
Knowledge of OSI PI ecosystem including asset framework
Experience with machine learning data pipelines

#LI-HYBRID

Compensation & Benefits | Senior Data Engineer (P4)

San Carlos Zone

$173,000—$190,000 USD

Actual base salary offered to the hired applicant will be determined based on their work location, level, qualifications, job-related skills, as well as relevant education or training and experience.

Base salary is just one part of Electric Hydrogen's total rewards package. We feel strongly that our team should not have to worry about having quality healthcare. In addition to the base salary offered, the hired applicant may receive:

an equity grant
time off programs
a $75/month cell phone allowance
a 4% employer 401(k) match
100% fully paid premiums for employees and their families: medical, dental, vision, life insurance, short-term & long-term disability coverage
a discretionary bonus

Electric Hydrogen's benefits programs are subject to eligibility requirements.

COVID-19 vaccination required for all employees and contingent workers, unless a reasonable accommodation is approved. All prospective hires will be expected to provide proof of vaccination to attend an onsite interview or at their first day of employment.

About Electric Hydrogen

Electric Hydrogen is a team of the world's experts in scaling technologies for the post-carbon world, with a proven record in transforming the grid and transportation sectors. Backed by some of the world's top venture capital firms, we design and manufacture electrolytic hydrogen systems matched to renewable power sources to create green hydrogen by splitting water. We are building a cost-effective and transformative path between renewable energy and multiple large industrial sectors. Abundant and low-cost renewable energy sources will power the world, and Electric Hydrogen technology will use this energy to decarbonize industry through sustainable materials. We were founded in 2020 and are based in California and Massachusetts.

Electric Hydrogen is proud to be an equal opportunity employer. We are dedicated to building a diverse, inclusive, and authentic workplace for all to belong. We are aware that people from historically underrepresented groups are less likely to apply if they don't meet 100% of the job requirements. We are actively working on efforts to change this social norm. If you are excited about this role, we encourage you to apply!",2020,Energy & Utilities,Unknown / Non-Applicable,"Energy, Mining & Utilities",51 to 200 Employees,Company - Private,False
Senior Software Engineer-Data Platform,"PlayStation Global
","San Diego, CA",$148K - $182K (Glassdoor est.),4.0,"Why PlayStation?

PlayStation isn't just the Best Place to Play — it's also the Best Place to Work. Today, we're recognized as a global leader in entertainment producing The PlayStation family of products and services including PlayStation®5, PlayStation®4, PlayStation®VR, PlayStation®Plus, acclaimed PlayStation software titles from PlayStation Studios, and more.

PlayStation also strives to create an inclusive environment that empowers employees and embraces diversity. We welcome and encourage everyone who has a passion and curiosity for innovation, technology, and play to explore our open positions and join our growing global team.

The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.

At SIE, data is a critical business asset that facilitates business operations, empowers decision making, and provides vital insights into improvement and innovation of PlayStation products and services.

The Audience Platform team provides an in-house customer data platform supporting multiple teams across SIE. We are responsible for allowing our end-users to build rule-based groups of users to be used for marketing campaigns, promotions, etc. Our team works with a variety of teams to integrate their data into our platform and represent that data as attributes to build the aforementioned rule-based groups of users.

Responsibilities:

End to end ownership of the development process; from working with product requirements to go-to-market strategy
Identify performance bottlenecks and build solutions for them
Build highly available and performant systems
Design, implement, ship and maintain highly visible consumer-facing features
Tackle scalability issues with innovative technologies
Understand the existing processes and share recommendations on process improvements
Be an advocate for technical excellence and data quality
Lead and mentor junior team members

Qualifications

Experience developing high scale, distributed systems
Experience with stream/batch data processing systems such as Apache Spark and/or Apache Flink is a plus
Experience with Scala, Java, or Kotlin
Experience working with event streaming platforms (Kafka/Kinesis/SQS)
Experience with container technologies, such as Docker, Kubernetes, AWS EKS
Experience building and developing Cloud-based applications or services, preferably in AWS
Experience with one or more technologies such as Lambda, DynamoDB, Snowflake,
Ability to handle periodic on-call duty as well as out-of-band requests
Ability to conduct technical deep dives into the code, cloud networking, deployments, and architecture, and work closely with product owners
Self-starter with a strong sense of ownership for your work
Strong communication skills - both verbal and written



#LI-GM1


Please refer to our Candidate Privacy Notice for more information about how we process your personal information, and your data protection rights.




At SIE, we consider several factors when setting each role's base pay range, including the competitive benchmarking data for the market and geographic location.

Please note that the base pay range may vary in line with our hybrid working policy and individual base pay will be determined based on job-related factors which may include knowledge, skills, experience, and location.

In addition, this role is eligible for SIE's top-tier benefits package that includes medical, dental, vision, matching 401(k), paid time off, wellness program and coveted employee discounts for Sony products. This role also may be eligible for a bonus package. Click here to learn more.


The estimated base pay range for this role is listed below.

$147,500—$221,300 USD

Equal Opportunity Statement:

Sony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to gender (including gender identity, gender expression and gender reassignment), race (including colour, nationality, ethnic or national origin), religion or belief, marital or civil partnership status, disability, age, sexual orientation, pregnancy or maternity, trade union membership or membership in any other legally protected category.

We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.

PlayStation is a Fair Chance employer and qualified applicants with arrest and conviction records will be considered for employment.",1994,Video Game Publishing,$10+ billion (USD),Media & Communication,5001 to 10000 Employees,Subsidiary or Business Segment,True
Data Engineer III,"Herbalife
","Torrance, CA",$110K - $151K (Glassdoor est.),4.0,"Overview:
THE ROLE:

The Data Engineer role is responsible for data modelling, design, optimization, security and administration of ETL/ELT tools and data engineering interfaces. The role will be responsible for building data interfaces focusing on data accuracy, completeness and availability. The role will analyze source and target systems design, build and test solutions to make data available Business intelligence systems, websites mobile apps and other applications.

HOW YOU WOULD CONTRIBUTE:

Level III

Design, Build, Test and migrate ETL/ELT systems and data interfaces
Analyze and design source and target systems data architectures
Design and implement data tables, functions, views, procedures and routines to provide accurate and complete data to BI and data applications.
Identify opportunities for technical innovation that add value to the platform.
Assist in establishing and embedding data management and governance processes.
Enhance performance in the Applications environment.
Meet service level agreements for production support response and resolution.
Research, Design and Develop technical solutions to a pre-defined requirement and develop components including extensions, views, customizations, modifications, reports, and workflows independently or as a part of a team.
Follow documentation, software development methodology, version control and testing, and migration standards.
Develop and improve the current data architecture, emphasizing data security, data quality and timeliness, scalability, and extensibility.
Provide technical guidance and mentoring to others in areas of expertise.
Deploy and use various technologies and run pilots to design low latency data architectures at scale
Collaborate with BI teams, business analysts, product managers, and application teams to provide data for BI, web, mobile applications
Collaborate with business analysts, data scientists, product managers, and BI teams to develop, implement, and validate KPIs, statistical analyses, data profiling, prediction, forecasting, clustering.
Develop a cooperative environment that fosters knowledge sharing.

Qualifications:
SKILLS AND BACKGROUND REQUIRED TO BE SUCCESSFUL:


Expert proficiency in building data pipelines and ETL/ELT using tools such as Informatica, ODI, Azure Data Factory etc.
Experience in administration and migration activities of data movement and transformation tools.
Snowflake
Informatica or any other Integration Tools
Python
Apigee/Kafka or any other streaming tool experience
Expert knowledge in advanced SQL, stored procedures, views, functions, indexes etc.
Expert knowledge of Entity Relationship Diagrams.
Expert knowledge of data modeling techniques (type 1,2,3,4), dimensions, facts and aggregations.
Proficiency in relational and non-relational databases such as OLTP, MPP appliances, NoSQL, DaaS, Cloud etc.
Proficiency in data movement techniques such as replication, switching, pipelines etc.
Proficiency in data integrity, profiling and storage and mining techniques.
Proficiency in change data capture techniques including timestamp, log and trigger-based mechanisms.
Proficiency in working with different types of large and small sets of data; structured, semi structured and unstructured.
Proficiency in working with scheduling tools.
Proficiency in working with change management tools and processes include source control, versioning, defect tracking and release management.
Proficiency in analyzing impact of smaller and large-scale initiatives.
Good working knowledge of Unix/Linux/PowerShell scripting.
Manage multiple priorities.
Excellent written and verbal communication skills.

Experience:

Level III

5+ year’s experience in working with data in a data mart, warehousing, OLTP environment.
5+ year’s experience working with ETL/ELT and data movement tools.

Education:

Bachelor’s in information technology, computer science or related field

#LI-AR1

US Benefits Statement: Herbalife offers a variety of benefits to eligible employees in the U.S. (limited to the 50 States and the District of Columbia), which includes Group Health Programs, other Voluntary Benefit Programs, and Paid Time Off. Group Health Programs include Medical, Dental, Vision, Health Savings Account (HSA), Flexible Spending Accounts (FSA), Basic Life/AD&D; Short-Term and Long-Term Disability, and an Employee Assistance Program (EAP). Other Voluntary Benefit Programs include a 401(k) plan, Wellness Incentive Program, Employee Stock Purchase Plan (ESPP), Supplemental Life/Critical Illness/Hospitalization/Accident Insurance, and Pet Insurance. Paid time off includes Company-observed U.S. Holidays, Floating Holidays, Vacation, Sick Time, a Volunteer Program, Paid Maternity and Paternity Leave, Bereavement Leave, Personal Leave and time off for voting.",1980,Beauty & Wellness,$5 to $10 billion (USD),Personal Consumer Services,5001 to 10000 Employees,Company - Public,False
"Software Engineer, Teleoperations Data and Web Applications","Nuro
","Mountain View, CA",$125K - $188K (Employer est.),4.0,"Who We Are

Nuro exists to better everyday life through robotics. The company's custom electric autonomous vehicles are designed to bring the things you need—from produce to prescriptions—right to your home. Nuro's autonomous, goods-focused solution can give you valuable time back and more freedom to do what you love. This convenient, eco-friendly alternative to driving has the potential to make streets safer and cities more livable.

About the Role

As we approach a matured commercial operation and at scale testing, the ability to monitor the fleet and improve operational efficiency plays a key role in our business strategy. As a Full Stack Software Engineer, you will work in the Mission Control team under Teleoperation, with a diverse team of engineers to build web applications and microservices to monitor the fleet, and improve operational efficiency. You will collaborate closely with our robotics, infrastructure, hardware, autonomy, operations, data science and product teams to close the loop for autonomy system testing and visualization, and meet real-world demands.

About the Work
Build full stack web applications and microservices for fleet management
Build full stack web applications for resources allocation and optimization on operation tasks
Build data pipelines to enable data driven UI/UX feature development and testing
Work with autonomy, operation and other XFN partners to deliver high impact feature in time
Test systems in real-world environments, gather feedback and drive innovation
About You
B.S., M.S., or Ph.D in Computer Science, Mathematics, or closely related field
Excellent communication, presentation, interpersonal, and analytical skills
Proficient with front end technologies including Typescript, Graphql, React
Working knowledge of back end development including K8S deployment, database, business logic implementation in Go, data pipelines and microservice design
3+ years working experience with web full stack development or data pipelines

At Nuro, your base pay is one part of your total compensation package. For this position, the reasonably expected base pay range is between $125,400 and $188,100 for the level at which this job has been scoped. Your base pay will depend on several factors, including your experience, qualifications, education, location, and skills. In the event that you are considered for a different level, a higher or lower pay range would apply. This position is also eligible for an annual performance bonus, equity, and a competitive benefits package.

At Nuro, we celebrate differences and are committed to a diverse workplace that fosters inclusion and psychological safety for all employees. Nuro is proud to be an equal opportunity employer and expressly prohibits any form of workplace discrimination based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, veteran status, or any other legally protected characteristics.",2016,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,True
Data Engineer,"Xperi
","San Jose, CA",-1,4.2,"Xperi invents, develops and delivers technologies that create extraordinary experiences at home and on the go for millions of people around the world. Powering billions of consumer electronics, connected cars and digital content titles, we make entertainment more immersive, driving more intelligent and every interaction seamlessly personalized through our renowned consumer brands: DTS®, HD Radio™, IMAX® Enhanced and TiVo®.

Xperi (NYSE: XPER) is a publicly traded technology company headquartered in San Jose, CA with over 2,000 employees across North America, Europe and Asia. Come join a thriving team where you can play an integral role in shaping the future of entertainment technology.

Title: Data Engineer

Primary Job Responsibilities:

Support in designing, developing and maintaining data pipelines
Collaborate with DevOps, Data Engineering, and analytics research teams
Develop, test, and launch analytics reports and dashboards
Apply expertise in quantitative analysis, data mining and communicate results within the data analytics team
Document processes, issues, and resolutions as needed
Identify and Implement automation opportunities



Qualifications:

1+ year experience working on ETL pipelines and data analytics
Bachelor’s Degree in computer science, Math, Engineering, or related quantitative field
Write complex SQL and ETL processes for data at scale
Working knowledge of programming in Python.
Knowledge of Cloud services like AWS environment including S3, cloud computing approach, Athena, and EMR or Other cloud services like GCP, Azure
Knowledge of scheduling, automation & orchestration software (such as Airflow, Control-M, Cloud Formation)
Knowledge of Enterprise software like Databricks or Qubole and BI platform like Tableau, Power BI
Excellent analytical, troubleshooting and communication skills

Life @ Xperi:

At Xperi, we value People, Customers, Performance and Innovation. We are dedicated to creating a workplace where all employees have a voice and sense of belonging, feel safe and valued, and are acknowledged for how their unique differences contribute to organizational culture and business outcomes.

Our employees and their families are important to us, and our comprehensive pay, stock and benefits programs reflect that. Xperi supports personal well-being, builds financial security and enables employees to share in our collective success.

Rewards include:

Competitive compensation (salary, equity and bonuses) and comprehensive benefits designed to foster work-life balance, care for your health, protect your finances and help you save and invest for the future.
Generous paid time away from work, including flexible time off, holidays and sick time, health and wellness initiatives, and a charitable match program to help you give back to your community.
Great perks, which vary by location and can be site-specific: employee discounts, transportation reimbursements, subsidized cafes and fitness facilities.
A flexible, hybrid work environment combining the best of in-office collaboration and community-building along with the benefits of working from home.

The estimated base salary range for this full-time position is $101,469 - $124,300 plus bonus, equity, and benefits, and can vary if outside of this location. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, competencies, experience, market demands, internal parity, and relevant education or training. Your recruiter can share more about the specific salary range and perks and benefits for your location during the hiring process.",1990,Software Development,$500 million to $1 billion (USD),Information Technology,1001 to 5000 Employees,Company - Public,False
Data Engineer,"Motion Recruitment
","Los Angeles, CA",$60.00 - $75.00 Per Hour (Employer est.),3.4,"Big Data Engineer
A client of ours in the financial space is looking to hire a Big Data Engineer to join their team. You will be responsible for developing and designing software applications as well as modifying existing applications to meet business requirements.
Required Skills & Experience
5+ years of software development experience
3+ years of experience with Map-Reduce, Hive, Spark
Hands-on experience writing and understanding complex SQL
Experience in UNIX shell-scripting
Bachelor’s degree in Engineering or Computer Science or equivalent
What You Will Be Doing
Tech Breakdown
100% Data Engineering
Daily Responsibilities
100% Hands On



Applicants must be currently authorized to work in the US on a full-time basis now and in the future. This role cannot be done on a C2C basis.",1989,HR Consulting,Unknown / Non-Applicable,Human Resources & Staffing,51 to 200 Employees,Company - Private,False
Principal Data Quality Engineer (Remote),"First American Financial Corporation
","Santa Ana, CA",$72K - $149K (Employer est.),3.8,"Who We Are

Join a team that puts its People First! Since 1889, First American (NYSE: FAF) has held an unwavering belief in its people. They are passionate about what they do, and we are equally passionate about fostering an environment where all feel welcome, supported, and empowered to be innovative and reach their full potential. Our inclusive, people-first culture has earned our company numerous accolades, including being named to the Fortune 100 Best Companies to Work For® list for eight consecutive years. We have also earned awards as a best place to work for women, diversity and LGBTQ+ employees, and have been included on more than 50 regional best places to work lists. First American will always strive to be a great place to work, for all. For more information, please visit www.careers.firstam.com.

What We Do

What You’ll Do:

Advise and assist with assigned activities of the Data Governance Office (DGO), such as issue intake/triage, governance tooling/platform configuration, stakeholder consultation and communication, editing policy, Data Steward and Data Owner engagement, implementation of Data Quality and Governance processes, definition of standards, business terminology definitions, research and analysis of DG-related topics.

Assist with implementing an enterprise-wide Data Quality (DQ) strategy by working with business and technology partners to ensure alignment and dedication to objectives.

Perform data analysis of identified data issues and recommend strategic and tactical remediations.

Assist with the advisement and assurance that all data assets are secured in accordance with First American and Data Management practices.

Engagement with the Data Operations and Data Engineering teams, et al. to establish and assure all processes, guidelines and procedures are followed on issues related to data security, data classification, compliance, audits, risk assessments & data quality issues.

Collaborate with other Data Governance members and other Data Management team members, such as Business Analysts, Technical Leads, Data Engineers, Product Owners, Project Managers, and other technical or functional specialists.

Perform technical and analytical efforts related to a Data Quality Framework, which includes data quality assessment / profiling, data quality monitoring, issue resolution, architectural considerations, design and implementation of KPIs/metrics/scorecards.

Data quality monitoring and analysis through the translation of business requirements into functional solutions

Evaluation of enterprise data from multiple standpoints, including timeliness, completeness, accuracy, integrity, conformance to standards, and security

Documentation of relevant information, e.g., technical specifications / diagrams / etc.

Advocate for best practices in Data Governance, Data Quality, & Data Management

Participate in scrums and coordination with the Scrum Master

Lead, coach and develop team members less knowledgeable.

Collaborate both inter-departmentally and across Business Units to develop, document, and implement ongoing opportunities for Data Quality Program advancement.

Lead with courage in support of change initiatives that impact organization and work with business units to educate and foster Data Quality and Data Literacy across the organization.


What You’ll Bring:

Data Quality Assurance – responsibilities related to data quality assurance testing, proactive monitoring solutions, data quality issue investigation and process, across multiple data domains.

Data Governance advocacy through advancement of data management best practices and concepts, fostering a culture of interaction and cooperation to support First American's strategic initiatives.

Ownership of data-quality issues from intake through resolution

Prior experience with conceptualizing, leading & implementing automated testing, monitoring & scripting processes for Data Quality.

Experience with data visualization and the ability to tell a story with data.

Prior experience working closely with the business at all levels.

Highly analytical mindset and the drive to understand the data from both a business and technical perspectives.

Change management experience.

Ability to prioritize competing deliverables.


Preferred Skills:

Experience working with Python, R or Java code a plus.

Advanced problem-solving skills.

Clear understanding of advanced analytical models.


Education

Bachelor’s in Business, Statistics, Mathematics, Information Systems, or related work experience


Experience

5 + years SQL required with the expertise to write complex queries, Snowflake helpful.

5 years of Data Quality experience

2+ years creating monitoring tools, automated validation processes, etc.


Pay Range: $71,500 - $148,500

This hiring range is a reasonable estimate of the base pay range for this position at the time of posting. Pay is based on a number of factors which may include job-related knowledge, skills, experience, business requirements and geographic location.


#LI-JC2

What We Offer

By choice, we don’t simply accept individuality – we embrace it, we support it, and we thrive on it! Our People First Culture celebrates diversity, equity and inclusion not simply because it’s the right thing to do, but also because it’s the key to our success. We are proud to foster an authentic and inclusive workplace For All. You are free and encouraged to bring your entire, unique self to work. First American is an equal opportunity employer in every sense of the term.

Based on eligibility, First American offers a comprehensive benefits package including medical, dental, vision, 401k, PTO/paid sick leave and other great benefits like an employee stock purchase plan.",1889,Insurance Carriers,$5 to $10 billion (USD),Insurance,10000+ Employees,Company - Public,False
Software Engineer - Data Analytics,"Bear Robotics
","Redwood City, CA",$120K - $215K (Employer est.),2.8,"Bear Robotics is a cutting-edge robotics company focused on developing innovative automation solutions for various industries. Our products, including robot devices, cloud services, and public APIs, are designed to help businesses operate more efficiently and effectively.

Bear Robotics is on the hunt for a dynamic and skilled Software Engineer to spearhead our Data Analytics team. If you are passionate about data and skilled at enabling data-driven decisions, then you could be our ideal candidate!

Key Duties/Responsibilities:

Oversee, manage, and monitor GCP BigQuery databases.
Administer Looker and create compelling data visualizations to serve our internal teams, or guide them in crafting their own.
Aggregate granular/high frequency data and decide when to discard non-essential information.
Guarantee the precision of all data points.
Uphold the database security.
Compose, review, and offer assistance with Terraform code.
Collaborate with application and infrastructure teams to design and implement optimized pipelines for data ingestion and processing.
Operate with significant autonomy, discerning and managing priorities effectively.

Performs other related duties as assigned.

Supervisory Responsibilities:

Lead a small Data Analytics team, providing guidance, mentorship, and direction.
Oversee the training and development of team members, ensuring they have the necessary tools and knowledge.
Conduct regular performance reviews, providing constructive feedback and recognizing accomplishments.
Collaborate with HR and upper management on hiring, promotions, and disciplinary actions as necessary.

Required Skills/Abilities/Qualifications:

Proven experience with enterprise-level visualization tools, such as Looker, Tableau, Superset, in a professional setting.

Preferred Skills/Abilities/Qualifications:

Hands-on programming experience, notably in Python, C++, or Go.
Prior professional leadership roles or experience.
Related personal projects or a compelling portfolio showcasing your passion and skill in the field.

Education/Experience:

Bachelor's degree in Computer Science or a related data-centric discipline.
A minimum of three years' professional experience with SQL databases, either using or administrating.

Physical Requirements:

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Prolonged periods of sitting/standing at a desk and working on a computer. The employee routinely is required to sit; stand, walk; talk and hear; use hands to keyboard
Specific vision abilities required by this job include close vision, color vision, peripheral vision, depth perception, and ability to adjust focus.
Ability to lift 20 lbs.






Benefits Summary

We hire the best, not only will you be surrounded by exceptionally smart and motivated people, but we believe excellent compensation and benefits are an essential part of our company's success.

Comprehensive Medical/Dental/Vision Insurance Plans

Company-Paid Long-Term and Short-Term Disability

Company-Paid Life/AD&D Insurance

Health Savings Account/Flexible Spending Account

Stock Options

Employee Assistance Program (EAP)

Wellness Reward Programs

Mental Health Benefits

Paid Vacation Time

Paid Sick Time

401K Plan Employer Match (No Vesting Schedule)

Paid Bearental (Parental) Leave (16 weeks)

Paid New Bearental (Parental) Transitional Time Off (2 weeks)

Annual Paid Holidays (11 days)

Annual Paid Family Time-Off (Between Christmas Holiday and New Year)

Employee Recognition Bonus Program

Peer Recognition Bonus Program

Employee Referral Reward Program

Patent Reward Program

Monthly Mobile Phone Reimbursement

Monthly Internet Reimbursement

Casual Dress Policy

Financial Wellness Education Sessions

Free Daily In-Office Lunch

Unlimited Office Snacks and Drinks

Wellness Room with Massage Chair

Day-Friendly Office

Flexible Work Schedule

Office Parties and Family Events

The pay range is $120K-$215K. Pay is dependent on the applicant's relevant experience

Bear Robotics, Inc. is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, color, ancestry, national origin, religion or religious creed, mental or physical disability, medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, citizenship, or other characteristics protected by state or federal law or local ordinance.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,True
"Clinical Data Engineer - Biosense Webster, Inc.","Johnson & Johnson
","Irvine, CA",$90K - $140K (Employer est.),4.2,"Biosense Webster Inc., part of Johnson & Johnson MedTech, is currently recruiting for a Clinical Data Engineer . This role can be remote from anywhere within the United States. At Biosense Webster, Inc. we have one goal — to ensure those with cardiac arrhythmias can live the lives they want. This means transforming the latest advancements in electrophysiology into a suite of tools that empowers physicians with a range of treatments for the best outcomes.

Quality products and approaches are achievable only through collaboration with the smartest minds in electrophysiology. For more than 30 years, we’ve been the global market leader in the science and technology of cardiac arrhythmia treatment, working with thousands of electrophysiologists to identify and develop diagnostic and treatment tools. And through onsite training, online courses and our global education centers, we work together to set new standards every day.

Learn more about Biosense Webster at www.biosensewebster.com

The Data Engineer is a key player in a cross functional team providing subject matter expertise for enhancing and troubleshooting complex Data platform business needs. The ideal candidate is an experienced data professional that exhibits strong skillset within redarning of the data via Tableau or other visualization packages. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing data architecture to support the next generation of products and data initiatives.

Key Responsibilities:

Maintain support and be the primary contact for managing, triaging, and resolving issues related to Clinical data managed outside of the Electronic Data Capture System (EDC).
Experienced in the utilization of AWS services and infrastructure to support large and complex data platforms.
Hands-on database administrator skills to manage or identify root cause and resolve issues stemming from the management of structured and/or unstructured data sources.

The base pay range for this position is $90,000 to $140,000 based on experience . The Company maintains highly competitive, performance-based compensation programs. Under current guidelines, this position is eligible for an annual performance bonus. The annual performance bonus is a cash bonus intended to provide an incentive to achieve annual targeted results by rewarding for individual and the corporation’s performance over a calendar/performance year. Bonuses are awarded at the Company’s discretion on an individual basis.




Employees may be eligible to participate in Company employee benefit programs such as health insurance, savings plan, pension plan, disability plan, vacation pay, sick time, holiday pay, and work, personal and family time off in accordance with the terms of the applicable plans. Additional information can be found through the link below.




https://www.careers.jnj.com/employee-benefits

QUALIFICATIONS

Required Qualifications:

Education:

Minimum of a Bachelors’ Degree required ; Advanced Degree preferred . Desired fields of study include Computer Science, Statistics, Informatics, Information Systems or related quantitative field.

Experience and Skills:

Minimum 2-4+ years of experience in a Data role, with exposure to the following software/tools:

o Big data tools: AWS Services (S3, GLUE, Postgres, Lambda and Sagemaker etc.)

o Relational SQL and NoSQL databases

o Analysis and visualization software such as R, RStudio, Python, and Tableau

o Data pipeline and workflow management tools

Advanced SQL knowledge and experience with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience with contributing to the building and optimizing data pipelines, architectures, and data sets.
A working knowledge of manipulating, processing, and extracting value from large datasets.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience in medical device or pharmaceutical environment preferred.
Excellent written, oral and presentation skills.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.",1887,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Company - Public,False
Marketing Analytics Engineer - Data Architecture,"Warner Bros. Discovery
","Culver City, CA",$72K - $134K (Employer est.),3.6,"Every great story has a new beginning, and yours starts here.

Welcome to Warner Bros. Discovery… the stuff dreams are made of.

Who We Are…

When we say, “the stuff dreams are made of,” we’re not just referring to the world of wizards, dragons and superheroes, or even to the wonders of Planet Earth. Behind WBD’s vast portfolio of iconic content and beloved brands, are the storytellers bringing our characters to life, the creators bringing them to your living rooms and the dreamers creating what’s next…

From brilliant creatives, to technology trailblazers, across the globe, WBD offers career defining opportunities, thoughtfully curated benefits, and the tools to explore and grow into your best selves. Here you are supported, here you are celebrated, here you can thrive.

Your New Role…

As an Analytics Engineer, you will drive insights for Warner Bros. Discovery’s streaming businesses through the development of reporting solutions, complex data analyses, and data modeling/architecture for the Marketing Analytics team. You are not only highly skilled at delivering scalable analytics products and frameworks, but are also adept at relational data modeling, architecture, warehousing, normalization, wrangling, and transformation, using a variety of data tools (ie. SQL, Python, etc.). You also have a strong command of ETL principles and best practices. You will work closely with cross-functional partners to plan and execute high-visibility projects, while ensuring excellence in data quality and performance. Your work will be used by the wider Warner Bros. Discovery marketing teams to measure and optimize campaign performance, and to drive their strategies.

Your Role Accountabilities…

Collaborate with other analytics, data engineering, and marketing technology teams to identify innovative solutions, build and execute project plans, and add layers of sophistication to our reporting capabilities.
Design and implement logical data models and transformations to support flexible self-service reporting.
Support cross departmental core metrics and data dependencies with leadership visibility.
Serve as a subject matter expert of marketing data pipelines and semantic layers.
Deliver solutions to democratize data cross-functionally and across our ecosystem.
Design data solutions to ensure data integrity throughout our pipelines, and support QA of our reports.
Continually research and drive enhancements to our data architecture and pipelines.
Rapidly deliver on new concepts through prototyping that can be presented for feedback and iteration.
Advance automation efforts that help the team spend less time validating data, and more time analyzing it.
Champion the creation and support of data modeling and architectural standards and best practices.

Qualifications & Experience…

Bachelor's degree or higher, ideally in a quantitative field of study (Mathematics, Statistics, Computer Science, Engineering, Finance, etc.).
6+ years relevant work experience in data modeling, data engineering and enterprise information architecture, preferably within a marketing and sales environment, and currently working in a similar role.
Expertise in SQL, data pipeline and workflow management tools (Apache Airflow, Spark), as well as data warehousing (Snowflake, BigQuery, Databricks).
Familiarity with data visualization and analytics tools (Looker, Tableau, Power BI).
Expertise with ETL solutions, including analyzing, compiling, cleansing, interpreting, joining and staging data.
Proficient in data manipulation & data-wrangling technologies (SQL, Python, Alteryx).
Able to facilitate user requirement gathering to inform design, or reverse engineer requirements from existing data sources & applications.
Understanding of digital marketing, social, and advertising technologies, such as Google Marketing Platform, Google Ad Manager, Social Ad Managers, MMPs (AppsFlyer), and Site Analytics tools (Google Analytics).
Past experience with CRM platforms (Braze, Salesforce, Hubspot, etc). An understanding of customer and/or subscription data is a plus.
Understanding of the digital media ecosystem and subscription business model.
Ability to guide projects forward independently and manage multiple deliverables and time constraints simultaneously.
Strong presentation, interpersonal, and communication skills. Must have the ability to communicate effectively with leadership and cross-functional teams, and to explain data concepts to users with varying backgrounds.
Proven ability to collaborate with key partners and stakeholders to define metrics, identify requirements and solve problems independently.

How We Get Things Done…

This last bit is probably the most important! Here at WBD, our guiding principles are the core values by which we operate and are central to how we get things done. You can find them at www.wbd.com/guiding-principles/ along with some insights from the team on what they mean and how they show up in their day to day. We hope they resonate with you and look forward to discussing them during your interview.

The Legal Bits…

In compliance with local law, we are disclosing the compensation, or a range thereof, for roles in locations where legally required. Actual salaries will vary based on several factors, including but not limited to external market data, internal equity, location, skill set, experience, and/or performance. Base pay is just one component of Warner Bros. Discovery’s total compensation package for employees. Pay Range: $72,240.00 - $134,160.00 salary per year. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Warner Bros. Discovery provides a variety of benefits to employees, including health insurance coverage, an employee wellness program, life and disability insurance, a retirement savings plan, paid holidays and sick time and vacation.

Warner Bros. Discovery embraces the opportunity to build a workforce that reflects the diversity of our society and the world around us. Being an equal opportunity employer means that we take seriously our responsibility to consider qualified candidates on the basis of merit, without regard to race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, and genetic information, marital status, citizenship status, military status, protected veteran status or any other category protected by law.

If you’re a qualified candidate with a disability and you need a reasonable accommodation in order to apply for this position, please contact us at recruitadmin@wbd.com.",2003,Film Production,$10+ billion (USD),Media & Communication,10000+ Employees,Company - Public,False
Data Engineer (Flex Hybrid),"UCLA Health
","Los Angeles, CA",$102K - $151K (Glassdoor est.),3.9,"Description

As a Data Engineer on the Data Architecture team, you will play a key role in technology initiatives to advance health informatics and analytics in the health sciences by advancing the usability, performance, and overall architecture of the Data Infrastructure. You will develop fastest, reliable, and large-scale data processing pipelines to ingest data from multiple data sources into Enterprise Data warehouse and Data Lake. Involves technical acumen for planning, designing, developing, implementing, and administering data-based systems that acquire, prepare, store, and provide access to data and metadata. Maintains and optimizes systems and migrates data and systems as needed. Ensures integrity and completeness of data and workflow, manages and / or develops data practices, databases, and information systems as well as guidelines, dictionaries, registries and / or services. May include interpretation of scientific research data artifacts as well as mediation across science and technology domains and long-term data care. As information architect and data steward, designs systems, data products and / or data production processes while focusing on data curation, data exchange, data security, data integrity and information environments. (Re)evaluates frameworks, strategies, standards, and standards-making activities. May involve work with a project-level data repository, a center, or an archive. You will be part of the team building UCLA Health’s Data Platform and products and is a unique opportunity to be part of advancing analytics for one of the nation’s leading Healthcare organizations where Big Data will be used as a platform to build solutions. You must be willing and able to be on-site at least once a month.

Qualifications

• Minimum five years of software development experience. • Development experience on the data processing side of the software development. • Experience with Orchestration tools like Airflow or SSIS is required. • Strong experience with Relational like SQL Server or Oracle is required. • Strong background in Data warehousing and ETL principles, architecture, and its implementation in large environments. • Strong industry experience in programming languages such as Python or C#, with the ability to pick up new languages and technologies quickly. • Working knowledge on leading cloud platforms like Azure, AWS, GCP; Microsoft Azure experience is preferred. • Healthcare experience (using claims and EHR data) strongly preferred. • Bachelor’s degree in computer science, Computer Engineering, or related field from an accredited college or university; Master’s Degree preferred.",1919,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,5001 to 10000 Employees,Company - Public,False
iPhone Data Analysis Engineer,"Apple
","Cupertino, CA",-1,4.2,"Summary
Posted: Oct 9, 2023
Weekly Hours: 40
Role Number:200508772
Apple’s iPhone Hardware Engineering organization is looking for a highly motivated engineer with a real passion in both hardware and software. As a member of the iPhone modeling and algorithm team, you will work on opportunities to extend iPhone/iPad user experiences and improve battery life by studying data from the field, internal data sources and vendors. Are you ready for your next challenge? You will have the opportunity to influence the architectural roadmaps and high-level system specifications for the future iOS devices. This is an extraordinary cross-disciplinary opportunity and it requires intensive team collaboration effort coupled with proven system-engineering background.
Key Qualifications
Data analysis and automation - Significant expert at processing large volume of data, analysis, visualization analytics.
A deep understanding of probability, statistics, algorithms and mathematics.
Practical modern machine learning experiences in regression, classification and clustering.
Strong software skills (Matlab, C/C++, R, Python).
Excellent communication, persuasion and negotiation skills.
Proven self motivation and ability to work independently.
Understanding of control theory and how it relates to modeling Li-on batteries is a plus.
Understanding embedded system architecture is a plus.
Deep knowledge in key system-engineering architectural and implementation tradeoffs is a plus.
Description
We are looking for an engineer capable of handling challenges from “cradle to grave”. We love self-motivated teammates who are committed to continually innovate. Bring your passion and dedication and you will discover excitement and endless possibilities in the process of building our next-gen products in Apple. IN THIS ROLE, YOU WILL BE RESPONSIBLE FOR: - Support automated power data collection infrastructure for latest iPhone. - Build visualization tool for x-functional team to digest the power performance data - Perform data mining and data analysis across gigantic amount of data generated by multiple generation of iPhones - Leverage machine learning techniques to analyze the field data and provide the mentorship to the x-function teams for design decision making - Use case power analysis - Drive the future power-saving algorithms/techniques
Education & Experience
BS/MS/PHD EE Required
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",1976,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Software Engineer - Data (Remote),"Kinect
","Pasadena, CA",$90K - $137K (Glassdoor est.),4.1,"We are seeking a highly skilled Senior Software Engineer to join our client's growing team. As a Senior Software Engineer, you will play a key role in designing and developing advanced data modeling solutions to help build cutting-edge AI technologies that improve patient outcomes.

Responsibilities:

Develop, test, and deploy high-quality software solutions using a mix of programming languages, including Java, Scala, Kotlin, Clojure, and Python • Design and optimize distributed data processing systems for scalability, streaming, fault tolerance, and ACID compliance • Work with a wide range of database storage technologies, including relational, columnar, key-value, and document-oriented databases • Optimize performance metrics such as latency, throughput, cost, and memory usage • Collaborate with cross-functional teams, including data scientists and product managers, to identify and deliver innovative solutions to complex problems • Stay up-to-date with the latest industry trends and technologies, and identify opportunities to apply them to our work • Provide technical guidance and mentorship to junior team members
Qualifications:

Bachelor's or Master's degree in Computer Science or a related field • 5+ years of experience in software engineering, with a focus on distributed systems and data modeling • Expertise in at least one major JVM language (Java, Scala, Kotlin, Clojure) and Python • Strong understanding of distributed data processing concepts, including scalability, streaming, fault tolerance, ACID, and CAP • Experience working with cloud provider ecosystems, particularly AWS • Familiarity with serialization technologies such as Avro, Protobuf, and Thrift • Experience with AWS DynamoDB, Lambda, and Kinesis is a plus • Strong problem-solving skills and a passion for building innovative solutions
If you are a talented Senior Software Engineer who is passionate about building cutting-edge AI solutions for the medical field, we would love to hear from you.",2015,-1,$1 to $5 million (USD),-1,1 to 50 Employees,Company - Public,False
Software Engineer - Big Data Technologies,"Apple
","San Diego, CA",-1,4.2,"Summary
Posted: Sep 19, 2023
Weekly Hours: 40
Role Number:200495242
Meaningful insights require a solid infrastructure that is able to scale with the large amount of data coming in. Our team is responsible for discovering such great insights from a sea of data, and our infrastructure needs innovative ideas to improve its performance and ease-of-use. Would you like to help understand the challenges of building and maintaining a large-scale analytics infrastructure? Are you excited about identifying areas for improvement and creating out-of-the-box solutions? If this describes you, we would love to hear from you!
Key Qualifications
Great programming skills in C, C++, Python or Java
Strong analytical thinking
Self-motivated and able to work independently
Excellent spoken and written communication skills
Description
We're looking for a motivated engineer with excellent programming, problem solving and communication skills. In this role, you will be responsible for effective provisioning, installation/configuration, operation, and maintenance of our team’s analytics infrastructure. You will enable continued innovation and progress within the infrastructure through research and development. You will help and support the execution, test and roll-out of solutions. To be successful in this role, you must have a solid software engineering background and be able to write production level code. As a member of this team, you will have the opportunity to solve challenging engineering problems across a broad range of Apple products.
Education & Experience
B.S., M.S. or Ph.D. in Computer Science, Electrical Engineering or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $52.98 and $79.75/hr, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",1976,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer,"BayOne
",California,-1,3.9,"Job Summary

The Data Warehouse Engineer plays a critical role in building and supporting client's Enterprise Data Warehouse to deliver strategic business value to the organization. The Data Warehouse Engineer is responsible for designing and developing enterprise applications utilizing primary technologies such as SQLServer, Bigdata, and moving from on premise to cloud infrastructure. This is a collaborative position that will partner with both technical and non-technical colleagues to support client's growth strategy, innovative mindset, and commitment to quality.

Responsibilities

Design, code, test, and deploy new data warehouse features.

Ensure that the established standards are followed for application architecture, development, documentation and deployment.

Actively participate in code walkthroughs/inspections to ensure consistency and quality.

Follow the established software development methodology

Collaborate with stakeholders and other departments to plan and deploy new data warehouse releases or product enhancements.

Analyze query performance and perform query tuning to assist development engineers in designing and optimizing queries.

Troubleshoot production support issues in the application environments.

Extract data from disparate sources and transform into internal formats for loading into our platform.

Perform technical analysis and requirements definition with our partners on service integrations.

Travel requirements: None

Perform other duties and responsibilities as required, assigned, or requested.

Qualifications

Bachelor's degree in computer science or related technical field

At least 5 years of experience with Data Warehouse design and development of data structures and ETL processes in MS SQL Server or Oracle environment

At least 2 years of experience with Tableau solution development, and integration with existing architecture and data engineering assets.

Experience with architecting, designing, implementing, managing and supporting OLTP, OLAP or Warehouse Database Management Systems is a big plus

Understanding of quality assurance and data quality principals as applied to an ETL architecture is a plus

Critical thinking abilities to take complex, ambiguous, abstract requirements and break them into smaller components, patterns, views and features

Strong ability to communicate technical and data concepts to non-technical audiences, and business concepts to technical audiences

Ability to collaborate with other team members in the execution of large-scale projects",2012,Information Technology Support Services,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,False
Vibration Test & Data Analysis Engineer,"Tesla
","Fremont, CA",$111K - $154K (Glassdoor est.),3.6,"What to Expect

This position will work as a member of Tesla’s reliability and test team to develop and execute vibration and durability validation tasks for Tesla products.

What You’ll Do
Process public roads, proving ground durability data and develop accelerated random vibration profiles for MAST/ED shakers
Develop constant amplitude durability test profiles based on raw data collected from proving ground or field data
Conduct vibration testing on various vehicle sub-systems on electrodynamic shaker tables
Development, improvement of vibration durability methodologies (simulation and testing)
Do hands-on test setup (mounting unit on and off the shaker table) and instrumentation (accelerometers etc.)
Design test fixtures in CATIA for mounting sub-systems on electrodynamic and other shaker tables
Conduct part inspections, root cause and report failures
Post process test data and make test reports
Be involved with general test equipment maintenance and lab expansions
Work in close collaboration with other technicians, instrumentation and design teams
Maintain a clean and organized work environment
What You’ll Bring
BS and/or MS degree in mechanical, automotive or mechatronics engineering or equivalent
Strong mechanical engineering, vibration, and durability (damage theory) fundamentals
1+ years of experience with automotive systems or competitive projects like Formula SAE etc.
Data processing and analysis using nCode Glyphworks, MATLAB, Python etc.
Well versed with the instrumentation, usage, and data consumption from accelerometers, strain gages, load transducers and other road load data acquisition sensors
Experience with modal testing
Experience with 3D CAD software for fixture design (CATIA or 3D Experience preferred)
Able to work well under pressure while managing competing demands and tight deadlines
Excellent written & verbal communication skills
Strong organization skills with meticulous attention to detail",2003,Transportation Equipment Manufacturing,$1 to $5 billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Software Engineer - Data Integration,Chan Zuckerberg Imaging Institute,"Redwood City, CA",$113K - $164K (Glassdoor est.),-1.0,"To develop a dynamic, integrated view of biological systems in health and disease, the Chan Zuckerberg Institute for Advanced Biological Imaging (CZ Imaging Institute) aims to push forward the development and application of new imaging technologies over the next 10 to 15 years. CZ Imaging Institute researchers will collaboratively develop breakthrough biological imaging systems centered around grand challenges that push the boundaries of what we can see and measure to obtain deep insights into the architecture of complex biological systems at the molecular level.

As an extension of the Chan Zuckerberg Initiative's Imaging program, the CZ Imaging Institute (https://czii.org/) will create breakthrough technologies — hardware, software, biological probes, data, and platforms — that will be made available to the scientific community and adopted worldwide through a combination of direct access to the Institute, open sharing of advances, and commercial partnerships.

The Opportunity

The Chan Zuckerberg Imaging Institute is seeking an experienced Software Engineer - Data Integration to work under a technology team leader and collaborate in developing software that supports interfaces for high-end microscopic instruments. Will work closely with researchers, scientists, and engineers developing novel approaches in cryoEM.

What You'll Do
Write software to support interfaces to high-end instruments
Develop automated workflows for data acquisition and analysis across multiple modalities (Transmission and Scanning Electron Microscopy, Light Microscopy)
Integrate software with databases for tracking all data and metadata across modalities
Develop a user interface to the workflow
Contribute to research development projects for instruments
Partner cross-functionally with scientist to apply software solutions to scientific applications
What You'll Bring

Essential -

BS in Computer Science or a comparable/relevant degree
1-5 years of software engineering experience
Well developed analytical observation and software optimization skills combined with interest to understand the scientific impact of software performance
Deep understanding of software engineering principles and design patterns and how to apply them
Excellent problem solving skills
Excellent communication skills
An open and collaborative mindset
A passion for developing high quality, robust software
Experience working with the Python language

Nice to have -

Experience in experimental physics, robotics or computer science
Experience collaborating cross-functionally with scientist
An interest in science and learning about biological imaging
Experience working in an startup environment
Diverse experience working with both desktop and web applications and understanding how they can interface with each other
Hands-on experience interfacing with scientific hardware such as microscopes
Experience working with mysql and/or javascript is plus

The Chan Zuckerberg Biohub Network requires all employees, contractors, and interns, regardless of work location or type of role, to provide proof of full COVID-19 vaccination, including a booster vaccine dose, if eligible, by their start date. Those who are unable to get vaccinated or obtain a booster dose because of a disability, or who choose not to be vaccinated due to a sincerely held religious belief, practice, or observance must have an approved exception prior to their start date.

Compensation
SW Engineer I = $92,000 to $126,500
SW Engineer II = $108,000 to $148,500

New hires are typically hired into the lower portion of the range, enabling employee growth in the range over time. To determine starting pay, we consider multiple job-related factors including a candidate's skills, education and experience, market demand, business needs, and internal parity. We may also adjust this range in the future based on market data. Your recruiter can share more about the specific pay range during the hiring process.

What We Provide
Resources to collaboratively develop breakthrough biological imaging systems that push the boundaries of what we can see and measure
An environment where nothing is considered impossible, where bold and creative thinking are the norm, and where a collaborative culture allows teams of people from multiple disciplines to accomplish more than any single person can achieve alone
Access to collaborators and resources at partner organizations in the CZ Biohub Network and beyond
Competitive compensation and benefits commensurate with experience

Benefits

We offer a robust benefits program that enables the important work employees do everyday. Our benefits include healthcare coverage, life and disability insurance, commuter subsidies, family planning services with fertility care, childcare stipend, 401(k) match, flexible time off and a generous parental leave policy. In addition, we honor our commitment to career development and our value of scholarly excellence through regular onsite opportunities to learn from the world's leading scientists.

The CZ Biohub Network is an equal opportunity employer committed to diversity of thought, ideas and perspectives. We are committed to cultivating an inclusive organization where all employees feel inspired and know their work makes an important contribution. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law.

Pursuant to the California Fair Chance Act, we will consider for employment qualified applicants with arrest and conviction records.

Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. The CZ Biohub Network does not accept unsolicited headhunter and agency resumes. The CZ Biohub Network will not pay fees to any third-party agency or company that does not have a signed agreement with the CZ Biohub Network.",-1,-1,Unknown / Non-Applicable,-1,51 to 200 Employees,Company - Private,True
Data Science & Analytics Engineer II,"Medtronic
","Northridge, CA",-1,3.9,"Careers that Change Lives



The Diabetes Operating Unit focuses on improving the lives of those within the global diabetes community. As a business, we strive to empower people with diabetes to live life on their terms by delivering innovation that truly matters and providing support in the ways they need it. We’re committed to meeting people with diabetes where they are in their journey, always with an aim to make their lives easier. Our portfolio of innovative solutions are designed to provide customers greater freedom and better health, helping them achieve better glucose control, while spending less time managing their disease.

Join a diverse team of innovators who bring their worldview, their unique backgrounds, and their individual life experiences to work every day. It’s no accident —we work hard to cultivate a workforce that reflects our patients and partners. We believe it’s the only way to drive healthcare forward and remain a global leader in medical technology and solutions.



A Day in the Life



We are looking for an enthusiastic person with strong analytical skills to join our team. The position involves research and development of medical devices related to continuous glucose monitors. The individual will work with members of research staff to improve the performance of continuous glucose sensors through the application of advanced signal processing techniques, statistically-driven analytics, data processing, machine learning, mathematical modeling and experimentation. The role will involve all aspects of the research process, including data gathering, data processing and clean up, analysis, theory development and validation. Additionally, the candidate will be involved in the documentation of such systems for regulatory submissions both domestically and internationally. The ideal candidate would have direct experience in data analytics for biomedical devices.

Responsibilities may include the following and other duties may be assigned.

Contribute to glucose sensing technology innovation and research, technology transfer from research to development, algorithm development, simulation, and modeling
Support data processing and ensuring data quality used in downstream analytics and algorithm development efforts
Apply principles of signal processing, machine learning, analytics, and modeling to construct algorithms in MATLAB or other software package to test concepts
Analyze and quantify large amounts of data to generate verifiable conclusions
Identify problem areas and work with the team to gather the experimental data necessary to address these
Support complex projects to meet technology performance and schedule objectives
Support department functional groups in defining product features and requirements
Comply with external and internal regulatory requirements
Write detailed technical and scientific reports and manuscripts
Apply data analysis results to aid product development decisions and clinical study design
Must Have: Minimum Requirements

Bachelors in Electrical Engineering, Computer Science, Biomedical Engineering (signal processing/analytics focus), Mathematics, Physics or related discipline 2+ years of industry experience,
OR, Masters in Electrical Engineering, Computer Science, Biomedical Engineering (signal processing/analytics focus), Mathematics, Physics or related discipline

Nice to Have

Working knowledge of advanced analytics methods, modeling, advanced signal processing, and/or machine learning methodologies
Demonstrated experience with, data processing, statistical analysis and/or signal processing
Proficient in MATLAB programming language, Python programming language and/or other signal processing environments
Excellent verbal and written communication skills with the ability to articulate complex ideas effectively
Demonstrated ability in managing/supporting multiple projects in a deadline driven environment
Experienced with producing and presenting engineering/technical presentations
Demonstrated ability in producing written documentation such as specifications, engineering reports, test plans, test procedures, validation plans, and validation reports
Excellent organization and multi-tasking abilities
Knowledge of and experience with machine learning
Industry or academic experience working with biological signals; preferably in medical devices
Demonstrated understanding of statistical techniques and methods
Experience with Big Data and Cloud environments

About Medtronic

Together, we can change healthcare worldwide. At Medtronic, we push the limits of what technology, therapies and services can do to help alleviate pain, restore health and extend life. We challenge ourselves and each other to make tomorrow better than yesterday. It is what makes this an exciting and rewarding place to be.

We want to accelerate and advance our ability to create meaningful innovations - but we will only succeed with the right people on our team. Let’s work together to address universal healthcare needs and improve patients’ lives. Help us shape the future.

Physical Job Requirements

The physical demands described within the Responsibilities section of this job description are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. For Office Roles: While performing the duties of this job, the employee is regularly required to be independently mobile. The employee is also required to interact with a computer, and communicate with peers and co-workers. Contact your manager or local HR to understand the Work Conditions and Physical requirements that may be specific to each role. (ADA-United States of America)",1949,Health Care Products Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Systems Engineer - Data Modeler (Hybrid),"BAE Systems
","San Diego, CA",$109K - $185K (Employer est.),4.0,"Job Description
BAE Systems is seeking a skilled Systems Engineer, Data Modeler to join our team. The Systems Engineer, Data Modeler will need a wide breadth of multi-domain knowledge to function as a Data Modeler. As a Data Modeler, you are an experienced professional with hands-on technical and domain expertise and a depth of understanding of how data models and ontologies support the conditioning, securing, storage, and dissemination of data in multiple types of data store technologies. The ideal candidate is a motivated, experienced engineer who understands the importance of data, and is comfortable critiquing and creating new schemas in support of customer data requirements. As a Data Modeler, you will collaborate closely with key stakeholders and system users to understand challenges and pain points so they can be addressed to increase system performance and organizational effectiveness.

Responsibilities will include:
Researching data types to design agnostic data models supporting multi-domain users
Creating, updating, and integrating new data models into the Unified Data Library
Understanding the existing overall UDL data model in order to create concepts for leveraging existing solutions to satisfy future requirements
Communicating the scope and state of work, identifying issues, and anticipating roadblocks.
Translating customer requirements into actionable items
Defining iterations and stories for development efforts
Providing support to customer and company planning efforts
Contributing to a program's technical roadmap
Supporting design and architecture studies for customers
Researching cutting-edge technology to enhance software product features, reliability, and performance
Supporting architecture trade studies and technology evaluations
Documenting work products in briefings and/or technical reports to customers and teammates
Collaborating with cross-domain teams in research and development

Because of the need for intermittent in-person collaboration and/or the requirement to perform a portion of work onsite, this position will be considered hybrid. This means work will be conducted on location at a BAE Systems facility as well as remotely, when applicable.

Required Education, Experience, & Skills

6+ years of systems engineering and data modeling experience
Network experience with protocols and best practices.
Broad operational Joint / Combined experience required with knowledge of or specific experience/training in at least one of the following domains:
Space Domain Awareness
Space Defense
Air
Land
Maritime

Preferred Education, Experience, & Skills

Platform instruction, delivering briefings or training (formal, instructional, or on the job) is highly desired
Hands-on history with the Atlassian Tool Suite, such as Confluence and Jira
Scrum/Agile development framework and methodologies
Detail-oriented with the ability to multi-task and work effectively while prioritizing multiple competing priorities
Possess stakeholder management, engagement, and collaboration skills along with a growth mindset
Highly effective written and verbal communicator - clearly articulates complex concepts and tailors communication based on the audience
Sees underlying and relevant concepts and patterns in complex situations
Independently prioritizes and escalates unforeseen issues
Personally, and professionally resilient - tolerates ambiguity or uncertainty well in a changing working environment
Displays a strong sense of ownership for projects

Pay Information
Full-Time Salary Range: $109120 - $185460

Please note: This range is based on our market pay structures. However, individual salaries are determined by a variety of factors including, but not limited to: business considerations, local market conditions, and internal equity, as well as candidate qualifications, such as skills, education, and experience.

Employee Benefits: At BAE Systems, we support our employees in all aspects of their life, including their health and financial well-being. Regular employees scheduled to work 20+ hours per week are offered: health, dental, and vision insurance; health savings accounts; a 401(k) savings plan; disability coverage; and life and accident insurance. We also have an employee assistance program, a legal plan, and other perks including discounts on things like home, auto, and pet insurance. Our leave programs include paid time off, paid holidays, as well as other types of leave, including paid parental, military, bereavement, and any applicable federal and state sick leave. Employees may participate in the company recognition program to receive monetary or non-monetary recognition awards. Other incentives may be available based on position level and/or job specifics.

About BAE Systems Electronic Systems
BAE Systems, Inc. is the U.S. subsidiary of BAE Systems plc, an international defense, aerospace and security company which delivers a full range of products and services for air, land and naval forces, as well as advanced electronics, security, information technology solutions and customer support services. Improving the future and protecting lives is an ambitious mission, but it’s what we do at BAE Systems. Working here means using your passion and ingenuity where it counts – defending national security with breakthrough technology, superior products, and intelligence solutions. As you develop the latest technology and defend national security, you will continually hone your skills on a team—making a big impact on a global scale. At BAE Systems, you’ll find a rewarding career that truly makes a difference. Electronic Systems (ES) is the global innovator behind BAE Systems’ game-changing defense and commercial electronics. Exploiting every electron, we push the limits of what is possible, giving our customers the edge and our employees opportunities to change the world. Our products and capabilities can be found everywhere – from the depths of the ocean to the far reaches of space. At our core are more than 14,000 highly talented Electronic Systems employees with the brightest minds in the industry, we make an impact – for our customers and the communities we serve.

Our Commitment to Diversity, Equity, and Inclusion:
At BAE Systems, we work hard every day to nurture an inclusive culture where employees are valued and feel like they belong. We are conscious of the need for all employees to see themselves reflected at every level of the company and know that in order to unlock the full potential of our workforce, everyone must feel confident being their best, most sincere self and be equipped to thrive. We provide impactful professional development experiences to our employees and invest in social impact partnerships to uplift communities and drive purposeful change. Here you will find significant opportunities to do meaningful work in an environment intentionally designed to be one where you will learn, grow and belong.",1999,Aerospace & Defense,$10+ billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
Data Center Controls Systems Engineer,"Google
","Sunnyvale, CA",-1,4.4,"Minimum qualifications:
Master's degree in Engineering, Science, a related field, or equivalent practical experience.

5 years of experience designing and implementing controls systems and dynamic modeling.

5 years of experience with Machine Learning and construction of algorithms.

Experience with programming in C, Python, MATLAB, or Shell.

Preferred qualifications:
PhD in Engineering, Science, or a related field.

Experience with modeling/statistical software such as TensorFlow, Simulink, R, or MATLAB Machine Learning Toolbox.

Experience with digital signal processing and time-series analysis.

Experience with optimization, Linear Programming, and Convex Optimization.

Experience with dynamic system analysis, feedback control systems (PID Control), and optimal control.
About the job

The Data Center Engineering team takes the physical design of our data centers into the future. In this role, you will take on complex topics, optimize for efficiencies, and always seek ways to improve. You will also generate ideas, communicate recommendations to executives and drive implementation alongside facilities technicians.

Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.

The US base salary range for this full-time position is $114,000-$167,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.


Responsibilities
Research and develop new algorithms and methods for optimizing data center efficiency and performance.
Design, validate, and implement controls algorithms to handle electrical and mechanical stability.
Analyze and recommend approaches to handling dynamics of the electromechanical systems and their interactions within a data center.
Conduct empirical statistical analysis/modeling on relevant data for use in data center controls.
Collaborate with the Engineering team to implement proposed strategies and algorithms in our technology system. Develop large scale Machine Learning algorithms for pattern recognition and Bayesian and non-linear systems.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",1998,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Sr. Software Engineer - ML/Data (Remote,"Gap Inc.
","San Francisco, CA",$95K - $138K (Employer est.),3.6,"About Gap Inc.

Our brands bridge the gaps we see in the world. Old Navy democratizes style to ensure everyone has access to quality fashion at every price point. Athleta unleashes the potential of every woman, regardless of body size, age or ethnicity. Banana Republic believes in sustainable luxury for all. And Gap inspires the world to bring individuality to modern, responsibly made essentials.

This simple idea—that we all deserve to belong, and on our own terms—is core to who we are as a company and how we make decisions. Our team is made up of thousands of people across the globe who take risks, think big, and do good for our customers, communities, and the planet. Ready to learn fast, create with audacity and lead boldly? Join our team.

About the Role

In this role, you will design highly scalable and high performing technology solutions in an Agile work environment and produce and deliver code and/or test cases using your knowledge of software development and Agile practice. You will collaborate closely with business support teams, product managers, security and architecture to assist in resolving critical production issues to help simplify and improve business processes through the latest in technology and automation. You are a technical expert that will lead through the requirements gathering, design, development, deployment, and support phases of a product. You are proficient in at least one core programming languages or packages.

This is a remote role is based out Dallas, TX. However, the Company may require you in the future to work in an on-site location designated by Gap Inc. on a full-time or part-time basis.

What You'll Do
Define technical specifications and development requirements that result in high performing technologies that are also domain specific.
Develop and enhance product and/or applications with limited direction to solve business problems of medium complexity by keeping customer experience at the forefront.
Adopt and model a DevOps mindset by applying automation, continuous integration and continuous delivery in everything we do.
Foster innovation by applying best practices and learning from emerging technologies and through collaboration with cross functional stakeholders.
Serve as application expert in support of domain areas.
Communicate difficult concepts, providing technical and professional interpretations and recommendations.
Advise and mentor junior team members and enable collaboration to help teams achieve their best.
Who You Are
Software Development experience and understanding of security, secure coding/testing and data structures and aware of industry and competitor practices.
Comprehensive knowledge of software development, practice, concepts and technology.
Proficiency with various software languages and platforms such as Java, Oracle, Azure etc.
Experience with related technology stack and platforms.
Experience with building and sustaining effective relationships with immediate team and stakeholders.
Benefits at Gap Inc.
Merchandise discount for our brands: 50% off regular-priced merchandise at Old Navy, Gap, Banana Republic and Athleta, and 30% off at Outlet for all employees.
One of the most competitive Paid Time Off plans in the industry.*
Employees can take up to five “on the clock” hours each month to volunteer at a charity of their choice.*
Extensive 401(k) plan with company matching for contributions up to four percent of an employee’s base pay.*
Employee stock purchase plan.*
Medical, dental, vision and life insurance.*
See more of the benefits we offer.
For eligible employees

Gap Inc. is an equal-opportunity employer and is committed to providing a workplace free from harassment and discrimination. We are committed to recruiting, hiring, training and promoting qualified people of all backgrounds, and make all employment decisions without regard to any protected status. We have received numerous awards for our long-held commitment to equality and will continue to foster a diverse and inclusive environment of belonging. In 2022, we were recognized by Forbes as one of the World's Best Employers and one of the Best Employers for Diversity.

Salary Range: $95,300 - $138,200 USD
Employee pay will vary based on factors such as qualifications, experience, skill level, competencies and work location. We will meet minimum wage or minimum of the pay range (whichever is higher) based on city, county and state requirements.

US Candidates
Please note that effective, June 30, 2022, Gap Inc. will no longer require any of its employees to wear face masks or require proof of COVID vaccination, unless required by local or state/provincial mandates or as part of Gap Inc’s quarantine guidelines after being exposed to or testing positive for COVID. Therefore, please disregard any language in any job posting that refers to Gap Inc.’s face mask and proof of vaccination policy as said policy is no longer effective.",1969,"Department, Clothing & Shoe Stores",$10+ billion (USD),Retail & Wholesale,10000+ Employees,Company - Public,False
Senior Data Engineer/Data Scientist,"Snowflake
","Dublin, CA",$146K - $189K (Glassdoor est.),4.0,"Build the future of data. Join the Snowflake team.

We’re looking for a talented Senior Data Scientist to come aboard. In this role, you will work closely with our Product and Engineering teams to uncover insights about how customers use Snowflake, helping to inform Product’s decision making and focus Engineering efforts. You will also work on long-running analytical initiatives marked by greater complexity and less structure that will yield substantial product enhancements. This is a strategic, high-impact role that will help shape the future of Snowflake products and services.

AS A SENIOR DATA SCIENTIST AT SNOWFLAKE YOU WILL:

Sleuth through large amounts of data to uncover feature-usage patterns, subtle issues with the system, potential performance enhancements, and areas to improve user experience.
Collaborate closely with Engineers and Product Managers to inform product decision making with data and to identify opportunities to create more value for our customers.
Build dashboards to help Engineering and Product Managers monitor performance and availability of our system.
Answer questions from the executive team for board reporting, publications, and industry reports.
Think creatively to find optimal solutions to our complex, often unstructured problems.

OUR IDEAL CANDIDATE WILL HAVE:

BS/MS in quantitative discipline (Math, Statistics, Operations Research, Economics, Engineering, or CS)
Expert-level experience working with SQL and relational data (8+ years on a regular basis).
8+ years of experience with Python, including scikit-learn, numpy, and pandas.
Experience working with large-scale machine generated data (e.g., log, application, or customer-usage data).
Hands-on experience with MPP databases, such as Snowflake, Redshift, BigQuery, Vertica, etc.
Ability to clearly present learnings to business leaders and technical stakeholders.
The ability to thrive in a dynamic environment. That means being flexible and willing to jump in and do whatever it takes to be successful.
Prior experience on data engineering products like ingestion, connectors is a plus

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.",2012,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,5001 to 10000 Employees,Company - Public,False
Senior Software Engineer - Data Lake,"Snowflake
","San Mateo, CA",$214K - $328K (Employer est.),4.0,"Build the future of data. Join the Snowflake team.

The Snowflake Data Lake team’s mission is to power open standards with Snowflake innovation. Our customers want to bring more data to Snowflake to support their variety of data lake use cases with large data sets but face the common challenges of control, cost, and interoperability. This team aims to address these challenges and enable customers to benefit from Snowflake’s rich features and integrated platform capabilities while embracing their choice of open table standards (e.g., Apache Iceberg), file formats (e.g.,Apache Parquet), storage solutions, and third-party open source tool set (e.g.,Apache Spark). We’re on the early journey to build the best data lake solutions for any workload at scale.

We are seeking talented Senior Software Engineers who are technical leaders in the big data open source community to join us to define the strategy, engage and deliver innovation into the open source community, and bring Snowflake to millions of big data professionals.

AS A SENIOR SOFTWARE ENGINEER AT SNOWFLAKE, YOU WILL:

Understand customer requirements and define product strategies.
Design, develop, and operate highly reliable large scale data lake systems.
Embrace Snowflake innovations with open source standards and tool sets.
Be an active influencer for the direction of open source standards.
Partner closely with Product teams to understand requirements and design cutting edge new capabilities that go directly into customer’s hands.
Analyze fault-tolerance and high availability issues, performance and scale challenges, and solve them.
Ensure operational excellence of the services and meet the commitments to our customers regarding reliability, availability, and performance.

IDEAL CANDIDATE WILL HAVE MOST OF THE FOLLOWING QUALIFICATIONS:

8+ years of hands-on experience in large scale data intensive distributed systems, especially in distributed file systems, object storage, data warehouse, data lake, data analytics, and data platform infrastructure.
Strong development skills in Java and C++.
An active PMC (Program Management Committee) or Committer to open source like Apache Iceberg, Parquet, Spark, Hive, Flink, Delta Lake, Presto, Trino, and Avro.
Proven track record of leading and delivering large and complex big data projects across organizations.
A growth mindset and excitement about breaking the status quo by seeking innovative solutions.
An excellent team player who is consistent in making everyone around you better.
Experience with public clouds (AWS, Azure, GCP) is a plus
BS/MS in Computer Science or related major, or equivalent experience

The following represents the expected range of compensation for this role:

The estimated base salary range for this role is $214,000 - $327,750.
Additionally, this role is eligible to participate in Snowflake’s bonus and equity plan.

The successful candidate’s starting salary will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location. This role is also eligible for a competitive benefits package that includes: medical, dental, vision, life, and disability insurance; 401(k) retirement plan; flexible spending & health savings account; at least 12 paid holidays; paid time off; parental leave; employee assistance program; and other company benefits.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?",2012,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,5001 to 10000 Employees,Company - Public,False
"Data Engineer, E-Commerce","TikTok
","San Jose, CA",$136K - $280K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

The Global E-Commerce team focuses on building data infrastructure and data product areas to support business engineering teams working directly on TikTok's E-Commerce platform.

As a data engineer in the Global E-Commerce team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

Responsibilities - What You'll Do

Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis);
Design and implement reliable, scalable, robust and extensible big data systems that support core products and business;
Establish solid design and best engineering practice for engineers as well as non-technical people.
Qualifications

BS or MS degree in Computer Science or related technical field or equivalent practical experience;
Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.);
Experience with performing data analysis, data ingestion and data integration;
Experience with ETL(Extraction, Transformation & Loading) and architecting data systems;
Experience with schema design, data modeling and SQL queries;
Passionate and self-motivated about technologies in the Big Data area.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at Dennis.Chau@tiktok.com
Job Information
The base salary range for this position in the selected city is $136000 - $280000 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Systems Engineer - Data Protection/Storage - Hybrid Remote,"CEDARS-SINAI
","Los Angeles, CA",$86K - $137K (Employer est.),4.1,"Grow your career at Cedars-Sinai!

The Enterprise Information Services (EIS) team at Cedars-Sinai understands that true clinical transformation and the optimization of a clinical information systems implementation is fueled through the alignment of the right people, processes, and technologies. Cedars-Sinai has once again solidified its position as a global healthcare technology leader.

Why work here?

Cedars-Sinai placed in the top 20 on Newsweek’s “World's Best Smart Hospitals 2024” list, which highlights hospitals that have excelled in the utilization of electronic functionalities, telemedicine, digital imaging, artificial intelligence and robotics.

The organization’s Healthtech excellence was acknowledged again, this time by the esteemed “CHIME Digital Health Most Wired“ recognition program. Cedars-Sinai was assigned a Level 10—the most prestigious level of certification—among more than 300 surveyed healthcare organizations. Cedars-Sinai netted high scores across multiple verticals and particularly excelled in the areas of infrastructure, interoperability, and population health innovation.

What will you be doing in this role:

The Systems Engineer (Data Protection/Storage) is part of the Service Delivery Infrastructure Team. They will be responsible for a broad variety of technical administration and support for Health System information systems and enterprise applications. Emphasis will be on supporting the IT Infrastructure components that involves Data Protection/Backups (Commvault), Storage (Dell/EMC, Netapp), and Linux (Redhat).

Responsible for technical administration of IT Infrastructure involving Backup Systems, SAN, and Linux.
Configures, installs, maintains, applies patches/fixes and troubleshoot physical and logical tiers of applications/software/systems.
Provides technical expertise and direct support for the planning, coordination, upgrade, improvement and implementation of infrastructure and application software.
Ensures stable performance through performance monitoring and tuning.
Ensure timely system maintenance, plan and implement major software and hardware upgrades, ensuring organizational change procedures and methodologies are implemented and followed.
Work as a liaison with contractors and vendors as needed.
Works independently or as a member of interdisciplinary teams on complex projects. Serves as a mentor for other technical staff and provides technical consultation, guidance, and support as needed to operational and technical staff.



Experience Requirements:

Three (3) plus years of experience as a systems engineer in a complex multi-platform, multi-protocol environment.

Administration for IT infrastructure: Data Protection/Backups. Commvault preferred. Storage Netapp/EMC.

Experience with Linux (Redhat), SAN (Dell/EMC, Netapp), Backup (Commvault).

Experience with Cisco UCS, AIX, and heath care environment is a plus.

Strong DevOps skills is helpful. (Ansible, Powershell, VRO, Python, Perl, Shell, etc.)

Solid project management and interpersonal skills; able to deal effectively with diverse abilities and personalities, provide strong team leadership, and work effectively as a standout colleague.

Educational/Certification Requirements:

Bachelor's Degree in Computer Science or Electrical Engineering. (preferred)

Certification in Commvault, Netapp, EMC preferred.

Jobs-Indeed

LI-Hybrid





Working Title: Systems Engineer - Data Protection/Storage - Hybrid Remote
Department: Technology Operations
Business Entity: Cedars-Sinai Medical Center
Job Category: Information Technology
Job Specialty: Network & Systems Engineering
Position Type: Full-time
Shift Length: 8 hour shift
Shift Type: Day
Base Pay:$85,900.00 - $137,300.00",1902,Health Care Services & Hospitals,$1 to $5 billion (USD),Healthcare,10000+ Employees,Nonprofit Organization,False
"Software Development Engineer - Advertising, Partner Growth, Partner Opportunities & Data","Amazon.com Services LLC
","San Luis Obispo, CA",$115K (Employer est.),3.7,"3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
Amazon Advertising operates at the intersection of eCommerce and advertising, offering a rich array of digital display advertising solutions with the goal of helping our customers find and discover anything they want to buy. We help advertisers reach Amazon customers on Amazon.com, across our other owned and operated sites, on other high quality sites across the web, and on millions of Kindles, tablets, and mobile devices. We start with the customer and work backwards in everything we do, including advertising. If you’re interested in joining a rapidly growing team working to build a unique, world-class advertising group with a relentless focus on the customer, you’ve come to the right place.
The Global Advertising Partner Development team helps suppliers, agencies, marketers, authors, content creators, designers, non-endemic advertisers and developers to scale their use of Amazon Advertising and grow their business by surfacing a diverse selection of products to millions of worldwide Amazon customers. We do this via software tools and marketing/engagement programs that enable developers (internal and external) and partners (agencies and tool providers) to better serve advertiser needs.

Job Responsibilities:

Drive initiatives to increase advertising revenue across Amazon's sites and devices worldwide
Design, develop and scale APIs and other tools for external developers to help brands and their partners optimize their advertising spend
Building brand new distributed software applications using cloud services and Amazon proprietary technologies to deliver these tools to external developers
Impact and Career Growth:

Opportunity to learn many facets of advertising and retail, and understand how they come together, equipping you with the skills to grow your career
Opportunity to experiment, innovate and deliver in a fast, agile and reliable manner with high quality and low technical debt
Opportunity to grow and broaden your technical skills as you work in an environment that thrives on creativity, experimentation, and product innovation
If you are looking to make an impact, this is the team for you. Change the world by building, improving and championing the product with a strong sense of ownership. Thrive in our creative, self-motivated environment with a strong customer-focused mindset. You enjoy making strong impact with all aspects of application development across full-stack engineering with an emphasis towards APIs and service-oriented architecture. Take your team to the next level by driving meaningful initiatives with a leadership role in the latest service-oriented technologies.

We are open to hiring candidates to work out of one of the following locations:

San Luis Obispo, CA, USA


3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.",1994,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Senior Data Engineer,"Activision
","Santa Monica, CA",$101K - $187K (Employer est.),3.7,"Job Title:
Senior Data Engineer

Requisition ID:
R022176

Job Description:

Welcome to Solid State Studios. We’re a new in-house studio within Activision, dedicated to developing the best AAA mobile games in the world. Our first project is Call of Duty: Warzone for Mobile, and we’re looking for great talent, passionate about their work, who share our belief in what AAA experiences on mobile can and should be. We’re incredibly excited to build out our teams and get to work, and invite you to join us in making something special!

Our first project is Call of Duty Warzone for Mobile and we’re looking for great talent from mobile, console and PC backgrounds passionate about their work, who share our belief in what AAA experiences on mobile canand should be. We’re incredibly excited to build out our teams and get to work, and invite you to join us in making something special.
Your Profile

As a Sr. Data Engineer you will be responsible for the millions of events our game will emit each day.

You will collaborate closely with engineers to instrument events in the game code, work with data analysts to define the processing of data through ETLs into our data architecture, and be responsible for the infrastructure that automates reporting of business insights.

You will work cross-title with other data teams to evolve the

pipeline that processes events across a large-scale data footprint.

You will lead the monitoring solutions used to ensure the availability and reliability of our data and our game, including the machine learning based alerting system for anomaly detection and identify a solution to detect slow moving trends.

As the senior member of the team, you will dentify new ways to elevate our data systems, increase the self-serve nature of our data ecosystem, and minimize data and game outages.

You will also mentor and guide other members of the team and set roadmaps and priorities.

Main Mission

Contribute to the solutions used for processing and storing of data, from

code libraries to ETLs to Databricks Lakehouse, dashboards, and in-grown

coding projects used for data analysis

Maintain and expand upon our ETL process, consuming data from third

parties where needed, and ensure a clean data architecture

Work with multi-functional team members in defining and documenting single

sources of truth to ensure consistent and high-quality data

Reconcile data issues and alerts between various systems, finding

opportunities to innovate and drive improvements

Work in a highly collaborative team to devise solutions to business problems,

bringing your skills and ideas into every discussion

Learn new technical skills when needed and use them to help the team

achieve success

Collaborate with other Call of Duty teams to ensure the consistent and

coherent growth of our data and tools capabilities

Assist the data scientist community, helping to analyse the results of AB tests

and define predictive models

Minimum Requirements:

MS/BS in Computer Science, Data Science, Systems Engineering, Applied Mathematics or equivalent experience

8+ years of experience as a Data Engineer or in a similar role

Expert-level knowledge of SQL

Experience with Python including common data science libraries (e.g. Pandas,

NumPy, Jupyter, IPython)

Experience working with Google Cloud Platform OR Exposure to Big Data

technologies like Databricks and/or BigQuery

Ability to build API integrations with our internal systems and third-party data

sources

Strong communication skills with the ability to translate business needs into

technical specifications

Highly collaborative work style, but not afraid to take on solo tasks

Curious and inquisitive mind-set

Bonus Objectives:

Experience in solving complex data engineering problems at a really large

scale

Familiarity with version control tools (Git commands) and basic

understanding of containerization, build, and deployment processes

Experience with big data platforms technologies such as Kafka, Spark,

Airflow, and others

Familiarity with live monitoring solutions like Anodot

We love hearing from anyone who is enthusiastic about changing the games

industry. Not sure you meet all qualifications? Let us decide! Research shows that

women and members of other under-represented groups tend to not apply to jobs

when they think they may not meet every qualification, when, in fact, they often do!

At Activision Blizzard, we are committed to creating a diverse and inclusive

environment and strongly encourage you to apply.

About Activision

Activision Blizzard, Inc. (NASDAQ: ATVI), is one of the world's largest and most

successful interactive entertainment companies and is at the intersection of media, technology and entertainment. We are home to some of the most beloved entertainment franchises including Call of Duty®, World of Warcraft®,

Overwatch®, Diablo®, Candy Crush™ and Bubble Witch™. Our combined

entertainment network delights hundreds of millions of monthly active users in 196 countries, making us the largest gaming network on the planet!

Our ability to build immersive and innovative worlds is only enhanced by diverse teams working in an inclusive environment. We aspire to have a culture where everyone can thrive in order to connect and engage the world through epic entertainment. We provide a suite of benefits that promote physical, emotional and financial well-being for ‘Every World’ - we’ve got our employees covered!

The videogame industry and therefore our business is fast-paced and will continue to evolve. As such, the duties and responsibilities of this role may be changed as advised by the Company at any time to promote and support our business and relationships with industry partners.

Activision is an Equal Opportunity Employer. All qualified applicants will receive

consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, protected veteran status, or any other basis protected by applicable law and will not be discriminated against on the basis of disability.

Rewards

We provide a suite of benefits that promote physical, emotional and financial well-being for ‘Every World’ - we’ve got our employees covered! Subject to eligibility requirements, the Company offers comprehensive benefits including:

Medical, dental, vision, health savings account or health reimbursement account, healthcare spending accounts, dependent care spending accounts, life and AD&D insurance, disability insurance;
401(k) with Company match, tuition reimbursement, charitable donation matching;
Paid holidays and vacation, paid sick time, floating holidays, compassion and bereavement leaves, parental leave;
Mental health & wellbeing programs, fitness programs, free and discounted games, and a variety of other voluntary benefit programs like supplemental life & disability, legal service, ID protection, rental insurance, and others;
If the Company requires that you move geographic locations for the job, then you may also be eligible for relocation assistance.

Eligibility to participate in these benefits may vary for part time and temporary full-time employees and interns with the Company.

In the U.S., the standard base pay range for this role is $101,000.00 - $186,754.00 Annual. These values reflect the expected base pay range of new hires across all U.S. locations. Ultimately, your specific range and offer will be based on several factors, including relevant experience, performance, and work location. Your Talent Professional can share this role’s range details for your local geography during the hiring process. In addition to a competitive base pay, employees in this role may be eligible for incentive compensation. Incentive compensation is not guaranteed.",1979,Video Game Publishing,$500 million to $1 billion (USD),Media & Communication,1001 to 5000 Employees,Subsidiary or Business Segment,False
Data Engineer,DUOPEAK,"Menlo Park, CA",$110K - $163K (Glassdoor est.),-1.0,"At DuoPeak we’re a team of passionate and hard-working individuals with a real love for mobile games. We found ourselves enamored with understanding the process of what makes a game successful. Through our combined understanding, we found that the real essence of a successful game comes down to three things: Product, Marketing and Operations.




What we’re looking for is the Data Engineer, who will thrive in an environment that is hands on and is always looking for ways to improve and further our business through big data and AI. We are offering a large opportunity for growth.




Job Type: Full-time

Key Responsibilities:




Create and maintain optimal data pipeline architecture.
Identify, design, and implement internal data process improvements for security, accuracy, stability and scalability purposes.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, GCS and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipelines to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Create data tools and deploy ML models for the analytics/data scientist team members, which will assist them in building and optimizing our product into an innovative industry leader.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.



What We're Looking For:




Highly analytical, data-driven individuals
Detail-oriented and organized people
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience with data processing software (such as Hadoop, Spark, Pig, Hive) , data processing algorithms (MapReduce, Flume) and data pipeline & workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience building processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.

A Plus For:




Strong project management and organizational skills is a plus
Experience supporting and working with cross-functional teams in a dynamic environment.
A Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with Google or AWS cloud services
Experience with stream-processing systems: Storm, Kafka, Spark-Streaming, etc.



Benefits:




Fully Covered Health insurance
Unlimited DTO
401K
Snacks (Food/Drinks)
Cell Phone Reimbursement
‍

Apply",-1,-1,Unknown / Non-Applicable,-1,51 to 200 Employees,Company - Private,False
Data Communications Engineer - III,"GTA (Global Technology Associates)
","San Francisco, CA",$91K - $181K (Employer est.),4.6,"Looking for a Data Communications Engineer - III

What you will be doing as a Data Communications Engineer – III

This member of technical staff will be responsible for managing the standalone IT network and 4G/5G infrastructure and mobile edge cloud environments for a test and development lab program.
This is a technical position focused on supporting the development of technology solutions testing and incubation of new platforms and the product engineering of greenlit projects.
In this role the candidate will work with internal technology and product groups and external partners to support the development of new solutions.
He/She will be responsible for the architecture design and deployment of new 4G/5G and MEC platforms and features and will work very closely with Device testing Product engineering Business groups and peer TPD teams.
The candidate will be a member of a small team of Sr. Network engineers who manage remote lab access configure and manage virtual environments to support projects monitor and troubleshoot problems and make recommendations on how to streamline development with internal and external partners.

What you will bring to the table as a Data Communications Engineer - III

BA in IT/EE or Computer Engineering
The ideal candidate needs to have a strong technical background with experience in wireless and wireline networks hands on integration experience with MEC/Cloud/IT
Experience working in a customer facing environment Expert understanding of computer technologies and architectures including O/S Database NFV Cloud and SDN.
Passion for working with cutting edge technology Ability to work well in a team environment.

What you didn’t know about us:

Competitive salary
Health, Dental and Vision Benefits
Short/Long Term Disability and Critical Care/Illness Protection
Life Insurance and Retirement Plans
Employee Assistance Program
With this position, you will get the opportunity to work with our game changing clients and further advance your already valuable experience in the telecom industry!

We are Connectors. We thrive on ‘quality over quantity’ and put in the work building strong relationships. We create connections, discover qualities, uncover skills, and place people with accuracy. We are your true partner!
We are Collaborators. You’ll be working with a wholly-owned subsidiary of Kelly and part of the Kelly Telecom division. It allows us to be as nimble and fiercely competitive as a startup while having the backing of a multibillion dollar publicly traded company which has been in business for 75 years. With direct access to hiring managers, services don’t stop at standard recruiting processes. We use our expertise to improve your application skills and provide ongoing career support.
We give 24/7 Support. We are in this together. We provide around the clock availability, competitive employee benefits, and continuously check-in to make sure things are going smoothly. Check out our Glassdoor page!

Kelly Telecom is an equal opportunity employer and will consider all applications without regard to race, genetic information, sex, age, color, religion, national origin, veteran status, disability, or any other characteristic protected by law. For more information click Equal Employment Opportunity is the law.

You should know: Your safety matters! Vaccination against COVID-19 may be a requirement for this job in compliance with current client and governmental policies. A recruiter will confirm and share more details with you during the interview process.

#JobsAtKellyTelecom

Job Types: Full-time, Contract

Salary: $91,144.17 - $180,998.90 per year

Work Location: In person",-1,-1,Unknown / Non-Applicable,-1,Unknown,Company - Private,True
Data Engineer,Daffodil Health Co,"Menlo Park, CA",$140K - $190K (Employer est.),-1.0,"Position Summary

Healthcare costs are among the top expenditures for households in the US, growing faster than both our GDP and household income. At Daffodil Health, our mission is to reduce healthcare costs by minimizing the IT overhead associated with healthcare administration. In doing so, we aim to make healthcare more affordable for everyone in the US.

As an ambitious startup located in Silicon Valley, we're poised to challenge the status quo and revolutionize traditional healthcare pricing processes using advanced data technologies. Specifically, we employ data transparency mechanisms to unify insurance companies, employers, and healthcare providers on a more equitable and transparent pricing platform. We have the strong backing of a top Silicon Valley VC as our Seed round investor, which has invested in several healthcare startup unicorns. With their support, we are addressing this multi-billion-dollar opportunity.

We are a cohesive team, composed of passionate individuals who bring together deep healthcare expertise and a profound technical background. We are in search of a data engineer passionate about crafting data-intensive applications using the latest data technologies. In this role, you will help us construct our data platform from the ground up. This platform will be designed to orchestrate intricate data pipelines, swiftly analyze vast amounts of healthcare price data, and scale with the growth of our business. Your contributions will play a pivotal role in establishing the company's technical foundation.

What You Will Do:

Collaborate closely with our CTO and a data platform advisor who boasts decades of expertise.
Take charge of constructing our cloud-native data platform's foundation. Assist us in making pivotal technical decisions, and evaluate both commercial and open-source tools to determine the best fit for our needs.
Develop intricate pipelines with an emphasis on scalability and data integrity. Employ state-of-the-art big data solutions to address challenges within the healthcare sector.

Requirements

Self-motivated and accountable, with a penchant for delivering high-caliber software.
Ability to thrive in a fast-paced setting.
Demonstrable expertise in SQL and Python programming, proficiency in translating business needs into data models is vital, and you should be adept at writing complex SQL queries.
Familiarity with contemporary data warehousing platforms such as Snowflake, Athena, and Databricks; hands-on experience on DBT will be a great plus;
Excellent communication skills, both written and verbal. Regularly present your work and technical designs to stakeholders.
Familiarity with RDS/Relational databases is a bonus

Daffodil Health Co is an equal opportunity employer and does not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity expression, status as a veteran, or basis of disability or any other federal, state or local protected class. We sponsor H1-B and immigration process for the candidate who needs help.

Job Type: Full-time

Pay: $140,000.00 - $190,000.00 per year

Benefits:

Dental insurance
Health insurance
Paid time off
Vision insurance

Compensation package:

Bonus opportunities
Stock options

Experience level:

3 years
4 years
5 years
6 years
7 years
8 years

Schedule:

Monday to Friday

Ability to commute/relocate:

Menlo Park, CA 94025: Reliably commute or planning to relocate before starting work (Required)

Experience:

Snowflake: 2 years (Required)
SQL: 3 years (Required)
Python: 3 years (Required)

Work Location: Hybrid remote in Menlo Park, CA 94025",-1,-1,-1,-1,-1,-1,True
Data Science Engineer,"Adobe
","San Francisco, CA",$122K - $223K (Employer est.),4.4,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Our Team
We are a group of storytellers, technology innovators, and change agents. We are the Adobe Express team , where we are re-imagining the way people discover, create, and publish the full range of media types - from graphics to imaging to video - right in the browser and on their mobile devices. Our aim is to build fast and easy product experiences that enable students, social influencers, marketers, small businesses - really anyone with something to say - to make something that will stand out and impress their audience. Join us in building a new creativity platform that will help define Creative Cloud and Adobe's Digital Media business!

The Opportunity
We are seeking a hands-on data scientist with the knowledge and ability to help us scale. You'll be working with a team of data-specialists to understand and optimize all parts of the product. This role is a strategic role, working with product managers, growth marketers and the leadership team, to make key decisions about the direction of our products. We are looking for an experienced data scientist with a passion for understanding users to help them build better software.

Challenges

Prioritize and lead deep dives into Adobe Express data to uncover new product and business opportunities, including a machine learning strategy and roadmap

Partner with the product development teams and leadership to develop business strategy and product roadmaps based on analytical insights

Design, implement, and analyze A/B experiments to provide reports and impactful insights

Inspire the data science and product teams around experimentation and product insights

Work directly with the development teams on product instrumentation, product flow and data capture

What we're looking for

Degree in a quantitative field like statistics, economics, applied math, operations research or engineering (advanced degrees are preferred) or work experience

6+ years of hands-on technical experience in a data science role

Experience exploring large amounts of information, extracting insights, and achieving real-world results

Experience in ML modeling and data inference is preferred

Ability to dig-in, understand the data, and to use creative thinking and problem-solving skills are musts

History of deriving and communicating insights from data analyses to product and/or business leaders
Our compensation reflects the cost of labor across several U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $122,400 -- $223,000 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.

At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).

In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.

Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.

Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees.",1982,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Cloud Data Backend Engineer,"IBM
","San Jose, CA",$123K - $229K (Employer est.),3.9,"Introduction
A career in IBM Software means you'll be part of a team that transforms our customers challenges into solutions.

Seeking new possibilities and always staying curious, we are a team dedicated to creating the world's leading AI-powered, cloud-native software solutions for our customers. Our renowned legacy creates endless global opportunities for our IBMers, so the door is always open for those who want to grow their career.

We are seeking a skilled back-end developer to join our IBM Software team. As part of our team, you will be responsible for developing and maintaining high-quality software products, working with a variety of technologies and programming languages.

Your Role and Responsibilities

Collaborate in an Agile environment to deploy and maintain IBM Data and AI data management SaaS products on various hyperscale platforms.
Foster collaboration across development teams to establish a high-productivity, defect-prevention-focused continuous integration environment.
Create automation for deployment, monitoring, logging, and alerting in large-scale open data management SaaS setups.
Utilize tools like Jenkins and Artifactory to construct automation pipelines for deploying diverse service workloads in open data management SaaS environments.

Required Technical and Professional Expertise

Virtualization, containerization technologies, containers orchestration software and cloud platforms (Kubernetes/Docker).
Usage of cloud services (Amazon Web Services, IBM Cloud, Microsoft Azure, Google Cloud Platform).
Data transformation and manipulation using open-source technologies, with a strong emphasis on Presto.
Languages: GO, Python, Ruby.
Experience with CI/CD tools, including Jenkins and Artifactory, for automated deployment and testing.

Preferred Technical and Professional Expertise

Experience with cloud SaaS security.
Knowledge of relational databases (RDBMS), data warehouses, data lakes, and data lakehouses.
Familiarity of RDBMS, data warehouse, data lakes, data lakehouse.
Familiarity with Hive metastore and open data formats (Iceberg, Delta Lake, Hudi).
Open-source data engines: Presto, Spark.
Familiarity with machine learning concepts and applications in the context of data analytics.

About Business Unit
IBM Software infuses core business operations with intelligence—from machine learning to generative AI—to help make organizations more responsive, productive, and resilient. IBM Software helps clients put AI into action now to create real value with trust, speed, and confidence across digital labor, IT automation, application modernization, security, and sustainability. Critical to this is the ability to make use of all data, because AI is only as good as the data that fuels it. In most organizations data is spread across multiple clouds, on premises, in private datacenters, and at the edge. IBM’s AI and data platform scales and accelerates the impact of AI with trusted data, and provides leading capabilities to train, tune and deploy AI across business. IBM’s hybrid cloud platform is one of the most comprehensive and consistent approach to development, security, and operations across hybrid environments—a flexible foundation for leveraging data, wherever it resides, to extend AI deep into a business.

Your Life @ IBM
In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.

Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.

Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.

Are you ready to be an IBMer?


About IBM
IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement
IBM offers a competitive and comprehensive benefits program. Eligible employees may have access to:


Healthcare benefits including medical & prescription drug coverage, dental, vision, and mental health & well being
- Financial programs such as 401(k), the IBM Employee Stock Purchase Plan, financial counseling, life insurance, short & long- term disability coverage, and opportunities for performance based salary incentive programs

Generous paid time off including 12 holidays, minimum 56 hours sick time, 120 hours vacation, 12 weeks parental bonding leave in accordance with IBM Policy, and other Paid Care Leave programs. IBM also offers paid family leave benefits to eligible employees where required by applicable law
Training and educational resources on our personalized, AI-driven learning platform where IBMers can grow skills and obtain industry-recognized certifications to achieve their career goals
Diverse and inclusive employee resource groups, giving & volunteer opportunities, and discounts on retail products, services & experiences

The compensation range and benefits for this position are based on a full-time schedule for a full calendar year. The salary will vary depending on your job-related skills, experience and location. Pay increment and frequency of pay will be in accordance with employment classification and applicable laws. For part time roles, your compensation and benefits will be adjusted to reflect your hours. Benefits may be pro-rated for those who start working during the calendar year.

We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",1911,Information Technology Support Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer,"University of California San Francisco
","San Francisco, CA",$110K - $160K (Glassdoor est.),4.1,"This key position will be integral in using data to support our Education mission. This position is responsible for the design, specifications, coding, testing, implementation, maintenance, documentation, debugging, and troubleshooting of data warehouse solutions. Its work includes analyzing source system data and creating data visualization products such as reports and dashboards. The position plays a critical role in requirement gathering, project plan planning, technical architecture design, go-live implementation, and ongoing system support. In addition to these duties, the position is required to perform any other tasks assigned to support the department’s function.

A data engineer is responsible for designing, developing, testing, documenting, and maintaining data warehouse and analytics architecture to meet UCSF’s data and analytics needs.
Collaborate with business and technology partners to gather business requirements and create architectural designs spanning UCSF missions: Education, Research, Health, and Financial and Administrative Services
Use business domain knowledge to profile data and determine the best approaches to extract data into data warehouses.
Acting independently and taking guidance from the Engineer / Architect and Supervisor, design, develop, test, document, and support new and existing ETL processes using Microsoft SQL Server Integration Services (SSIS), AWS Glue, Azure Data Factory, IBM InfoSphere DataStage, or other tools.
Design and implement ETLs in the Education Data Warehouse for all UCSF Schools and Programs.
Demonstrate advanced experience in SQL programming and performance tuning.
Develop business intelligence products, such as reports and dashboards, using Tableau or other data visualization tools.
Document business rules and metadata in the data dictionary and keep the information updated.
Possess excellent communication skills and the ability to articulate system designs and patterns to varying levels of leadership.
Participate in project planning, including scoping backlogs and determining estimates.
Assume on-call duties to support the operation of reporting and analytics systems.
Maintain appropriate business domain knowledge in healthcare, education, research, finance, and business administration.

To see the salary range for this position (we recommend that you make a note of the job code and use that to look up): TCS Non-Academic Titles Search (ucop.edu)

Please note: The compensation ranges listed online for roles not covered by a bargaining unit agreement are very wide, however a job offer will typically fall in the range of 80% - 120% of the established mid-point. An offer will take into consideration the experience of the final candidate AND the current salary level of individuals working at UCSF in a similar role.

For roles covered by a bargaining unit agreement, there will be specific rules about where a new hire would be placed on the range.

To learn more about the benefits of working at UCSF, including total compensation, please visit: https://ucnet.universityofcalifornia.edu/compensation-and-benefits/index.html

Department Description

UCSF: As a preeminent health sciences campus and health system, the University of California, San Francisco (UCSF) is at the forefront of creating new knowledge from the exploding volume of clinical, discovery, and education data that it creates and manages. UCSF believes that the ability to leverage these data assets is an important differentiator for an academic healthcare center and is critical to our drive toward Precision Medicine and the execution of key UCSF strategies for the Clinical Enterprise. These strategies include supporting better population health by improving the quality of care and population health of the University of California health system’s 14 million patients. As part of this exciting and important endeavor, UCSF is seeking a highly qualified Data Warehouse Supervisor.

Information Technology Services: This position will reside within the Enterprise Information and Analytics team, and work in close alignment with IT Education to develop an overall education data strategy and data warehouse to support the education mission at UCSF.

Enterprise Information and Analytics: EIA’s vision is advancing UCSF’s ability to care, heal, teach and discover by providing ubiquitous access to relevant and high-quality information and analytics. We do this by working with our clinical, research, education and business customers to organize, integrate and govern UCSF’s information assets and then develop targeted data sets and analyses that provide important insights.

IT Education: To better serve the Education Mission, UCSF IT has recently created a new IT Education unit, which is in a period of growth. Led by the Associate CIO for Education, this unit is charged with developing collaborative relationships, processes and services that appropriately enable the education community to execute their mission, while keeping UCSF’s IT environment secure and sufficiently cost effective. With a focus on diversity, equity, inclusion and accessibility, this IT Education team is actively working to establish a computing architecture and services to support digital equity and digital transformation to support and advance the UCSF education mission.



Required Qualifications

Bachelor's degree in a related area and/or equivalent experience/training.
Experienced in enterprise data warehousing development. Possesses strong experience developing reports based on fact and dimension models.
At least 3 years of writing T-SQL. Experienced in writing complex SQL queries and stored procedures. Understanding of query performance tuning.
At least 3 years of designing and creating reports, scorecards, and dashboards using Tableau, Power BI, or any data visualization tools.
Expertise in documenting business and functional requirements, and data flows. Able to document business rules and metadata.
Experience developing and executing complex test plans.
Must be able to work with multiple RDBMS environments such e.g. Oracle, SQL Server, MySQL, and so on.
Demonstrate effective communication and interpersonal skills. Demonstrate ability to communicate technical information to technical and non-technical personnel at various levels in the organization.
Self-motivated and works independently and as part of a team. Able to learn effectively and meet deadlines.
Demonstrate complex problem-solving skills.

Preferred Qualifications

Understanding of advanced statistical analytics, machine learning, and data science principles.
Experience with cloud computing and technologies.
Experience in Agile working environment is desired.
Experience in one programming language such as Python, R, Java, C++, C+, etc.
Experience with secure software development
Experienced with software specification, design, modification, implementation and deployment of large-scale scope.
Able to resolve and improve performance issues. Experience in working with other technical and business teams to carry out system performance tuning.
Experience with healthcare, education, research, financial, or business administrative data.
Experience with the data and business processes in ERP, CRM, business administration, tertiary education, research proposals/grants is a plus.

About UCSF

The University of California, San Francisco (UCSF) is a leading university dedicated to promoting health worldwide through advanced biomedical research, graduate-level education in the life sciences and health professions, and excellence in patient care. It is the only campus in the 10-campus UC system dedicated exclusively to the health sciences. We bring together the world’s leading experts in nearly every area of health. We are home to five Nobel laureates who have advanced the understanding of cancer, neurodegenerative diseases, aging and stem cells.

Pride Values

UCSF is a diverse community made of people with many skills and talents. We seek candidates whose work experience or community service has prepared them to contribute to our commitment to professionalism, respect, integrity, diversity and excellence – also known as our PRIDE values.

In addition to our PRIDE values, UCSF is committed to equity – both in how we deliver care as well as our workforce. We are committed to building a broadly diverse community, nurturing a culture that is welcoming and supportive, and engaging diverse ideas for the provision of culturally competent education, discovery, and patient care. Additional information about UCSF is available at diversity.ucsf.edu

Join us to find a rewarding career contributing to improving healthcare worldwide.

Equal Employment Opportunity

The University of California San Francisco is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information.

Organization

Campus

Job Code and Payroll Title

007199 DATA SYS ANL 3

Job Category

Clinical Systems / IT Professionals

Bargaining Unit

99 - Policy-Covered (No Bargaining Unit)

Employee Class

Career

Percentage

100%

Location

Flexible (combination of onsite and remote work), Mission Center Building (SF)

Shift

Days

Shift Length

8 Hours

Additional Shift Details

M-F 8-5",1864,Colleges & Universities,$25 to $100 million (USD),Education,10000+ Employees,College / University,False
Principal Software Engineer - Data Lake,"Snowflake
","San Mateo, CA",$214K - $328K (Employer est.),4.0,"Build the future of data. Join the Snowflake team.

The Snowflake Data Lake team’s mission is to power open standards with Snowflake innovation. Our customers want to bring more data to Snowflake to support their variety of data lake use cases with large data sets but face the common challenges of control, cost, and interoperability. This team aims to address these challenges and enable customers to benefit from Snowflake’s rich features and integrated platform capabilities while embracing their choice of open table standards (e.g., Apache Iceberg), file formats (e.g.,Apache Parquet), storage solutions, and third-party open source tool set (e.g.,Apache Spark). We’re on the early journey to build the best data lake solutions for any workload at scale.

We are looking for outstanding Principal Software Engineers who are technical leaders and know the internals in query engines, data warehouses, and big data open sources to join us to define strategies, set technical directions, design and execute, engage and deliver innovation and bring Snowflake data lake solutions to thousands of Enterprise customers.

AS A PRINCIPAL SOFTWARE ENGINEER AT SNOWFLAKE, YOU WILL:

Understand customer requirements and define product strategies
Design, develop, and operate highly reliable large scale data lake systems
Embrace Snowflake innovations with open source standards and tool sets
Be an active influencer for the direction of open source standards
Partner closely with Product teams to understand requirements and design cutting edge new capabilities that go directly into customer’s hands
Analyze fault-tolerance and high availability issues, performance and scale challenges, and solve them
Ensure operational excellence of the services and meet the commitments to our customers regarding reliability, availability, and performance
Set technical directions and influence cross-functional teams

AN IDEAL CANDIDATE WILL HAVE MOST OF THE FOLLOWING QUALIFICATIONS:

15+ years of hands-on direct internal experience in large scale data intensive distributed systems, especially in query engines, object storage, data warehouse, data lake, data analytics, SQL/NoSQL databases, distributed file systems and data platform infrastructure
Proven track record of leading and delivering multi-year large and complicated projects across organizations
Strong development skills in Java and C++.
An active PMC (Program Management Committee) or Committer to open sources like Apache Iceberg, Parquet, Spark, Hive, Flink, Delta, Presto, Trino, and Avro
A growth mindset and excitement about breaking the status quo by seeking innovative solutions
An excellent team player who is consistent in making everyone around you better
Experience with public clouds (AWS, Azure, GCP)
BS/MS/PhD in Computer Science

The following represents the expected range of compensation for this role:

The estimated base salary range for this role is $214,000 - $327,700.
Additionally, this role is eligible to participate in Snowflake’s bonus and equity plan.

The successful candidate’s starting salary will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location. This role is also eligible for a competitive benefits package that includes: medical, dental, vision, life, and disability insurance; 401(k) retirement plan; flexible spending & health savings account; at least 12 paid holidays; paid time off; parental leave; employee assistance program; and other company benefits.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?",2012,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,5001 to 10000 Employees,Company - Public,False
"Application Software Engineer, Data","SpaceX
","Hawthorne, CA",$120K - $145K (Employer est.),3.9,"SpaceX was founded under the belief that a future where humanity is out exploring the stars is fundamentally more exciting than one where we are not. Today SpaceX is actively developing the technologies to make this possible, with the ultimate goal of enabling human life on Mars.

APPLICATION SOFTWARE ENGINEER, DATA

The application software team is the central nervous system of SpaceX – we create mission critical applications that are used throughout SpaceX to accelerate launch vehicle production and flight as well as systems that allow Starlink to grow into a worldwide fast, reliable Internet service.

We are looking for engineers who treat fellow teammates with fairness, respect, and support.

Our team is creating systems to ingest and store concurrent streams of data from many always-on assets to manage the world's largest satellite constellation, reusable rockets, and Dragon spacecraft. Other applications range from platforms that enable rapid build and reuse of Starship, designing the next generation manufacturing software that will be used in high throughput factories for Starlink, and public facing systems where customers can join our Starlink network globally.

We work closely with engineers throughout the company to create and update our systems with respect to crewed launches, Starship flights, changes to the Starlink network and much more.

Aerospace experience is not required to be successful here - rather we look for smart, motivated, collaborative engineers who love solving problems and want to make an impact on a super inspiring mission. You will have full ownership of challenging problems, working with a team of enthusiastic engineers to design and produce solutions that enable SpaceX to move towards our goals at a rapid pace. The success of the missions at SpaceX depends on the software that you and your team produce.

RESPONSIBILITIES:

Develop highly reliable and scalable data pipelines to empower engineers across SpaceX
Create new applications that improve how the business at SpaceX operates
Collaborate with peers on architecture, design, and code reviews
Build prototypes to prove out key design concepts and quantify technical constraints
Own all aspects of software engineering and product development
Deep dive into business problems, find efficient solutions and apply first principles thinking

BASIC QUALIFICATIONS:

Bachelor's degree in computer science, data science, engineering, math, physics, or scientific discipline; OR 2+ years of professional experience building software in lieu of a degree
Experience in full stack development, software engineering, data engineering, or data science

PREFERRED SKILLS AND EXPERIENCE:

Programming experience in Python, C#, Java, Scala, Go or similar languages
Experience working with in-stream, big data processing and analytics using Apache Kafka, Spark, Flink, SQL or similar
Experience with relational and non-relational databases, data lakes e.g. HBase, Hive, Delta Lake, PostgreSQL, CockroachDB or similar
Experience with data exploration tools like Grafana, Jupyter Notebooks, Metabase, PowerBI or similar
Good understanding of version control, testing, continuous integration, build, deployment and monitoring
Some front-end experience in Angular, React, or similar JavaScript framework
Good understanding of statistics, machine learning algorithms and frameworks

ADDITIONAL REQUIREMENTS:

Willing to work extended hours and weekends when needed
COMPENSATION AND BENEFITS:
Pay Range:
Application Software Engineer/Level I: $120,000.00 - $145,000.00/per year
Application Software Engineer/Level II: $140,000.00 - $170,000.00/per year
Your actual level and base salary will be determined on a case-by-case basis and may vary based on the following considerations: job-related knowledge and skills, education, and experience.

Base salary is just one part of your total rewards package at SpaceX. You may also be eligible for long-term incentives, in the form of company stock, stock options, or long-term cash awards, as well as potential discretionary bonuses and the ability to purchase additional stock at a discount through an Employee Stock Purchase Plan. You will also receive access to comprehensive medical, vision, and dental coverage, access to a 401(k) retirement plan, short & long-term disability insurance, life insurance, paid parental leave, and various other discounts and perks. You may also accrue 3 weeks of paid vacation & will be eligible for 10 or more paid holidays per year. Exempt employees are eligible for 5 days of sick leave per year.

ITAR REQUIREMENTS:

To conform to U.S. Government space technology export regulations, including the International Traffic in Arms Regulations (ITAR) you must be a U.S. citizen, lawful permanent resident of the U.S., protected individual as defined by 8 U.S.C. 1324b(a)(3), or eligible to obtain the required authorizations from the U.S. Department of State. Learn more about the ITAR here.

SpaceX is an Equal Opportunity Employer; employment with SpaceX is governed on the basis of merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status.

Applicants wishing to view a copy of SpaceX's Affirmative Action Plan for veterans and individuals with disabilities, or applicants requiring reasonable accommodation to the application/interview process should notify the Human Resources Department at (310) 363-6000.",2002,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,5001 to 10000 Employees,Company - Private,False
Senior Data Engineer / Remote,"Motion Recruitment
","Daly City, CA",$166K - $180K (Employer est.),3.4,"Our client is changing the way we can find our friends and family from around the world. Founded in 2008, they have millions of users per month visiting their platform for various reasons.

They are looking for a Senior Data Engineer to join their Data Ops team to come in and make an impact right away. This Senior Data Engineer should have at least 7 years of professional experience woking with Python, PySpark, Airflow, AWS, and have a computer Science Degree. If this is you APPLY NOW!



Basic Qualifications (Required Skills & Experience)

6-8 years of experience
Python – 5 years of experience
Spark – 5 years (Prefer Pyspark)
AWS – 2+ years of experience
Airflow – 2+ years of experience
EMR
ETL work
SQL
Technology degree is important as well! (ex: CS degree)

Other Qualifications & Desired Competencies
Fully Remote!!!
Equity and Bonuses involved
You will receive the following benefits:
Medical Insurance
Dental Benefits
Vision Benefits
401(k)",1989,HR Consulting,Unknown / Non-Applicable,Human Resources & Staffing,51 to 200 Employees,Company - Private,False
Senior Data Engineer (Snowflake) - Contractor,"EY
",United States,$90.00 - $130.00 Per Hour (Employer est.),3.9,"The primary responsibility for the Sr. Data Engineer / Tech Lead is to ensure data accessibility, quality, and reliability within the client's data platform ecosystem.

RESPONSIBILITIES

Design and develop end-to-end data pipelines and ETL processes using Snowflake, Denodo, DBT Cloud, Fivetran, and AWS Glue, ensuring seamless data integration, transformation, and loading.
Collaborate with cross-functional teams to gather data requirements and implement scalable data models and schemas within Snowflake and Denodo, ensuring optimal performance and data consistency.
Implement and maintain data orchestration workflows using Stonebranch, ensuring efficient and reliable scheduling and automation of data processes.
Work with EnterpriseDataLake for ingestion and storage of data from various sources, ensuring the availability and accessibility of data for analytics and reporting purposes.
Utilize Azure DevOps and Teraform to implement and manage infrastructure as code, ensuring streamlined deployment and scalability of data engineering solutions.
Skills

snowflake

denodo

dbt cloud

fivetran

Qualifications

REQUIREMENTS

Proficiency in Snowflake and Denodo: Strong understanding and hands-on experience in working with Snowflake and Denodo for data integration, transformation, and analysis.
Knowledge of DBT Cloud: Familiarity with DBT Cloud, including experience in building and maintaining efficient data transformation workflows and deploying reliable data pipelines.
Experience with Fivetran: Demonstrated experience in utilizing Fivetran for data ingestion, source connectivity, and ensuring data accuracy and completeness.
Understanding of EnterpriseDataLake: Knowledge of EnterpriseDataLake principles and practices, including data ingestion, storage, and organization for analytics and reporting purposes.
Familiarity with Stonebranch: Proficiency in using Stonebranch for data orchestration and scheduling, ensuring efficient and reliable execution of data pipelines and workflows.
Proficiency in Azure DevOps and Teraform: Experience in leveraging Azure DevOps and Teraform for infrastructure as code, enabling streamlined deployment and scalability of data engineering solutions.

The expected pay rate range for this contract assignment is $90 to $130 per hour. The exact pay rate will vary based on skills, experience, and location. The position is approximately 65-70% remote and 30-35% travel to the client as needed.

#GigNowTechOpportunities

GigNowOpportunities

Equal Employment Opportunity Information
EY provides equal opportunities to applicants, employees, contractors, vendors, and stakeholders without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. If you are an individual with a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please email gignow.recruiting@ey.com.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,False
"Software Engineer, Data Platform","Notion
","San Francisco, CA",$129K - $180K (Glassdoor est.),4.8,"About Us:

We're on a mission to make it possible for every person, team, and company to be able to tailor their software to solve any problem and take on any challenge. Computers may be our most powerful tools, but most of us can't build or modify the software we use on them every day. At Notion, we want to change this with focus, design, and craft.

We've been working on this together since 2016, and have customers like Pixar, Mitsubishi, Figma, Plaid, Match Group, and thousands more on this journey with us. Today, we're growing fast and excited for new teammates to join us who are the best at what they do. We're passionate about building a company as diverse and creative as the millions of people Notion reaches worldwide.

About The Role:

You’ll join a team of talented engineers who will design and own foundational data products that are key to the company’s business and product. Notion’s data platform and infrastructure are vital to both empowering every team at Notion to make decisions using data, and are increasingly used in our product features, like search, user notifications, workspace analytics and Notion AI.

What You'll Achieve:
You'll work cross-functionally with partners from the Data Science, Data Engineering, AI, Product, Go-to-Market, Legal and Finance organizations to deliver short- and long-term impact
You’ll help in executing the roadmap for data infrastructure and systems to power high volume product features using Notion’s data.
You'll play a pivotal role in the development of tools and infrastructure that democratize data access and enable analytics capabilities across the organization
You'll determine the best ways to handle Notion's unique data model and usage patterns to derive insights and bring intelligence to product features like search and discovery.
Skills You'll Need to Bring:
You have worked cross-functionally to establish the right overarching data architecture for a company's needs, to build data ingestion (real-time & batch), and to provide guidance on best data practices for the business.
You have worked on data or infrastructure-focused engineering teams, particularly ones that own a wide swath of software platforms (hosted or built in-house).
You've experienced the challenges of scaling and re-architecting data platforms and infrastructure through orders of magnitude of growth and scaling data volume.
You have a deep background with big data compute, storage, and best practices that you can ask the right questions of your team, balance technology and people concerns, and make hard tradeoffs.
Nice to Haves:
You've built out data infrastructure from, or nearly from, scratch at a fast-growing startup.
You've led or managed a Data Engineering / Platform / Infrastructure Team.
You have experience building MLOps and ML serving infrastructure.

Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Notion.

Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation made due to a disability, please let your recruiter know.

#LI-Onsite",2016,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,501 to 1000 Employees,Company - Private,False
"Software Engineer, Data Platform","Zoox
","Foster City, CA",$164K - $234K (Employer est.),3.9,"The Data team leverages data from our autonomous vehicles and operations to determine autonomy and service readiness. We provide the foundation for strategic decision-making at Zoox. You will develop and implement the next generation of our data pipeline to ensure visibility into our business as we scale toward the launch of an autonomous mobility service. You will define the system and build the pipeline to enable Zoox to develop and scale with a data-first culture.

You will join a diverse, experienced team with rapidly growing scope and responsibility while also having access to one of the most unique data sets in the autonomous vehicle industry. Hence, we are seeking all skill levels to grow with the team.
Responsibilities
Design, build, and maintain the pipelines that transform autonomous vehicle data at scale to support analytics throughout the company
Build and contribute to tools that help discover data, support data governance and ensure high data quality
Contribute to design and development of data infrastructure that can scale to support our exponentially increasing data needs
Optimize existing data infrastructure and tools to provide improved performance, reduced latency and effective utilization of resources.
Work closely with data scientists, data engineers, and stakeholders across the company to understand data needs and provide solutions that meet their needs.
Requirements
4+ years of software engineering experience
Strong Python skills
Strong data operations mindset and opinions on next-generation warehouse tools
Strong written and verbal communication skills
Experience with building production grade applications using Python
Experience with data warehouse platforms (e.g. Amazon Redshift, Google BigQuery, Snowflake, …)
Experience with relational databases (e.g. MySQL, Postgres, …)
Bonus Qualifications
Experience with full-stack development (e.g. Flask, …)
Experience with Docker and Kubernetes
Basic fluency in SQL, C++, and/or TypeScript
Experience operating a workflow manager such as Airflow
Experience with data visualization technologies (e.g. Tableau, Looker, …)
Experience with CI/CD
$164,000 - $234,000 a year
Compensation
There are three major components to compensation for this position: salary, Amazon Restricted Stock Units (RSUs), and Zoox Stock Appreciation Rights. The salary will range from $164,000 to $234,000. A sign-on bonus may be part of a compensation package. Compensation will vary based on geographic location, job-related knowledge, skills, and experience.

Zoox also offers a comprehensive package of benefits including paid time off (e.g. sick leave, vacation, bereavement), unpaid time off, Zoox Stock Appreciation Rights, Amazon RSUs, health insurance, long-term care insurance, long-term and short-term disability insurance, and life insurance.

About Zoox
Zoox is developing the first ground-up, fully autonomous vehicle fleet and the supporting ecosystem required to bring this technology to market. Sitting at the intersection of robotics, machine learning, and design, Zoox aims to provide the next generation of mobility-as-a-service in urban environments. We’re looking for top talent that shares our passion and wants to be part of a fast-moving and highly execution-oriented team.

Follow us on LinkedIn

A Final Note:
You do not need to match every listed expectation to apply for this position. Here at Zoox, we know that diverse perspectives foster the innovation we need to be successful, and we are committed to building a team that encompasses a variety of backgrounds, experiences, and skills.",2014,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Senior Data Platform Engineer,"Crunchbase
",California,$175K - $195K (Employer est.),3.8,"About Crunchbase

Crunchbase helps over 75 million people around the world connect with the companies and people that matter. Powered by best-in-class proprietary data, Crunchbase is democratizing access to opportunities so salespeople, entrepreneurs, investors, job seekers, and others can accelerate innovation for a better future. We’re proud to build intelligent products that shape how companies and people connect and enable them to communicate in a more meaningful way.

We are committed to a positive, diverse, and inclusive culture by hiring for potential, focused on the inclusion of people who have different ways of thinking, different viewpoints, different backgrounds, and different skill sets. We value a transparent and open culture that positively impacts our teams and our products.

Crunchbase has a remote-first approach, and is open to hiring in residents of these states:
California, Colorado, Illinois, Florida, Georgia, Massachusetts, Nevada, New Jersey, New York, North Carolina, Oregon, Pennsylvania, South Carolina, Texas, Virginia, and Washington

Our inclusive remote-first culture, generous PTO policies, competitive pay, and employee wellness benefits set us apart!

Engineering at Crunchbase

We’re working to build an unparalleled innovative company data graph, and are continually improving that scalable, flexible platform and rich client application to connect the world's companies and entrepreneurs. Our mission is to turn data into knowledge and make it accessible for everyone to explore and search.

What You’ll Do:
Design and develop innovative services, features, and schema enhancements to elevate the accessibility, efficiency, consistency, and quality of data for both internal use and our customers.
Craft, deploy, oversee, and refine data ETL (Extract, Transform, Load) pipelines that are the engines behind our product and analytical capabilities.
Act as a catalyst for scaling and enhancing our data operations to keep pace with Crunchbase's growth.
Foster a data-centric culture by equipping engineers and the Product team with the tools to interrogate our datasets effortlessly and reliably.
Empower data scientists to deploy NLP (Natural Language Processing) and ML (Machine Learning) algorithms at scale within systems that prioritize fault tolerance and high availability.
What We’re Looking For:
A solid grasp of computer science and software engineering principles is evident in your background.
Proficiency in Python programming is essential.
Exposure to technologies like Kubernetes, Kafka, Spark, data warehousing solutions, or Airflow is highly beneficial.
Prior experience in constructing data pipelines or operationalizing machine learning algorithms is advantageous.
A dedication to engineering excellence, maintenance best practices, and the creation of outstanding software.
You are articulate, with exemplary verbal and written communication skills.
A passion for agile methodologies, cross-functional team collaborations, and a data-informed approach to development and decision-making.
Salary Range
$175,000—$195,000 USD
You may also be entitled to receive equity and benefits.
What Crunchbase Offers:
Competitive salary and equity
Remote first policy
Generous Reimbursement policy for learning and development activities
Monthly fitness / mental health reimbursement
14 weeks of fully-paid time off for new parents
Flexible Paid Time Off (PTO)
Volunteering Paid Time Off
Incredible medical, vision and dental benefits for employees and their families
Free One Medical Group membership for employees and their families
401(k) and Roth plans, and free annual financial adviser check-in
Monthly internet stipend
Work from home allowance to purchase furniture for your work from home space
Annual carbon offset
Matching charity contributions for our Townhall awards
A team of creative, transparent entrepreneurs driven to accomplish our mission
At Crunchbase, we value team members who are passionate and enthusiastic about what we're building here. We believe there is no ""perfect"" candidate, and want to encourage applying even if all the requirements listed aren’t met. If you're passionate about Crunchbase and looking to learn and grow, then we look forward to reviewing your application!
Crunchbase does not discriminate on the basis of race, creed, color, ethnicity, national origin, religion, sex, sexual orientation, gender expression, age, height, weight, veteran status, military obligations, or marital status. We will consider for employment qualified applicants with arrest and conviction records. Every day our team is honored to work with entrepreneurs and innovators from every corner of the globe, and we aim to build a team that reflects the diversity of our customers. Each individual at Crunchbase brings their own perspectives, work experiences, lifestyles, and cultures with them, and we believe that a more diverse team creates more innovative products, provides a better service to its customers, and helps us all grow and learn as individuals.",2007,Internet & Web Services,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
Data Engineer II (Remote),"Mercury Insurance Services, LLC
","Brea, CA",$88K - $166K (Employer est.),3.5,"Join an amazing team that is consistently recognized for our achievements and culture, including our most recent Forbes award of being one of America's Best Midsize Employers for 2023!

Position Summary:

As a Data Engineer II you will create production data pipelines for our advanced analytics and data science teams – as well as collaborate with other technical personnel on internal & external data sources and infrastructure needs. The Data Engineer II will assist in design, evaluate, and test data infrastructures and be a subject matter expert for all things data across the organization.

Essential Job Functions:

Design, build, and launch collections of high-quality big data/data lake solutions on Cloud platform preferably AWS, Snowflake that support multiple use cases across all departments, all products, and all states.

Solve our most challenging data integration problems, utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources.

Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts.

The Data Engineer is an expert in all data lakes, data warehouses, and data cubes within Mercury, with no gaps in knowledge. Can efficiently and accurately extract and manipulate data from any source.

Collaborate with teams of data analysts and data scientists, who research and integrate algorithms to develop solutions to address complex data problems. Influence all functions across the organization to identify data opportunities to drive profitable growth. Proactively identify pain points that Analytics & Data Science face with our existing data models.

Leverages existing data infrastructure to fulfill all data-related requests, perform necessary data housekeeping, data cleansing, normalization, hashing, and implementation of required data model changes. Analyzes data to spot anomalies, trends and correlate similar data sets. Designs, develops and implements natural language processing software modules.

Other functions may be assigned

Education:

Bachelor's degree in Computer Engineering, Computer Science, Mathematics, Electrical Engineering, Information Systems, or related field
Actuarial experience/exams preferred.
Or equivalent combination of education and/or experience

Experience:

3 or more years of experience in data analytics, data engineering, and/or data science

3 or more years of experience in development of big data/data lake solutions on Cloud platforms, preferably AWS (S3, Glue/EMR, Athena, AppFlow) or Snowflake

3 or more years of experience in Python, Java and/or Scala programming

3 or more years of experience in writing SQL statements and query performance tuning

3 or more years of experience in RDMS or MPP databases, preferably AWS Redshift or Snowflake

Knowledge and Skills:

A high-level specialist who regularly interacts and works with senior management.
Expert at analyzing data to identify gaps and inconsistencies
Able to multitask, prioritize, and manage time effectively.
The ability to think conceptually, analytically and creatively comfortable with ambiguity.
Experience managing and communicating data plans and data models to internal clients.
Demonstrated solid understanding, and passion for, all areas of data/analytics engineering best practices.
Demonstrated expert skills in data mining and data analytics
Expert in Python and/or SQL programming; some experience with R preferred
Solid experience with cloud-based advanced data and analytics environment
Knowledge of working with AWS, GitHub, and other cloud-based infrastructure
Expert data skills and the ability to work with large structured and unstructured data sources
Excellent problem-solving skills required
Excellent analytical and critical thinking required
Excellent written and verbal communication skills required
Demonstrate Company’s Core Values



Why choose a career at Mercury?

At Mercury, we have been guided by our purpose to help people reduce risk and overcome unexpected events for more than 60 years. We are one team with a common goal to help others. Everyone needs insurance and we can’t imagine a world without it.

Our team will encourage you to grow, make time to have fun, and work together to make great things happen. We embrace the strengths and values of each team member. We believe in having diverse perspectives where everyone is included, to serve customers from all walks of life.

We care about our people, and we mean it. We reward our talented professionals with a competitive salary, bonus potential, and a variety of benefits to help our team members reach their health, retirement, and professional goals.

Learn more about us here: https://www.mercuryinsurance.com/about/careers

We offer many great benefits, including:

Competitive compensation
Flexibility to work from home/hybrid in
Company vehicle + gas card
Paid time off (vacation time, sick time, 9 paid Company holidays, volunteer hours)
Incentive bonus programs (potential for holiday bonus, referral bonus, and performance-based bonus)
Medical, dental, vision, life, and pet insurance
401 (k) retirement savings plan with company match
Engaging work environment
Promotional opportunities
Education assistance
Professional and personal development opportunities
Company recognition program
Health and wellbeing resources, including free mental wellbeing therapy/coaching sessions, child and eldercare resources, and more

Mercury Insurance is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by federal, state, or local law.",1961,Insurance Carriers,$1 to $5 billion (USD),Insurance,1001 to 5000 Employees,Company - Public,True
Staff Software Engineer - Data Platform,"Discord
","San Francisco, CA",$143K - $202K (Glassdoor est.),3.0,"The central Data Platform seeks to build a self-service tooling platform to make the petabytes of data at Discord easily accessible for everyone at the company. We build full-stack applications, tooling, and frameworks to improve the productivity of teams at Discord, in particular our product, analytics, and machine learning teams. Our tooling covers the end-to-end lifecycle of data from acquisition to consumption. Reporting to the Engineering Manager of Data Products, you will work on strategy that is foundational to the company and product. To learn more about Discord Engineering,read our engineering blog here — including ""How We Create Insights From Trillion Data Points"" that this team is behind! What you'll be doing Lead end-to-end development of data tooling and frameworks, using modern technologies such as BigQuery, Apache Beam, Airflow, Dagster, dbt, Kubernetes, and Rust. Ensure tight-knit collaboration with leadership, cross-functional stake-holders and senior engineers across the organizationCollaborate with leadership and senior engineers across the team to define the technical vision and build on the technical roadmap for Data Platform. Work with Data Platform to ensure we have a platform with strong governance that respects our users' privacy throughout. Care deeply about business outcomes and constraints and keep them in mind as you solve hard, unbounded problems. Work with other Staff Engineers to make decisions for the organization and engineering function as a whole. Coach and mentor the next generation of technical leaders at Discord. What you should have 7+ years of experience as a Software Engineer. Empathy for both your internal and external users and seek feedback on your work. Ability to approach problems with first principles thinking, embrace ambiguity, and enjoy collaborative work on complex solutions. Experience defining architecture, tooling, and strategy for a large-scale data processing system. Proactive in staying up-to-date with industry trends and assessing new technologies to enhanse problem solving capabilities. Bonus Points Experience working with very high-scale data infrastructure and tooling Experience with data products on Google Cloud Platform, Kubernetes, or Airflow Full-stack development or product engineering experience The US base salary range for this full-time position is $214,000 to $233,000 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits.#buildbelonging #LI-Remote #LI-Hybrid #LI-HY1 Benefits and Perks Comprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures) Mental health resources and quarterly wellness stipends 14+ paid holidays, 4 weeks of PTO + use-what-you-need sick days Paid parental leave (plus fertility, adoption and other family planning benefits) Flexible long-term work options (remote and hybrid) Volunteer time off A diverse slate of Employee Resource Groups Plus commuter contributions and other perks for office-based employees About Us Discord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests — from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations. We’re working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It’s a mission that gives us the chance to positively impact millions of people all over the world. So if this strikes a chord with you, come build belonging with us!",2015,Internet & Web Services,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,False
"Software Engineer, Data Science","Forward
","San Francisco, CA",$128K - $171K (Glassdoor est.),3.5,"Forward is on a bold mission to make high quality healthcare available to a billion people across the globe. We’re building the world’s most advanced healthcare platform from the ground up, combining hardware, software and doctors under one roof. We are scaling our engineering team and looking for world-class engineers with experience and expertise in Data Science, Machine Learning and AI. As an early member of our engineering team, you’ll have a key role in building the future of healthcare from first principles.

Forward was founded in January 2016 by former executives and engineering leaders from Google and Uber. We are funded by some of the world's best investors and entrepreneurs including Founder's Fund, Khosla Ventures, First Round Capital, Eric Schmidt (Google/Alphabet Chairman), Marc Benioff (Salesforce Founder), Joe Lonsdale (Palantir Founder), Joshua Kushner (Oscar co-Founder) and Garrett Camp (Uber co-Founder).

You can read our story here or check out a quick YouTube video.
WHAT YOU'LL DO:
Develop algorithms and design highly scalable software solutions for real world problems using data science and machine learning.
Collaborate with domain experts in fields like AI and NLP. Our engineers made major contributions to projects such as Amazon Go and TensorFlow.
Work with top-flight software and hardware engineering talent from places like Google, Amazon, Nvidia, Palantir, and NASA JPL.
Own entire projects while working alongside cross-functional teams of doctors, designers, and operators.
Your work will directly contribute to saving and improving people’s lives. For real. :)
WHAT WE'RE LOOKING FOR:
Impact - You’re deeply mission-driven and you think there’s more to life than software that enables puppy ears to be superimposed on photos. Although we concede those are cute.
Data Science - You have experience developing production software involving building data models for consumer or industrial applications. You are familiar with robust and scalable infrastructure for visualization and presentation.
Product passion - You care about the bits you ship ending up in users’ hands, and work backwards from user needs to come up with solutions to problems.
Entrepreneurship - You’re a self-starter who loves to own things end-to-end. You don’t ask for permission - you’re too busy making things happen.
Team player - You know how to make those around you better and feed off their energy. You take care of your teammates.
Curiosity - You like to prototype mobile apps based on the latest psychological research in habit formation in your free time? You open sourced your own neural network library? Boy have we got some fun things for you…
You have a BS, MS or PhD in computer science or a related field with focus on data science or machine learning.
The base salary range for this full-time position is $100,000-$220,000, plus equity and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all locations. Within the range, individual pay is determined by factors including job-related skills, experience, relevant education or training, and location.

WHY JOIN FORWARD?

We don’t want to just move dollars around the healthcare industry - we want to rebuild it and fix it. All of it. You’d be a major part of the story behind one of the most ambitious startup attempts of the past decade and you’d work with a team of people who want to use their talents for good.

We are an equal opportunity employer. In accordance with anti-discrimination law, it is the purpose of this policy to effectuate these principles and mandates. We prohibit discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. We conform to the spirit as well as to the letter of all applicable laws and regulations. Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, we will consider for employment qualified applicants with arrest and conviction records.

Information collected and processed as part of any job application you choose to submit is subject to Forward’s Privacy Notice to California Job Applicants.",2016,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,Unknown,Company - Private,False
Data Analytics Platform - Engineer,"Salesforce
","San Francisco, CA",$123K - $169K (Employer est.),4.0,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Software Engineering

Job Details

About Salesforce

We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.

At Salesforce we are continuing our own Digital Transformation to accelerate our growth and deliver outstanding service to our customers. A key pillar of this transformation is scaling the deployment, configuration, and management of our global analytics platforms to measure and generate insights on Salesforce prospect and customer behaviors.

We’re looking for an Engineer to support Salesforce’s global analytics platforms across clouds and regions. This person will have experience in digital analytics and in the global deployment of systems such as Google Analytics 360 and GA4 across multiple regions and business units.

This person will support our efforts to build consistency, quality, and value of our digital analytics data at Salesforce. This includes relationships with a distributed team of digital analysts and engineers.

The right candidate brings business understanding on the value of digital analytics data along with the technical expertise required to support a world class implementation of digital analytics platforms. This includes data layer design and implementation, tag management, custom dimensions and variables, events, goals, content and traffic classifications, and similar aspects of digital analytics expertise. This candidate has experience translating desired business insight outcomes from marketing and customer teams into actionable deployment plans and system design.

Responsibilities:

Continue to improve Salesforce’s instance of Google Analytics 360 / GA4, Google Tag Manager

Work within the Digital Analytics Platform team to deploy and manage updates to the digital data layer and analytics code live on Salesforce web properties.

Configure the digital analytics platform to meet the needs of key internal customers such as Analytics Reporting Team, Cloud Teams, Field Teams, Paid Media, and Product Marketing

Participate in a team culture of critical thinking, creativity, innovation, experimentation, diversity, and inclusivity that aligns with Salesforce core values

Constantly learn, have a clear pulse on innovation across the enterprise SaaS, data science, customer data, and analytics communities.

Required Skills

A related technical degree.

2-5+ years of deep expertise in global analytics platforms such as Google Analytics 360 / GA4. Must have practical, hands on knowledge and ability to design and handle a world class implementation of these platforms

1+ years experience working with global analytics platforms at Fortune 500 companies. Must have experience working with global analytics suites across multiple countries, regions, and business units with a high volume of customer traffic per month (10s of millions+).

Broad understanding of digital marketing and the role of digital analytics platforms in evaluating the performance of campaigns, events, paid media, e-commerce, social media, etc.

Data manipulation skills, with experience in BigQuery / SQL. Have the ability to closely partner with data engineers and architects.

Understanding of governmental privacy regulations on the collection and use of customer data (such as GDPR and CCPA) and how this impacts digital data collection. Experience with OneTrust a plus.

Good communicator in written and verbal form with the ability to work well with other technical teams.

Problem solver who simplifies problems to their core elements and finds creative solutions.

Get-it-done mentality with strong bias towards action.

Advanced Salesforce product knowledge a plus

B2B customer data experience a plus

LI-Y

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .

Posting Statement

At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .

Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce . ﻿

Salesforce welcomes all.

Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.

For Washington-based roles, the base salary hiring range for this position is $122,600 to $168,700.
For California-based roles, the base salary hiring range for this position is $133,800 to $183,900.

Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.",1999,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer - Data Platform,"TikTok
","San Jose, CA",$145K - $355K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

Team Introduction
The Data Platform team works on building data infrastructures and data products to support business engineering teams at TikTok.

As a data engineer in the data platform team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

Responsibility

Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, and multi-dimensional analysis)
Design and implement reliable, scalable, robust and extensible big data systems that support core products and business
Establish solid design and best engineering practice for engineers as well as non-technical people
Qualifications

BS or MS degree in Computer Science or related technical field or equivalent practical experience
Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.)
Experience with performing data analysis, data ingestion and data integration
Solid communication and collaboration skills
Experience with ETL (Extraction, Transformation & Loading) and architecting data systems
Experience with schema design and data modeling
Experience in writing, analyzing and debugging SQL queries
Deep understanding of various Big Data technologies
Passionate and self-motivated about technologies in the Big Data area
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at dataecommerce.accommodation@tiktok.com
Job Information
The base salary range for this position in the selected city is $145000 - $355000 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Applied AI/ML Data Engineer,"Intuitive Surgical
","Sunnyvale, CA",$142K - $240K (Employer est.),4.2,"Company Description
At Intuitive, we are united behind our mission: we believe that minimally invasive care is life-enhancing care. Through ingenuity and intelligent technology, we expand the potential of physicians to heal without constraints.

As a pioneer and market leader in robotic-assisted surgery, we strive to foster an inclusive and diverse team, committed to making a difference. For more than 25 years, we have worked with hospitals and care teams around the world to help solve some of healthcare's hardest challenges and advance what is possible.

Intuitive has been built by the efforts of great people from diverse backgrounds. We believe great ideas can come from anywhere. We strive to foster an inclusive culture built around diversity of thought and mutual respect. We lead with inclusion and empower our team members to do their best work as their most authentic selves.

Passionate people who want to make a difference drive our culture. Our team members are grounded in integrity, have a strong capacity to learn, the energy to get things done, and bring diverse, real world experiences to help us think in new ways. We actively invest in our team members to support their long-term growth so they can continue to advance our mission and achieve their highest potential.

Join a team committed to taking big leaps forward for a global community of healthcare professionals and their patients. Together, let's advance the world of minimally invasive care.
Job Description

Primary Function:

The Applied AI/ML Engineer plays a critical role in bringing Generative AI and Machine Learning (ML) solutions to Enterprise Analytics. These technologies offer transformative potential to optimize operations, generate valuable insights, and drive innovation, thus shaping our organization's future.

The AI/ML Engineer will play a pivotal role in identifying, testing, and implementing scalable and cost-effective AI and ML solutions across the teams supported by Enterprise Analytics. Through maintaining, troubleshooting, and optimizing AI models, as well as developing business applications on top of them, this role will be instrumental in enhancing our organization's analytical capabilities. The role will work directly with business stakeholders, IT partners, enterprise data architects, data engineering, and external service providers to ensure that new capabilities meet the needs of the business and can support its growth.

Roles and Responsibilities:

Develop and maintain the infrastructure for incorporating and fine-tuning third-party AI NLP and/or Computer Vision models into the company's technology stack.
Troubleshoot any integration issues and ensuring the seamless operation of the integrated models.
Collaborate with stakeholders to understand the functional needs and fine-tune and/or train AI models to improve their performance on specific tasks.
Build end-to-end ML Ops pipelines, including AI applications. Maintain, troubleshoot, and optimize ML and AI models in production environment, monitor models’ performance.
Build business applications on top of AI models, work with a team of engineers to develop and deploy ML solutions.
Qualifications
Minimum Bachelor's degree or Master's degree in Computer Science, Data Science, or a related field
A minimum 6+ years of experience in machine learning, with a strong understanding of the latest ML research and technologies
Strong knowledge and experience with LLMs/Generative AI models
Strong programming skills in Python (3+ years), SQL
Experience with a variety of ML frameworks and libraries, such as PyTorch, TensorFlow, and scikit-learn
Familiarity with open-source LLM/CV models and platforms, such as Hugging Face, LangChain, etc
Proficiency with cloud platforms such as Microsoft Azure, Google Cloud or AWS
Familiarity with a cloud-based data warehousing platform such as Snowflake and data analytics platforms such as Databricks
Strong problem-solving skills
Strong communication skills

#LI-Hybrid

Additional Information

Due to the nature of our business and the role, please note that Intuitive and/or your customer(s) may require that you show current proof of vaccination against certain diseases including COVID-19. Details can vary by role.

Intuitive is an Equal Employment Opportunity Employer. We provide equal employment opportunities to all qualified applicants and employees, and prohibit discrimination and harassment of any type, without regard to race, sex, pregnancy, sexual orientation, gender identity, national origin, color, age, religion, protected veteran or disability status, genetic information or any other status protected under federal, state, or local applicable laws.

We will consider for employment qualified applicants with arrest and conviction records in accordance with fair chance laws.

Preference will be given to qualified candidates who do not reside, or plan to reside, in Alabama, Arkansas, Delaware, Florida, Indiana, Iowa, Louisiana, Maryland, Mississippi, Missouri, Oklahoma, Pennsylvania, South Carolina, or Tennessee.

We provide market-competitive compensation packages, inclusive of base pay, incentives, benefits, and equity. It would not be typical for someone to be hired at the top end of range for the role, as actual pay will be determined based on several factors, including experience, skills, and qualifications. The target salary ranges are listed.

Base Salary Range Region 1:$167,000 - $240,200
Base Salary Range Region 2: $141,900 - $204,300
Shift: Day
Travel: None
Workplace Type: Purposeful Onsite - This job requires being onsite for leader-defined events and activities which could be monthly/annually. Onsite frequency may increase based on business need.",1995,Health Care Products Manufacturing,$1 to $5 billion (USD),Manufacturing,5001 to 10000 Employees,Company - Public,False
Data Integration Engineer,"The Wonderful Company
","Los Angeles, CA",$130K - $145K (Employer est.),3.7,"Company Description


From farm to table, The Wonderful Company is a privately held $5 billion company committed to offering high-quality, healthy, and iconic brands such as Wonderful Pistachios, Wonderful Halos, FIJI Water, and POM Wonderful. We’re looking to make the world a healthier place through an uncompromising commitment to the well-being of our employees and their families.

We are seeking a talented and experienced Data Integration Engineer to join our team and play a crucial role in designing, building, and maintaining our ETL (Extract, Transform, Load) processes. As a Data Integration Engineer, you will work closely with data analysts, data scientists, and other stakeholders to ensure the efficient extraction, transformation, and loading of data from various sources into our data warehouse. Your expertise in data integration, data quality, and performance optimization will be essential in supporting our organization's data-driven decision-making efforts.

This position will be based at our West Los Angeles, CA office and working a hybrid schedule with 3 days per week in the office.



Job Description

Design, develop, and maintain data warehouses and data marts to store and organize data from the Oracle ERP and other sources.
Design, model and document the logical and conceptual relationship of data and implement database changes for Business Intelligence (BI) applications in ODI and Oracle Fusion Analytics Warehouse (FAW).
Understand the data related challenges, nuances, and requirements to identify and recommend the optimal technical approach.
Understand project timelines for IT Projects and lead development and training efforts for IT Projects using Agile methodology.
Perform proof of concepts for innovation and to continuously improve and enhance the capabilities of the data analytics platform.
Develop and maintain strong effective working relationships with team members and internal customers.
Train and educate internal team members as well as partner consultants about best practices in data engineering and governance.


Qualifications

Datawarehouse Design Skills: Focus area includes exceptional skills with data design and management.
Strong Experience with data warehousing ETL process design/development/support (ODI, Informatica).
Experience working with ERP systems data such as Oracle EBS/Fusion (Purchasing, Order Management, Manufacturing and/or Financials modules).
Extensive experience in SQL/PLSQL, Logical SQL Queries and Performance Tuning.
Proven experience working with REST APIs and bringing data from REST APIs from multiple sources.
Excellent understanding of star/snow-flake schema, SCDs and de-normalized operations.
Experience in leading requirements gathering, gap analysis and create user requirements documentation.
Solid exposure to varied cloud databases such as Snowflake, Oracle Autonomous DW (ADW), etc.
Oracle Fusion Analytics Warehouse (FAW) experience is a plus.

Pay Range: $130,000 - $145,000 and may include a discretionary bonus. Final compensation will be dependent upon skills & experience.


Additional Information

Competitive benefits package including Medical (including 24/7 online access to a physician), Vision, Dental and 401k with match eligibility
Opportunities for development and internal mobility
Manager and leadership training, biweekly L&OD webinars, and eLearning offerings
Companywide problem solving and continuous improvement training
Wonderful Giving (wonderfulgiving.com) - allowing you to donate company money to a cause of your choice
Company prioritizes wellness through its Wonderful NOW (Nourish Our Wellness) initiative, which provides a robust suite of wellness offerings such as access to mental health resources and life coaching, employee community groups, cash rewards for healthy habits, and on-demand fitness videos

Headquartered in Los Angeles, The Wonderful Company is a privately held $5 billion global company dedicated to harvesting health and happiness around the world through its iconic consumer brands. The company’s 10,000 employees worldwide are committed to bringing consumers everywhere the freshest, most wholesome pistachios, citrus and pomegranates; bottling the finest water and wines; and creating colorful bouquets that are sure to touch the heart. This commitment is reflected in the company’s market share: Wonderful Pistachios is America’s No. 1 tree nut and America’s fastest-growing snack; Wonderful Halos is the No. 1 mandarin orange in America; POM Wonderful is the No. 1 100% pomegranate brand in America; FIJI Water is America’s No. 1 premium imported bottled water brand; JUSTIN Wine has the No. 1 Cabernet Sauvignon in California; and Teleflora is the world’s leading floral delivery service.

The Wonderful Company’s connection to consumers has health at its heart and giving back in its DNA. The company has a long-standing commitment to corporate social responsibility, including more than $2.5BN invested in education, health and wellness, community development, and sustainability initiatives across California’s Central Valley, Fiji, and the world.

To learn more about The Wonderful Company, its products, and its core values, please visit wonderful.com, or follow The Wonderful Company on LinkedIn, Facebook, Instagram, and Twitter. To learn more about the company’s corporate social responsibility impact, visit csr.wonderful.com.

The Wonderful Company is an Equality Opportunity Employer that provides opportunities for advancement. We are committed to creating a diverse workforce that embodies a deep culture of acceptance, equity, and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, protected veteran status, or other protected categories.

#LI-JB1

#LI-Hybrid

EEO is the law - click here for more information",1980,Consumer Product Manufacturing,$1 to $5 billion (USD),Manufacturing,5001 to 10000 Employees,Company - Private,True
Senior Data Engineer,"Hatch IT
","San Francisco, CA",$110K - $160K (Employer est.),5.0,"Hatch I.T. is partnering with an AI startup to find a Senior Data Engineer. See details below:

About the role
As a Senior Data Engineer, you will build and maintain data pipelines, and help us scale our data systems and run client reports. You'll manage core database systems, evaluate A/B tests, establish industry benchmarks, and uncover trends from shoppers around the world. You'll need to bring new ideas and see the big picture, communicate with the team, and ensure projects are delivered on time. Your work will have a real impact on the industry and be seen by leaders at some of the top apparel brands and retailers in the world. You'll also develop and maintain metrics, reports, analyses, dashboards, and more, and translate data-related questions into persuasive analyses for business partners. You'll create compelling narratives and refine processes for data collection and analysis, among other responsibilities.

About You
You are a humble, passionate, and experienced data engineer that is excited to write code but also comfortable working with sales, accounts, and other engineers. You have a positive outlook and are interested in working in a highly collaborative work environment. If you have a natural curiosity for data and don't mind rolling up your sleeves and digging through messy data to find interesting insights, this might be your jam.

About the Company
The company is an AI-based platform that's transforming the apparel industry. Their platform helps retailers and brands reduce returns, improve sustainability, and optimize their supply chain. With machine learning and AI at their core, they're able to predict body measurements with incredible accuracy. This enables brands and retailers to gain a better understanding of their customers' buying habits, the fit and sizing of their products, and make optimizations in a completely new way. Their focus on data-driven insights is helping some of the world's most well-known brands and retailers leverage AI to make an impact across their entire organization.
How you will make an impact
You’ll directly impact client relations with full understanding of how we’re able to impact their business
You’ll work alongside our customer success team to help understand our clients’ needs and help the answer and explore their data
You’ll drive data analysis and help create analysis the entire apparel industry will adopt
Skills and Qualifications: (even if you do not 100% meet these skills, they still welcome you to apply)
10+ years experience as a Data Engineer in a professional setting
5+ years of Data Analysis experience in a professional setting
Very comfortable with SQL & Python
Able to identify trends and patterns in data
You can clearly communicate acceptance criteria and work well with a data team
You love understanding the nuances of data and are excited to take command of client analysis and data
Comfortable using a VPN, a database GUI and Jupyter
Experience working on an eCommerce and/or retail site a plus
B.A. or B.S. degree required
Don't think you're 100% qualified for this position? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At hatch I.T., we're dedicated to helping companies build diverse, inclusive and authentic workplaces, so if your experience doesn't perfectly align with every qualification in the job description, we encourage you to apply anyway. You may just be the right candidate for this or other roles.

If you are interested in learning more about this company or any Startups/Small Businesses in the area, please contact us and check us out here!!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",2013,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Private Practice / Firm,False
Senior Data Engineer,"Mastercard
","San Francisco, CA",$144K - $179K (Glassdoor est.),4.3,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Senior Data Engineer
Have you ever wondered how do you see offers on your credit card based on your past purchase? If you wanted to find the answer do join our team.

We are looking for a Data Engineer to not only build data pipelines but also extend the next generation of our data tools. As a Data Engineer, you will develop a clear sense of connection with our platform - as Data Engineering is the eyes through which they see the product.

Data Engineer Responsibilities

Lead day to day system development and maintenance activities of the team to meet service level agreements and create solutions with high level of innovation, cost effectiveness, high quality and faster time to market.

Support code versioning, and code deployments for Data Pipelines.

Ensure test coverage for unit testing and support integration and performance testing.

Contribute ideas to help ensure that required standards and processes are in place.

Research and evaluate current and upcoming technologies and frameworks.

Build data expertise and own data quality for your areas.

Minimum Qualifications

Extensive Java/Scala development experience.
Extensive experience with SQL.
Strong experience with Spark Processing engine.
Strong experience with Big data tools / technologies (Hive, Impala, OOZIE, Airflow, NIFI)
Strong experience with Data Modeling.
Experience in Kafka and PCF (Pivotal Cloud Foundry)
Experience analyzing data to discover opportunities and address gaps.
Experience working with cloud or on-prem Big Data platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).

#LI-JN1
#LI-HYBRID
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Pay Ranges
San Francisco, California: $134,000 - $208,000 USD",1966,Financial Transaction Processing,Unknown / Non-Applicable,Financial Services,10000+ Employees,Company - Public,False
Data Infrastructure Engineer,"Applied Intuition
","Mountain View, CA",$65K - $400K (Employer est.),4.0,"About Applied Intuition

Applied Intuition is a vehicle software supplier that accelerates the adoption of safe and intelligent machines worldwide. Founded in 2017, Applied Intuition provides a simulation and validation platform for various industries such as automotive, trucking, construction, and more. 17 of the top 20 global automakers rely on Applied Intuition's solutions to shorten development cycles, deliver high-quality systems, and accelerate the production of modern vehicles with confidence. Applied Intuition is headquartered in Mountain View, CA, with offices in Ann Arbor, MI, Washington, DC, Munich, Stockholm, Seoul, and Tokyo. Learn more at https://applied.co.

About the role

We are looking for talented engineers who are excited about building products that wrangle AV data to supercharge our customers. You will drive the design and development of data infrastructure across both our external products and internal tools. Handling massive volumes of data for Applied Intuition's platform needs is a critical area and we are looking for someone who can be hands-on in supporting our data products and services across the company. Being part of a fast-moving company, this position will require being an independent-thinker and ability to own projects, including development of greenfields projects end-to-end. At Applied Intuition, we encourage all engineers to take ownership over technical and product decisions, closely interact with external and internal users to collect feedback, and contribute to a thoughtful, dynamic team culture.

At Applied Intuition, you will:

Develop and deploy event-driven pipelines using extract, load and transform (ELT) architecture focused on distributed ingestion
Build features to tune processing pipeline for fast data ingestion and indexing depending on customer's needs and workloads
Enable product workflows that expose performant query interfaces and offer easy-to-use integration hooks
Develop and deploy high-quality software using modern tooling and frameworks
Encourage change, especially in support of data engineering best practices, and maintain a high standard of excellence
Work with products and teams across Applied Intuition

We're looking for someone who has:

Experience with large-scale open source data processing frameworks (Spark, RabbitMQ, Kafka, Airflow, Flink, etc.)
Experience with containerization and other modern software development workflows
Strong knowledge of SQL and data concepts, including experience in using a big data warehouse
Deep knowledge of data quality, data profiling and cleansing techniques

Nice to have:

Expertise with modern programming languages (Python, C++, GoLang, etc.)
Experience with enterprise software, including on-prem and/or cloud environments
Experience with either autonomy or simulation products

The salary range for this position is $65,000 USD to $400,000 USD annually. This salary range is an estimate, and the actual salary may vary based on the Company's compensation practices.

Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.

Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.

Applied Intuition is an equal opportunity employer and federal contractor or subcontractor. Consequently, the parties agree that, as applicable, they will abide by the requirements of 41 CFR 60-1.4(a), 41 CFR 60-300.5(a) and 41 CFR 60-741.5(a) and that these laws are incorporated herein by reference. These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. These regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. The parties also agree that, as applicable, they will abide by the requirements of Executive Order 13496 (29 CFR Part 471, Appendix A to Subpart A), relating to the notice of employee rights under federal labor laws.",2017,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
Data Science Engineer - Freelance,"Fantasy
","San Francisco, CA",$115K - $167K (Glassdoor est.),4.7,"This role may sit anywhere as long as the individual is willing to work North America hours.

Realize the unimagined

Fantasy is a digital product and innovation company. We realize the unimagined for the world’s most ambitious organizations. Founded in 1999, our global reputation is based on our teams’ unique ability to think beyond the ordinary and launch ground-breaking products and services. We believe that our phenomenal team is the core reason for our success, our growth, and our thriving culture.

The Role

As a Data Science Engineer, your primary responsibility will be to build out exciting new AI-driven tools that our clients will love and use every day. Collaborating with the best design and research teams in the world, and world class client teams, your work will not only drive the future of Fantasy, but influence the future of the industry. Your work will frequently be on the bleeding edge of AI, incorporating the latest innovations in LLMs, machine learning, and data science.

Responsibilities

Prototype and build cutting edge, proof-of-concept AI products.
Collaborate with product managers, designers, researchers, and executives to create successful and compelling solutions.
Work with a large and globally distributed team.
Solve challenging cutting-edge problems, using state-of-the-art techniques, services, and best practices.
Evaluate and integrate new machine learning frameworks and tools, ensuring that Fantasy is always at the forefront of ML, LLMs, and Generative AI.
Actively contribute to continuous improvement of AI at Fantasy, through educational presentations and thought partnership with internal teams.

Experience / Key Personal Qualities

Bachelor’s or Master’s degree in Data Science, Computer Science, Statistics, or a related field.
Fluent in Python, C++, and Java.
3+ years of experience designing and building machine learning platforms and services.
Demonstrable expertise in LLMs, including fine-tuning and pre-training.
Experience with LLM specific packages and services (e.g. LangChain, vector databases).
Experience with AI frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn).
Strong communication skills to convey complex concepts to non-technical stakeholders.
Front end experience a plus.
Data harvesting / scraping experience a plus.
Experience in design-related fields or understanding of design processes is a plus.
Ability to work collaboratively in a cross-functional team environment.

Fantasy EOE

Fantasy is an Equal Opportunity Employer. Since 1999, diversity has been vital to our success and ability to create products and services used and loved by millions of people all over the world. We are committed to continually fostering a diverse, equitable, and inclusive workplace.",1999,Internet & Web Services,$5 to $25 million (USD),Information Technology,51 to 200 Employees,Company - Private,False
Senior Data Engineer,"Tri Counties Bank
","Roseville, CA",$120K - $160K (Employer est.),3.4,"Check us out, this could be the best career move you ever make.

The hiring range for this opportunity is $120,000 - $160,000 annually along with incentive opportunities, creating a competitive total compensation package based on our pay scale, and may be modified by location and is commensurate with qualifications and experience.

POSITION SUMMARY

The Senior Data Engineer is responsible for the end-to-end development life cycle for the Bank’s data warehouse. The implementation of Extract, Transform, Load (ETL) procedures, modeling for database and performance management, and dimensional design of the table structure are all tasks that fall under the purview of the Senior Data Engineer. The position collaborates closely with the Product Management, other Data Engineers, and Analyst teams to achieve insights, provide the organization with valuable data solutions, and enable reliably to inform strategic decisions. The Senior Data Engineers will work independently on projects while keeping senior leadership informed. They also need strong communication skills and effectively convey their ideas to senior leadership, other members of the team and mentor less experienced Data Engineers and Analysts.

MAJOR RESPONSIBILITIES

Create data models used to extract information from various sources and store it in a usable format.
Automation of pipelines, data quality rules and data governance practices
Maintain data integrity by designing backup and recovery procedures.
Identify opportunities to enhance performance by improving database structure or indexing methods.
Conduct research to identify new technologies that can be applied to current projects.
Ensure delivery of reports, dashboards, and custom solutions for various business lines.
Accountable for all aspects of data engineering from delivery planning, estimating and analysis, through to data architecture and pipeline design, delivery, and production implementation.
Analyze data to find patterns or insights that can be used to develop strategies or make business decisions.
Oversee development of new dashboards using existing data sets to create new products or improve existing services.
Maintain existing applications by updating existing code or adding new features to meet new requirements.
Design and implement security measures to protect data from unauthorized access or misuse.
Proactively recommend infrastructure changes to improve storage capacity or performance.
Analyze and organize raw data, build data systems and pipelines.
Evaluate business needs, objectives, interpret trends and patterns through conducting business interviews.
Conduct complex data analysis and report on results.
Prepare data for prescriptive and predictive modeling.
Build algorithms and prototypes, combine raw information from different sources.
Establish SLA’s and communication mechanisms for report disruption.
Establish a centralized reporting portal for role-based organization wide pull reporting.
Explore ways to enhance data quality and reliability.
Identify opportunities for data acquisition.
Collaborate with data analysts and architects on several projects.
Design, contribute and maintain a data dictionary.
Working knowledge of Master Data management and Data Lineage
Expertise in translating business requirements into actionable work
Advanced knowledge working with business stakeholders on Date Governance and Data Quality.

SECONDARY RESPONSIBILITIES

Maintain a current understanding of stated procedures and policies, including regulatory compliance issues as it relates to all pertinent FDIC, DFPI, and other Federal security regulations related to Data Governance and Data Security.
Maintain a current understanding of Bank policies and procedures in compliance with all federal and state laws, including but not limited to Bank Secrecy Act (SARs, CIP, OFAC), Information Security (GLBA), Privacy Laws (CCPA), Identity Theft Red Flags, Financial Elder Abuse Reporting, and any other applicable regulations that may be specific to your job duties.
Understand data privacy and data security concepts and experience with delivering data-related projects.
Ability to communicate across disciplines (ex. security, privacy, legal, risk).

OTHER RESPONSIBILITIES

Firm understanding of Data Governance, specifically in the banking and financial sector.
Review, comprehend and maintain a current knowledge of all applicable laws, rules and regulations governing assigned area of responsibility.
Extensive experience managing corporate data warehouse programs within medium to large organizations.
Knowledge of evolving and current threats including Cyber terrorism.
Maintain confidentiality regarding all customer and employee information.
Perform other duties as assigned.

EDUCATION, EXPERIENCE AND OTHER SKILLS REQUIRED

Bachelor’s degree in Information Security, Information Technology or related field, strongly preferred.
8-10 years of proven data and performance engineering experience.
Extensive experience providing practical direction within AWS & Azure cloud native services, implementing data migration and data processing using Azure services: ADLS, Azure Data Factory, Synapse/DW /Azure SQL DB, Fabric.
Proven experience with SQL, namely schema design and dimensional data modelling
Expert knowledge of data warehouse best practices, development standards and methodologies
Strong experience with Azure Cloud on data integration with Snowflake (developing ETL pipelines)
Advanced knowledge on Power BI
Be an independent self-learner with the “let’s get this done.”
Strong understanding on ML Studio, AI/ML, MLOps etc.
Python & Data Bricks experience preferred.
Expert track record of developing custom-built data/analytics solutions and experience in supporting large scale programs.
Advanced experience with system analysis, data analysis or programming, using a variety of computer languages and procedures.
Experience establishing an Agile system and working environment for a data warehouse.
Banking experience strongly preferred.
Expert leading complex regulatory projects.
Experience across multiple bank departments desired.
Knowledge of laws and regulations impacting data protection and confidentiality, integrity, and availability of systems and data in the financial industry such as Sarbanes-Oxley, and state regulations.
Effective interpersonal skills with the ability to work effectively with individuals and groups at all organizational levels.
Leadership ability to provide guidance, coaching and training to staff and to other Bank employees.
Ability to take initiative and prioritize tasks, good time-management, problem prevention and problem-solving skills.
Proven track record of success demonstrating leadership and management skills.
Expert verbal and written communication skills, including presentation skills.
Knowledge in DevOps and CI/CD deployments, Cloud migration methodologies and processes.
Nice to have: Event Hub, IOT Hub, Azure Stream Analytics, Azure Analysis Service, Cosmos DB knowledge, PBI Gateway knowledge.

COMPANY PROFILE:

Established in 1975, Tri Counties Bank is a wholly-owned subsidiary of TriCo Bancshares (NASDAQ: TCBK) headquartered in Chico, California, with assets of nearly $10 billion and more than 45 years of financial stability. Tri Counties Bank provides a unique brand of Service With Solutions® for communities throughout California with a breadth of personal, small business and commercial banking services, plus an extensive branch network, more than 37,000 surcharge-free ATMs nationwide, and advanced online and mobile banking.

Tri Counties Bank remains strong and profitable through our top-down commitment to our core values, sound business principles and responsible lending practices.

Our success is also based on our community engagement. We still believe in the vision of the helpful and caring community banker. As we grow and serve more communities, we become more involved, providing substantial financial and volunteer support to local economies and community organizations. We applaud our employees who roll up their sleeves to work and volunteer for a greater good in our communities.

Tri Counties Bank hires individuals who are qualified for the role and who represent the communities in which we serve. We look to place people in positions where they can best utilize their abilities and strengths, and where they are able to grow with the Bank.

Tri Counties Bank is an Affirmative Action and Equal Opportunity Employer, Race/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disability/Veteran.",1975,Investment & Asset Management,$100 to $500 million (USD),Financial Services,501 to 1000 Employees,Company - Public,False
Software Engineer: Data Platform,"Observe, Inc.
","San Mateo, CA",$112K - $165K (Glassdoor est.),5.0,"Observe is building an Observability Cloud that allows customers to bring all their machine data (logs, metrics, traces, etc.) together in one place. At the core of the service is our data management platform which enables our users to build sophisticated streaming pipelines and express complex temporal queries all without learning complex database concepts. The platform is built on top of a cloud data warehouse platform (Snowflake).

As a data platform engineer, your will work on making the platform perform better, adding new capabilities, and reducing its cost. Typical work involves:
Compiling and optimizing user queries so that they can be executed more efficiently
Support new query functions to make the platform more powerful and flexible
Make streaming more cost-effective and reduce the end-to-end latency

The ideal candidate should be:

Experience with relational database internals
Experience with query optimization and stream processing is a strong plus
Experience with Go is a plus but not required
Self-motivated, fearless, likes to dive in the code and get stuff done
Strong teamplayer who can work independently but cares about context and knows when to reach out",2017,Enterprise Software & Network Solutions,$1 to $5 million (USD),Information Technology,1 to 50 Employees,Company - Private,True
Data Engineer - Health Technologies,"Apple
","San Diego, CA",-1,4.2,"Summary
Posted: Oct 18, 2023
Weekly Hours: 40
Role Number:200399604
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
5+ years of experience in software development
Expert in at least one of the following programming languages: (Python, Scala, Java)
Expert in large-scale data processing using parallel computing (e.g. Apache Spark, Hadoop, Dask)
Workflow orchestrations (e.g., Airflow, Luigi)
Proficiency in the Python programming language
Proficiency in Python frameworks and libraries for scientific computing (e.g. Numpy, Pandas, SciPy, Pytorch, Pyarrow)
Designing and maintaining relational and file system databases (e.g. Postgres, SQL, Parquet, S3, Data Lake)
Great understanding of infrastructure designs
In depth experience working with enterprise DE tools and the ability to learn and improve upon in-house DE tools
Experience designing and implementing custom ETL workflows
Demonstrated technical leadership and good communication skills
Description
Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data Process, troubleshoot, and clean incoming data from human studies Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications Create and maintain databases with existing and incoming clinical data Architect data models and create tools to harmonize disparate data sources Incorporate and comply with regulations as they pertain to electronic and clinical data and databases.
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent
Additional Requirements
Desired/Preferred Qualifications:
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realm
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with machine learning development pipelines
Experience with data modeling of diverse types of data streams
Familiarity with AWS (or similar) cloud services and backend development
Familiarity with development on Linux and MacOS
Familiarity with iOS and WatchOS frameworks and app development
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $88,100 and $170,100 annualized, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",1976,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
ML and Data Infrastructure Engineer - SPG,"Apple
","Cupertino, CA",-1,4.2,"Summary
Posted: Dec 13, 2022
Role Number:200425055
As an engineer in the Special Projects Group, you will be part of a team building infrastructure and tools for exciting new technologies that will shape the future. You will work in a startup-like environment where products are still being defined and developed, giving you the chance to influence some of the core tools used by the project. You will be part of every stage of development from concept to deployment. We are looking for an senior engineer to architect, build and scale a robust ecosystem for data processing and distributed computation. Specifically you will develop solutions that will orchestrate and support the seamless transitioning of petabytes of data through various stages like ingestion, indexing/mining, transformation, machine learning and algorithm validation.
Key Qualifications
You have hands-on experience in building distributed systems, including real-time streaming and batch data processing
You are proficient in multiple programming languages relevant for such systems (e.g. Python, C++, Go, Java)
You know what it takes to deploy and operate high availability production systems in the cloud
You have experience designing service-oriented architectures and leveraging various data stores technologies (blob, NoSQL, and relational)
You have experience with cloud computing platform like AWS, GCP and Azure
Description
• Develop and scale a data processing platform using the latest open-source technologies • Develop platforms that enable researchers and developers to run machine learning jobs in the cloud easily • Define a consistent continuous integration/deployment model that will encourage cross-functional development teams to self-service application unit testing, deployment and operations • Influence and lead cross-functional initiatives that will align the team towards commonly used technologies and methodologies
Education & Experience
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",1976,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Software and Data Engineer,"TGS Management Company
","Irvine, CA",$84K - $122K (Glassdoor est.),5.0,"At TGS, data is a core part of our business and our data focused software developers are among our most valued resources. This role is mission critical, so we’re searching for an uncommonly reliable professional who enjoys coding, working with and analyzing data, and providing support for production systems. In addition to programming and data analysis, this position is likely to involve interaction with external resources such as data providers, brokers, dealers, and software vendors.

Successful candidates will have experience in a number of the following general areas:

Programming: strong experience with Python, Java, SQL, and/or similar languages
Large data sets: experience developing programs to parse, process, clean, organize, and analyze large data sets
Applications: experience designing, developing, and maintaining software applications
Vendor interaction: working with external resources to solve problems, acquire data, and improve relationships.
System tools: experience with scripting languages (Perl, Python, shell scripts, etc.), and Unix-based operating systems (especially Linux)


About Us

For over two decades, the TGS team has built quantitative trading systems that have produced exceptional results across a range of financial markets. We use scientific methods and engineering discipline to solve challenging problems and develop technology solutions. Our Irvine office is as unique as our Southern California location, combining elements of high tech, finance, and applied research in a collegial atmosphere and beautiful workspace.

As an employer, we are small, discreet, and highly selective. We look for exceptional people with proven track records of performance and achievement, and are far more interested in aptitude and potential than expertise in any particular technology, tool set, or professional domain. If you're inspired by the idea of working on interesting problems with talented colleagues, we invite you to share your resume and explore the possibility of joining our team.

Applicants residing in California may find our CCPA notice to California residents HERE.",1989,Investment & Asset Management,Unknown / Non-Applicable,Financial Services,Unknown,Company - Private,False
Data Engineer,GTECH LLC,"South San Francisco, CA",$120K - $130K (Employer est.),-1.0,"Job Title: Data Engineer

Job Location: San Francisco, CA

Mandatory Skills:

o Python

o DataBricks

o PySpark

o AWS

o SQL

Job Description :

o 5+ years in a customer facing Technical architecture, consulting role with the expertise in The following technology.

o Developing modern Data warehouse solutions using Databricks and AWS/Azure stack.

o Drive technical discussion with client architect and team members.

o Knowledge in Databricks DELTA lake for the Analytical data lake use case

o Hand on experience in create MLOPS data pipeline creation.

o AIML Models develop, train and implement for the AIML use cases.

o Knowledge in Banking domain on card and payment areas.

o Any relation database – Data classification/ Data profiling for MLOPS use cases

o Good experience in offshore onsite coordination.

o Experience in translating a customer’s business needs

Job Type: Full-time

Salary: $120,000.00 - $130,000.00 per year

Experience level:

5 years

Schedule:

8 hour shift

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Data Infrastructure Engineer,Tasktoday,"Newark, CA",$111K - $158K (Glassdoor est.),-1.0,"At Tasktoday we are building a shared task list for teams in an effort to re-imagine the way people work together. As knowledge workers, we and our loved ones spend most of our time living in programs (email, calendar, document editors, etc.) that help us move and manage data, and get things done. This is an opportunity to improve that part of our lives.

The Metrics Infrastructure Engineer is a critical role for Tasktoday’s growth. As a key member of the engineering team, you will work closely with the product teams to build out and refine the infrastructure we use to gain insights from our data and evaluate our success. As our user base rapidly grows, you will architect and develop improvements to our data infrastructure, and design and implement data analysis tools that increase the scalability, accuracy and accessibility of our data to support ongoing product decisions.

With this data infrastructure, you will be in the unique position to help shape the company roadmap by identifying opportunities in our data and enabling us to rapidly test our assumptions.

Requirements

Strong background in computer science, math or other technical field
Fluent in SQL and at least one modern scripting language
Capable of supporting live production infrastructure, can put out fires under pressure when things go wrong
Distributed computing experience
Passion for deriving insights from data and transforming it into actionable facts
Desirable
Extensive experience with data infrastructure and reporting tools
Strong analytical skills including the ability to identify problems and draw conclusions that are supported by a principled analysis of data
Capable of explaining results in a clear and effective manner
Knowledge of modern web technologies",-1,-1,Unknown / Non-Applicable,-1,Unknown,Company - Public,False
"Software Engineer, Data Infrastructure","Forward
","San Francisco, CA",$104K - $162K (Glassdoor est.),3.5,"Forward is on a bold mission to make high quality healthcare available to a billion people across the globe. We’re building the world’s most advanced healthcare platform from the ground up, combining hardware, software and doctors under one roof. We are scaling our engineering team and looking for world-class engineers with experience and expertise in building robust, scalable APIs and integrating third-party systems. As an early member of our engineering team, you’ll play a key role in building the future of healthcare from first principles.

Forward was founded in January 2016 by former executives and engineering leaders from Google and Uber. We are funded by some of the world's best investors and entrepreneurs including Founder's Fund, Khosla Ventures, First Round Capital, Eric Schmidt (Google/Alphabet Chairman), Marc Benioff (Salesforce Founder), Joe Lonsdale (Palantir Founder), Joshua Kushner (Oscar co-Founder) and Garrett Camp (Uber co-Founder).

Press and Videos:
Virtual Tour of Forward [YouTube]
Health Moves Forward [CEO Blog Post]
Series D Funding Funds Doctor-led Programs [TechCrunch]
Forward - What Quality Healthcare Should Look Like [Mashable]
Primary Care Start-ups Vying for 170B Market [Business Insider]
The Pivot to Virtual Care [Chief Medical Officer @ Stanford Medicine]
The Meaning of Trans Broken-Arm Syndrome [USA Today]
WHAT YOU'LL DO:
Design and evolve our cloud data infrastructure for 10x data growth.
Own foundational datasets used by teams across the company.
Build platforms that empower non-engineers to create data pipelines and data products.
Invest in tools that proactively measure, monitor, and improve data quality and accessibility.
Own entire projects while working alongside cross-functional teams of doctors, designers, and operators.
Your work will directly contribute to saving and improving people’s lives. For real. :)
WHAT WE'RE LOOKING FOR:
Data Engineering - You have firsthand experience with database performance tuning, cloud storage and processing technologies (e.g. Redshift, S3, Glue, Lambda, Databricks, DBT), workflow orchestration (e.g. Dagster, Airflow), distributed computing (e.g. Spark, EMR), message queues and streams (e.g. Kafka, Kinesis).
Good Practices - You care about more than just shipping data, but also doing it in a scalable, efficient, reliable, and secure way.
Empathy - You spend time understanding the needs, and driving alignment among different data users.
Entrepreneurship - You’re a self-starter who loves to own things end-to-end. You are excited to try out new technologies and build proof-of-concepts.
Team player - You know how to make those around you better and feed off their energy. You take care of your teammates.
You have a BS or MS in computer science or a related technical field.
You have a minimum of 3 years experience working in a related field.
The base salary range for this full-time position is $100,000-$220,000, plus equity and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all locations. Within the range, individual pay is determined by factors including job-related skills, experience, relevant education or training, and location.

WHY JOIN FORWARD?

We don’t want to just move dollars around the healthcare industry - we want to rebuild it and fix it. All of it. You’d be a major part of the story behind one of the most ambitious startup attempts of the past decade and you’d work with a team of people who want to use their talents for good.

We are an equal opportunity employer. In accordance with anti-discrimination law, it is the purpose of this policy to effectuate these principles and mandates. We prohibit discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. We conform to the spirit as well as to the letter of all applicable laws and regulations. Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, we will consider for employment qualified applicants with arrest and conviction records.

Information collected and processed as part of any job application you choose to submit is subject to Forward’s Privacy Notice to California Job Applicants.",2016,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,Unknown,Company - Private,False
Data Engineer,"AEG Worldwide
","Los Angeles, CA",$96K - $152K (Glassdoor est.),4.0,"For more than 20 years, AEG has played a pivotal role in transforming sports and live entertainment. Annually, we host more than 160 million guests, promote more than 10,000 shows and present more than 22,000 events around the world. We are committed to innovation, artistry, and community, and leverage the power of our 300+ venues, leading sports franchises, marquee music brands, integrated entertainment districts, premier ticketing platform and global sponsorship activations, to create memorable moments that give the world reason to cheer.

Our business is interwoven with the human mind and heart, and we strive to build a diverse and inclusive company that reflects the artists, athletes, and fans that we host; reach beyond traditional boundaries to support the communities in which we operate; and minimize our impact on the environment by adopting sustainable practices throughout our business operations.

If you want to be challenged to up your game and make a difference, then join us in giving the world reason to cheer!

Position Summary:

The holder of the Data Engineer position is responsible for building data systems and developing and managing infrastructure and data pipelines that collect and process data according to AEG and AEG Sports needs and business goals. Having a high attention to detail and a desire to learn and develop are essential attributes as AEG and AEG Sports look to develop their data strategy and become support data driven decision making. The role will support the AEG and AEG Sports teams developing the pipelines for ingesting new data sources, preparing data to support analytics and visualization teams and working with the other team members to QA and monitor all elements of the data environments.

Essential Duties

Work with the Manager, Data Platforms, other members of the data team and AEG Sports Business Ops and Strategy team to manage and support all existing data related requests related to the AEG, AEG Sports and other data environments.
Engineer, manage and monitor ETL (Extract, Transform, and Load) and data pipeline tasks using available tools as required to consume new sources of data into the respective data environments.
Support the development of data models and provide guidance for optimizations and improvements to improve performance of data infrastructure and related products.
Proactively monitor and remediate issues with the data held and processed within the AEG and AEG Sports data ecosystem, including the development and publication of data quality and hygiene reports and the identification of new sources of data and validation methods.
Ensure that all data flows and the data environment as a whole are documented, including creating ERDs, and that source control policies are followed
Engage with and build relationships with internal customers, including business leaders within AEG Sports, other entities and with external suppliers to ensure that data is made available and exposed to support business requirements
Provide support as required to data analysts and ML specialists as regarding data environments as required.
Ensure that all data protection, security and governance policies and implemented and adhered to, particularly in relation to PII and other sensitive data

Required Qualifications

BA/BS Degree (4-year) Computer Science, Engineering, or a related technical area
4-6 Years Related technical experience
Experience of working with Big Data Technologies such as Hadoop, Spark or Databricks
Experience of Azure SQL Database, Azure Synapse, Azure Data Factory and other Azure services, including NoSQL technologies.
Experience of creating and managing database objects (tables, views, indices, stored procedures, UDFs, triggers, etc.)
Strong understanding of ETL, Big Data technologies and/or programming languages such as Python, Pyspark, Scala and experience using these languages to develop reliable and robust data pipelines and data solutions
Knowledge of SQL Server components
Strong attention to detail and commitment to data quality
Must be able to prioritize workload and manage complex requirements from diverse stakeholders.
Strong communication skills and ability to work with all levels of employees; must be able to communicate technical aspects to non-technical team members
Ability to work independently to accomplish work objectives, as well as in a team environment.
Experience of or interest in Sports (specifically Hockey) and/or the Live Entertainment industry.

Payscale: $112,444 - $147,583

AEG reserves the right to change or modify the employee's job description whether orally or in writing, at any time during the employment relationship. AEG may require an employee to perform duties outside their normal description.",-1,Sports & Recreation,Unknown / Non-Applicable,"Arts, Entertainment & Recreation",10000+ Employees,Subsidiary or Business Segment,True
Data Engineer,Kodeva,"San Jose, CA",$113K - $182K (Glassdoor est.),-1.0,"Location: San Jose CA

Duration: 12 Months

Job Description :

Profile should have more than 8years of experience
Hands on experience in designing and executing projects on Google Cloud Platform features like App Engine, Compute, storage, Big Query, Data Proc, Data Flow.
Strong Programming Skills in R, Python or Spark.
Strong Knowledge on Data Engineering, Simulation and Modelling concepts
Proficiency in handling the billions of structured or unstructured transactional data.
Proficiency in modeling techniques such linear regression, logistic regression, GLM
Knowledge on machine learning techniques such as Decision Trees, xgboost, random forest, PCA etc.
Knowledge on unsupervised Machine learning techniques such as Clustering, Segmentation
Strong knowledge on Data Manipulation and transformation
Knowledge on data loading to GCP services like big query, cloud storage.
Knowledge in Hadoop, HIVE and Pig languages.
Good communication skills.",-1,-1,Unknown / Non-Applicable,-1,51 to 200 Employees,Company - Private,False
Big Data Platform Engineer,"Apple
","Cupertino, CA",-1,4.2,"Summary
Posted: Nov 20, 2022
Weekly Hours: 40
Role Number:200444140
The SWE (Software) Data Analytics team at Apple collects, processes, and analyzes diagnostics and usage data from Apple devices across the world. We leverage streaming and batch analytics solutions to generate data that advises and drives product strategies across all of Apple software and hardware development. We discuss, analyze, and implement ground breaking solutions to problems of scale and distributed computing and are looking to expand our team with an engineer passionate about the big data workspace! Kafka, Flume, Hadoop, Spark, and other innovative technologies are core to our large scale infrastructure. You will be collaborating with data analysts, device engineers, and diverse engineering teams and drive the development of data pipelines and services with a high degree of ownership.
Key Qualifications
Experience developing large scale distributed computing systems.
In-depth knowledge and experience in one or more large scale distributed technologies including but not limited to: Hadoop ecosystem, Kafka, Samza, Flink, Storm, Flume, HBase, Cassandra, Redshift, Vertica, Spark.
Passion for and understanding of key algorithms and tools for developing high efficiency data processing systems.
Proficient in working with Linux or other POSIX operating systems, shell scripting, and networking technologies.
Problem-solving and debugging skills with experience in one or more of the following languages: Java, Python, Scala, Go, or Ruby.
There is a lot of communication involved! Excellent interpersonal skills are highly valued.
Description
As part of a team of highly skilled data engineers you will own significant responsibility in crafting, developing and maintaining our large-scale ETL pipelines, storage, and processing services. You will build self-service analytics tools to help engineering teams derive concrete metrics out of large volumes of raw data. You will partner with data science and engineering teams and develop algorithms to answer sophisticated questions on usage of Apple products. You will work closely with the DevOps team and develop monitoring and alerting scripts on various data pipelines and jobs. You will have the opportunity to learn and work on the latest Big Data technologies, lead PoCs to exercise new insights and, influence the strategic direction of our technology stack.
Education & Experience
Bachelors in Computer Science or equivalent experience
Additional Requirements
Experience using data storage technologies such as Apache Parquet or Avro Experience in machine learning algorithms is a plus.
Testing tools and methodologies to test large scale distributed computing systems.
Experience in data modeling and developing SQL database solutions is a plus.
Validated software engineering experience and field in design, test, source code management, and CI/CD practices.
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",1976,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Senior Data Engineer,"Heirloom
","Brisbane, CA",$160K - $180K (Employer est.),5.0,"Are you a talented Data Engineer looking to bring your expertise to the climate fight and be a part of a world class team at Heirloom? We are looking for a Senior Data Engineer to design our data architecture to optimize our future Carbon Capture systems and bring Heirloom’s carbon technology to life!



About Us
All across the world, from the azure pools of Turkey and Oman to the travertine terraces of Yellowstone, our planet quietly pulls carbon dioxide from the air and turns it to stone. For eons, Earth has relied on this process to balance its carbon cycle. What if it could be harnessed? What if we could do it faster, in larger quantities, and at a low enough cost to make it an effective tool in the fight against climate change?

At Heirloom, we are turning that into reality. We use the natural carbon capture properties of abundant minerals to pull CO2 from the air, and store it permanently underground. We come to work every day to slow climate change, and are united behind a single, common goal - to remove 1 billion tons of CO2 from the sky by 2035, and to not stop before we get there.

We bring together the precise recipe of science, technology, know-how, and strategy necessary to make low cost, high quality carbon removal a reality. If we’re successful, we will directly mitigate climate change, build a world we can proudly hand over to our children and grandchildren, and catalyze an industry that will rival the largest the world has ever seen. If you want to change the planet, come join us.

Our Commitment to Diversity, Equity, and Inclusion
As temperatures continue to rise, individuals from marginalized communities will face the harshest impacts of climate change. We believe wholeheartedly that building a diverse company is critical to Heirloom’s success. To accomplish this, we’ve put recruiting, hiring and retaining individuals from underrepresented groups at the top of our priority list. We urge you to apply if you identify as Black, Native Hawaiian or Pacific Islander, American Indian or Alaskan Native, Hispanic or Latino, LGBTQ+ – or with any other underrepresented group – even if you don’t tick all the boxes in the description below.

The Role
Data is at the core of how we operate and optimize our carbon removal systems at Heirloom. As Heirloom scales and strengthens its cybersecurity posture on the path to removing 1 billion tons of CO2, it will be essential to implement new methods of storing, transmitting and processing data. In this role, you will drive the development of data infrastructure that spans both remote production deployments and R&D activities. The Senior Data Engineer will partner across engineering, research and commercialization to identify use cases for data, and collaborate with other members of the software team to meet those needs.



What you will bring
From your strong background in data engineering, you have developed proficiency in configuring, monitoring and profiling relational (MySQL, PostgreSQL, etc.) and non-relational (MongoDB, Couchbase, etc.) database systems. As an experienced data engineer, you have deep knowledge of database sharding and replication, data encryption and compression, and time-series data management best practices. In addition to being proficient in one or more modern programming languages (Python, Java, Golang, etc.), you also are comfortable with developing extract, transform and load (ETL) pipelines for data warehousing. You have a keen ability to break down complex or ambiguous technical problems into incremental steps, and your ability to communicate technical projects in written and verbal forms is your superpower!

Please note: the examples in the list above are just that - examples! You don’t have to have every listed skill to be a great fit - you may even teach us something about what we should be looking for! If you are passionate about this opportunity and think you have the skills to succeed, please apply!

Our Principles
Radical Honesty means we are open, transparent, and inclusive in everything we do. We aren't scared to challenge each other, but bring clear motives and our best intentions when we do.

Persistent Optimism means we carry an infinite amount of optimistic energy with us on our journey, constantly chipping away at what may
seem insurmountable.

Maximize our learning rate means we're always in discovery mode. Compounding knowledge is our key to victory - we continuously hone our crafts, seek the fastest paths to new learning, and are quick to absorb new knowledge.
Why you should join Heirloom
We are solving the engineering problem of our generation. Climate change is an existential threat, and we need as many of the world’s motivated minds as possible to help. There is no greater challenge or opportunity than fighting climate change.
We have done this before. We have done this before. We’re engineers, scientists, and concerned humans from a variety of backgrounds and experiences who are pooling our knowledge and skills to collectively build a more equitable, prosperous future for all.
We are a united, resilient, and optimistic bunch. We are all here for the same reason - to slow climate change. We recognize the magnitude of the challenge ahead of us, and believe we can solve it. We can see a hopeful future where we eventually reverse climate change. It won’t be easy, but we won’t quit.
We are backed by the best climate partners in the world. We’re well funded by investors from Breakthrough Energy Ventures, Ahren Innovation Capital, Carbon Direct, Microsoft, Lowercarbon Capital, ARPA-e and the National Science Foundation. Our early customers include Stripe, Shopify, and Klarna, and we’re building durable partnerships that enable us to tackle this decades-long problem.
Perks and Benefits
Robust health coverage. Excellent health, dental and vision insurance covered up to 100% by Heirloom. FSA option.
Generous parental leave. 16 weeks paid leave for all Heirloom employees, regardless of primary/secondary caregiver status.
Generous stock options.
Flexible time off. Unlimited PTO for exempt (salaried) employees & 80 hours for full time non-exempt (hourly) employees.
401(k).
Stay healthy. Monthly health and wellness reimbursement.
Learn on the job. Robust annual education and conference budget, including airfare and hotel costs.
Target annual compensation for this role is between $160,000 and $180,000 depending on level and experience.
At Heirloom we will be deploying systems all over the world in different conditions, including hot and cold weather. This role may require you to occasionally work at heights, perform repetitive activities, including lifting 50 pounds or more, and occasionally use some basic hand and power tools.",-1,Energy & Utilities,Unknown / Non-Applicable,"Energy, Mining & Utilities",51 to 200 Employees,Company - Private,True
Data Platform Engineer,"BayOne
","Santa Clara, CA",$85.00 - $90.00 Per Hour (Employer est.),3.9,"We have a urgent requirement for Data Platform Engineer with Gurbhud. This associate must have good experience with Kafka

Client : Grubhub

Location : NY City, NY(Remote till COVID is done)

Rate : $85 to $90 an hour.

Grubhub is looking for an innately curious, business-minded, results-oriented Senior Software Engineer with a focus on data intensive applications, specifically Kafka and other streaming applications. In this role you will build and deploy platform-level tools and applications that enable a variety of data products across the Grubhub enterprise. You will be working alongside other platform engineers to help the company improve its data products and analytics. Specific responsibilities include, but are not limited to, development of streaming applications, problem solving, performance analysis, data model tooling (protobuf/avro/json-schema) and data pipeline tooling using cutting edge technologies on AWS.

Why Work For Us

We have a fast-paced environment and that is what our teams thrive on. Grubhub believes in empowering people and offering opportunities for development, as well as professional growth. We value strong, positive relationships in all areas: with each other, our customers and our greater community. Want to be a part of a team of diverse collaborators in an authentically fun culture? If so, we want to talk to you - and hear what's your favorite restaurant for food delivery!

The Impact You Will Make

Understand the business! Work directly with application developers, data engineers and data analysts to address their needs.

Build streaming data applications.

Be a stakeholder for our data platform tools! Help guide and prioritize development of the tooling to enhance our capabilities.

Help build a multi-datacenter, performant and highly available data platform and the frameworks to support it.

Help build and support frameworks to interact with various cloud technologies.

Actively contribute to the adoption of strong software architecture, the development of best practices, and new technologies. We are always improving the process of building software; we need you to help contribute

Help train software developers and other technologists on using the data platform, software stack (e.g. Kafka, Presto, Spark) to build their product-specific applications.

Relentlessly analyze and improve the performance of our systems.

You Should Have

Bachelor's Degree in Science, Programming or Engineering related field.

5+ years experience building highly-scalable, highly-available applications.

1-2 years of experience with Streaming technologies (Kafka, Beam, Flink, Spark).

expertise in Java, Scala, Python or a similar modern object-oriented language

Data querying capabilities using SQL

Ability to explain technical concepts in simple terms to business stakeholders

Knowledge of or experience with developing distributed systems

Experience with End-to-End (E2) testing frameworks

Experience mentoring/coaching engineers along with overseeing the technical work of developers from other teams.

A knack for analyzing and improving processes using data

Got These? Even Better

Experience designing and implementing multi-region streaming and data applications.

Experience deploying data pipelines in a production environment

Experience with distributed data and computing tools like Spark, Hive and Presto

Experience using cloud infrastructure like AWS",2012,Information Technology Support Services,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,False
Senior Data Engineer (Hybrid),"First American Financial Corporation
","Santa Ana, CA",$88K - $183K (Employer est.),3.8,"Who We Are

Join a team that puts its People First! Since 1889, First American (NYSE: FAF) has held an unwavering belief in its people. They are passionate about what they do, and we are equally passionate about fostering an environment where all feel welcome, supported, and empowered to be innovative and reach their full potential. Our inclusive, people-first culture has earned our company numerous accolades, including being named to the Fortune 100 Best Companies to Work For® list for eight consecutive years. We have also earned awards as a best place to work for women, diversity and LGBTQ+ employees, and have been included on more than 50 regional best places to work lists. First American will always strive to be a great place to work, for all. For more information, please visit www.careers.firstam.com.

What We Do

The Underwriting Innovation Team is looking for promising new Senior Data Engineer to help accelerate our digital transformation. We want diverse thinkers who know how to bring innovation to life by facilitating the design and development of simple, intuitive, and user-centered software solutions. You’ll help senior department leadership drive the transformation of a traditionally paper-based business by re-imagining underwriting as a digital experience, thinking through both the underwriter’s and customer’s lenses. The Data Engineer is a data expert and plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. Supports building scalable and effective solutions using modern technology stack to grow and leverage the company’s vast data assets. Works with functional teams and supports software developers, database architects, data analysts, and data scientists on data initiatives and ensures that optimal data delivery architecture is consistent throughout ongoing projects.

***Candidates will need to be local to Southern California and will get to work out of First American's Corporate HQ's in Santa Ana, CA for 2-3 days a week!

What You'll Do:

Viewed as a data expert; drives innovation and plays a key role in the department. Participates in highly visible initiatives that have broad impact.
Identify, design, and implement internal process improvements: automate manual processes, optimize data delivery, re-design infrastructure for greater scalability.
Design, develop, code, test, and document architectures and applications.
Work closely with team members and cross-functional teams to ensure design/architecture/deliverables support business requirements and align with best-practices.
Troubleshoot and resolve a wide range of data issues.
Makes innovative recommendations to improve data reliability, efficiency and quality.
Required to perform duties outside of normal work hours based on business needs.

What You'll Bring:

Strong database development skills
Strong knowledge of SQL and NoSQL databases
Strong experience with ETL processes to ingest large amounts of data at regular intervals
Strong knowledge of database performance optimization techniques, such as clustered, non-clustered, spatial, full-text indexing, etc.
Geospatial data knowledge preferred
Experience working in Agile SDLC methodology
Proficient with SQL and T-SQL programming skills
Working experience building data/ETL pipeline and data warehouse
Demonstrated expertise in data modeling, database maintenance, monitoring and performance tuning on SQL Server, MongoDB or other NoSQL databases
Exceptional analytical skills analyzing large and complex data sets
Perform thorough testing and data validation to ensure the accuracy of data transformations
Strong written and verbal communication skills, with precise documentation
Self-driven team player with ability to work independently and multi-task
Analytical, creative thinker and innovative problem solver
Working knowledge/proficient in modern cloud computing technology
Bachelor's degree in Computer Science/related field or equivalent combination of education and experience
5-8 years of directly related experience

Salary Range: $87,900.00 - $182,700 Annually

This hiring range is a reasonable estimate of the base pay range for this position at the time of posting. Pay is based on a number of factors which may include job-related knowledge, skills, experience, business requirements and geographic location.

#techreferral

#LI-DS1

What We Offer

By choice, we don’t simply accept individuality – we embrace it, we support it, and we thrive on it! Our People First Culture celebrates diversity, equity and inclusion not simply because it’s the right thing to do, but also because it’s the key to our success. We are proud to foster an authentic and inclusive workplace For All. You are free and encouraged to bring your entire, unique self to work. First American is an equal opportunity employer in every sense of the term.

Based on eligibility, First American offers a comprehensive benefits package including medical, dental, vision, 401k, PTO/paid sick leave and other great benefits like an employee stock purchase plan.",1889,Insurance Carriers,$5 to $10 billion (USD),Insurance,10000+ Employees,Company - Public,False
Staff Software Data Engineer,"Match Group
","San Francisco, CA",$225K - $240K (Employer est.),3.4,"Our Mission

As humans, there are few things more exciting than meeting someone new. At Tinder, we’re inspired by the challenge of keeping the magic of human connection alive. With tens of millions of users, hundreds of millions of downloads, 2+ billion swipes per day, 20+ million matches per day, and a presence in 190+ countries, our reach is expansive—and rapidly growing.
We work together to solve complex problems. Behind the simplicity of every match, we think deeply about human relationships, behavioral science, network economics, AI and ML, online and real-world safety, cultural nuances, loneliness, love, sex, and more.

The Engineering team is responsible for building innovative features and resilient systems that bring people together. We're always experimenting with new features to engage with our members. Although we are a high-scale tech company, the member-to-engineer ratio is very high—making the level of impact each engineer gets to have at Tinder enormous.

Tinder is looking for an expert engineer who's eager to architect, design and implement the next generation of our data platform. Our growing business always has new needs for actionable information, and this gives us an exciting roadmap with high-value products ready to be designed and many more waiting to be identified. This role will involve working with large scale data pipelines in near-real-time, batch, and lambda frameworks.
In this role, you will have the opportunity to:
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams.
Work with internal engineering and product teams to see opportunities for improvements or feature enhancements to our data platforms & frameworks to improve overall engineering efficiency
Drive self-serve capabilities for the engineering teams to easily onboard their critical data workloads onto our platforms
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure
Provide solutions, recommendations, documentation and training to the technical and business teams for continuous improvement of building a data-informed business
Drive adoption of data engineering best practices in a team of engineers, and ability to mentor junior team members

What we are looking for:
8+years of experience in data engineering on distributed frameworks such as Spark, Flink, Kafka Streams, Storm, Hadoop etc
Proficiency with any of the following programming languages - Scala, Java or Python
Experience with ETL job orchestration, preferably with a feature-rich tool such as Airflow, Argo, AWS step functions, Luigi etc.
Experience with at least one massively parallel processing data technology such as Redshift, Snowflake, Spark etc.
Experience with a NoSQL databases like DynamoDB etc.
Experience building real time data pipelines using Flink or Spark
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with any public cloud environment - AWS, GCP or Azure
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets

Bonus points if you have:
You’ve worked in a technical lead role in a data team
You’ve driven cross-functional initiatives with different teams and stakeholders
If you have led projects related to GRC like GDPR (Data deletion, RER, Right to be forgotten etc...), DLP and Role based Access Control
Experience providing technical leadership and mentor other engineers for data engineering best practices

As a full-time employee, you’ll enjoy:
Unlimited PTO (with no waiting period), 10 annual Wellness Days
Time off to volunteer and charitable donations matched up to $15,000 annually
Comprehensive health, vision, and dental coverage
100% 401(k) employer match up to 10%, Employee Stock Purchase Plan (ESPP)
100% paid parental leave (including for non-birthing parents) and family forming benefits
Investment in your development: mentorship through our MentorMatch program, access to 6,000+ online courses through Udemy, and an annual $3,000 stipend for your professional development
Investment in your wellness: access to mental health support via Modern Health, paid concierge medical membership, pet insurance, fitness membership subsidy, and commuter subsidy
Free subscription to Tinder Gold
Factors such as scope and responsibilities of the position, candidate's work experience, education/training, job-related skills, internal peer equity, as well as market and business considerations may influence base pay offered. This salary range is reflective of a position based in the posted location. This salary will be subject to a geographic adjustment (according to a specific city and state), if an authorization is granted to work outside of the location listed in this posting.
Commitment to Inclusion

At Tinder, we don’t just accept difference, we celebrate it. We strive to build a workplace that reflects the rich diversity of our members around the world, and we value unique perspectives and backgrounds. Even if you don’t meet all the listed qualifications, we invite you to apply and show us how your skills could transfer. Tinder is proud to be an equal opportunity workplace where we welcome people of all sexes, gender identities, races, ethnicities, disabilities, and other lived experiences. Learn more here: https://www.lifeattinder.com/dei",2015,Internet & Web Services,$1 to $5 billion (USD),Information Technology,1001 to 5000 Employees,Company - Public,False
Senior Data Platform Engineer,"Salesforce
","San Francisco, CA",$160K - $220K (Employer est.),4.0,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Software Engineering

Job Details

About Salesforce

We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.

Senior Platform Engineer, MDS Platforms

Position Overview:

The Marketing Decisions Science team is working to rebuild and modernize our data architecture with a cloud first approach and using code reusability through a standardized metadata drive approach and we are looking for an expert Data Platform Engineer to join our team. This role is responsible for designing, building, and maintaining data engineering architecture on the AWS cloud platform, with a strong focus on tools like Apache Airflow and dbt . The ideal candidate will have a deep understanding of metadata-driven design approaches and a passion for crafting scalable and efficient data pipelines.

Key Responsibilities:
Architect and Build Data Engineering Infrastructure: Design, develop, and maintain data engineering infrastructure on AWS, using services like ECS, S3, Glue, and others.
Implement Data Orchestration: Build and manage data orchestration workflows using Apache Airflow to schedule, monitor, and optimize data processing tasks.
Data Transformation: Improve the functionality of dbt (data build tool) to integrate into our cloud data platform.
Metadata-Driven Design : Implement and advocate for metadata-driven design principles to enhance data lineage, documentation, and data governance.
Optimize Performance : Continuously supervise and optimize data pipelines for efficiency, scalability, and cost-effectiveness.
Security and Compliance: Ensure data security and compliance with industry standards and company policies, including data encryption, access controls, and auditing.
Collaboration : Collaborate with data scientists, analysts, and other partners to understand data requirements and deliver data solutions that meet their needs.
Documentation : Maintain thorough documentation of data engineering processes, pipelines, and architecture.
Problem Solving: Identify and address data engineering challenges, tackle issues, and propose innovative solutions.
Stay Curren t: Stay up-to-date with industry trends, standard processes, and emerging technologies in data engineering and cloud computing.
Qualifications:

A related technical degree.
Proven experience as a data platform engineer, with a focus on AWS cloud platform.
Strong expertise in Apache Airflow and dbt for data orchestration and transformation.
Proficiency with programming languages like Python, SQL, and familiarity with relevant SDKs.
Experience with metadata-driven design approaches and data modeling.
Deep knowledge of AWS services such as EC2, S3, Glue, and IAM.
Deep knowledge of Infrastructure as Code (IaC), Terraform preferred.
Understanding of data governance, security, and compliance principles.
Excellent problem-solving skills and the ability to work collaboratively in a team.
Strong communication skills to effectively interact with multi-functional teams.
AWS certifications (e.g., AWS Certified Data Analytics, AWS Certified DevOps Engineer) are a plus.

LI-Y

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .

Posting Statement

At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .

Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce . ﻿

Salesforce welcomes all.

Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.

For California-based roles, the base salary hiring range for this position is $160,000 to $220,000.

Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.",1999,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Staff Software Engineer - Data Platform,"Databricks
","San Francisco, CA",$192K - $260K (Employer est.),4.4,"P-58

At Databricks, we are passionate about enabling data teams to solve the world's toughest problems, from security threat detection to cancer drug development. We do this by building and running the world's best data and AI infrastructure platform, so our customers can focus on the high value challenges that are central to their own missions. Our engineering teams build technical products that fulfill real, important needs in the world. We always push the boundaries of data and AI technology, while simultaneously operating with the resilience, security and scale that is important to making customers successful on our platform.

We develop and operate one of the largest scale software platforms. The fleet consists of millions of virtual machines, generating terabytes of logs and processing exabytes of data per day. At our scale, we observe cloud hardware, network, and operating system faults, and our software must gracefully shield our customers from any of the above.

As a Staff Software Engineer working on the Data Platform team you will help build the Data Intelligence Platform for Databricks. You will architect and run highly-available, large-scale, multi-geo data pipelines for analyzing product telemetry and logs, and using it to guide business decisions. You will do this using the latest, bleeding-edge Databricks product and other tools in the data ecosystem - the team also functions as a large, production, in-house customer that dog foods Databricks and guides the future direction of the product.

The impact you will have:

Design and run the cross-company Data Intelligence Platform, which contains every business and product metric used to run Databricks. You’ll play a key role in developing the right balance of data protections and ease of shareability for the Data Intelligence Platform as we transition to a public company.
Develop tooling and infrastructure to efficiently manage and run Databricks on Databricks at scale, across multiple clouds, geographies and deployment types. This includes CI/CD processes, test frameworks for pipelines and data quality, and infrastructure-as-code tooling.
Design and run the Databricks metrics store that enables all business units and engineering teams to bring their detailed metrics into a common platform for sharing and aggregation, with high quality, introspection ability and query performance.
Design the base ETL framework used by all pipelines developed at the company.
Partner with our engineering teams to provide leadership in developing the long-term vision and requirements for the Databricks product.
Build reliable data pipelines and solve data problems using Databricks, our partner’s products and other OSS tools. Provide early feedback on the design and operations of these products.
Establish conventions and create new APIs for telemetry, debug, feature and audit event log data, and evolve them as the product and underlying services change.
Represent Databricks at academic and industrial conferences & events.

What we look for:

BS (or higher degree) in Computer Science, or a related field
Experience providing technical leadership on large projects similar to the ones described above - ETL frameworks, metrics stores, infrastructure management, data security.
Experience building, shipping and operating reliable multi-geo data pipelines at scale.
Experience working with and operating workflow or orchestration frameworks, including open source tools like Airflow and DBT or commercial enterprise tools.
Experience with large-scale messaging systems like Kafka or RabbitMQ or commercial systems.
Excellent cross-functional and communication skills, consensus builder.
Passion for data engineering and for enabling others by making their data easier to access.

Benefits

Comprehensive health coverage including medical, dental, and vision
401(k) Plan
Equity awards

Flexible time off
Paid parental leave
Family Planning
Gym reimbursement
Annual personal development fund
Employee Assistance Program (EAP)

Pay Range Transparency

Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.


Local Pay Range
$192,000—$260,000 USD

About Databricks

Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.

Our Commitment to Diversity and Inclusion

At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.

Compliance

If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.",2013,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
"Staff Software Engineer, Data Integration","Nuna
","San Francisco, CA",$165K - $230K (Employer est.),2.9,"At Nuna, our mission is to make high-quality healthcare affordable and accessible for everyone. We are dedicated to tackling one of our nation's biggest problems with ingenuity, creativity, and a keen moral compass.

Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.

Nuna partners with healthcare payers, including government agencies and health plans, to turn data into learnings and information into meaning.

YOUR TEAM

We build technology to enable users (from data scientists to analysts to policy-makers) to understand healthcare data while ensuring its integrity, security and privacy. Our work runs the gamut from joining streams of messy real-world data to building queryable data warehouses to constructing visualizations and dashboards that provide actionable insight. We build systems that are auditable, automated, an accurate representation of the underlying data, and, most importantly, responsive to our end users' needs. We strive for a creative, collaborative engineering environment that implements best practices of peer review, readability, maintainability, and security of the code base and infrastructure.

The Nuna Integration team is responsible for developing the automation platform that ingests customer and third-party data into the Nuna value-based care cloud. This role primarily focuses on backend software development. We work closely with health data experts to combine engineering excellence with healthcare expertise, addressing the diverse data needs of our customers. Our tasks include integrating large datasets and orchestrating various processes. We measure the success of our products by their ability to improve healthcare and reduce costs.

YOUR OPPORTUNITIES

In this role, you will play a pivotal role in shaping and executing our overall architecture and strategy. You will have the opportunity to work with cutting-edge technologies such as generative AI and collaborate with a highly skilled team of engineers and health data experts. Your work will directly impact our ability to acquire, transform, and deliver high-quality data to drive critical business decisions.

Your responsibilities will include:

Architect and Develop Data Ingestion Solutions: Design, develop, and maintain robust and scalable data ingestion pipelines that efficiently collect data from various sources, ensuring data quality and reliability
Data Curation and Transformation: Transform and curate raw data into structured and usable formats. Implement data validation, cleaning, and enrichment code to maintain data integrity.
Performance Optimization: Continuously optimize data ingestion and curation pipelines for speed, efficiency, and scalability
Collaboration: Collaborate with cross-functional teams including data scientists, data analysts, and domain experts to understand their requirements and deliver actionable insights
Quality Assurance: Implement best practices for quality monitoring, validation, and error handling to ensure data accuracy and reliability
Documentation: Maintain comprehensive documentation for data ingestion and curation processes, making it easy for team members to understand and use the pipelines
Mentorship: Provide technical leadership and mentorship to junior engineers, fostering their growth and development
Stay Current: Keep abreast of emerging technologies and industry best practices in data engineering and data management
QUALIFICATIONS
Required Qualifications
Bachelor's or Master's degree in Computer Science, Engineering, or related field
8 years of experience in software engineering with a focus on backend software development
Proficiency in programming languages such as Python, Javascript, Typescript, Go or Java
Deep understanding of data storage and retrieval technologies in both relational and NoSQL databases
Excellent problem-solving skills and a passion for delivering high-quality data solutions
Ability to diagram, articulate, and document data science and engineering concepts
Strong communication and collaboration skills
Experience with cloud technologies in AWS or GCP as well as container systems such as Docker or Kubernetes
Preferred Qualifications
Experience with data processing frameworks and tools, e.g. Apache Spark or similar
Experience with data modeling, ETL processes, and data warehousing.
Familiarity with orchestration tools such as Airflow or Prefect
Experience with Great Expectations library

We take into account an individual's qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company's equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $165,000 to $230,000. The actual offer will be at the company's sole discretion and determined by relevant business considerations, including the final candidate's qualifications, years of experience, and skillset.

Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.",2010,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,201 to 500 Employees,Company - Private,False
Staff Data Engineer,"Linktree
","San Francisco, CA",$175K - $225K (Employer est.),3.2,"The Role


Linktree’s Data Engineering team is at the forefront of transforming the way Linktree leverages data, working closely with the insights, data platform product and marketing teams to become truly data driven.


As a Staff Data Engineer at Linktree, you will be the driving force behind scaling how data is consumed at Linktree. Not only will you be modelling some of our most important data sets to gain insights, such as the data that helps us understand the driving factors behind the success of our product or our revenue, we take self-service one step further. You will also build the platform that can be used by Data Analysts, Marketers, Engineers and anyone else who is interested to model their own data to fit their specific needs and not be dependent on a data team.


This is your opportunity to make an impact at Linktree and push the boundaries of what is possible with data self-service!

Location Expectations: Hybrid. We're growing our team in LA and the Bay Area, and plan to have offices in both locations. We expect team members to come into their respective office 2x/week.

What You Will Do

Build the platform that allows data analysts, product managers, marketers and other heavy data users to model their own data as well as making that data available in tools of their choosing, such as product analytics tools, BI tools, an experimentation platform or our CRM system.
Continue leading the transformation to make data a first-class citizen in software development at Linktree. This includes defining standards and providing guidance to product teams who emit the vast majority of our data.
Build and maintaining robust, efficient and integrated data models. We don’t believe that Analytics Engineers should be painfully cleaning up after others and deal with bad data all day long, if you are faced with a “garbage in, garbage out” situation, you will work with the engineers in our product teams to come up with a better way to emit the raw data.
You will also provide support to other data users including peer-reviews, training and acting as a data modeling/SQL/dbt SME across various business initiatives.

What We Are Looking For

A platform mindset. Data teams main focus is not to do repetitive data transformation and integration jobs for others. The team builds the infrastructure and tools that allows Linktree to perform these tasks at scale by enabling all teams to perform data-related jobs themselves.
You understand data-driven product development and have experience with the typical tools used by high-performing product teams, such product analytics, experimentation, but also general purpose BI tools.
Experience in data modeling with the ability to translate business requirements to fit for purpose data products for critical use-cases (reporting to the board, understanding key drivers of product success).
Experience operating at scale. You have worked on data systems that power a product that serves hundreds of millions of active users.
Proficient in SQL and experience with working on cloud-based warehouses (experience in Snowflake is a bonus), as well as working with DBT.


Linktree is committed to providing a competitive compensation package. Our cash compensation amount for this role is targeted at $175,000-$225,000 in the San Francisco Bay or Los Angeles area. Final offer amounts are determined by multiple factors including candidate expertise, the scope of role and level, and may vary from the amounts listed above.

P.S. If you don’t tick every box in this ad, please don’t rule yourself out.

Where and How We Work

We are a global and diverse group offering a truly flexible and family friendly work environment. Kids, pets, and the occasional delivery person are all actively encouraged to appear on our Zoom screens. All of us at Linktree work either fully remote or a hybrid ""remote, but in-office sometimes"" approach.

We currently have offices in Melbourne, Sydney and LA, but our team is spread across Australia, United States, and New Zealand. As our team approaches 200 people, our company will be 10x the size we were in 2020.

We offer autonomy and flexibility in how you structure your days and weeks. There will be the need for some collaboration outside of a ""normal"" 9-5 being a global company, but we aim to work asynchronously where possible.

Our Culture and Benefits

Linktree's company culture and values are based around collaboration, diversity, inclusion, and flexibility. Those are all nice words but to give you some more specific examples:

We recognize that our team are individually unique and have designed our benefits with this in mind. Each person has an annual allowance to use on things like (but not limited to) fitness memberships, development courses, childcare, travel, charitable donations, pet insurance, home office set up - the choice is yours!
We provide top-flight medical, dental, vision, disability and life insurance - we cover 100% of your monthly premiums (and 80% for your dependents).
401k matching up to 6%.
Employee Stock Option Program - we want each and every employee to share in the company’s success as we go further together.
To learn more about our benefits, including our parental leave program, volunteering leave, DE&I initiatives, and more, !

Our Story

We're on a mission to empower anyone to curate and grow their digital universe. We created the ""link in bio"" category and are trusted by some of the world's biggest brands and celebrities including TikTok, The UN Environmental Program, The White House, F1, Manchester United, Selena Gomez, Alicia Keys, and Dwayne “The Rock” Johnson. With a flexible work environment and a team spread across multiple time zones, we offer autonomy and flexibility. Join us in empowering people to control their online presence!

At Linktree, we celebrate and support everyone’s perspective and background, and we’re proud to be an equal opportunity workplace. We aim to foster a diverse and inclusive environment where all team members have a sense of belonging, because we believe in going further together. Linktree welcomes all people regardless of sex, gender identity, race, ethnicity, disability, pregnancy, age, or other lived experience. If you require accommodations to fully participate in our opportunities, please don't hesitate to reach us at recruiting@linktr.ee – your needs are important to us.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
"Senior Software Engineer, Data Platform (Contract)","SoFi
","San Francisco, CA",$143K - $192K (Glassdoor est.),3.7,"Employee Applicant Privacy Notice

Who we are:

Shape a brighter financial future with us.

Together with our members, we're changing the way people think about and interact with personal finance.

We're a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we're at the forefront. We're proud to come to work every day knowing that what we do has a direct impact on people's lives, with our core values guiding us every step of the way. Join us to invest in yourself, your career, and the financial world.

Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.

1 year contract to start.

The Role:

SoFi runs on data! We are seeking a highly motivated Senior Software Engineer to join our Data Platform team. As a Senior Software Engineer, you will work alongside our experienced team of data engineers and product managers to develop and maintain our cutting-edge data handling platform using Snowflake, dbt, Sagemaker, and Airflow. In this role you will be contributing to the long-term success of SoFi's data vision by building out distributed systems and scalable data platforms.

As a Senior engineer on the Data Platform team at SoFi, you'll be tasked with building critical components and features. You will implement battle-tested patterns and interfaces, squash bugs, refactor code and continually grow as an engineer. The ideal candidate has a strong software engineering background and problem-solving ability along with cloud computing (AWS) and data engineering skill set with prior experience on technologies such as Snowflake, Airflow, dbt, Kafka, Spark, Dask, Python, and Tableau. Additionally, you will demonstrate SoFi's core values by honing your skills as an effective communicator, showing personal responsibility, and setting ambitious goals. If you like working on problems with tangible and lasting impact, we would love to have you in our team!




What You'll Do:

Collaborate with cross-functional teams to understand data requirements and design scalable data solutions.
Write high-quality, efficient, and scalable code to implement new features and functionality on the data platform.
Participate in code reviews and provide feedback to other team members to ensure code quality and maintainability.
Work with product managers and other stakeholders to understand user requirements and implement solutions that meet their needs.
Participate in team meetings and contribute to discussions on technology, design, and implementation.
Keep up-to-date with the latest developments in data engineering, and cloud technologies.
Develop and optimize data pipelines using dbt and Airflow to ensure efficient data processing and data quality checks.
Architect and implement data governance and metadata management solutions to maintain data integrity and compliance.
Build a system to identify data quality issues and implement solutions to address them effectively.
Utilize your proficiency in Python to develop custom scripts and tools to enhance data operations and automation.
Mentor and guide junior team members, providing technical expertise and fostering a culture of continuous learning.



What You'll Need:




Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
Minimum of 5 years of experience as a Software Engineer, with a focus on data engineering and data platform development.
Extensive hands-on experience with Snowflake, AWS services, dbt, and Airflow.
Strong understanding of data quality best practices and data governance principles.
Proven track record in metadata management and data infrastructure design.
Proficiency in Python for data manipulation, scripting, and automation.
Excellent problem-solving skills and the ability to thrive in a fast-paced, collaborative environment.
Strong communication skills to effectively work with diverse stakeholders and present technical concepts.



Nice to Have:

Interest in personal finance



**Please note the following benefits only apply to full-time employees**




#LI-CA1

#LI-Remote

Compensation and Benefits
The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate's experience, skills, and location.
To view all of our comprehensive and competitive benefits, visit our Benefits at SoFi page!
SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
New York applicants: Notice of Employee Rights
SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.
Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.
Internal Employees
If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.",2011,Banking & Lending,Unknown / Non-Applicable,Financial Services,1001 to 5000 Employees,Company - Public,False
"Staff Software Engineer, AI/ML and Data Infrastructure","Chan Zuckerberg Initiative
","Redwood City, CA",$241K - $362K (Employer est.),3.7,"We're on an ambitious mission to solve some of society's toughest challenges — from eradicating disease to improving education and addressing the needs of our local communities. Join us to build a better future for everyone!

Learn more about our work modes, benefits, and interview process at www.chanzuckerberg.com/careers.

We're on an ambitious mission to solve some of society's toughest challenges — from eradicating disease to improving education and addressing the needs of our local communities. Join us to build a better future for everyone!

Learn more about our work modes, benefits, and interview process at www.chanzuckerberg.com/careers.

The Team

By pairing engineers with leaders in our science and education teams, we can bring AI/ML technology to the table in new ways to help drive solutions. We are uniquely positioned to design, build, and scale software systems to help educators, scientists, and policy experts better address the myriad challenges they face. Our technology team is already helping schools bring personalized learning tools to teachers and schools across the country. We are also supporting scientists around the world as they develop a comprehensive reference atlas of all cells in the human body, and are developing the capacity to apply state-of-the-art methods in artificial intelligence and machine learning to solve important problems in the biomedical sciences.

The AI/ML and Data Engineering Infrastructure organization works on building shared tools and platforms to be used across all of the Chan Zuckerberg Initiative, partnering and supporting the work of a wide range of Research Scientists, Data Scientists, AI Research Scientists, as well as a broad range of Engineers focusing on Education and Science domain problems. Members of the shared infrastructure engineering team have an impact on all of CZI's initiatives by enabling the technology solutions used by other engineering teams at CZI to scale. A person in this role will build these technology solutions and help to cultivate a culture of shared best practices and knowledge around core engineering.

What You'll Do
Provide technical leadership in designing and building efficient, stable, performant, scalable and secure AI/ML and Data engineering solutions.
Actively take a hands-on approach to the architecture and build of our AI/ML compute infrastructure tooling - both as a Principal Engineer and System Architect. This includes design and coding across the platform for everything from streaming data systems based on Apache Kafka, our complex multi-modal Data Hub metadata management system we are building, and the containerized infrastructure we are building using Kubernetes in support of our various heterogeneous and distributed AI/ML environments.
Provide insight and guidance for overall systems integration and architecture approaches for our containerized AI/ML platform components.
Drive the technical design for how we extend our Cloud based AI/ML platform to successfully encompass our current Cloud based Databricks Ray on Spark, Weaviate Vector Databases, and Containerized Ray on Kubernetes with a workflow that extends to running pre-training, AI training, fine tuning, and inference in the hosted Cloud GPU Compute services.
Provide technical leadership for the AI/ML and Data Engineering team in delivering and integrating our AI.ML platform with the various research teams across CZI, CZIF, and our CZ Biohub Network partners, as well as evangelize and educate our partners on best AI lifecycle practices for making use of our advanced AI platform tooling and Dataset curation systems as we collaborate with them.
Guide cross-functional integration and approach to making optimal use of our shared infrastructure in empowering our AI/ML efforts with world class GPU Compute Cluster and other compute environments such as our AWS based services.
Dive into deep stack complex coding challenges that you and the team will undertake in various areas such as scaling data engineering applications in support of LLM pre-training and in optimizing LLM code and workflows in support of AI tuning, training, and inference.
Provide expertise across multiple engineering disciplines - Data Infrastructure, AI Compute Platform Infrastructure, Security Engineering, Data Governance, System/Data Compliance programs (SOC2 for example), and Scalable Containerization Platforms.
What You'll Bring
BS or MS degree in Computer Science or a related technical discipline or equivalent experience
8+ years of relevant coding experience
8+ years of systems Architecture and Design experience, with a broad range of experience across Data, AI/ML, Core Infrastructure, and Security Engineering
Proficiency with Amazon Web Services (AWS), Google Cloud Platform (GCP), or Microsoft Azure, and experience with On-Prem and Colocation Service hosting environments
Shown ability with a scripting language such as Python, PHP, or Ruby
Proven coding ability with a systems language such as C, C++, C#, Go, Rust, Java, or Scala
AI/ML Platform Operations experience in an environment with challenging data and systems platform challenges - including large scale Kafka and Spark deployments (or their coralaries such as Pulsar, Flink, and/or Ray) as well as Workflow scheduling tools such as Apache Airflow, Dagster, or Apache Beam
Scaling containerized applications on Kubernetes, including expertise with creating custom containers using secure AMIs and continuous deployment systems that integrate with Kubernetes.
Working knowledge of Nvidia CUDA and AI/ML custom libraries.
Knowledge of Linux systems optimization and administration
Deep understanding of Data Engineering, Data Governance, Data Infrastructure, and AI/ML execution platforms.
HPC and Slurm experience a strong nice to have

The Redwood City, CA base pay range for this role is $241,000.00 - $362,000.00. New hires are typically hired into the lower portion of the range, enabling employee growth in the range over time. Actual placement in range is based on job-related skills and experience, as evaluated throughout the interview process. Pay ranges outside Redwood City are adjusted based on cost of labor in each respective geographical market. Your recruiter can share more about the specific pay range for your location during the hiring process.

#LI-Hybrid

Onsite work mode is site-based in our office at our HQ in Redwood City, CA.
Flex work mode is open to a hybrid approach, but not open to be fully remote.
Remote work mode is eligible for all three modes (Remote, Flex, or Onsite) available to you at CZI.

About Us

The Chan Zuckerberg Initiative was founded in 2015 to help solve some of society's toughest challenges — from eradicating disease and improving education, to addressing the needs of our local communities. Our mission is to build a more inclusive, just, and healthy future for everyone.

CZI is committed to creating a more inclusive and diverse workplace. We welcome interest from individuals of all backgrounds and levels of experience who share our mission. If you're interested in this role but your previous experience doesn't perfectly align with each qualification in the job description, we still encourage you to apply as you may be the perfect fit for this or another role!",2015,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,201 to 500 Employees,Company - Private,False
"Backend Software Engineer, Data Platform","Zoox
","Foster City, CA",$164K - $234K (Employer est.),3.9,"The Data team leverages data from our autonomous vehicles and operations to determine autonomy and service readiness. We provide the foundation for strategic decision-making at Zoox. You will develop and implement the next generation of our data pipeline to ensure visibility into our business as we scale toward the launch of an autonomous mobility service. You will define the system and build the pipeline to enable Zoox to develop and scale with a data-first culture.

You will join a diverse, experienced team with rapidly growing scope and responsibility while also having access to one of the most unique data sets in the autonomous vehicle industry. Hence, we are seeking all skill levels to grow with the team.
Responsibilities
Design, build, and maintain a platform used by Zoox teams to build large-scale data pipelines
Drive platform efficiency improvements to reduce latency and improve data freshness
Support data-driven engineering decisions through improved observability and key metrics
Partner with engineering teams to support long-term scaling of their data pipelines
Requirements
4+ years of software engineering experience
Strong fluency with Python, C/C++, or Java
Strong understanding of distributed systems
Strong written and verbal communication skills
Good experience building and maintaining data intensive production systems at scale
Good experience with relational databases and non-relational (NoSQL) databases
Good experience with infrastructure-as-code tools (e.g. Terraform, …)
Experience with large scale streaming platforms (e.g. Kafka, Kinesis) and storage engines (e.g. HDFS, HBase, …)
Bonus Qualifications
Experience with data warehouse platforms (e.g. Redshift, BigQuery, Databricks, …)
Experience building scalable and maintainable data pipelines
Experience with AWS ECS and/or Kubernetes
Experience with a workflow manager such as Airflow
Experience with large scale processing frameworks (e.g. Spark, Hadoop, …)
Compensation
There are three major components to compensation for this position: salary, Amazon Restricted Stock Units (RSUs), and Zoox Stock Appreciation Rights. The salary will range from $164,000 to $234,000. A sign-on bonus may be part of a compensation package. Compensation will vary based on geographic location, job-related knowledge, skills, and experience.

Zoox also offers a comprehensive package of benefits including paid time off (e.g. sick leave, vacation, bereavement), unpaid time off, Zoox Stock Appreciation Rights, Amazon RSUs, health insurance, long-term care insurance, long-term and short-term disability insurance, and life insurance.

About Zoox
Zoox is developing the first ground-up, fully autonomous vehicle fleet and the supporting ecosystem required to bring this technology to market. Sitting at the intersection of robotics, machine learning, and design, Zoox aims to provide the next generation of mobility-as-a-service in urban environments. We’re looking for top talent that shares our passion and wants to be part of a fast-moving and highly execution-oriented team.

Follow us on LinkedIn

A Final Note:
You do not need to match every listed expectation to apply for this position. Here at Zoox, we know that diverse perspectives foster the innovation we need to be successful, and we are committed to building a team that encompasses a variety of backgrounds, experiences, and skills.",2014,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Senior Staff Data Platform Engineer,"Crunchbase
",California,-1,3.8,"About Crunchbase

Crunchbase helps over 75 million people around the world connect with the companies and people that matter. Powered by best-in-class proprietary data, Crunchbase is democratizing access to opportunities so salespeople, entrepreneurs, investors, job seekers, and others can accelerate innovation for a better future. We’re proud to build intelligent products that shape how companies and people connect and enable them to communicate in a more meaningful way.

We are committed to a positive, diverse, and inclusive culture by hiring for potential, focused on the inclusion of people who have different ways of thinking, different viewpoints, different backgrounds, and different skill sets. We value a transparent and open culture that positively impacts our teams and our products.

Crunchbase has a remote-first approach, and is open to hiring in residents of these states:
California, Colorado, Illinois, Florida, Georgia, Massachusetts, Nevada, New Jersey, New York, North Carolina, Oregon, Pennsylvania, South Carolina, Texas, Virginia, and Washington

Our inclusive remote-first culture, generous PTO policies, competitive pay, and employee wellness benefits set us apart!

Engineering at Crunchbase

The Crunchbase engineering team is a dynamic, fast paced team that is committed to quickly delivering features, evaluating their performance, and iterating towards the product vision shared by the company.
We are organized in vertical teams that include cross-functional engineers as well as functional guilds aimed at working tightly with the product team to deliver high standards code while iterating quickly on features. We value open and honest communication, and strive to create an environment where opinions and views can be shared and considered in an effort to reach the best decision.

Our data organization is a dynamic and evolving force, currently comprising four teams with plans to expand by two more teams this year. The structure of each team is meticulously designed to empower them to seamlessly deliver end-to-end features into production. These interdisciplinary teams consist of data engineers, data scientists, machine learning engineers (MLEs), and front-end developers where necessary. The versatility of our teams allows for adaptability in mission, enabling them to align closely with company strategy and execute on the ever-evolving roadmap and strategic focus.

What You’ll Do:
As a vital member of Crunchbase’s technical leadership, you will not only be part of shaping but actively lead and direct the future of the data organization, influencing key technological decisions to align with and support our evolving business needs. Your role will involve architecting and constructing robust systems dedicated to meeting the diverse data requirements at Crunchbase. This includes providing crucial support to our products and internal stakeholders, such as data scientists and analytics teams. Collaboration will be a cornerstone of your responsibilities as you work closely with other engineers and product stakeholders to define and execute our comprehensive data roadmap. Your leadership will extend to ensuring the currency and relevance of our tools and technologies, actively guiding the Data Engineering Guild to adopt and uphold standards that contribute to the continual advancement of our data capabilities.
What We’re Looking For:
You have 6+ years of industry experience, including 2+ years of technical leadership experience.
You have a solid understanding of computer science and software engineering fundamentals.
You are a Python expert.
You are proficient with SQL
You may have experience with Kubernetes Kafka, data warehouse, or Airflow. If not, you are enthusiastic about learning.
You have experience in building data pipelines, or supporting machine learning algorithms in production.
You keep up to date with current trends and technologies. You are interested in the state of the art development in data engineering and machine learning ops.
You have excellent verbal and written communication skills.
You care about agile software, cross teams collaborations and data driven development and evaluation
What Crunchbase Offers:
Competitive salary and equity
Remote first policy
Generous Reimbursement policy for learning and development activities
Monthly fitness / mental health reimbursement
14 weeks of fully-paid time off for new parents
Flexible Paid Time Off (PTO)
Volunteering Paid Time Off
Incredible medical, vision and dental benefits for employees and their families
Free One Medical Group membership for employees and their families
401(k) and Roth plans, and free annual financial adviser check-in
Monthly internet stipend
Work from home allowance to purchase furniture for your work from home space
Annual carbon offset
Matching charity contributions for our Townhall awards
A team of creative, transparent entrepreneurs driven to accomplish our mission
At Crunchbase, we value team members who are passionate and enthusiastic about what we're building here. We believe there is no ""perfect"" candidate, and want to encourage applying even if all the requirements listed aren’t met. If you're passionate about Crunchbase and looking to learn and grow, then we look forward to reviewing your application!
Crunchbase does not discriminate on the basis of race, creed, color, ethnicity, national origin, religion, sex, sexual orientation, gender expression, age, height, weight, veteran status, military obligations, or marital status. We will consider for employment qualified applicants with arrest and conviction records. Every day our team is honored to work with entrepreneurs and innovators from every corner of the globe, and we aim to build a team that reflects the diversity of our customers. Each individual at Crunchbase brings their own perspectives, work experiences, lifestyles, and cultures with them, and we believe that a more diverse team creates more innovative products, provides a better service to its customers, and helps us all grow and learn as individuals.",2007,Internet & Web Services,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
"Principal IT Engineer Applications - Bioinformatics, Genomic Data, NGS Data","Kaiser Permanente
","San Jose, CA",$148K - $192K (Employer est.),3.9,"Job Summary:

This job is for a bioinformatics expert working in genomic testing lab


Collaborate with cross-functional teams, including operations, research and development (R&D), laboratory and hospital Information Technology (IT) groups, and genetic counselors (GCs), among others, to ensure the successful execution of bioinformatics projects.


Develop and implement bioinformatics algorithms, tools, and pipelines to analyze large and complex data sets generated from our NGS (Miseq, Hiseq2500, Novaseq6000) based hereditary panel, WES, and somatic oncology sequence tests.


Stay up to date with the latest advances in bioinformatics and genomics and apply these advancements to our products and services.


Manage and maintain bioinformatics software, tools, and pipelines, ensuring they meet the highest standards of quality and performance.


Ensure compliance with relevant state and federal regulatory requirements


This senior level employee is primarily responsible for translating business requirements and functional specifications into software solutions, for contributing to and leveraging the technical direction for the development of integrated business and/or enterprise application solutions, and for serving as a technical expert for project teams while providing consultation to help ensure new and existing software solutions are developed.

Essential Responsibilities:


Conducts or oversees business-specific projects by applying deep expertise in subject area; promoting adherence to all procedures and policies; developing work plans to meet business priorities and deadlines; determining and carrying out processes and methodologies; coordinating and delegating resources to accomplish organizational goals; partnering internally and externally to make effective business decisions; solving complex problems; escalating issues or risks, as appropriate; monitoring progress and results; recognizing and capitalizing on improvement opportunities; evaluating recommendations made; and influencing the completion of project tasks by others.


Practices self-leadership and promotes learning in others by building relationships with cross-functional stakeholders; communicating information and providing advice to drive projects forward; influencing team members within assigned unit; listening and responding to, seeking, and addressing performance feedback; adapting to competing demands and new responsibilities; providing feedback to others, including upward feedback to leadership and mentoring junior team members; creating and executing plans to capitalize on strengths and improve opportunity areas; and adapting to and learning from change, difficulties, and feedback.


As part of the IT Engineering job family, this position is responsible for leveraging DEVOPS, and both Waterfall and Agile practices, to design, develop, and deliver resilient, secure, multi-channel, high-volume, high-transaction, on/off-premise, cloud-based solutions.


Provides insight into recommendations for technical solutions that meet design and functional needs.


Translates business requirements and functional specifications into physical program designs, code modules, stable application systems, and software solutions by partnering with Business Analysts and other team members to understand business needs and functional specifications.


Ensures appropriate translation of business requirements and functional specifications into physical program designs, code modules, stable application systems, and software solutions by partnering with Business Analysts and other team members to understand business needs and functional specifications.


Serves as an expert for innovative technical solutions that meet design and functional needs.


Facilitates and serves as a technical expert for project teams throughout the release schedule of business and enterprise software solutions.


Builds and maintains trusting relationships with internal customers, third party vendors, and senior management to ensure the alignment, buy-in, and support of diverse project stakeholders.


Recommends complex technical solutions that meet design and functional needs.


Collaborates with architects and/or software consultants to ensure functional specifications are converted into flexible, scalable, and maintainable solution designs.


Provides expertise and guidance to team members for systems incident responses for complex issues.


Provides implementation and post-implementation triage and support of business software solutions by programming and/or configuring enhancements to new or packaged-based systems and applications.


Reviews and validates technical specifications and documentation.


Identifies specific interfaces, methods, parameters, procedures, and functions to support technical solutions while incorporating architectural designs.


Supports component integration testing (CIT) and user acceptance testing (UAT) for application initiatives by providing triage, attending test team meetings, keeping the QC up-to-date, performing fixes and unit testing, providing insight to testing teams in order to ensure the appropriate depth of test coverage, and supporting the development of proper documentation.


Leads systems incident support and troubleshooting for complex and non-complex issues.


Identifies specific interfaces, methods, parameters, procedures, and functions, as required, to support technical solutions serving as an escalation point for complex or unresolved issues related to requirements translation.


Develops and validates complex testing scenarios to identify application errors and ensure software solutions meet functional specifications.


Participates in all software development lifecycle phases by applying comprehensive understanding of company methodology, policies, standards, and internal and external controls.


Develops, configures, or modifies basic to moderately complex integrated business and/or enterprise application solutions within various computing environments by designing and coding component-based applications using programming languages.


Provides consultation to help ensure new and existing software solutions are developed with insight into industry best practices, strategies, and architectures.


Builds partnerships with IT teams and vendors to ensure written code adheres to company architectural standards, design patterns, and technical specifications.


Leads the development, validation, and execution of testing scenarios to identify application errors and ensure software solutions meet functional specifications.


Leads, mentors, and trains other technical resources to develop software applications.

Minimum Qualifications:


Minimum five (5) years experience working on project(s) involving the implementation of solutions applying development life cycles (e.g., SDLC).


Minimum two (2) years in a technical leadership role with or without direct reports.


Bachelors degree in Computer Science, CIS, or related field and Minimum eight (8) years experience in software development or a related field. Additional equivalent work experience may be substituted for the degree requirement.

Additional Requirements:

PrimaryLocation : California,San Jose,NCAL Regional Genetics Laboratory
HoursPerWeek : 40
Shift : Day
Workdays : Mon, Tue, Wed, Thu, Fri
WorkingHoursStart : 08:00 AM
WorkingHoursEnd : 04:00 PM
Job Schedule : Full-time
Job Type : Standard
Employee Status : Regular
Employee Group/Union Affiliation : NUE-NCAL-09|NUE|Non Union Employee
Job Level : Individual Contributor
Job Category : Information Technology
Department : Regional Genetics Lab - Med Adm Fac Strat Activity - K - 0206
Travel : Yes, 10 % of the Time
Kaiser Permanente is an equal opportunity employer committed to a diverse and inclusive workforce. Applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy), age, sexual orientation, national origin, marital status, parental status, ancestry, disability, gender identity, veteran status, genetic information, other distinguishing characteristics of diversity and inclusion, or any other protected status.",1945,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Nonprofit Organization,False
Sr. Cloud Data Engineer,"Lucid Motors
","Newark, CA",$135K - $171K (Glassdoor est.),3.2,"Leading the future in luxury electric and mobility
At Lucid, we set out to introduce the most captivating, luxury electric vehicles that elevate the human experience and transcend the perceived limitations of space, performance, and intelligence. Vehicles that are intuitive, liberating, and designed for the future of mobility.
We plan to lead in this new era of luxury electric by returning to the fundamentals of great design – where every decision we make is in service of the individual and environment. Because when you are no longer bound by convention, you are free to define your own experience.
Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.

We are looking for a top-notch Python developer with hands-on experience to join our Infrastructure and Cloud team. As a Cloud Developer, you will work within a newly formed team to expand the capabilities of departmental tooling using fault-tolerant and scalable solutions for multiple customers.

You will have a strong background using modern development approaches including Agile and Test-Driven development alongside source control tools such as Git. You will be comfortable with an 'infrastructure as code' philosophy and have worked on delivering solutions via CICD pipelines. You will have a hands-on approach and be able to work from high level architecture to detailed design and administrative tasks as required.

You will implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes by leveraging AWS technologies and big data tools. Collaborate with engineers to help adopt best practices in data system creation, data integrity, test design, analysis, validation, and documentation. Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.


Responsibilities
Develop and deliver fault-tolerant and scalable solutions empowering user self-service.
Contribute code to continue improving across our infrastructure environments with a drive towards automation of everything.
Help to enable innovation through continuous deployment across technology stacks and demonstrate best practices around advanced cloud solutions.
Evaluate new and emerging technologies, services, tools, and multiple vendors for innovative new capabilities, and lead POC of Technologies.
Work closely with the Platform DevOps teams to design and engineer innovative platform solutions.
Support internal teams with migrations of existing applications to the cloud.
Contribute to the improvement of software development processes and methodologies.
Requirements
Bachelor's degree in Computer Science or equivalent. Master's degree preferably.
Demonstrated experience with Python software development.
a) Experience with software testing and at least one testing methodology
b) Experience with scalable web application architecture and engineering concepts such as microservices, REST, and APIs
In-depth knowledge of AWS services such as EC2, S3, RDS, and Lambda
Experience with the AWS CLI, SDKs, and API
Experience in source and version control methodologies and technologies, ideally Git.
Experience with automating tasks with CICD tooling such as Jenkins and AWS Tools.
Experience with Infrastructure as code, ideally Terraform.
Exposure to front-end development ideally using REACT.
Solid grasp of Agile and DevOps principles
Familiarity using Atlassian products such as JIRA & Confluence
Ideally the candidate will have experience of deployment within an AWS enterprise environment.
Salary Range: The compensation range for this position is specific to the locations listed below and is the range Lucid reasonably and in good faith expects to pay for the position taking into account the wide variety of factors that are considered in making compensation decisions, including job-related knowledge; skillset; experience, education and training; certifications; and other relevant business and organizational factors.
California (Bay Area) - $127,000 - $181,500
Additional Compensation and Benefits: Lucid offers a wide range of competitive benefits, including medical, dental, vision, life insurance, disability insurance, vacation, and 401k. The successful candidate may also be eligible to participate in Lucid’s equity program and/or a discretionary annual incentive program, subject to the rules governing such programs. (Cash or equity incentive awards, if any, will depend on various factors, including, without limitation, individual and company performance.)

Lucid maintains your privacy according to its Candidate Privacy Notice. If you are a California resident, please refer to our California Candidate Privacy Notice.



At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.
To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.",2007,Transportation Equipment Manufacturing,Unknown / Non-Applicable,Manufacturing,5001 to 10000 Employees,Company - Public,True
Lead Data Engineer,"GoodRx
","Santa Monica, CA",$202K - $323K (Employer est.),3.7,"GoodRx is America’s healthcare marketplace. Each month, millions of people visit
goodrx.com
to find reliable health information and discounts for their healthcare — and we’ve helped people save $60 billion since 2011. We provide prescription discounts that are accepted at more than 70,000 pharmacies in the U.S., as well as telehealth services including doctor visits and lab tests. Our services have been positively reviewed by Good Morning America, The New York Times, NBC News, AARP, and many others.
Our goal is to help Americans find convenient and affordable healthcare. We offer solutions for consumers, employers, health plans, and anyone else who shares our desire to provide affordable prescriptions to all Americans.
About the Role
GoodRx is looking for extremely smart and innovative data engineers, who are deft at working with a wide variety of languages, such as Python and SQL, a variety of raw data formats, such as parquet and CSV, in a fast-paced and friendly environment. You will collaborate and work with teams across GoodRx to build an outstanding data platform that supports hundreds of data pipelines which move big data accurately and quickly to guide enterprise data decisions.
Responsibilities
Collaborate with product managers, data scientists, data analysts and engineers to define features needed for a data platform
Provide mentorship and technical leadership for a team
Work closely with other engineers to scale infrastructure, improve reliability and efficiency
Improve developer tooling with a focus on reliability and efficiency
Write good technical documentation
Perform large system upgrades and migrations
Maintenance and improvement of multiple CI/CD pipelines
Act as an in-house data expert who makes recommendations regarding standards for code quality and pipeline architecture
Develop, deploy and maintain data processing pipelines using cloud technology such as AWS, Kubernetes, Lambda, Kafka, Airflow, Redshift, S3, Glue, and EMR
Make smart engineering and infra decisions based on data auditing and collaboration
Lead and architect cloud-based data infrastructure solutions to meet stakeholder needs
Skills & Qualifications
8+ years of professional experience in any one of the Cloud providers such as AWS, Azure or GCP
8+ years experience in engineering data pipelines using data technologies (Python, Databricks, pySpark, Kafka) on large scale data sets
Experience building or maintaining a Data Platform that supports multiple engineering teams and processes big data
Ability to quickly learn complex domains and new technologies
Innately curious and organized with the drive to analyze data to identify deliverables, anomalies and gaps and propose solutions to address these findings
Experience designing data models that have been implemented in production
Strong experience in writing complex SQL and ETL development with experience processing large data sets
Familiarity with AWS services (Redshift, RDS, EKS, S3, EMR, Glue, Lambda)
Experience using GitHub, Docker, Terraform, CodeFresh, Jira
Experience contributing to full lifecycle deployments with a focus on quality and scalability
Good to Have
Experience with customer data platform tools such as Segment
Experience contributing to full lifecycle deployments with a focus on testing and quality
Experience with data quality processes, data quality checks, validations, data quality metrics definition and measurement
AWS/Kafka/Databricks or similar certifications
At GoodRx, pay ranges are determined based on work locations and may vary based on where the successful candidate is hired. The pay ranges below are shown as a guideline, and the successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, and other relevant business and organizational factors. These pay zones may be modified in the future. Please contact your recruiter for additional information.
San Francisco Office:
$202,000.00 - $323,000.00
New York and Seattle Offices:
$185,000.00 - $296,000.00
Santa Monica Office:
$168,000.00 - $269,000.00
Other Office Locations:
$151,000.00 - $242,000.00
GoodRx also offers additional compensation programs such as annual cash bonuses and annual equity grants for most positions as well as generous benefits. Our great benefits offerings include medical, dental, and vision insurance, 401(k) with a company match, an ESPP, unlimited vacation, ""Take Care of Yourself"" days, 11 paid holidays, and 72 hours of sick leave. GoodRx also offers additional benefits like mental wellness and financial wellness programs, fertility benefits, supplemental life insurance for you and your dependents, company-paid short-term and long-term disability, and more!
We’re committed to growing and empowering a more inclusive community within our company and industry. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has a seat at the table and the tools, resources, and opportunities to excel.
With that said, research shows that women and other underrepresented groups apply only if they meet 100% of the criteria. GoodRx is committed to leveling the playing field, and we encourage women, people of color, those in the LGBTQ+ communities, and Veterans to apply for positions even if they don’t necessarily check every box outlined in the job description. Please still get in touch - we’d love to connect and see if you could be good for the role!
GoodRx is America's healthcare marketplace. The company offers the most comprehensive and accurate resource for affordable prescription medications in the U.S., gathering pricing information from thousands of pharmacies coast to coast, as well as a telehealth marketplace for online doctor visits and lab tests. Since 2011, Americans with and without health insurance have saved $60 billion using GoodRx and million consumers visit
goodrx.com
each month to find discounts and information related to their healthcare. GoodRx is the #1 most downloaded medical app on the iOS and Android app stores. For more information, visit
www.goodrx.com
.",2011,Biotech & Pharmaceuticals,Unknown / Non-Applicable,Pharmaceutical & Biotechnology,201 to 500 Employees,Company - Public,False
"Senior Software Engineer, Data Engineering","Disney Entertainment & ESPN Technology
","San Francisco, CA",$143K - $191K (Employer est.),3.8,"Disney Streaming is looking for a Senior Software Engineer to join the Targeting Innovation team inside the Media Engineering organization.


The Targeting Innovation team develops automated feedback loops that control traffic shaping for Disney Streaming’s suite of streaming services, including Disney+, Hulu, and more. We balance the needs of our business strategy with the demands of an involving internet to provide the highest possible quality of experience directly to consumers in the form of pristine, error-free streaming media.

As a Senior Software Engineer on this team, you will develop robust data pipelines that calculate and report the quality of experience that our customers receive so that we can continually improve the way we deliver media. There will be opportunities to collaborate with a varied team of data engineers, other software engineers, researchers, product managers and more, as well as to provide leadership by example to other developers on the team and in the organization.

If you enjoy streaming media, are interested in live sports and entertainment, or just want to join a fast-growing team that plays an integral part of the revenue producing arm of a company, then our team is for you.


Technologies we use include Scala, AWS (Lambda, Kinesis, Step Functions, Aurora, many others), Apache Flink, Apache Spark, PostgresQL, Kubernetes and more.


Qualifications

5+ years of experience in a development background with data engineering experience.

You have an excellent understanding of software development fundamentals and architecture, and you aren't dogmatic about technology choices.

You have an interest and some experience in both object-oriented programming and functional programming concepts.

You have experience designing and shipping distributed systems.

You can mentor less experienced developers and help them improve their skills.

You have working knowledge of Scala and associated technologies, like cats-effect or zio or other functional programming languages or libraries.

You have experience with AWS products and services or other cloud providers.

You have an interest in video streaming and internet networking.

Required Qualifications

Bachelor’s degree in computer science-related field or equivalent work experience

About Disney Streaming:

Disney Streaming is responsible for developing and operating The Walt Disney Company’s direct-to-consumer video businesses globally, including Disney+, ESPN+ and Hulu. Our core mission is to deliver global audiences the freedom to access content on their terms across any connected device, time or location. We serve consumers by bringing the world’s most beloved characters, timeless stories, legendary athletes, and epic sporting events to global audiences through best-in-class direct-to-consumer video services. We strive daily to imaginatively challenge convention with innovative technology that gives consumers the freedom to access content on their terms across any connected device, time or location.

About The Walt Disney Company:

The Walt Disney Company, together with its subsidiaries and affiliates, is a leading diversified international family entertainment and media enterprise with the following business segments: media networks, parks and resorts, studio entertainment, consumer products and interactive media. From humble beginnings as a cartoon studio in the 1920s to its preeminent name in the entertainment industry today, Disney proudly continues its legacy of creating world-class stories and experiences for every member of the family. Disney’s stories, characters and experiences reach consumers and guests from every corner of the globe. With operations in more than 40 countries, our employees and cast members work together to create entertainment experiences that are both universally and locally cherished.


#DISNEYTECH


The hiring range for this position in Seattle, WA and in New York City, NY is $142,516 to $191,180 per year; the hiring range for this position in Santa Monica/Burbank/Glendale/L.A., California and in Bristol, Connecticut is $136,038 to $182,490; and the hiring range for this position in San Francisco, California is $148,994 to $199,870 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",1901,Culture & Entertainment,$1 to $5 billion (USD),"Arts, Entertainment & Recreation",10000+ Employees,Subsidiary or Business Segment,False
"Senior Principal Software Engineer, Data Platform","Atlassian
","Mountain View, CA",$153K - $206K (Glassdoor est.),4.1,"Overview:
Working at Atlassian
Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.


Atlassian's mission ""to unleash the potential of every team"" is the guiding light behind what we do. We have developed well-known products such as Jira, Confluence, and Trello that fit into the fabric of teamwork across different types of teams and the processes to help every team succeed. Atlassian helps teams everywhere change the world. Our products are revolutionizing the software industry, and helping teams collaborate and create the magic that provides their best work. Think NASA launching the Rover on Mars or Cochlear gifting those born deaf with the ability to hear, your work directly impacts the products they use to promote humanity.


We're looking for an experienced Senior Architect, who will report into our Head of Engineering - Core Data Services, to provide architectural oversight and technical leadership to our growing Core Data Platform organization. You will bring a wealth of experience in architecting complex cloud scale systems. You will also need to be fairly comfortable working with senior leadership and in navigating cross org challenges. You will be working with the team to define architectural/organizational future states that we can scale to in years 2 and 3. We'll need to make balanced calls that align with our forward-looking vision and current business & technology critical asks. This is a remote position.


Your future team

We're transforming Atlassian and data is at the heart of that. Core Data Platform is responsible for low latency, cost efficient compliant cloud storage and data processing capabilities at scale for services that power our products. Think of Data Abstraction, Streaming, Transformation, Replication, Governance and GraphAPIs.

Qualifications:

Your background:

BS in Computer Science or related technical field or equivalent experience
12+ years of experience developing large scale distributed systems.
4+ years of experience providing architectural oversight and technical leadership.

If you have these skills, even better:

A track record of cross-group/cross-discipline collaboration.
Broad experience architecting, designing, and building large-scale distributed systems.
Broad knowledge and understanding of SaaS, PaaS, IaaS with hands-on experience of one or more public cloud offerings (ideally AWS)
Fluency in any modern object-oriented programming language (e.g., Java, Kotlin, Python, Javascript, go etc.) and in architecture patterns for distributed systems
Deep Experience with Storage and streaming technologies such as Dynamo, S3, Kafka, flink
Ability to drive the long term vision and strategy
Ability to thrive in an ambiguous environment

Compensation

At Atlassian, we strive to design equitable and explainable compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience.


In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:


Zone A: $239,000 - $318,600

Zone B: $215,100 - $286,800

Zone C: $198,400 - $264,500


This role may also be eligible for benefits, bonuses, commissions, and equity. Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter. #LI-Remote


Our perks & benefits
Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more.

Visit go.atlassian.com/perksandbenefits to learn more.

About Atlassian
At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

To learn more about our culture and hiring process, visit go.atlassian.com/crh.",2002,Software Development,Unknown / Non-Applicable,Information Technology,5001 to 10000 Employees,Company - Public,False
Principal Data Engineer,"Walmart
","Sunnyvale, CA",$168K - $252K (Employer est.),3.4,"Position Summary...

What you'll do...

About Team:
The mission of Walmart Display Ads is to connect brand owners and shoppers with relevant display ads. We bring brand awareness and rich product information to shoppers and help brand owners grow their business with advanced targeting and optimization techniques. This is a fast-growing business never lack ing opportunities ! We are looking for an experienced tech lead to spearhead advertising data analytics related to deman d, supply, and overall marketplace healt h. You will be responsible for extracting meaningful insights about campaign performance, marketplace efficiency, and gaps in systems and products , surfacing marketplace health metrics via dashboards , and working with cross-functiona l partners to move the needle in display advertising.

What you will do:



Building data pipelines and dashboards to monitor display ads serving funnel and marketplace health.


Leading analytics for display ads marketplace and presenting findings and recommendations to engineering teams and cross functional partners.
Collaborating with engineering and data science leads to improve data quality, build ing data warehouse, and delivering predictive models for market place insights and anomaly detection.
Bringing data driven culture to the engineering team to assure product and system quality.

What you'll bring :



Bachelor's degree in data science , computer science, statistics, operation research, or related fields
6 years' experience of building data pipelines, extracting signals from noisy data, and establishing metrics for monitoring.
Proficiency in data analysis tools (e.g., as Python, R, SQL) and data visualization tools (e.g., Tableau, Superset, Looker ) .
Analytical thinking and detail-oriented mindset. Familiar with S QL and N on- SQL database s.
String communication skills. Ability to convey complex ideas and findings to non-technical stakeholders .
Knowledge of A/B testing.

Preferred qualifications:



Advanced degree in data science, computer science, statistics, operation research, or related fields
6 + years' experience in programmatic advertising, on-line content distribution, or e-commerce.
Knowledge of optimization, auction, and ML applications.
People management experience is a big plus.

About Walmart Global Tech :
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That is what we do at Walmart Global Tech. We are a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity and those looking for the opportunity to define their career. Here, you can kickstart a distinguished career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work:
We use a hybrid way of working that is primarily in the office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO , multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas, and opinions - while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .

The annual salary range for this position is $168,000.00-$252,000.00

Additional compensation includes annual or quarterly performance incentives.

Additional compensation for certain positions may also include:


Regional Pay Zone (RPZ) (based on location)


Stock equity incentives

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor's degree in Computer Science and 5 years' experience in software engineering or related field. Option 2: 7 years' experience in software engineering or related field. Option 3: Master's degree in Computer Science and 3 years' experience in software engineering or related field.
4 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master's degree in Computer Science or related field and 5 years' experience in software engineering or related field

Primary Location...
840 W CALIFORNIA AVE, SUNNYVALE, CA 94086-4828, United States of America",1962,General Merchandise & Superstores,$10+ billion (USD),Retail & Wholesale,10000+ Employees,Company - Public,False
Software Engineer - Synthetic Data & Annotations,"Applied Intuition
","Mountain View, CA",$65K - $400K (Employer est.),4.0,"About Applied Intuition

Applied Intuition is a vehicle software supplier that accelerates the adoption of safe and intelligent machines worldwide. Founded in 2017, Applied Intuition provides a simulation and validation platform for various industries such as automotive, trucking, construction, and more. 17 of the top 20 global automakers rely on Applied Intuition's solutions to shorten development cycles, deliver high-quality systems, and accelerate the production of modern vehicles with confidence. Applied Intuition is headquartered in Mountain View, CA, with offices in Ann Arbor, MI, Washington, DC, Munich, Stockholm, Seoul, and Tokyo. Learn more at https://applied.co.

About the role

We are looking for a software engineer with expertise in computational geometry, simulation, and machine learning. As a software engineer focused on synthetic data and annotations, you'll build systems to generate labeled data that is suitable for training a variety of machine learning systems. This position will join an existing team of engineers with expertise in computer vision, sensor modeling, rendering, and data infrastructure.

At Applied Intuition, you will:

Design and implement core components of our sensor simulation and data generation pipeline
Develop systems for programmatically generating ground-truth-labeled data from a simulated world
Work with machine learning pipelines to understand and improve synthetic datasets
Work with top autonomy companies to understand and solve unique challenges in perception with synthetic data

We're looking for someone who has:

Strong software engineering skills in Python and C++
Familiarity with Unreal Engine
Competent skills & experience in computational geometry, linear algebra, optics, electro-optics, and physics
Familiarity with synthetic data and its applications in perception systems

Nice to have:

Experience with applying synthetic data to machine learning tasks
Detailed knowledge of game pipelines and Unreal Engine
Hands-on experience with characterization of models for Lidar, Radar, and Camera

The salary range for this position is $65,000 USD to $400,000 USD annually. This salary range is an estimate, and the actual salary may vary based on the Company's compensation practices.

Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.

Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.

Applied Intuition is an equal opportunity employer and federal contractor or subcontractor. Consequently, the parties agree that, as applicable, they will abide by the requirements of 41 CFR 60-1.4(a), 41 CFR 60-300.5(a) and 41 CFR 60-741.5(a) and that these laws are incorporated herein by reference. These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. These regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. The parties also agree that, as applicable, they will abide by the requirements of Executive Order 13496 (29 CFR Part 471, Appendix A to Subpart A), relating to the notice of employee rights under federal labor laws.",2017,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
Senior Software Engineer (Data Platform),"Freeform
","Los Angeles, CA",$140K - $250K (Employer est.),5.0,"SENIOR SOFTWARE ENGINEER (DATA PLATFORM)

Freeform is deploying software-defined, autonomous metal 3D printing factories around the world, bringing the scalability of software to physical production. Our proprietary technology stack leverages advanced sensing, real-time controls, and data-driven learning to produce digitally-verified, flawless parts at unprecedented speed and cost. Our mission is to make the transformative power of 3D printing available to all industries at scale and unlock the future of innovation.

As a Senior Software Engineer at Freeform, you will be responsible for architecting and implementing data pipeline infrastructure to create an advanced telemetry capability on our metal 3D printing systems. You will also develop CI/CD platforms to automate the build process and allow for the seamless deployment of code. As a crucial member of the engineering team, you will be responsible for driving the pace of innovation, maximizing development speed, and maintaining a standard of excellence within the entire engineering team. Ultimately, your solutions will enable the first production-scale, high quality, and fully automated metal 3D printing factory.

Responsibilities:

Architect state-of-the art software for an advanced production-scale metal 3D printing system
Develop software to collect, process, and analyze petabytes of high-rate, in-situ sensor data
Create data processing pipelines to feed the machine learning team with critical print data
Develop software required to implement production automation solutions
Develop, unit test, and deploy functional, scalable, robust, and maintainable software

Basic Qualifications:

5+ years of professional experience in software development
Proficiency writing, deploying, and maintaining production code in an industry-standard language (preferably Rust, Python, or C++)
Experience developing robust data pipeline software

Nice to Have:

Bachelor's or advanced degree in computer science, engineering, mathematics, or related field
10+ years of professional software engineering experience
Experience serving as technical lead throughout the full software development lifecycle, from concept, detailed architectural design, implementation, and testing to documentation, delivery, and maintenance
Experience with Arrow, Parquet, Datafusion, Polars, or Ballista
Experience with gRPC, protobufs, and flatbuffers
Experience with computer vision, image processing, graphics rendering, and/or distributed server systems
Proficient in developing and deploying multi-threaded applications
Experience working with both Windows and Linux operating systems
Experience with big data warehousing solutions and cloud computing is a plus
Creative thinker able to apply first-principles reasoning to solve complex problems
Excellent verbal and written communication skills
Experience developing CI/CD, DevOps, or Build Systems platforms

Location:

We are located in Hawthorne, CA in a 35,000 square foot, state-of-the-art facility featuring large open spaces for team collaboration, R&D, and production, as well as easy access to the 405, 105, and 110 freeways. Our facility is in the heart of Los Angeles' vibrant emerging tech ecosystem alongside many other high growth startups and enterprises.

What We Offer:

We have an inclusive and diverse culture that values collaboration, learning, and making deliberate data-driven decisions.
We offer a unique opportunity to be an early and integral member of a rapidly growing company that is scaling a world-changing technology.
Benefits
Significant stock option packages
100% employer-paid Medical, Dental, and Vision insurance (premium PPO and HMO options)
Life insurance
Traditional and Roth 401(k)
Relocation assistance provided
Paid vacation, sick leave, and company holidays
Generous Paid Parental Leave and extended transition back to work for the birthing parent
Free daily catered lunch and dinner, and fully stocked kitchenette
Casual dress, flexible work hours, and regular catered team building events
Compensation
As a growing company, the salary range is intentionally wide as we determine the most appropriate package for each individual taking into consideration years of experience, educational background, and unique skills and abilities as demonstrated throughout the interview process. Our intent is to offer a salary that is commensurate for the company's current stage of development and allows the employee to grow and develop within a role.
In addition to the significant stock option package, the estimated salary range for this role is $140,000-$250,000, inclusive of all levels/seniority within this discipline.
Freeform is an Equal Opportunity Employer that values diversity; employment with Freeform is governed on the basis of merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,True
Senior Software Engineer - Data Infrastructure,"Applied Intuition
","Mountain View, CA",$65K - $400K (Employer est.),4.0,"About Applied Intuition

Applied Intuition is a vehicle software supplier that accelerates the adoption of safe and intelligent machines worldwide. Founded in 2017, Applied Intuition provides a simulation and validation platform for various industries such as automotive, trucking, construction, and more. 17 of the top 20 global automakers rely on Applied Intuition's solutions to shorten development cycles, deliver high-quality systems, and accelerate the production of modern vehicles with confidence. Applied Intuition is headquartered in Mountain View, CA, with offices in Ann Arbor, MI, Washington, DC, Munich, Stockholm, Seoul, and Tokyo. Learn more at https://applied.co.

About the role

(We are hiring for all levels of experience.)
We are looking for a Senior Data Infrastructure Engineer who is excited about building products that wrangle autonomous vehicle (AV) data to supercharge our customers. You will drive the design and development of data infrastructure across our products and internal tools. At Applied Intuition, we encourage all engineers to take ownership over technical and product decisions, interact closely with users to collect feedback, and contribute to a thoughtful, dynamic team culture.
At Applied Intuition, you will:
Design powerful data pipelines that efficiently process large volumes of AV sensor and telemetry data
Enable product workflows that expose performant query interfaces and offer easy-to-use integration hooks
Build features to tune processing pipeline for fast data ingestion and indexing depending on customer's needs and workloads
Develop and deploy high-quality software using modern tooling and frameworks
Work with products and teams across Applied Intuition
Work with customers across the AV ecosystem to understand their needs and the innards of their data systems

We're looking for someone who has:

Experience with open source data processing frameworks (Spark, RabbitMQ, Kafka, etc.)
Experience with different data lakes or warehouses
Experience with containerization and other modern software development workflows
Ability to take initiative and ownership in a fast-paced environment

Nice to have:

Expertise with multiple modern programming languages (Python, C++, Go, etc.)
Prior work in enterprise software, including on-prem and/or cloud deployments
Prior work in either autonomy or simulation products

The salary range for this position is $65,000 USD to $400,000 USD annually. This salary range is an estimate, and the actual salary may vary based on the Company's compensation practices.

Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.

Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.

Applied Intuition is an equal opportunity employer and federal contractor or subcontractor. Consequently, the parties agree that, as applicable, they will abide by the requirements of 41 CFR 60-1.4(a), 41 CFR 60-300.5(a) and 41 CFR 60-741.5(a) and that these laws are incorporated herein by reference. These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. These regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. The parties also agree that, as applicable, they will abide by the requirements of Executive Order 13496 (29 CFR Part 471, Appendix A to Subpart A), relating to the notice of employee rights under federal labor laws.",2017,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
"Data Engineer, Data Platform - USDS","TikTok
","Mountain View, CA",$137K - $360K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About USDS
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.

U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

Team Introduction
Tiktok's Data Platform Team focuses on challenges in the areas of data infrastructure and data products. The team is in charge of various aspects including Query Engine, Logging and Data Ingestion Infra, Experimentation Platform, as well as Workflow Management Platform. The goal is to support ad-hoc/interactive queries, batch pipelines, logging and ingesting large amounts of realtime data, and supporting A/B testing for all product features launches.

As a data engineer in the data platform team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world that directly supports the TikTok app. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.


Design, build and maintain data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)
Design, implement and maintain reliable, scalable, robust and extensible big data systems that support core products and business
Establish solid design and best engineering practice for engineers as well as non-technical people
Qualifications

Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience
Experience in performing data analysis, data ingestion and ETL(Extraction, Transformation & Loading)
Experience with the Big Data technologies is a plus (Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc)
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at USRC@tiktok.com
Job Information
The base salary range for this position in the selected city is $136800 - $359720 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Sr. Data Engineer,"Fanatics
","Los Angeles, CA",$160K - $200K (Employer est.),3.5,"Company Overview
Fanatics is building a leading global digital sports platform. The company ignites the passions of global sports fans and maximizes the presence and reach for hundreds of sports partners globally by offering innovative products and services across Fanatics Commerce, Fanatics Collectibles, and Fanatics Betting & Gaming, allowing sports fans to Buy, Collect and Bet. Through the Fanatics platform, sports fans can buy licensed fan gear, jerseys, lifestyle and streetwear products, headwear, and hardgoods; collect physical and digital trading cards, sports memorabilia, and other digital assets; and bet as the company builds its Sportsbook and iGaming platform. Fanatics has an established database of over 100 million global sports fans, a global partner network with over 900 sports properties, including major national and international professional sports leagues, teams, players associations, athletes, celebrities, colleges, and college conferences, and over 2,000 retail locations, including its Lids retail business stores.
As a market leader with more than 18,000 employees, and hundreds of partners, suppliers, and vendors worldwide, we take responsibility for driving toward more ethical and sustainable practices. We are committed to building an inclusive Fanatics community, reflecting and representing society at every level of the business, including our employees, vendors, partners and fans. Fanatics is also dedicated to making a positive impact in the communities where we all live, work, and play through strategic philanthropic initiatives.

We are a startup building products to transform the trading card industry. We aren’t a startup in the traditional sense, though. While we are a small team building new products from the ground up, we also have the backing of Fanatics – the world’s largest sports merchandiser with over 900 sports relationships and more than 81 million reachable fans. We have exclusive licensing deals with the MLB, NFL and NBA and the products we build will be used by millions of trading cards fans from day 1. We are out to reinvent the trading card industry, which is a bold and ambitious mission.

Fanatics Collectible’s Data Engineering, Science, and Analytics Team is hiring experienced data engineers. You will be among the founding members of our team. You will help build a world-class data engineering organization with a strong data and software engineering culture. You will also establish, advocate, and execute data strategy and technical capabilities that support the business and enable data-driven decisions. Ideally, you are passionate about the trading card industry, sports, and importantly, data and technology. Our data engineers are required to partner very closely with other engineering and business teams and understand our business needs. You will own high impact technical decisions and lead hiring efforts to help build out a world class data engineering team.
What does this mean as a member of the engineering team?
We are fans-and-collectors-obsessed and product-focused. We work backward from the focus of fans and collectors to drive our technical work and the development of products (physical and digital) that will reach tens of million.
We are agile and move at warp speed. We work hard and are not afraid to try, experiment, and pivot (as needed). We have a lot to do and are looking for folks who will drive projects to completion with a sense of urgency, but not at the expense of quality, scalability, and performance.
We think about scale. The trading card market is massive, and we will be the de facto entry point into the hobby.
We’re pragmatic. We embrace new technologies if they add business value.
We are passionate about trading cards, sports, and data. We take data seriously and work tirelessly to ensure their highest possible quality. We build data infrastructure to enable the seamless flow data from source to impactful actions.
Qualifications:
A computer science or equivalent experience required.
5+ years of experience as a data engineer or software engineer focusing on building data infrastructure, solving complex technical challenges at a large scale, and delivering data products that drive business impact
Experience in architect, develop, deploy, and monitor a new, end-to-end data infrastructure leveraging cloud technologies that ingests data from a wide range of internal and external sources and enables user-friendly consumption of data for data-driven decisions
Experience in designing data architecture for multiple database models such as RDBMS, document, columnar, graph, and key-value data stores
Expertise in both SQL and Python
Proficiency in Java and JavaScript
Proficiency and both SQL and NoSQL database technologies
Well-verse in modern cloud native data tech stacks
Familiar with container tech such as Docker and Kubernetes
Familiar with data and ML orchestration tools
Experience in designing and implementing modern CI/CD pipelines with cloud native tools
Strong computer science fundamentals and data/software engineering hygiene
Excellent communication skills to be an effective bridge among our team, other engineering teams, and business partners/stakeholders
Key Responsibilities include, but not limited to,
Research, architect, develop, deploy, monitor, and maintain an efficient, reliable, and secure cloud data infrastructure to enable data-driven decisions
Collaborate with internal and external tech teams and stakeholders/business partners
Research and integrate 3rd-party vendor data solutions
Help develop, implement, and evolve our data strategy, which will include data governance, data security, and tech roadmap
Establish and participate in on-call technical support
Contribute to data engineering and science team recruitment process
Actively mentor and coach team members on advanced technical methods, advocate best practices, and help others to grow their skill set
Set a high standard for data/software engineering excellence through example
Develop a strong understanding of Fanatics Collectibles and the trading cards industry
The salary range for this position is $160,000-$200,000, which represents base pay only and does not include short-term or long-term incentive compensation. When determining base pay, as part of a final compensation package, we consider several factors such as location, experience, qualifications, and training.

Ensure your Fanatics job offer is legitimate and don’t fall victim to fraud. Fanatics never seeks payment from job applicants. Feel free to ask your recruiter for a phone call or other type of communication for interview, and ensure your communication is coming from a Fanatics or Fanatics Brand email address. For added security, where possible, apply through our company website at www.fanaticsinc.com/careers

Tryouts are open at Fanatics! Our team is passionate, talented, unified, and charged with creating the fan experience of tomorrow. The ball is in your court now.

Fanatics is committed to responsible planning and purchasing (RPP) practices, working with its business partners across its global and multi-layered supply chain, to ensure that planning, sourcing, and purchasing decisions, along with other supporting processes, do not impede or conflict with the fulfillment of Fanatics’ fair labor practices.

NOTICE TO CALIFORNIA RESIDENTS/APPLICANTS: In connection with your application, we collect information that identifies, reasonably relates to or describes you (“Personal Information”). The categories of Personal Information that we collect include your name, government issued identification number(s), email address, mailing address, other contact information, emergency contact information, employment history, educational history, criminal record, and demographic information. We collect and use those categories of Personal Information about you for human resources and other business management purposes, including identifying and evaluating you as a candidate for potential or future employment or other types of positions, recordkeeping in relation to recruiting and hiring, conducting criminal background checks as permitted by law, conducting analytics, and ensuring compliance with applicable legal requirements and Company policies. For additional information on how we collect and use personal information in connection with your job application, review our Candidate Privacy Policy-CA",1996,Internet & Web Services,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Private,True
"Software Engineer - AWS Glue, Data Integration","Amazon Development Center U.S., Inc.
","East Palo Alto, CA",$115K (Employer est.),3.7,"3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Company:
Amazon Web Services (AWS) is the pioneer and recognized leader in Cloud Computing. Our web services provide a platform for IT infrastructure in-the-cloud that is used by hundreds of thousands of developers and businesses around the world. These customers range from start-ups to leading web companies to Global 500 companies.

The Group:
AWS Data Integration group provides rapidly growing, industry acclaimed cloud services in areas of big data platforms to data analytics to operational databases. The group is at the forefront of innovation in these areas producing world-class cloud services such as EMR to Redshift to RDS Aurora and many more.

The Team:
Glue is a serverless platform for Data Analytics, with a focus on Data Analyst/Engineer experience. Our goal is to redefine how Data Analytics is done and make it easy and fast for customers to query their data.

We are looking for strong engineers to be part of building a product from ground up in the space of data analytics.

Top reasons to join our team:

Be catalyst to deliver a truly disruptive product that is growing rapidly
Solve unique and first-order problems in areas of Big Data, Serverless computing, Spark, Distributed Systems and Machine Learning
Influence and build products that will leverage scale of resources to orchestrate data workflows
Be part of big data revolution in cloud
Learn how to build & operate distributed systems at massive scale
About you:

Passionate in building large scale distributed systems
Thrive in culture of ownership, delivery and bias for action
Fast pace environment energizes you to be at your best
Innovate and invent in agile and collaborative environment
Curious and eager to learn to expect more of you and others
Responsibilities:

Translate functional and technical requirements into detailed architecture, design and extensible code
Technically lead a team of smart engineers on complex projects
Be an advocate of industry best-practices to produce reliable, fault-torrent and dependable code
Code and test complex system modules; develop and leverage frameworks to be effective and efficient
Participate in architecture, design and code reviews to maintain our high development standards
Own system architecture, scalability, reliability, and performance
Collaborate and influence other teams to deliver and operate large scale, distributed services in the cloud
Mentor other engineers, defining our challenging technical culture, and helping to build a fast-growing team
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Our team also puts a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here, which is why we aren’t focused on how many hours you spend at work or online. Instead, we’re happy to offer a flexible schedule so you can have a more productive and well-balanced life—both in and outside of work.

We are open to hiring candidates to work out of one of the following locations:

East Palo Alto, CA, USA


3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.",1994,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Staff Software Engineer - Data Platform,"Inclusively
","San Francisco, CA",$214K - $233K (Employer est.),5.0,"Inclusively is partnering with a a voice, video, and text communication service company to hire a Staff Software Engineer - Data Platform.

ABOUT INCLUSIVELY:

Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD). Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability.

The central Data Platform seeks to build a self-service tooling platform to make the petabytes of data at the APP easily accessible for everyone at the company. We build full-stack applications, tooling, and frameworks to improve the productivity of teams, in particular our product, analytics, and machine learning teams. Our tooling covers the end-to-end lifecycle of data from acquisition to consumption. Reporting to the Engineering Manager of Data Products, you will work on strategy that is foundational to the company and product. To learn more about the Company Engineering, read our engineering blog here — including ""How We Create Insights From Trillion Data Points"" that this team is behind!

What you'll be doing

Lead end-to-end development of data tooling and frameworks, using modern technologies such as Big Query, Apache Beam, Airflow, Dagster, dbt, Kubernetes, and Rust.
Ensure tight-knit collaboration with leadership, cross-functional stake-holders and senior engineers across the organization Collaborate with leadership and senior engineers across the team to define the technical vision and build on the technical roadmap for Data Platform.
Work with Data Platform to ensure we have a platform with strong governance that respects our users' privacy throughout.
Care deeply about business outcomes and constraints and keep them in mind as you solve hard, unbounded problems.
Work with other Staff Engineers to make decisions for the organization and engineering function as a whole.
Coach and mentor the next generation of technical leaders at the Company.

What you should have:

7+ years of experience as a Software Engineer.
Empathy for both your internal and external users and seek feedback on your work.
Ability to approach problems with first principles thinking, embrace ambiguity, and enjoy collaborative work on complex solutions.
Experience defining architecture, tooling, and strategy for a large-scale data processing system.
Proactive in staying up-to-date with industry trends and assessing new technologies to enhanse problem solving capabilities.

Bonus Points

Experience working with very high-scale data infrastructure and tooling
Experience with data products on Google Cloud Platform, Kubernetes, or Airflow
Full-stack development or product engineering experience

The US base salary range for this full-time position is $214,000 to $233,000 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits.

Job Type: Full-time

Pay: $214,000.00 - $233,000.00 per year

Experience level:

7 years

Schedule:

Monday to Friday

Work Location: In person",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,False
"Principal Engineer, Data Solutions","Neurocrine Bioscience
","San Diego, CA",$124K - $179K (Employer est.),4.1,"Who We Are:
At Neurocrine Biosciences, we pride ourselves on having a strong, inclusive, and positive culture based on our shared purpose and values. We know what it takes to be great, and we are as passionate about our people as we are about our purpose - to relieve suffering for people with great needs, but few options.
What We Do:
Neurocrine Biosciences is a neuroscience-focused, biopharmaceutical company with a simple purpose: to relieve suffering for people with great needs, but few options. We are dedicated to discovering and developing life-changing treatments for patients with under-addressed neurological, endocrine and psychiatric disorders. The company’s diverse portfolio includes FDA-approved treatments for tardive dyskinesia, Parkinson’s disease, endometriosis* and uterine fibroids*, as well as clinical programs in multiple therapeutic areas. For three decades, we have applied our unique insight into neuroscience and the interconnections between brain and body systems to treat complex conditions. We relentlessly pursue medicines to ease the burden of debilitating diseases and disorders, because you deserve brave science. *in collaboration with AbbVie
About the Role:
Responsible for leading a cross-functional Data & Analytics team to design, develop, operationalize, and socialize the Business Intelligence (BI) strategy, roadmap, and architecture. Partner with our business stakeholders at various levels of the organization to provide Data Engineering & BI solutions and recommendations for high complex BI and analytics use cases. Additional responsibilities include: modeling highly complex, novel analytical problems, providing best in class visualization solutions based on high level of business acumen. Expert at integrating and preparing large, varied datasets and semantics models and analytical solutions. The ideal candidate will enjoy the Data Engineering & Data Platform components of the work with experience using Python and related services on AWS and Azure platforms. Experience with Version Control Systems (VCS) and Continuous Integration and Continuous Deployment (CI/CD) that helps our team better align with new infrastructure resources in IT. We currently use GitHub Enterprise & Terraform.
_
Your Contributions (include, but are not limited to):
Leads cross-functional teams to address highly technical business problems with best-in-class data solutions
Designs and creates end-to-end BI solutions and collaborates with business partners who also contribute to a non-traditional (hub-and-spoke) data warehousing & BI ecosystem
Owns the design, development, and maintenance of data models at all levels—logical, relational, and dimensional—to make data more accessible, consistent, and clear
Responsible for recommending, implementing, administering and maintaining the software and hardware that make up the company’s BI data architecture, including maintaining access to the tool via users, groups and security settings, general tool configuration and settings, monitoring the system performance, and tuning
Manages various database and system environments (from test to production) to ensure solutions meet rigorous development standards
Partners with IT security and infrastructure teams to implement a highly accurate, performant, and secure BI technology stack
Drives Agile delivery and independently manages small projects and tasks with internal and external stakeholders
Monitors, validates, and tests all relevant extract, transform, load (ETL) / extract, load, transform (ELT) processes; establishes baseline metrics to ensure optimal performance
Designs and implements processes and solutions that support effective query performance and quality
Defines rules and processes to separate operational and analytic data structures and ensures data integrity across data & presentation layers
Understands and considers differences between operational and analytical data systems
Creates and updates documentation to support development work, including ETL/ELT source-to-target mappings, code review logs, validation results, execution logs, and profiling results
Creates required documentation of data definitions, content domains, data classes, subject area classification, and conformed dimensions—and make it available to other systems and applications for broad consumption
Recommends data governance framework, data models, taxonomies
Other job-related duties as assigned
Requirements:
Bachelor's Degree in Computer Science, Information Technology or a related field and 6+years in an analytical capacity in conjunction with the development/maintenance of a reporting library, experience using Tableau Software (inclusive of both Tableau and Tableau CRM) or other business intelligence solutions OR
Master's Degree in Computer Science, Information Technology or a related field and 4+ years as noted above
Expert level knowledge of Data Modeling and Business Intelligence Solution development, including translating business requirements into technical requirements and data models
Demonstrated expertise with data flow orchestration
Strong knowledge of Git/GitHub, Jira, and Agile workflows a plus
Expert knowledge in one or more of each of the following technology stacks/competencies: Cloud: AWS, Azure; Integration/Data Engineering: e.g. AWS Glue, Azure Data Factory, Workato; BI: e.g. Power BI, Tableau
Well-versed in data profiling, data manipulation and/or data analysis
Proven success writing complex queries on large data sets from disparate data sources
Strong data warehousing principles and SQL knowledge is preferred
Demonstrated expertise in predictive modeling and machine learning is a preferred
Proven success effectively positioning and conveying the merits of the enterprise platform to customers and prospects
Experience testing, troubleshooting & establishing API connectivity utilizing software documentation and tools such as Postman
Knowledge of UI-based integration solutions using tools such as Power Automate, Workato, etc.
Experience developing code-based integration solutions using languages such as Python
Skilled with data queries, functions and/or procedures using languages such as SQL
Experience developing business intelligence solutions using tools such as Power BI, Tableau
Experience with team-owned software (across integration, business intelligence & data management competencies) & select platforms services in Azure & AWS
Has knowledge of best practices in the functional discipline and familiarity with the broader underlying concepts of related business disciplines
Works to improve tools and processes within functional area
Developing reputation inside the company as it relates to area of expertise
Ability to work as part of and lead multiple teams
Exhibits leadership skill and ability, typically leads lower levels and/or indirect teams
Excellent communications, problem-solving, analytical thinking skills
Sees broader picture, impact on multiple departments/divisions
Ability to meet multiple deadlines across a variety of projects/programs, with a high degree of accuracy and efficiency
Excellent project management skills
#LI-SA1
Neurocrine Biosciences is an EEO/AA/Disability/Vets employer.
We are committed to building a diverse, equitable, and inclusive workplace, and we recognize there are a variety of ways to meet our requirements. We are looking for the best candidate for the job and encourage you to apply even if your experience or qualifications don’t line up to exactly what we have outlined in the job description.
_
The annual base salary we reasonably expect to pay is $123,700.00-$179,350.00. Individual pay decisions depend on various factors, such as primary work location, complexity and responsibility of role, job duties/requirements, and relevant experience and skills. In addition, this position offers an annual bonus with a target of 30% of the earned base salary and eligibility to participate in our equity based long term incentive program. Benefits offered include a retirement savings plan (with company match), paid vacation, holiday and personal days, paid caregiver/parental and medical leave, and health benefits to include medical, prescription drug, dental and vision coverage in accordance with the terms and conditions of the applicable plans.",1992,Biotech & Pharmaceuticals,$1 to $5 billion (USD),Pharmaceutical & Biotechnology,1001 to 5000 Employees,Company - Public,False
Data Center Chief Engineer,"Amazon Data Services, Inc.
","San Francisco, CA",$74K (Employer est.),3.7,"4+ years of relevant work experience in a data center or other critical environment or 8+ years of Technical (Military/Trade School) training and/or experience with relevant data center facilities equipment
High School diploma or equivalent
Amazon is looking for an energetic, detail-oriented individual to join our Data Center Engineering Operations Team. This committed group works to maintain the critical physical infrastructure that supports Amazon Web Services. Specifically, this team works to ensure that the data center's MEP operates at 100% availability while maintaining first-class customer service to the teams and groups within the data centers.

The Data Center Chief Engineer (CE) is responsible for ensuring that all electrical, mechanical, and fire/life safety equipment within the data center is operating at peak efficiency. This involves both planned preventative maintenance of equipment, daily corrective work, and emergency response to emergent issues. The CE serves as an expert technical resource reporting to a site’s Data Center Facility Manager and interacting with onsite Engineering Operations Technicians (EOT) and any third party vendors. They are expected to be a singular focal point for all facility operations within a given data center and to support Amazon within its owned and operated data centers. Data center equipment that supports mission-critical servers must maintain better than 99.999% uptime.

Also expected from the CE is the ability to management small-to-medium impacting projects from conception to completion. These projects involve large amounts of independent work as well as collaboration with external support groups including engineering, automation, processing, and finance in both local and global settings. The CE will be tasked with creating and delivering on key milestones, obtaining and tracking quotes for all necessary costs, and documenting project results for future implementation at other facilities. The goals of such projects are for the CE to drive innovation and resiliency while reducing operational costs in the facilities.

The CE directs, trains and supports EOT’s in their role of providing hands-on electrical and mechanical equipment troubleshooting and operations. Implementation and execution of site/equipment-specific training exercises is also expected. This equipment includes, but is not limited to, stand-by diesel generators, switchgear, UPS’s, PDU’s, AHU’s, chillers, cooling towers, chemical treatment systems, pumps, motors, VFD’s, and building automation systems.

Responsibilities:

Oversee the day-to-day operations and maintenance of mechanical and electrical equipment in a data center.
Operate independently with limited direct management
Act as an escalation point for all facilities-related issues within the data center, escalating to the Data Center Facility Manager as needed
Perform root cause analysis of equipment failures
Troubleshoot and report of facility and data sever-level events within internal SLA
Create and deploy new standard practices for Engineering Operations Technicians, Chief Engineers, and vendor support teams
Provide training and guidance to Engineering Operations Technicians
Ensure all safety procedures are adhered to by vendor and Amazon staff
Utilize internal CMMS to manage building workflows
Communicate complex technical information to a non-technical audience
Physical Requirements:

Walk job sites in uneven terrain
Work at heights and from ladders
Regularly lift and/or move up to 49 pounds; and participate in group lifts for 50 pounds or more
Coordinate body movements when using tools or equipment
Reach and stretch to position equipment and fixtures while maintaining balance
Bend or twist the body into unusual positions while working
Perform physical tasks all day without becoming overly tired
Use hands to manipulate small wires and objects
Push or pull heavy objects into position
Work in a noisy environment
Work at depths, such as under raised floors
We are open to hiring candidates to work out of one of the following locations:

San Francisco, CA, USA


Associates or Bachelors in applicable engineering field or mechanical or electrical trades
Operating engineering licenses such as DC II, DC III, or equivalent
Stationary Engineering or Building Engineering License
Electrical or mechanical Journeyman License
CFC license
NFPA 70E
Strong verbal and written communication skills
Solid leadership and organizational skills
Proven self-starter
Ability to prioritize in a complex, fast-paced environment
Attention to detail
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $73,900/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.",1994,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Senior Data Engineer,"FLYR Labs
","San Francisco, CA",$119K - $167K (Employer est.),3.5,"Our Vision

FLYR is focused on the relentless application of advanced and intuitive technologies that help transportation leaders unlock their ultimate potential.

FLYR is a technology company that is purpose-built for the travel industry. Leveraging deep learning, an advanced form of AI, FLYR is helping airlines, cargo, and hospitality businesses around the globe elevate their results. With FLYR, businesses are able to improve revenue performance and modernize the e-commerce experience through accurate forecasting, automation, and analytics.
Flight Itinerary (About The Role)

Our data-driven, deep-learning-based methodology enables any airline to truly maximize their revenue and accurately forecast outcomes, even under unprecedented conditions such as COVID-19. To achieve this vision, we’re looking for a talented Senior Data Engineer to join our leading-edge data engineering customer implementation team. This team delights new customers throughout the onboarding process, applying innovative, best-in-class tools and workflows to build performant, reliable data pipelines. The Data Engineer will play a key role in ensuring our customers see rapid time-to-value, and will build creative technical solutions for new and complex problems.

What Your Journey Will Look Like (Responsibilities)
Complete complex customer ingest and data warehousing projects
Develop and implement best practices and standardized, repeatable processes for implementing enterprise-grade data transformation/ingest pipelines, with an eye toward scalability
Engage with customers from data discovery, to ETL development, to data QA/QC metrics determination and delivery SLAs
Develop and implement best practices and standardized, repeatable processes for implementing enterprise-grade data transformation/ingest pipelines, with an eye toward scalability
Learn our customers’ business needs and apply business acumen to ensure the success of highly technical projects
Collaborate closely with FLYR's data platform team to define tool requirements to support onboarding and ingest of new data sources
Defining platform data validation test suites
Provide mentorship and training to newer crew members
What To Pack For This Trip (Qualifications)
Quantitative work/education background (computer science or equivalent)
Ability to ship production-quality Python code
5+ years of hands-on experience with cloud computing services, Airflow and BigQuery
5+ years of experience building and operating data transformation pipelines
Experience with data warehouses, ETL automation, BI visualization tools, and cloud-based data management tools
Advanced SQL. You know your way around analytical and aggregate functions, complex joins, window functions, and are confident in wrangling all types of data in SQL
Can identify impediments to customer onboarding and propose improvements to processes. Can work with Product, Data Science and Data Platform teams to define product and platform capabilities to improve customer onboarding
Ability to clearly communicate status, blockers, risks, and dependencies to FLYR and customer stakeholders
First-Class Amenities
Equity in Series C startup with high growth potential
Comprehensive healthcare plans (Choice of PPO & HMO available)
Generous PTO policy and flexible working arrangements
401K with company match
Free breakfast/Lunch (in-office)
100% paid Parental Leave for 12 weeks
Annual educational fund



Compensation: The salary range for this role is commensurate with experience and is as follows:
$119,000—$167,000 USD
Our Commitment to Equality
Here at FLYR, we’re committed to growing with intention, having our teams better reflect the world around us. We strive to create an environment of inclusion and even more importantly, belonging, where psychological safety, empathy, and human connection are at the center of our leadership principles. Not only does this enable us to create better products and have a better work environment, it’s good for the bottom line and it’s the right thing to do.
FLYR provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, gender identity, sex, sexual orientation, national origin, age, physical or mental disability, genetics, marital or veteran status. In addition to federal law requirements, FLYR complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company operates.
Privacy Policy
All applicants, including those based in California or the EU, are encouraged to review our Privacy and Cookie Policy.
#LI-Hybrid",2013,Internet & Web Services,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,False
"Customer Engineer, Data Management, Google Cloud","Google
","San Diego, CA",-1,4.4,"Minimum qualifications:
Bachelor's degree in Computer Science, a related technical field, or equivalent practical experience.

5 years of experience with data migration strategies and moving production systems in on-premise/data center environments to the cloud.

5 years of experience with database technologies and database administration techniques.




Preferred qualifications:
Master's degree in Computer Science or a related technical field.

5 years of experience with optimizing database performance with respect to transactional or analytic workloads.

4 years of experience in technical sales or professional consulting in the fields of systems integration, data transfer/management, and enterprise database performance.

Knowledge of Disaster Recovery (DR) and data backup strategies.

Ability to learn, understand, and work with new emerging technologies, methodologies, and solutions in the Cloud/IT Technology space.
About the job

When leading companies choose Google Cloud it's a huge win for spreading the power of cloud computing globally. Once educational institutions, government agencies, and other businesses sign on to use Google Cloud products, you come in to facilitate making their work more productive, mobile, and collaborative. You listen and deliver what is most helpful for the customer. You assist fellow sales Googlers by problem-solving key technical issues for our customers. You liaise with the product marketing management and engineering teams to stay on top of industry trends and devise enhancements to Google Cloud products.

As an Enterprise Customer Engineer, you will work directly with the Technical Sales teams as an enterprise database subject matter expert to differentiate and portray the goal of Google Cloud to our customers. You will help prospective customers and partners understand Google Cloud, explain technical features, help customers design architectures, engage in proof- of-concepts, and troubleshoot potential roadblocks related to database migration and data back ends for new app development.

Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.

The US base salary range for this full-time position is $118,000-$177,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.


Responsibilities
Work with the team to identify and qualify business opportunities, identify key customer technical objections, and develop a strategy to resolve technical blockers.
Support the technical relationship with Google customers, including product and solution briefings, proof-of-concept work, coordination and prioritization of solutions impacting customer adoption of Google Cloud.
Work with customers to demonstrate and prototype Google Cloud product integrations in customer/partner environments.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to implement a complete solution using best practices on Google Cloud.
Travel to customer sites, conferences, and other related events as needed.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",1998,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Staff Software Engineer, Data Pipelines","Nuna
","San Francisco, CA",$165K - $230K (Employer est.),2.9,"At Nuna, our mission is to make high-quality healthcare affordable and accessible for everyone. We are dedicated to tackling one of our nation's biggest problems with ingenuity, creativity, and a keen moral compass.

Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.

Nuna partners with healthcare payers, including government agencies and health plans, to turn data into learnings and information into meaning.

YOUR TEAM

We build technology to enable users (from data scientists to analysts to policy-makers) to understand healthcare data while ensuring its integrity, security, and privacy. Our work runs the gamut from joining streams of messy real-world data to building queryable data warehouses to constructing visualizations and dashboards that provide actionable insight. We build systems that are auditable, automated, an accurate representation of the underlying data, and, most importantly, responsive to our end users' needs. We strive for a creative, collaborative engineering environment that implements best practices of peer review, readability, maintainability, and security of the code base and infrastructure.

The Nuna Data Platform team is responsible for building the pipeline, tooling, and processing to power our apps. This is a hands on role, and you will be expected to spend 20+ hours a week writing code. We work closely with our Health Data Engineering and Health Data Analyst teams to combine engineering excellence with healthcare knowledge to accommodate our customer's diverse data.

YOUR OPPORTUNITIES
Build products that change the dynamics and incentives of the healthcare industry, changing a zero-sum game of competition between payers and providers into patient-centered collaboration
Build interactive features including predictive analytics and dynamic modeling for our customers to gain insight into ways to improve
Build the engine that will enable data scientists to build, iterate, and deploy analytics as code
Manage our high stakes production environment, ensuring high availability/low latency and protecting our sensitive data with rigorous security
Identify big opportunities to improve our technology and our products, blazing trails through ambiguity
Mentor more junior engineers and, in turn, learn from more senior engineers, because we are learners, not knowers, and growing Nuna's people is the most reliable way to scale our impact
Work as part of a team, not in a silo - at Nuna, we rise by lifting others!
QUALIFICATIONS
8+ years of experience
Experience building production-hardened data pipelines, with consideration for performance, scalability, reliability, and repeatability
Familiarity with orchestration tools like Airflow or Prefect
Experience with rules-based engines that lets internal and external users define business logic in a controlled fashion
Experience rapidly prototyping new product concepts, especially for enterprise clients
Understanding of data testing concepts and the ability to consistently apply them.
Knowledge of database fundamentals like indexing and SQL queries
Experience managing production services and designing smooth deployment processes, ideally in AWS
Experience with Hadoop and Spark
TECHNOLOGIES USED AT NUNA
Python, Scala, SQL, testing tools (e.g. pytest), build tools (Bazel, poetry)
Spark, Prefect, JupyterHub, k8s
Linux, OS X
AWS ECS, RDS, IAM, Lambda; Hashicorp Terraform and Vault

We take into account an individual's qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company's equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $165,000 to $230,000. The actual offer will be at the company's sole discretion and determined by relevant business considerations, including the final candidate's qualifications, years of experience, and skillset.

Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.",2010,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,201 to 500 Employees,Company - Private,False
Sr. Data Analytics Engineer,"Lucid Motors
","Newark, CA",$122K - $161K (Glassdoor est.),3.2,"Leading the future in luxury electric and mobility
At Lucid, we set out to introduce the most captivating, luxury electric vehicles that elevate the human experience and transcend the perceived limitations of space, performance, and intelligence. Vehicles that are intuitive, liberating, and designed for the future of mobility.
We plan to lead in this new era of luxury electric by returning to the fundamentals of great design – where every decision we make is in service of the individual and environment. Because when you are no longer bound by convention, you are free to define your own experience.
Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.

We are currently seeking a Senior Data Analytics Engineer. This position requires an experienced professional to contribute to the development of a Big Data Platform. Our ideal candidate exhibits a can-do attitude and approaches his or her work with vigor and determination. Candidates will be expected to demonstrate excellence in their respective fields, to possess the ability to learn quickly and to strive for perfection within a fast-paced environment.
The Role:
ETL Design and Development, contribute to the development of a big data platform using pipeline technologies such as Spark, Kafka, Airflow
Design, develop and automate, self-service, scalable analytical solutions with Tableau, Zeppelin or Looker
Expert in normalization/de-normalization techniques for data analysis and optimum performance in big data environment using Presto, Redshift and Elastic Search
Develop and deploy pipelines and CI/CD in Docker and Kubernetes.
Expert in data warehouse, data lake design, data modeling and data management
Interface with business customers, gathering requirements and delivering complete reporting solutions.
Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
Deliver near-real-time and non-near-real-time data and applications to a team of analysts and data scientists who create insights and analytics applications for our stakeholders.
Participate in data strategy and road map exercises, business intelligence/data warehouse product selection, design, and implementation
Qualifications:
Bachelor/master's in computer science, Engineering, Mathematics, Statistics or related field
6+ years of work experience with ETL, data modeling, and business intelligence big data architectures.
Expert in at least one SQL language such as ANSI SQL, T-SQL or PL/SQL.
Experience developing and managing data warehouses on a terabyte or petabyte scale.
Strong experience in massively parallel processing & columnar databases.
Experience with Python and shell scripting.
Advanced skills in data visualization tools like Tableau, Looker, Zeppelin
Advanced ability to draw insights from data and communicate them to the stakeholders and senior management as required
Familiarity with AWS solutions such as S3, Redshift
Working with unstructured or semi-structured datasets
Streaming data systems such as Kafka and Spark Streaming
Distributed processing using tools such as Spark
Experience with Scheduling and orchestration tools such as Airflow
Container-based deployments using Docker and Kubernetes
Experience with Sales, Accounting and Finance data
Experience working directly with business users to build reports, dashboards and solving business questions with data
Salary Range: The compensation range for this position is specific to the locations listed below and is the range Lucid reasonably and in good faith expects to pay for the position taking into account the wide variety of factors that are considered in making compensation decisions, including job-related knowledge; skillset; experience, education and training; certifications; and other relevant business and organizational factors.
California (Bay Area) - $127,000 - $181,500

Additional Compensation and Benefits: Lucid offers a wide range of competitive benefits, including medical, dental, vision, life insurance, disability insurance, vacation, and 401k. The successful candidate may also be eligible to participate in Lucid’s equity program and/or a discretionary annual incentive program, subject to the rules governing such programs. (Cash or equity incentive awards, if any, will depend on various factors, including, without limitation, individual and company performance.)

Lucid maintains your privacy according to its Candidate Privacy Notice. If you are a California resident, please refer to our California Candidate Privacy Notice.



At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.
To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.",2007,Transportation Equipment Manufacturing,Unknown / Non-Applicable,Manufacturing,5001 to 10000 Employees,Company - Public,True
"Technical Support Engineer (L5) - Data Platform, Big Data / Analytics","Netflix
","Los Gatos, CA",$105K - $173K (Glassdoor est.),4.2,"Los Gatos, California

Core Engineering
Netflix is the world’s leading streaming entertainment service with 250 million paid memberships in over 190 countries, enjoying TV series, documentaries, and feature films across a wide variety of genres and languages. Members can watch as much as they want, anytime, anywhere, on any internet-connected screen. Members can play, pause and resume watching, all without commercials or commitments.
About the Engineering Support Organization
The aim of the Engineering Support Organization is to enable Productivity Engineering to effectively and sustainably scale the support they provide to their customers. The team is the frontline resource for the engineering support needs of our customers (i.e., our engineering workforce) - handling, troubleshooting, and resolving customer requests and issues. In addition, the team will focus on ways of working, customer advocacy, support tooling, platform product offerings, documentation, and developer education.



Our Mission
Deliver an excellent support experience to Netflix’s developer community. To advocate for our customers, follow through on issues and resolve them in a reasonable time. If blockers prevent immediate resolution, we communicate status and ensure there is visibility into why there is a delay.



Provide insights, feedback and champion customer sentiment about the tools we support to our partners across Productivity Engineering. Partner with PM and Engineering to track and maintain visibility into ongoing issues and communicate customer needs to ensure improving in these areas is prioritized.

Drive collaboration efforts to reduce product friction and increase usability so that Productivity Engineering can build, deploy and deliver highly functional solutions for the Developer Community.

Our culture is unique, and we tend to live by our values, allowing you to do your best work and grow. To learn more about Productivity Engineering, feel free to listen to this podcast.

The Role
We are looking for a Technical Support Engineer with a passion for productivity infrastructure and tooling, customer service, and automation. You will be responsible for monitoring and handling our customers’ requests, troubleshooting, solving issues, automating support needs, developing runbooks, improving and maintaining support tools, understanding our product offerings, and continuously looking for ways to improve the engineering support experience.

Our ideal team member has first-hand experience working in customer-facing, engineering support roles, writing and building a comprehensive self-service knowledge base and has knowledge of infrastructure, internal tooling, platforms, and cloud computing. You are excellent at understanding and solving complex and ambiguous problems and constantly seek improvement. As an Engineer in this role, we need a candidate who can understand our complex offerings on a technical level, be hands-on in the development of our support automation tooling, and recommend product and operational improvements based on customer interactions.
Location
Los Gatos, CA or US Remote only.
What you’ll need to be successful
You are skilled in providing superior customer support across a complex organization, ideally as part of a central team
You are passionate about customer experience, striving to be an excellent customer advocate
You are highly adaptable and comfortable taking on diverse roles and responsibilities from end to end in an investigation
You are a data-driven and evidence-based decision-maker
You have excellent communication skills and a proven track record of meaningful enhancements toward comprehensive documentation
You are proficient in at least one programming language, ideally Python and/or Java, enabling you to contribute to codebases across related domains
Prior experience supporting platforms built using open-source technologies such as Apache Kafka, Spark, and Hadoop
You have worked with big data warehouse storage systems (e.g. Iceberg or Hive)
You have experience developing data and/or ETL pipelines using Apache Spark framework or technologies such as Flink and Kafka
Ability to read and write SQL queries to pull required complex data to support any reported issues/product defects
Experience with cloud infrastructure and/or container orchestration platforms is a plus
You have the desire and aptitude to learn how the pieces of big data platform work together
You thrive in fast-paced environments and seek to improve on operational efficiencies by leaning into automation and visualization tooling
We are an equal opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Our culture is unique, and we tend to live by our values, allowing you to do your best work and grow. To learn more about Productivity Engineering, feel free to listen to this podcast.

At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.

The overall market range for roles in this area of Netflix is typically $150,000 - $400,000

This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.",1997,Internet & Web Services,$5 to $10 billion (USD),Information Technology,5001 to 10000 Employees,Company - Public,False
Senior Data Engineer,"EPCVIP, Inc
","Los Angeles, CA",$200K (Employer est.),4.9,"Job Overview

We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The Data Engineer will support our software engineers, database architects and analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Responsibilities:

Develop core data relationship, data ingest, data transformation services and search capabilities.
Maintain all facets of data infrastructure, including backups/disaster recovery, software deployment/configuration, security best practices, performance tuning, and troubleshooting.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies
Review project objectives and determine best technology for implementation. Implement best practice standards for development, build and deployment automation.
Design, maintain and optimize highly distributed analytics data stores
Write well-abstracted, reusable and efficient code





Requirements:

5+ years of relevant Data Engineering technical experience
Bachelor’s degree in Technology based discipline preferred.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Build processes supporting data transformation, data structures, metadata, dependency and workload management
Experience with AWS cloud services: Lambda, S3, Glue, Redshift, and Athena, or their open source equivalent (Zeppelin, Presto, etc)
Experience with data pipelining with AWS Datapipeline, Airflow or Luigi
Experience with object-oriented/object function scripting languages: Python code development, python unit testing (tox), Pyspark
Up-to-date on latest industry trends; able to articulate trends and potential clearly and confidently
Understanding of best practices within the development process

Benefits:

401K
Paid Vacation and Sick Time off
Paid Parental Leave
Health, Dental and Vision Insurance Coverage
Short term/Long Term Disability Insurance Coverage
Life Insurance Coverage

Perks:

Wellness Reimbursement
Tuition Reimbursement
In-home Vet Care
Referral bonus
Relocation Assistance
Free parking
Friday lunch catering
Daily free snacks and drinks
Yearly mini paid holiday company trip
Lunch and Learn Sessions

AFFIRMATIVE ACTION/EQUAL OPPORTUNITY EMPLOYER
EPCVIP, Inc is an affirmative action and equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, criminal history, genetic information or any of the protected classes. EPCVIP, Inc is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, contact Human Resources at hr@epcvip.com.",2014,Information Technology Support Services,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,True
Senior Data Engineer (Snowflake) - Contractor,"EY
",United States,$90.00 - $130.00 Per Hour (Employer est.),3.9,"The primary responsibility for the Sr. Data Engineer / Tech Lead is to ensure data accessibility, quality, and reliability within the client's data platform ecosystem.

RESPONSIBILITIES

Design and develop end-to-end data pipelines and ETL processes using Snowflake, Denodo, DBT Cloud, Fivetran, and AWS Glue, ensuring seamless data integration, transformation, and loading.
Collaborate with cross-functional teams to gather data requirements and implement scalable data models and schemas within Snowflake and Denodo, ensuring optimal performance and data consistency.
Implement and maintain data orchestration workflows using Stonebranch, ensuring efficient and reliable scheduling and automation of data processes.
Work with EnterpriseDataLake for ingestion and storage of data from various sources, ensuring the availability and accessibility of data for analytics and reporting purposes.
Utilize Azure DevOps and Teraform to implement and manage infrastructure as code, ensuring streamlined deployment and scalability of data engineering solutions.
Skills

snowflake

denodo

dbt cloud

fivetran

Qualifications

REQUIREMENTS

Proficiency in Snowflake and Denodo: Strong understanding and hands-on experience in working with Snowflake and Denodo for data integration, transformation, and analysis.
Knowledge of DBT Cloud: Familiarity with DBT Cloud, including experience in building and maintaining efficient data transformation workflows and deploying reliable data pipelines.
Experience with Fivetran: Demonstrated experience in utilizing Fivetran for data ingestion, source connectivity, and ensuring data accuracy and completeness.
Understanding of EnterpriseDataLake: Knowledge of EnterpriseDataLake principles and practices, including data ingestion, storage, and organization for analytics and reporting purposes.
Familiarity with Stonebranch: Proficiency in using Stonebranch for data orchestration and scheduling, ensuring efficient and reliable execution of data pipelines and workflows.
Proficiency in Azure DevOps and Teraform: Experience in leveraging Azure DevOps and Teraform for infrastructure as code, enabling streamlined deployment and scalability of data engineering solutions.

The expected pay rate range for this contract assignment is $90 to $130 per hour. The exact pay rate will vary based on skills, experience, and location. The position is approximately 65-70% remote and 30-35% travel to the client as needed.

#GigNowTechOpportunities

GigNowOpportunities

Equal Employment Opportunity Information
EY provides equal opportunities to applicants, employees, contractors, vendors, and stakeholders without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. If you are an individual with a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please email gignow.recruiting@ey.com.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,False
Senior Cloud Data Engineer,"Kforce
","Westlake Village, Los Angeles, CA",$116K - $145K (Employer est.),3.9,"RESPONSIBILITIES:
Kforce has a client that is seeking a Senior Cloud Data Engineer out of Westlake Village, CA (1-3 days onsite required).

Summary:
This role is a highly visible and value driven individual contributor role, providing data infrastructural help for fellow analysts and data scientists as well as operationalizing ML models at scale integrated to customer facing applications. The Senior Cloud Data Engineer will be hands-on developing Deep learning models, Holtz Winters anomaly detection models, Classification and Regression models as well as operationalizing them as unsupervised continuous learning models. Model outcomes will be pushed into Timeseries data stores like Apache Pinot for quick rendering and REST API end points.

Responsibilities:

Design and build reliable, scalable data infrastructure with leading privacy and security echniques to safeguard data using AWS technologies
Design and Build scalable, secure, low latency, resilient and cost-effective solutions for enabling predictive and prescriptive analytics across the organization
Design/ Architect frameworks to Operationalize ML models through serverless architecture and support unsupervised continuous training models
Take over and scale our data models (Tableau, Dynamo DB, Kibana)
Experience in shipping low-latency massive scale systems to production
Communicate data-backed findings to a diverse constituency of internal and external stakeholders
Build frameworks for data ingestion pipeline both real time and batch using best practices in data modeling, ETL/ELT processes and hand off to data engineers
Participate in technical decisions and collaborate with talented peers
Review code, implementations and give meaningful feedback that helps others build better solutions
REQUIREMENTS:

AWS Certified Big Data - Specialty desirable
5+ years of experience working directly with enterprise data solutions
Experience working in a public cloud environment and on-prem infrastructure
Specialty on Columnar Databases like Redshift Spectrum, Time Series data stores like Apache Pinot and the AWS cloud infrastructure
Experience with in-memory, serverless, streaming technologies and orchestration tools such as Docker, Spark, Kafka, Airflow, Kubernetes is needed
Excellent SQL skills and Python coding is a must
Implementation experience required, possessing 5or more years of IT platform implementation experience
Experience designing and implementing AWS big data and analytics solutions in large digital and retail environments is desirable
SQL savvy, self-sufficient in handling large volumes of data as well as excellent data visualization capabilities using Tableau or like solutions

Experience in online transactional (OLTP) processing and analytical processing (OLAP) databases, data lakes, and schemas
Experience with AWS Cloud Data Lake Technologies and operational experience of Kinesis/Kafka, S3, Glue and Athena
Experience with any of the message/file formats: Parquet, Avro, ORC
Design and development experience on subscribing to a Streaming Service, EMS, MQ, Java, XSD, File Adapter, and ESB based applications
Experience in distributed architectures such as Microservices, SOA, RESTful APIs and data integration architectures is a plus
Experience migrating On-Prem Data solutions to cloud
Experience managing On-prem Enterprise Data Warehouse solutions like Netezza is a plus
Experience with a wide variety of modern data processing technologies, including
Big Data Stack (Spark, spectrum, Flume, Kafka, Kinesis etc.)
Data streaming (Kafka, SQS/SNS queuing, etc.)
Expert in Columnar databases primarily, Redshift or like technologies lile Snowflake, Firebolt
The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",1962,Business Consulting,$1 to $5 billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Analytics Platform - Engineer,"Salesforce
","San Francisco, CA",$123K - $169K (Employer est.),4.0,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Software Engineering

Job Details

About Salesforce

We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.

At Salesforce we are continuing our own Digital Transformation to accelerate our growth and deliver outstanding service to our customers. A key pillar of this transformation is scaling the deployment, configuration, and management of our global analytics platforms to measure and generate insights on Salesforce prospect and customer behaviors.

We’re looking for an Engineer to support Salesforce’s global analytics platforms across clouds and regions. This person will have experience in digital analytics and in the global deployment of systems such as Google Analytics 360 and GA4 across multiple regions and business units.

This person will support our efforts to build consistency, quality, and value of our digital analytics data at Salesforce. This includes relationships with a distributed team of digital analysts and engineers.

The right candidate brings business understanding on the value of digital analytics data along with the technical expertise required to support a world class implementation of digital analytics platforms. This includes data layer design and implementation, tag management, custom dimensions and variables, events, goals, content and traffic classifications, and similar aspects of digital analytics expertise. This candidate has experience translating desired business insight outcomes from marketing and customer teams into actionable deployment plans and system design.

Responsibilities:

Continue to improve Salesforce’s instance of Google Analytics 360 / GA4, Google Tag Manager

Work within the Digital Analytics Platform team to deploy and manage updates to the digital data layer and analytics code live on Salesforce web properties.

Configure the digital analytics platform to meet the needs of key internal customers such as Analytics Reporting Team, Cloud Teams, Field Teams, Paid Media, and Product Marketing

Participate in a team culture of critical thinking, creativity, innovation, experimentation, diversity, and inclusivity that aligns with Salesforce core values

Constantly learn, have a clear pulse on innovation across the enterprise SaaS, data science, customer data, and analytics communities.

Required Skills

A related technical degree.

2-5+ years of deep expertise in global analytics platforms such as Google Analytics 360 / GA4. Must have practical, hands on knowledge and ability to design and handle a world class implementation of these platforms

1+ years experience working with global analytics platforms at Fortune 500 companies. Must have experience working with global analytics suites across multiple countries, regions, and business units with a high volume of customer traffic per month (10s of millions+).

Broad understanding of digital marketing and the role of digital analytics platforms in evaluating the performance of campaigns, events, paid media, e-commerce, social media, etc.

Data manipulation skills, with experience in BigQuery / SQL. Have the ability to closely partner with data engineers and architects.

Understanding of governmental privacy regulations on the collection and use of customer data (such as GDPR and CCPA) and how this impacts digital data collection. Experience with OneTrust a plus.

Good communicator in written and verbal form with the ability to work well with other technical teams.

Problem solver who simplifies problems to their core elements and finds creative solutions.

Get-it-done mentality with strong bias towards action.

Advanced Salesforce product knowledge a plus

B2B customer data experience a plus

LI-Y

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .

Posting Statement

At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .

Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce . ﻿

Salesforce welcomes all.

Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.

For Washington-based roles, the base salary hiring range for this position is $122,600 to $168,700.
For California-based roles, the base salary hiring range for this position is $133,800 to $183,900.

Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.",1999,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Software Engineer - Big Data Technologies,"Apple
","San Diego, CA",-1,4.2,"Summary
Posted: Sep 19, 2023
Weekly Hours: 40
Role Number:200495242
Meaningful insights require a solid infrastructure that is able to scale with the large amount of data coming in. Our team is responsible for discovering such great insights from a sea of data, and our infrastructure needs innovative ideas to improve its performance and ease-of-use. Would you like to help understand the challenges of building and maintaining a large-scale analytics infrastructure? Are you excited about identifying areas for improvement and creating out-of-the-box solutions? If this describes you, we would love to hear from you!
Key Qualifications
Great programming skills in C, C++, Python or Java
Strong analytical thinking
Self-motivated and able to work independently
Excellent spoken and written communication skills
Description
We're looking for a motivated engineer with excellent programming, problem solving and communication skills. In this role, you will be responsible for effective provisioning, installation/configuration, operation, and maintenance of our team’s analytics infrastructure. You will enable continued innovation and progress within the infrastructure through research and development. You will help and support the execution, test and roll-out of solutions. To be successful in this role, you must have a solid software engineering background and be able to write production level code. As a member of this team, you will have the opportunity to solve challenging engineering problems across a broad range of Apple products.
Education & Experience
B.S., M.S. or Ph.D. in Computer Science, Electrical Engineering or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $52.98 and $79.75/hr, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",1976,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer,"Atlassian
","San Francisco, CA",$112K - $158K (Glassdoor est.),4.1,"Overview:

Working at Atlassian

Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Responsibilities:

This is a remote position. To help our teams work together effectively, this role requires you to be located in the PST timezone.

Atlassian is looking for a Data Engineer to join our Data Experience Enablement team. This team owns the customer facing data model available to Atlassian customers in the Atlassian Analytics product offering. Building a high quality, easy to use, and insightful data model for our Enterprise customers involves ingesting, modeling, and validating the data in the Atlassian Data Lake is ready for customer usage.

That's where you come in. We're looking for a data engineer familiar with data pipelines, analysis, and modeling to help us expand and improve our customer facing data offerings. You'll be working in a team of 6 engineers within the larger Analytics and Visualization Platform group. We are excited to have you join our team!

What you'll do

Launch new data capabilities to Atlassian customers through our Atlassian Analytics product suite.

Build tooling to empower the business to launch new data capabilities faster and easier.

Collaborate with teams across Atlassian to build high quality data models for our customers.

Work alongside a team of engineers, contributing to the team culture through your passion, creativity, and experience.

Learn and grow as an engineer through various career development opportunities.

Qualifications:

Your background

BS in Computer Science or equivalent experience with 3+ years of data engineering experience

Fluency in Python

SQL skills that enable advanced analysis and data modeling

Experience with data pipeline tooling and warehouses, specifically DBT, AWS data services (Redshift, Athena, EMR), and Apache projects (Spark, Flink, Hive, and Kafka)

Familiar with modern software development practices (Agile, TDD, CICD) applied to data engineering

General familiarity with cloud environments such as AWS or GCP

Compensation

At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:

Zone A: $176,200 - $234,900

Zone B: $158,600 - $211,500

Zone C: $146,300 - $195,000

This role may also be eligible for benefits, bonuses, commissions, and equity.

Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.

#LI-Remote

Our perks & benefits

Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more.

About Atlassian

At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

To learn more about our culture and hiring process, visit go.atlassian.com/crh.",2002,Software Development,Unknown / Non-Applicable,Information Technology,5001 to 10000 Employees,Company - Public,False
Software Engineer - Data Team,"Applied Intuition
","Mountain View, CA",$65K - $400K (Employer est.),4.0,"About Applied Intuition

Applied Intuition is a vehicle software supplier that accelerates the adoption of safe and intelligent machines worldwide. Founded in 2017, Applied Intuition provides a simulation and validation platform for various industries such as automotive, trucking, construction, and more. 17 of the top 20 global automakers rely on Applied Intuition's solutions to shorten development cycles, deliver high-quality systems, and accelerate the production of modern vehicles with confidence. Applied Intuition is headquartered in Mountain View, CA, with offices in Ann Arbor, MI, Washington, DC, Munich, Stockholm, Seoul, and Tokyo. Learn more at https://applied.co.

About the role

We are looking for talented engineers who are excited about building products that wrangle AV data to supercharge our customers. You will drive the design and development of data processing across our products and internal tools. Handling massive volumes of data for Applied Intuition's platform needs is a critical area and we are looking for someone who can be hands-on in improving our data quality via data tools and processes.

We have multiple data engineer roles open for all levels of seniority, from mid-level to Lead.

At Applied Intuition, you will:

Design and develop systems for programmatically generating ground-truth-labeled data from a simulated world
Develop and deploy high-quality software using modern tooling and frameworks
Work with machine learning pipelines to understand and improve quality of datasets
Work with top autonomy companies to understand and solve unique challenges in perception with synthetic data
Work with products and teams across Applied Intuition

We're looking for someone who has:

Strong software engineering skills in programming languages (Python, C++, GoLang, etc.)
Experience with containerization and other modern software development workflows
Experience with synthetic data and its applications in perception systems

Nice to have:

Experience with applying synthetic data to machine learning tasks
Hands-on experience with characterization of models for Lidar, Radar, and Camera

The salary range for this position is $65,000 USD to $400,000 USD annually. This salary range is an estimate, and the actual salary may vary based on the Company's compensation practices

Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.

Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.

Applied Intuition is an equal opportunity employer and federal contractor or subcontractor. Consequently, the parties agree that, as applicable, they will abide by the requirements of 41 CFR 60-1.4(a), 41 CFR 60-300.5(a) and 41 CFR 60-741.5(a) and that these laws are incorporated herein by reference. These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. These regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. The parties also agree that, as applicable, they will abide by the requirements of Executive Order 13496 (29 CFR Part 471, Appendix A to Subpart A), relating to the notice of employee rights under federal labor laws.",2017,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
Data Infrastructure Engineer,"United Talent Agency (UTA)
","Los Angeles, CA",$170K - $200K (Employer est.),3.6,"United Talent Agency is committed to building high performance data and application platforms by utilizing the most effective cutting-edge technology we can. UTA's Engineering Team's mission is to use Continuous Integration and Continuous Delivery methods to create a sustainable and secure pipeline in delivering solutions to its business stakeholders. We do this by continuously analyzing areas of improvement and identifying areas of opportunity to automate, secure and codify our environment.

At UTA, you’ll play an essential role in ensuring the effective and seamless integration for workload optimization, query optimization and high performing distributed query execution. While dealing with the fast-paced development and operational process, we strive for world-class tooling, automation and infrastructure to further advance our SaaS platform.

We’re hiring a Data Infrastructure Engineer to join our Engineering team, reporting to the VP, Engineering, you will provide automation and fundamental frameworks that allow us to efficiently perform data warehousing, data lakes, data engineering, data science, data application development, and secure sharing and consumption of real-time / shared data.

The salary range for this role is $170,000 to $200,000 commensurate with experience and skills.
What You’ll Do
Create a framework that enables the development team to understand the full impact of their features for stakeholders, including testing before it is enabled in production Providing insights into performance and reliability on actual production, guaranteeing no customer impact
Design a visualization framework that provides the ability to visualize all queries in all environments, including production, while also designing improvements for better insights into potential issues and query plan manipulation
Develop a service that automatically finds and resolves data corruption in the system, at all stages of development, including in production
Responsible for creating a testing platform, meant to find correctness and reliability issues in pre-production environments
Creation of automated system to safely orchestrate the enablement of features in production that will automatically detect and mitigate production issues, for rapid end-to-end feature rollout process at scale
Identify infrastructure gaps, for which you can design and implement automated solutions
Contribute to the design, development, and maintenance of some of our existing projects
What You’ll Need
5+ years hands-on software engineering experience, including experience using Snowflake
Advanced CS fundamentals including data structures, algorithms, and distributed systems
Good understanding of database fundamentals
Background in database tooling, database internals, schema design, or building components for large scale data processing systems
Systems programming skills with fluency in Java, JavaScript or Python
Track record of identifying and implementing creative solutions with data from multiple sources
What You'll Get
The unique and exciting opportunity to work at one of the leading global entertainment companies
Access to the tools, leadership, and resources you will need to create and drive a center of excellence
The opportunity to do the best work of your career
Work in an inclusive and diverse company culture
Competitive benefits and programs to support your well-being
Collaborative colleagues who are focused on making an impact
About UTA
UTA unites ideas, opportunities and talent. The company represents some of the world's most iconic, barrier-breaking artists, creators and changemakers—from actors, athletes and musicians to writers, gamers and digital influencers. One of the most influential companies in global entertainment, UTA's business spans talent representation, content production, as well as strategic advisory and marketing work with some of the world's biggest brands. Affiliated companies include Digital Brand Architects, KLUTCH Sports Group, Curtis Brown Group, and MediaLink. UTA is headquartered in Los Angeles with offices in Atlanta, Chicago, Nashville, New York and London.
For more information:
https://www.unitedtalent.com/about/
UTA and its Affiliated Companies are Equal Employment Opportunity employers and welcome all job seekers including individuals with disabilities and veterans with disabilities.
#LI-CB1",1991,Culture & Entertainment,$5 to $25 million (USD),"Arts, Entertainment & Recreation",501 to 1000 Employees,Company - Private,False
AWS Data Engineer,"Agama Solutions
","San Francisco, CA",$106K - $143K (Glassdoor est.),4.5,"creating AWS infrastructure for Salesforce syncs to/from Redshift
managing AWS infrastructure as code using Terraform
understanding of AWS IAM roles and VPC connectivity are important
creating scripts to be run on said AWS infrastructure that performs the sync
uploading script deployment packages to AWS and Git
managing code on a properly-secured secret storage system so that passphrases/secrets are not committed directly in source code to AWS/Git
Good understanding of Salesforce APIs and platform behavior

Skill set:

Python (or Go Lang), AWS Lambda, AWS S3, AWS EC2, AWS Redshift, AWS Postgres, Informatica and SFDC config if not dev.",-1,Computer Hardware Development,$5 to $25 million (USD),Information Technology,51 to 200 Employees,Contract,False
Senior Software Engineer (Cloud/Data Lake ),"Palo Alto Networks
","Santa Clara, CA",$175K (Employer est.),4.1,"Company Description


Our Mission

At Palo Alto Networks® everything starts and ends with our mission:

Being the cybersecurity partner of choice, protecting our digital way of life.

Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.

Our Approach to Work

We lead with flexibility and choice in all of our people programs. We have disrupted the traditional view that all employees have the same needs and wants. We offer personalization and offer our employees the opportunity to choose what works best for them as often as possible - from your wellbeing support to your growth and development, and beyond!

At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!



Job Description


Your Career

Cortex Data Lake (CDL) enables AI-based innovations for cybersecurity with the industry’s only approach to normalizing and stitching together an enterprise’s data. Cortex Data Lake can:

Radically simplify customer security operations by collecting, integrating, and normalizing an enterprise’s security data
Effortlessly run advanced AI and machine learning with cloud-scale data and compute
Constantly learns from new data sources to evolve customer defenses

CDL is built to benefit from public cloud scale and locations ready for elastic scale, eliminating the need for local compute and storage. CDL has strict privacy and security controls in place to prevent unauthorized access to sensitive or identifiable information. Its infrastructure is secured with industry-standard best practices for security and confidentiality, including rigorous technical and organizational security controls.

Your Impact

Tackle new and challenging problems by building a new generation of highly scaled data processing and analytics systems for use in AI-powered use cases
Contribute in architecture, design and development of features
Solve complex problems in pipeline scaling and data storage to facilitate AI/ML analytics and AI-powered dashboards
Suggest and implement improvements to the development processes
Work with DevOps and Technical Support teams to investigate and resolve critical customer defects


Qualifications


Your Experience

Must have
8+ years of hands-on experience in building large enterprise applications primarily in Java
3+ years of experience as a backend Java developer on a distributed systems environment
Deep understanding of design patterns
Good communication skills and ability to work in a fast-paced environment
Good to have
Strong knowledge of databases SQL, NoSQL, Time series, GraphDB etc
Experience in working on cloud environments especially GCP
Knowledge of Linux fundamentals and networked computing environment concepts

Additional Information


The Team

Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.

We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.

Our Commitment

We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.

We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.

Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.

All your information will be kept confidential according to EEO guidelines.

The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/com-missioned roles) is expected to be $175,000/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.",2005,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Software Engineer, Big Data Infrastructure, 11+ Years of Experience","Snapchat
","Palo Alto, CA",$196K - $285K (Employer est.),3.7,"Snap Inc
is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are
Snapchat
, a visual messaging app that enhances your relationships with friends, family, and the world;
Lens Studio
, an augmented reality platform that powers AR across Snapchat and other services; and it's AR glasses,
Spectacles
.
Snap Engineering
teams build fun and technically sophisticated products that reach hundreds of millions of Snapchatters around the world, every day. We’re deeply committed to the well-being of everyone in our global community, which is why
our values
are at the root of everything we do. We move fast, with precision, and always execute with privacy at the forefront.
We are looking for a Software Engineer to join the Big Data Infrastructure team!
What you’ll do:
Architect, build and optimize Snap’s batch and real-time data processing infrastructure and platform for a wide range of use cases, including ML, ETL, reporting, and analytics
Collaborate across teams to design and enhance some of Snap’s most critical data applications
Act as a developer advocate and educator, promoting the adoption of big data best practices among Snap teams
Help in defining and building Snap’s DataLake solution to ensure it's efficient, compliant, and user-friendly
Knowledge, Skills & Abilities:
In-depth experience building and operating data systems at scale, with a focus on big data processing (either batch or streaming)
Proficiency in Java, C++, and/or Python, with a strong coding background in building robust and scalable systems
Proven ability to independently execute on medium to large-sized features, spanning multiple weeks and PRs
Strong understanding of the operational aspects of systems, and the ability to participate in incident or hotfix investigation and resolution
Excellent collaboration and communication skills, enabling effective teamwork across diverse technical teams
Familiarity with other Big Data technologies, NoSQL solutions, and cloud services (like Kubernetes, Google Cloud, AWS)
Minimum Qualifications:
BS/BA degree in a technical field such as Computer Science or equivalent years of experience
11+ years of software development experience
Specialization in building backend services and distributed systems
Familiarity with Apache Spark/Flink/Iceberg, Google Dataflow/Beam, or other pertinent big data technologies
Preferred Qualifications:
Experience building Flink/Spark/big data platform that serves enterprise use cases.
Expertise in building and optimizing large-scale big data applications
Hands-on experience deploying Spark/Flink on platforms like Kubernetes, ideally in a cloud setting
Specialization in building and operating Datalake/Lakehouse at scale
Familiar with MLOps/platforms with a large data footprint, such as training/feature data
Expertise in areas such as large-scale microservices, cloud computing, infrastructure design, networking, and data storage
""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office at least 80% of the time (an average of 4 days per week). For roles with remote consideration: Remote team members still are expected to travel for mandatory in-person gatherings and to fulfill business needs, at least 4 to 6 times per year.
At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at
accommodations-ext@snap.com
.
Our Benefits
: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!
Compensation
In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These pay zones may be modified in the future.
Zone A (CA, WA, NYC)
:
The base salary range for this position is $230,000-$335,000 annually.

Zone B
:
The base salary range for this position is $219,000-$318,000 annually.
Zone C
:
The base salary range for this position is $196,000-$285,000 annually.
This position is eligible for equity in the form of RSUs.",2011,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,5001 to 10000 Employees,Company - Public,False
Data Engineer IV,"Capital Group Companies
","Irvine, CA",$141K - $226K (Employer est.),4.1,"“I can succeed as a Data Engineer at Capital Group.""
As Data Engineer IV with an agile mindset, you will lead the design and implementation of large scale, critical and complex data solutions that source and integrate data from multiple investment data sources and publish to multiple distribution channel consumers with capabilities to monitor and manage data quality. You will partner with the business to influence ways to achieve business priorities and provide leadership through innovation, critical thinking, collaboration, and proactive risk management.
You will live by the motto: “you ship it, you own it,” by providing and receiving constructive code reviews and taking ownership of outcomes. Your data insights will drive business decisions that improve the lives of millions of people, every single day.
“I am the person Capital Group is looking for.”
You have a bachelor’s degree in Computer Science, Engineering, Data Science or a related technical field.
You have minimum 7 years of experience delivering data solutions, including data warehousing, data integration, data lake, reporting, and analytics.
You have demonstrated technical leadership in driving the solution design and implementation, along with continuous process improvement.
You have expertise and deep understanding of AWS cloud platform, deep working knowledge of AWS Services, such as: S3, Cloud Front, Cloud Watch, Cloud Trail, Cloud Formation, Lambda, SNS, Data Lake, Athena, Glue, EMR, Aurora, Spark, Presto SQL.
You have expert technical knowledge of AWS data pipeline technologies and a proven implementation track record with PySpark, with significant experience automating complex pipelines that include file based and API endpoints.
You have working knowledge of performance tuning and query optimization across large data sets with AWS data pipelines desired
You are an expert with SQL skills in data analysis, data profiling, data modeling and data visualizations skills, and Business Intelligence/Reporting and visualization skills (e.g., Tableau, SQL Server Reporting Services, PowerBI) desired
Strong experience in troubleshooting infrastructure bottlenecks at the storage, network, and/or compute layers desired
You have experience in developing custom application on AWS platform. Experience with front-end application frameworks like React or Angular and backend frameworks like Spring desired.
‎
Southern California Base Salary Range: $140,995-$225,592
‎
‎
‎
‎
‎
‎
‎
‎
‎
‎
‎
‎
‎
In addition to a highly competitive base salary, per plan guidelines, restrictions and vesting requirements, you also will be eligible for an individual annual performance bonus, plus Capital’s annual profitability bonus plus a retirement plan where Capital contributes 15% of your eligible earnings.
You can learn more about our compensation and benefits
here
.

We are an equal opportunity employer, which means we comply with all federal, state and local laws that prohibit discrimination when making all decisions about employment. As equal opportunity employers, our policies prohibit unlawful discrimination on the basis of race, religion, color, national origin, ancestry, sex (including gender and gender identity), pregnancy, childbirth and related medical conditions, age, physical or mental disability, medical condition, genetic information, marital status, sexual orientation, citizenship status, AIDS/HIV status, political activities or affiliations, military or veteran status, status as a victim of domestic violence, assault or stalking or any other characteristic protected by federal, state or local law.",1931,Investment & Asset Management,$1 to $5 billion (USD),Financial Services,5001 to 10000 Employees,Company - Private,False
"Senior Principal Software Engineer, Data Infrastructure, 14+ Years of Experience","Snapchat
","Palo Alto, CA",$259K - $370K (Employer est.),3.7,"Snap Inc
is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are
Snapchat
, a visual messaging app that enhances your relationships with friends, family, and the world;
Lens Studio
, an augmented reality platform that powers AR across Snapchat and other services; and it's AR glasses,
Spectacles
.
Snap Engineering
teams build fun and technically sophisticated products that reach hundreds of millions of Snapchatters around the world, every day. We’re deeply committed to the well-being of everyone in our global community, which is why
our values
are at the root of everything we do. We move fast, with precision, and always execute with privacy at the forefront.
We’re looking for a Senior Principal Software Engineer to join Snap Inc!
What you’ll do:
Design, implement, and scale critical engineering components and services to support Snap's most strategic initiatives
Work across teams to understand product requirements, evaluate trade-offs, and deliver the solutions needed to build innovative products or services
Advocate for and apply best practices when it comes to availability, scalability, operational excellence, and cost management
Provide technical direction that influences the entire company
Knowledge, Skills & Abilities
Excellent programming and software design skills, including debugging, performance analysis, and test design
Proven track record of operating highly-available systems at scale
Ability to proactively learn new concepts and technology and apply them at work
Skilled at solving ambiguous problems
Strong collaboration and mentorship skills
Minimum Qualifications:
Bachelors in technical field such as computer science, mathematics, statistics or equivalent years of experience
14+ years of industry experience
4+ years of experience acting as a technical lead
Experience in technical leadership/ownership and setting technical direction for engineering projects
Experience architecting, designing, and developing distributed systems
Preferred Qualifications:
Advanced degree in a technical field such as computer science
Experience with platform development
Ability to promote product excellence and collaboration, driving a portfolio of concurrent engineering projects, from short-term critical feature launches to long-term research initiatives.
Ability to create a compelling vision for the future, communicate clearly, and have a collaborative leadership approach.
""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office at least 80% of the time (an average of 4 days per week). For roles with remote consideration: Remote team members still are expected to travel for mandatory in-person gatherings and to fulfill business needs, at least 4 to 6 times per year
At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at
accommodations-ext@snap.com
.
Our Benefits
: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!
Compensation
In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These pay zones may be modified in the future.
Zone A (CA, WA, NYC)
:
The base salary range for this position is $305,000-$435,000 annually.

Zone B
:
The base salary range for this position is $290,000-$413,000 annually.
Zone C
:
The base salary range for this position is $259,000-$370,000 annually.
This position is eligible for equity in the form of RSUs.",2011,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,5001 to 10000 Employees,Company - Public,False
Controls and Data Systems Engineer,"SLAC National Accelerator Laboratory
","Menlo Park, CA",$108K - $163K (Employer est.),4.2,"SLAC Job Postings



Position overview:

Do you enjoy collaborating with a diverse group of people to solve complex challenges? Does contributing to breakthrough discoveries in science and working with unique experimental instrumentation in a world-leading scientific research environment excite you? The Photon Controls and Data Systems (PCDS) Department within the Linac Coherent Light Source (LCLS) Directorate at SLAC is seeking a Controls and Data Systems Engineer to plan, implement, and operate customized experimental installations, and develop enhancements to our scientific instrumentation and supporting hardware and software for the Control, Data Acquisition, and Data Analysis systems for the Hard X-ray science instruments (X-ray Pump Probe (XPP), X-ray Correlation Spectroscopy (XCS), Molecular Femtosecond Crystallography (MFX), and Coherent X-ray Imaging (CXI)).

Reporting to the Experiment Control Systems Delivery Department Head, the Controls and Data Systems Engineer will be a member of a multidisciplinary team comprised of electronic engineers and software developers focused on developing software and hardware solutions to support scientific instrumentation, laser systems, controls, and data acquisition systems. This position will also work with scientific and operations support staff involved in advancing scientific instrumentation capabilities. LCLS is the world’s first hard x-ray free electron laser (FEL) with unprecedented capabilities in photon energy range, peak power, and pulse lengths. There are seven independent instruments currently in operation, which are specifically designed to utilize the exceptional beam characteristics of the LCLS to probe the structure and dynamics of matter at atomic size and timescales. The evolution of science and experimental techniques on these instruments, along with upgrades in the x-ray FEL source and optical lasers (LCLS-II), require regular improvements to the supporting software and hardware platforms.

See for more on LCLS and the unique capabilities of our instrument facilities.

Your specific responsibilities include:

Plan, implement, and operate customized experimental installations.
Reconfigure hardware and software to meet experimental need; develop software for data analysis, data acquisition, controls, and to support new instrumentation.
Manage hardware and software for the controls, data acquisition, and data-analysis systems and related infrastructure such as computers and local networks, x-ray detector systems, digitizers, scopes, cameras, power supplies, motion systems, vacuum and PLC systems, etc.
Participate in upgrades to scientific instrumentation and capabilities including laser systems, timing systems, hardware and software selection, and lead teams of engineers and technicians to implement and integrate the control, data acquisition, and analysis aspects of these upgrades.

Additional opportunities include development toward, or project leadership for core capabilities of the CDS systems including:

Real time Data Acquisition and EPICS (Experimental Physics and Industrial Control System) control system software and driver development.
Real-time and offline data analysis frameworks which run on Field Programmable Gate Arrays (FPGAs), Graphics Processing Units (GPUs), teraflop computing clusters, multi-petabyte storage systems at SLAC and NERSC.
Graphical User Interface framework.

New and unique instrumentation and electronics systems such as

Sample delivery systems.
Peta-Watt laser systems.
Femtosecond timing systems.
X-ray sensitive CCD cameras and detectors.
Machine and human protection systems.

To be successful in this position you will bring:

Bachelor's degree in physics, computer science, engineering or related discipline and 2 years of relevant experience in data analysis, experimental process, design and development of prototypes, scientific instrumentation and/or systems. Advanced degree strongly preferred.
Ability to learn and understand the workings of a broad range of hardware and software.
Demonstrated programming skills with C and/or C++ and experience with Linux/Unix and a scripting language such as (and preferably) Python.
Exceptional communications skills and ability to work well in a research and development team.
Demonstrated project leadership, planning, and excellent organizational skills.
Ability to understand the basic functionality and scientific purpose of each part of the x-ray science instrument.

In addition, preferred requirements include:

Real-time and networking software, familiarity with EPICS framework, knowledge of motor, vacuum and camera controls.
Developing scientific instrumentation, laser and laser diagnostic systems.
Background in x-ray or material science.

SLAC Employee Competencies:

Effective Decisions: Uses job knowledge and solid judgment to make quality decisions in a timely manner.
Self-Development: Pursues a variety of venues and opportunities to continue learning and developing.
Dependability: Can be counted on to deliver results with a sense of personal responsibility for expected outcomes.
Initiative: Pursues work and interactions proactively with optimism, positive energy, and motivation to move things forward.
Adaptability: Flexes as needed when change occurs, maintains an open outlook while adjusting and accommodating changes.
Communication: Ensures effective information flow to various audiences and creates and delivers clear, appropriate written, spoken, presented messages.
Relationships: Builds relationships to foster trust, collaboration, and a positive climate to achieve common goals.

Physical requirements and Working conditions:

Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.
Given the nature of this position, SLAC will require onsite work.

Work Standard:

Interpersonal Skills: Demonstrates the ability to work well with Stanford colleagues and clients and with external organizations.
Promote Culture of Safety: Demonstrates commitment to personal responsibility and value for environment, safety and security; communicates related concerns; uses and promotes safe behaviors based on training and lessons learned. Meets the applicable roles and responsibilities as described in the ESH Manual, Chapter 1—General Policy and Responsibilities:
Subject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University's Administrative Guide,

-

Classification Title: Staff Engineer
Grade: K, Job Code: 0132
Duration: Regular Continuing

The expected pay range for this position is $108,000 to $163,000 per annum. SLAC National Accelerator Laboratory/Stanford University provides pay ranges representing its good faith estimate of what the university reasonably expects to pay for a position. The pay offered to a selected candidate will be determined based on factors such as (but not limited to) the scope and responsibilities of the position, the qualifications of the selected candidate, departmental budget availability, internal equity, geographic location and external market pay for comparable jobs.",1962,National Agencies,Unknown / Non-Applicable,Government & Public Administration,1001 to 5000 Employees,Government,False
Lead Application Engineer Data Center,"Cadence Design Systems
",California,$94K - $174K (Employer est.),4.3,"At Cadence, we hire and develop leaders and innovators who want to make an impact on the world of technology.
Implement Professional Services offerings that focus on accelerating implementations, creating, and evolving best practices for rolling out Digital Twin services.
Present Digital twin service offerings aligned to enterprise, hyperscale, co-location, and edge market segments, including value positioning, the scope of service, collateral, and pricing.
Understand customer requirements and work with them to develop and manage project scope.
Provide project delivery leadership on small to large, complex, and highly strategic solutions involving single to integrated solution deals.
Collaborate with sales and development teams to build project and deployment plans to understand and document customers’ expectations.
Work to understand how our clients use our products and help identify growth opportunities within existing accounts
Work with clients and educate them on product features and functionality through training/webinars and workshops to improve adoption and usage
Gather client feedback on product challenges to help improve the product.
Serve as the internal escalation point for complex technical client issues.
Coordinate project schedules and tasks and manage progress to ensure on-time, quality delivery of business requirements.
Develop project metrics, such as time-to-value, customer satisfaction, and on-time completion of projects.
Provide regular project status updates to clients and internal teams.
Train and mentor junior engineers and channel partners in the practices and procedures for selling and delivering Digital Twin projects.
Identify and mitigate risks.
Provide regular KPI reports of professional services work effort and status, from quoting to delivery, including resource utilization and project health.
The ideal candidate should have the following:
BS required in mechanical, aerospace, or equivalent, MS Preferred
At least 3-5 years of experience in Data center cooling and/or power technologies
Experience with Datacenter simulation tools like 6SigmaDCX or similar
Experience with DCIM tools and Databases like MongoDB desired
Customer service oriented with strong problem-solving skills
Strong attention to detail with the ability to organize and prioritize
Team player with a positive attitude, willing to offer and start, run ideas and solutions to enhance processes within an evolving environment
Prepared to travel and work at customer sites throughout North America
Must be in California or New York and be authorized to work in the US
The annual salary range for California is $93,800 to $174,200. You may also be eligible to receive incentive compensation: bonus, equity, and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the salary range is a guideline and compensation may vary based on factors such as qualifications, skill level, competencies and work location. Our benefits programs include: paid vacation and paid holidays, 401(k) plan with employer match, employee stock purchase plan, a variety of medical, dental and vision plan options, and more.
We’re doing work that matters. Help us solve what others can’t.",1988,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,10000+ Employees,Company - Public,False
Senior Software Engineer - Big Data,"Intuit
","Mountain View, CA",$146K - $186K (Glassdoor est.),4.4,"Overview

Come join Intuit as a Senior Software Engineer!

What you'll bring
BS in Computer Science or equivalent work experience
Strong CS fundamentals including data structures, algorithms and distributed systems.
Strong database fundamentals including SQL, performance and schema design.
Strong programming skills in Java, Scala, Python, or similar.
Experience with Git
6+ years of hands-on software engineering experience.
6+ years of experience integrating technical processes and business outcomes – specifically: data and process analysis, data quality metrics/monitoring, data architecture, developing policies/standards & supporting processes.
Experience with Spark, Hive, Hadoop, Kafka, Columnar Databases and Graph Databases.
Experience with various offerings from AWS, including S3, EMR, DynamoDB, EC2 and Athena
1+ years DevOps experience including configuration, optimization, backup, high reliability, monitoring and systems version control.
Track record working with data from multiple sources – willingness to dig-in and understand the data and to leverage creative thinking and problem-solving.
Excellent interpersonal and communication skills, including business writing and presentations. Ability to communicate objectives, plans, status and results clearly, focusing on critical few key points. Demonstrated ability to work in a matrix environment, ability to influence at all levels, and build strong relationships.
Knowledge of enacting service level agreements and the appropriate escalation and communication plans to maintain them
How you will lead
Design and develop big data and real-time analytics solutions using industry standard technologies.
Work with data architects to ensure that Big Data solutions are aligned with company-wide technology directions.
Lead fast moving development teams using agile methodologies.
Lead by example, demonstrating best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting, and incident response.
Communicate progress across organizations and levels from individual contributor to senior executive. Identify and clarify the critical few issues that need action and drive appropriate decisions and actions. Communicate results clearly and in actionable form.
Serve as technical “go to” person for our core technologies – Kafka, Spark, AWS and others.
Demonstrate strong implementation aptitude to translate objectives into a scalable solution to meet the needs of the end customer while meeting deadlines.
Demonstrate commitment to your professional development by attending conferences, taking classes, giving technical presentations, and participating in developer communities inside and outside of Intuit.",1983,Software Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Principal Engineer Software (Prisma Access Data-plane Applications),"Palo Alto Networks
","Santa Clara, CA",$144K - $233K (Employer est.),4.1,"Company Description


Our Mission

At Palo Alto Networks® everything starts and ends with our mission:

Being the cybersecurity partner of choice, protecting our digital way of life.

Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.

Our Approach to Work

We lead with flexibility and choice in all of our people programs. We have disrupted the traditional view that all employees have the same needs and wants. We offer personalization and offer our employees the opportunity to choose what works best for them as often as possible - from your well-being support to your growth and development, and beyond!

At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!



Job Description


Your Career

Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.

We are seeking an experienced Software Engineer to design, develop and deliver next-generation technologies within our Prisma Access team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. We are looking for leaders who take ownership of their areas of focus and who are driven to solve problems at every level. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate at a high level and work well with others towards achieving a common goal.

Your Impact

Design, develop and implement highly scalable software features and infrastructure on our next-generation security platform ready for cloud native deployment from inception to completion
Work with different development and quality assurance groups to achieve the best quality - You accomplish this by being hands-on, creating tools, processes, and systems that produce transparency, alignment, and direction
Profile, optimize and tune systems software (management/control/dataplane) for efficient cloud operation
Work with DevOps and the Technical Support teams to troubleshoot customer issues
Work with other software development team to apply PanOS features on Prisma Access
Interview, mentor and coach new team members


Qualifications


Your Experience

6+ years of experience in developing data-plane applications
Strong C/C++ Programming, Data structures/Algorithms & debugging
Experience with building applications in the cloud
Nice to have hands-on programming experience in Python and Go
Working experience with Envoy is strongly desired
In-depth understanding of Operating System principles and OS like Linux/Unix
In-depth understanding of networking concepts and TCP/IP stack, TLS
Exposure to building Microservices
Enjoys working with many different teams with strong collaboration and communication skills
Solid foundation in design, data structures, and algorithms, and strong analytical and debugging skills

Education

M.S./B.S. degree in Computer Science or equivalent military experience required

Additional Information


The Team

Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.

We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.

Our Commitment

We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.

We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.

Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.

All your information will be kept confidential according to EEO guidelines.

The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $144,200/yr to $233,200/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.

#LI-SM2",2005,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Infrastructure Engineer,Coframe,"San Francisco, CA",-1,-1.0,"One day, we’ll look at the digital interfaces we use today the same way we now look at floppy disks and dial-up internet.

Backed by Khosla Ventures and Nat Friedman, Coframe is pioneering this next generation of user interfaces that can adapt, evolve, and improve themselves: living interfaces.

We’re solving fundamental problems in AI and product, training multimodal models that understand users and business goals to enable user interfaces to continuously and autonomously improve themselves.

The ideal candidate has had experience building and managing data pipelines with large volume capacity and performing ETL for machine learning and AI models.

If you thrive in collaborative, early-stage startup environments and get excited about the future of user interfaces, we invite you to apply.",-1,-1,-1,-1,-1,-1,True
"Staff Engineer, Test Data and Instrumentation","Rivian
","Irvine, CA",$104K - $155K (Glassdoor est.),3.4,"About Rivian:
Rivian is on a mission to keep the world adventurous forever. This goes for the emissions-free Electric Adventure Vehicles we build, and the curious, courageous souls we seek to attract.

As a company, we constantly challenge what’s possible, never simply accepting what has always been done. We reframe old problems, seek new solutions and operate comfortably in areas that are unknown. Our backgrounds are diverse, but our team shares a love of the outdoors and a desire to protect it for future generations.
Responsibilities:
Assist in developing engineering group data logging and storage strategies
Identify acquisition hardware needs across multiple development programs and phases
Integrate high volume cloud data with bespoke and specialized engineering acquisition systems (fleet durability, road load data capture, etc.)
Research and implement emerging technologies to improve and optimize company-wide practices
Develop, specify, procure, use and train others in use of, and maintain data acquisition sensors, systems, practices and databases for all aspects of vehicle measurement (thermal, strain, NVH, and digital networks among others)
Leading Vehicle level design validation (DVP) testing instrumentation efforts
Liaison across multiple engineering departments
Qualifications:
7+ years in a similar role
Bachelors Degree or higher required
Mechanical/Mechatronics or similar background desired
Embedded Controls knowledge and cloud / big data system management preferred
Detailed experience working hands-on with in-vehicle data acquisition systems including experiment design, installation, use, and data analysis
Direct experience working with CAN, LIN, and Ethernet vehicle data networks, including debugging and reverse engineering
Racing/professional high performance instrumentation background preferred
Proving grounds and on-road / on-track experience a plus
Willing to travel up to of 25% of the time
Eye for detail with a focus on quality
Proven experience with at least 2 major vehicle systems (EG, Electric Powertrain, Chassis / Suspension, HVAC, Braking, etc.)
Pay Disclosure:
Salary range for California Based Applicants: $150,000-$173,000 (actual compensation will be determined based on experience, location, and other factors permitted by law).

Benefits Summary: Rivian provides robust medical/Rx, dental and vision insurance packages for full-time employees, their spouse or domestic partner, and children up to age 26. Coverage is effective on the first day of employment, and Rivian covers most of the premiums.
Company Statements:
Equal Opportunity
Rivian is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, ancestry, sex, sexual orientation, gender, gender expression, gender identity, genetic information or characteristics, physical or mental disability, marital/domestic partner status, age, military/veteran status, medical condition, or any other characteristic protected by law.

Rivian is committed to ensuring that our hiring process is accessible for persons with disabilities. If you have a disability or limitation, such as those covered by the Americans with Disabilities Act, that requires accommodations to assist you in the search and application process, please email us at candidateaccommodations@rivian.com.
Candidate Data Privacy
Rivian may collect, use and disclose your personal information or personal data (within the meaning of the applicable data protection laws) when you apply for employment and/or participate in our recruitment processes (“Candidate Personal Data”). This data includes contact, demographic, communications, educational, professional, employment, social media/website, network/device, recruiting system usage/interaction, security and preference information. Rivian may use your Candidate Personal Data for the purposes of (i) tracking interactions with our recruiting system; (ii) carrying out, analyzing and improving our application and recruitment process, including assessing you and your application and conducting employment, background and reference checks; (iii) establishing an employment relationship or entering into an employment contract with you; (iv) complying with our legal, regulatory and corporate governance obligations; (v) recordkeeping; (vi) ensuring network and information security and preventing fraud; and (vii) as otherwise required or permitted by applicable law.

Rivian may share your Candidate Personal Data with (i) internal personnel who have a need to know such information in order to perform their duties, including individuals on our People Team, Finance, Legal, and the team(s) with the position(s) for which you are applying; (ii) Rivian affiliates; and (iii) Rivian’s service providers, including providers of background checks, staffing services, and cloud services.

Rivian may transfer or store internationally your Candidate Personal Data, including to or in the United States, Canada, the United Kingdom, and the European Union and in the cloud, and this data may be subject to the laws and accessible to the courts, law enforcement and national security authorities of such jurisdictions.

Please note that we are currently not accepting applications from third party application services.",2009,Transportation Equipment Manufacturing,Unknown / Non-Applicable,Manufacturing,5001 to 10000 Employees,Company - Public,False
Staff Software Engineer - Front End - Data Visualization,"ServiceNow
","Santa Clara, CA",$152K - $266K (Employer est.),4.4,"Company Description


At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.

With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.

Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.

Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.


Job Description


We are currently seeking a Staff Software Engineer with experience designing and developing business intelligence and or data analytics applications.

In this role, you will be part of the ServiceNow Cloud Services Big Data Team. The Big Data team is building the next-generation platform that collects, stores and provides real-time access to large amounts of data.

You will be driving the design and implementation of ServiceNow in-house real-time data visualization and analytics platform to support the growth of ServiceNow.

What you get to do in this role:

Bring your innovation and experience in designing and developing the next generation data analytics platform using cutting-edge technologies.
Play a lead role with our global engineering team to drive end to end product design and implementation.
Standardize processes for complete development cycle including design, implementation, unit testing, code review, testing automation etc.
Research and adopt the right technologies to improve the scalability and productivity of the engineering group.
Work closely with key stakeholders and product owners to drive technical design for requirements of various use cases.
Coordinate with cross-function teams (DevOps, network, QA, etc.) to ensure a smooth cycle from development to deployment.

Qualifications


To be successful in this role you have:

6+ years of software development experience in data visualization, data analytics, BI tools and Hadoop ecosystem.
Hands-on experience architecting enterprise data analytics products with high scalability and performance.
Expert level skills with JavaScript, ReactJS strongly preferred along with NodeJS, Webpack or other modern UI frameworks, Java and REST API development.
Strong troubleshooting and debugging skills.
Experience and knowledge on ServiceNow Platform development is preferred
Ability to produce high-quality software that is unit tested, code reviewed, and checked in regularly for continuous integration.
Solid background in complicated SQL & data analytics.
Zeal for learning and adopting new ideas and patterns.
Strong Computer Science fundamentals, data structures, algorithms, and software design.

GCS-23

For positions in the Bay Area, we offer a base pay of $152,000 - $266,000, plus equity (when applicable), variable/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs (subject to eligibility requirements). Compensation is based on the geographic location in which the role is located, and is subject to change based on work location.


Additional Information


ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.

At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.

If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.

For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.

Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.




From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.

Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",2004,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Staff Software Engineer, Data Infrastructure","Rippling
","San Francisco, CA",$180K - $279K (Employer est.),3.4,"About Rippling
Rippling is the first way for businesses to manage all of their HR & IT—payroll, benefits, computers, apps, and more—in one unified workforce platform.

By connecting every business system to one source of truth for employee data, businesses can automate all of the manual work they normally need to do to make employee changes. Take onboarding, for example. With Rippling, you can just click a button and set up a new employees’ payroll, health insurance, work computer, and third-party apps—like Slack, Zoom, and Office 365—all within 90 seconds.

Based in San Francisco, CA, Rippling has raised $1.2B from the world’s top investors—including Kleiner Perkins, Founders Fund, Sequoia, Bedrock, and Greenoaks—and was named one of America’s best startup employers by Forbes (#12 out of 500).
About The Role
Rippling is the system of record for employee data - a complete Employee Management System. To solve this broad problem, a variety of applications and datasets need to come together as a graph connected through the employee record at its center. Hence, Rippling is building a customer data cloud to ingest and connect data from thousands of sources to power complex workflows, approvals, permissions, dashboards and reports.

We need a data platform to make it easy to make all forms of data accessible for different use cases, perform various transformations and query efficiently for a variety of online and offline use cases. You will be working on building this distributed data platform, defining key APIs, designing to scale, high availability, and handling both online, streaming and batch scenarios.

At Rippling, to support various use cases we use Redis, Mongo, Postgres, Kafka, Apache Pinot and Apache Presto for OLAP, and S3 and Snowflake for data lake and warehousing.
What You'll Do:

Lead our data processing and streaming platform (Kafka, Spark, Flink, Airflow, In-house grown workflow solutions) to solve various data processing needs by ML and Product teams

Work closely with our ML engineers to understand their offline and online data processing needs and propose the right solutions for them
Work on our data replication streaming platform (Kafka, Kafka Connectors) to build a polyglot self serve data platform to replicate data across various data stores (Apache Pinot, ElasticSearch etc.) to solve various product team needs at very high scale

Evaluate closed and open source data technologies to support Rippling’s exponential growth

Qualifications:

8+ years of professional work experience.

Experience working in a fast-paced, dynamic environment.

Experience in building projects with the right user abstractions and architecture.

Comfortable developing scalable and extendable core services used in many products.

Additional Information

Rippling is an equal opportunity employer. We are committed to building a diverse and inclusive workforce and do not discriminate based on race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, veteran or military status, or any other legally protected characteristics, Rippling is committed to providing reasonable accommodations for candidates with disabilities who need assistance during the hiring process. To request a reasonable accommodation, please email accomodations@rippling.com

Rippling highly values having employees working in-office to foster a collaborative work environment and company culture. For office-based employees (employees who live within a 40 mile radius of a Rippling office), Rippling considers working in the office, at least three times a week under current policy, to be an essential function of the employee's role.

This role will receive a competitive salary + benefits + equity. The salary for US-based employees will be aligned with one of the ranges below based on location.

A variety of factors are considered when determining someone’s compensation–including a candidate’s professional background, experience, and location. Final offer amounts may vary from the amounts listed below.",2016,Computer Hardware Development,$100 to $500 million (USD),Information Technology,1001 to 5000 Employees,Company - Private,False
Frontend Engineer Lead (Data Visualization),"Aquabyte
","San Francisco, CA",$120K - $150K (Employer est.),3.8,"Aquabyte is seeking a Lead Frontend Engineer to build an UI application that enables fish farm's sustainable operations across the world.

This role is on a hybrid split-week schedule, splitting time working in the office and working from home. #LI-Hybrid

We're happy to announce the completion of our Series B round of funding to continue our mission of transforming aquaculture to meet the world’s demand for sustainable protein!

Watch a short documentary on Aquabyte with Amazon's CTO at a Norwegian fish farm here! https://youtu.be/YZ_qJ5JFD3I

Our mission
Aquabyte is on a mission to revolutionize the sustainability and efficiency of aquaculture. By making fish farming cheaper and more viable than livestock production, we aim to mitigate one of the biggest causes of climate change and help prepare our planet for impending population growth. Aquaculture is the single fastest growing food-production sector in the world, and now is the time to define how technology is used to harvest the sea and preserve for generations to come.

We are a diverse, mission-driven team that is eager to work alongside kindred spirits. If this vision makes you smile, gives you goosebumps, or otherwise inspires you please get in touch.

Our product
We are currently focused on helping salmon farmers better understand their fish populations and make environmentally-sound decisions. Through custom underwater cameras, computer vision, and machine learning we are able to quantify fish weights, track fish health, and generate optimal feeding plans in real time. Our product operates at three levels: on-site hardware for image capture, cloud pipelines for data processing, and a user-facing web application. As a result, there are hundreds of moving pieces and no shortage of fascinating challenges across all levels of the stack.

Above all, Aquabyte is a customer-driven company. Our product development is dictated by the needs of fish farmers and we prioritize customer delight in everything we do. We are committed to build a global, collaborative team that creates value far beyond Silicon Valley.

The role
As a Lead Frontend Engineer at Aquabyte, you will build the UI for our fish farmer customers. You work well with product managers and UX designers and have the desire to build awesome products. You understand the language of our research scientists and are inspired to transform the numbers into insightful data visualizations. You are also responsible for foundation tools such as user management, authentication and authorization. Last but not least, you have a commitment to deliver high-quality software products and continuous improvement.
Job Requirements
5 years of frontend engineering experience, especially with React
Proficiency in HTML/CSS, JavaScript and Typescript
Experience with building interactive frontend interfaces for data-intensive applications
Experience in databases, in writing and optimizing SQL queries
Experience of building application in cloud environment
Benefits
Competitive salaries and generous equity
Unlimited vacation policy
Flexible working hours + hybrid work policy
Medical, vision, & dental insurance
Retirement plan
Potential travel to Norway
Evolve in a fast-paced environment
Be able to shape a business in its early days
Get ideas, feedback, and suggestions from other best-in-their-field colleagues
Mentorship opportunities, we'll be dedicated to investing in you and supporting you as you grow
$120,000 - $150,000 a year
Aquabyte takes a market-based approach to salary and equity. The pay varies on a variety of factors including: job-related qualification, years of experience and competence level, interview performance, and work location.
Aquabyte is a private company headquartered in San Francisco, and is supported by NEA, Costanoa Ventures, and many other respected investors.

At Aquabyte, we admire interesting people with a unique background. We strongly encourage you to apply even if you don’t satisfy all the requirements, and we will get back to you as soon as possible!",2017,Enterprise Software & Network Solutions,$5 to $25 million (USD),Information Technology,1 to 50 Employees,Company - Private,False
"IS Engineer, Data Scientist - Police (1042)","City and County of San Francisco
","San Francisco, CA",$129K - $162K (Employer est.),3.7,"Company Description


The San Francisco Police Department was established in 1849 and continually strives to become a more effective, inclusive and modern police department, while earning the trust and pride of those we serve and those who serve. Our goal is to reflect on current SFPD initiatives, assess best practices across the country, and evaluate the changing environment in policing and within the City to arrive at a strategy statement that the Department and our community can embody every day.

The San Francisco Police Department stands for Safety and Respect for All. We will engage in just transparent unbiased and responsive policing. We will do so in the spirit of dignity and in collaboration with the community. And we will maintain and build trust and respect as the guardians of Constitutional and human rights.

The San Francisco Police Department is committed to excellence in law enforcement and is dedicated to the people, traditions and diversity of our City. The department provides service with understanding, response with compassion, performance with integrity and law enforcement with vision. The department has grown into a nationally known police department providing law enforcement services to one of the most recognized cities in the United States.

Specific information regarding this recruitment process are listed below:

Application Opening: November 21, 2023
Application Deadline: Apply immediately, announcement may close anytime after two weeks from posting date.
Class & Compensation: $129,064 - $162,344
Recruitment ID: PEX-1042-141102
Work Location: SFPD Headquarters, 1245 3rd Street, San Francisco, CA 94158. Telecommuting work schedule available inline with CCSF policy.


Job Description


The Strategic Management Bureau (SMB) of the SFPD manages all major strategic projects for the department, to include police reform, change management, technology implementation, auditing, and policy development and implementation. As our new data scientist, you would immediately contribute to ongoing and yet to be approved projects at the department level, in one of the top 20 law enforcement agencies in the nation by size.

Under general direction of the SMB Program Manager and Business Analysis Team Lead, the 1042 IS Engineer (Journey) functions as a Data Scientist employing generally accepted data science techniques on dozens of available datasets. You will join our team as an analytics expert and data advisor/architect to assist the department in the development of its data collection, analysis, transparency, reporting and warehousing programs. You will help identify opportunities for data modeling and visualization, conduct and communicate the analysis and help deploy the insights into reports and operations. You will be a member of a team of data analyst who work to deliver the best insights using data and knowledge of business practices to provide reporting to the public, our enterprise, our accountability partners, local, state, and federal government entities, and the public at large.

Essential Duties:

Generates, define, and refine data science projects and manage a portfolio of data science projects from conception to implementation.
Conduct a range of analyses or experiments using whatever statistical and modeling methods and tools are most appropriate.
Serve as subject matter expert and help improve the skills of department data analysts, the efficiency of the workflow, and the quality of the work and outputs.
Develop data visualizations and tools to support analysis.
Conduct research and analysis as needed to inform the data analysis.
Develop presentations and communicate the results of your work.
Help develop and implement products, services, tools, or business process changes resulting from the analysis.
Create and maintain data pipelines for open data and data science projects as needed.
Advise the department on data architecture, collection and warehousing programs and policies.
Provide technical assistance and guidance to data analysts implementing their own analytical work.
Perform other related duties as assigned.


Qualifications

Education: An associate degree in computer science or a closely related field from an accredited college or university OR its equivalent in terms of total course credits/units [i.e., at least sixty (60) semester or ninety (90) quarter credits/units with a minimum of twenty (20) semester or thirty (30) quarter credits/units in computer science or a closely-related field].

AND

Experience: One (1) year of full-time experience analyzing, installing, configuring, enhancing, and/or maintaining the components of an enterprise network.

Substitution: Additional experience as described above may be substituted for the required degree on a year-for-year basis (up to a maximum of two (2) years). One (1) year is equivalent to thirty (30) semester units/r forty-five (45) quarter units with a minimum of 10 semester / 15 quarter units in computer science or a closely related field.

Desirable Qualifications:

Masters in GIS, computer science, engineering, statistics, mathematics, economics, engineering, policy analysis, public policy, user-centered design or related field.
Demonstrated experience with the following:
Python and R and fluency in SQL.
GIS and mapping concepts and tools or equivalent.
Data visualization tools.
Concepts of information design and presentation, including principles of visual encoding and communication.

Verification of Education and Experience: Applicants may be required to submit verification of qualifying education and experience at any point during the recruitment and selection process. If education verification is required, information on how to verify education requirements, including verifying foreign education credits or degree equivalency, can be found at https://sfdhr.org/how-verify-education-requirements

Note: Falsifying one’s education, training, or work experience or attempted deception on the application may result in disqualification for this and future job opportunities with the City and County of San Francisco.

All work experience, education, training and other information substantiating how you meet the minimum qualifications must be included on your application by the filing deadline. Information submitted after the filing deadline will not be considered in determining whether you meet the minimum qualifications.

Resumes will not be accepted in lieu of a completed City and County of San Francisco application.

Applications completed improperly may be cause for ineligibility or disqualification.

Background Investigation: Prior to employment with the San Francisco Police Department, a thorough background investigation will be conducted to determine the candidate’s suitability for employment. The investigation may include, but not be limited to: criminal history records, driving records, drug/alcohol screening, and other related employment and personal history records. Reasons for rejection may include use of controlled substances and alcohol, felony conviction, repeated or serious violations of the law, inability to work with co-workers, inability to accept supervision, inability to follow rules and regulations or other relevant factors. Candidates may be required to undergo drug/alcohol screening, and must clear Department of Justice and Federal Bureau of Investigation fingerprinting. Criminal records will be carefully reviewed; candidates who do not report their complete criminal records on their applications will be disqualified. Applicants will be fingerprinted.


Additional Information


Recruiter Information: If you have any questions regarding this recruitment or application process, please contact the Human Resources Analyst, Danny Wan at danny.wan@sfgov.org.

Additional Information Regarding Employment with the City and County of San Francisco:

Information About The Hiring Process
Conviction History
Employee Benefits Overview
Equal Employment Opportunity
Disaster Service Worker
ADA Accommodation
Right to Work
Copies of Application Documents
Diversity Statement

SFPD Recruitment: https://www.sanfranciscopolice.org/your-sfpd/careers

The City and County of San Francisco encourages women, minorities and persons with disabilities to apply. Applicants will be considered regardless of their sex, race, age, religion, color, national origin, ancestry, physical disability, mental disability, medical condition (associated with cancer, a history of cancer, or genetic characteristics), HIV/AIDS status, genetic information, marital status, sexual orientation, gender, gender identity, gender expression, military and veteran status, or other protected category under the law.",-1,State & Regional Agencies,Unknown / Non-Applicable,Government & Public Administration,Unknown,Government,False
Power Systems Engineer - Data Science Applications,"Lawrence Livermore National Laboratory
","Livermore, CA",$106K - $137K (Employer est.),4.4,"Company Description

Join us and make YOUR mark on the World!

Are you interested in joining some of the brightest talent in the world to strengthen the United States’ security? Come join Lawrence Livermore National Laboratory (LLNL) where our employees apply their expertise to create solutions for BIG ideas that make our world a better place.

We are committed to a diverse and equitable workforce with an inclusive culture that values and celebrates the diversity of our people, talents, ideas, experiences, and perspectives. This is important for continued success of the Laboratory’s mission.

Pay Range

$106,440 - $136,680 Annually for the SES.1 level
$127,680 - $163,968 Annually for the SES.2 level

Please note that the pay range information is a general guideline only. Many factors are taken into consideration when setting starting pay including education, experience, the external labor market, and internal equity.

Job Description

We are looking for engineers and scientists with expertise in power engineering and machine learning to help us use data science to modernize the power grid. Your work will help us make the grid more secure against climate change, improve reliability, and reduce operational costs. You will have opportunities to work on exciting projects and develop new skills.

We are looking for expertise in power engineering (power systems modeling, simulation and analysis) combined with experience in machine learning and data science (anomaly detection and classification, pattern recognition, unsupervised and supervised learning techniques, deep reinforcement learning, time series data processing).

These positions will be filled at either the SES.1 or SES.2 level based on knowledge and related experience as assessed by the hiring team. Additional job responsibilities will be assigned if you are selected at the higher level.

You will

Participate in research in power grid modeling and simulation which creates and implement new state-of- the-art algorithms. Participate in research in applying data science to power system engineering applications, reporting to principal investigators and program management.
Partner with scientists and engineers at LLNL, and external collaborators such as electric utilities and technology providers.
Co-author peer-reviewed scientific papers, reports and deliver presentations for audiences internal and external to LLNL.
Perform tasks as assigned to you on projects.

Additional job responsibilities, at the SES.2 level

Engage directly with sponsors and partners and participate in development of new program business.
Qualifications
Ability to secure and maintain a U.S. DOE Q-level security clearance which requires U.S. citizenship.
Master’s degree in Engineering, Computer Science, or relevant fields, or equivalent combination of education and related experience.
Fundamental knowledge of and experience in the following areas: power system automation, operations, and planning, modeling and simulation, machine learning/artificial intelligence.
Experience with standard programming languages to support data analytics, visualization, and algorithm development for machine learning/artificial intelligence.
Ability to collaborate well in a team environment, present and explain technical information, and document .

Additional qualifications at the SES.2 level

Comprehensive and state-of-the-art knowledge and broad experience in the application and development in areas including: power systems engineering, power systems operation and planning, modeling and simulation, and machine learning/artificial intelligence.
Ability to lead technical discussions, collaborate in diverse team environment, present and explain complex technical information.

Qualifications We Desire

Ph.D. in Electrical Engineering or Computer Science, or equivalent level of demonstrated knowledge.
1+ years of experience working with utilities, Department of Energy (DOE), and/or other relevant state government agencies.
Additional Information

All your information will be kept confidential according to EEO guidelines.

#smartjobs

Position Information

This is a Career Indefinite position, open to Lab employees and external candidates.

Why Lawrence Livermore National Laboratory?

Flexible Benefits Package
401(k)
Relocation Assistance
Education Reimbursement Program
Flexible schedules (*depending on project needs)
Inclusion, Diversity, Equity and Accountability (IDEA) - visit https://www.llnl.gov/diversity
Our core beliefs - visit https://www.llnl.gov/diversity/our-values
Employee engagement - visit https://www.llnl.gov/diversity/employee-engagement

Security Clearance

This position requires a Department of Energy (DOE) Q-level clearance. If you are selected, we will initiate a Federal background investigation to determine if you meet eligibility requirements for access to classified information or matter. Also, all L or Q cleared employees are subject to random drug testing. Q-level clearance requires U.S. citizenship.

Pre-Employment Drug Test

External applicant(s) selected for this position must pass a post-offer, pre-employment drug test. This includes testing for use of marijuana as Federal Law applies to us as a Federal Contractor.

How to identify fake job advertisements

Please be aware of recruitment scams where people or entities are misusing the name of Lawrence Livermore National Laboratory (LLNL) to post fake job advertisements. LLNL never extends an offer without a personal interview and will never charge a fee for joining our company. All current job openings are displayed on the Career Page under “Find Your Job” of our website. If you have encountered a job posting or have been approached with a job offer that you suspect may be fraudulent, we strongly recommend you do not respond.

To learn more about recruitment scams: https://www.llnl.gov/sites/www/files/2023-05/LLNL-Job-Fraud-Statement-Updated-4.26.23.pdf

Equal Employment Opportunity

We are an equal opportunity employer that is committed to providing all with a work environment free of discrimination and harassment. All qualified applicants will receive consideration for employment without regard to race, color, religion, marital status, national origin, ancestry, sex, sexual orientation, gender identity, disability, medical condition, pregnancy, protected veteran status, age, citizenship, or any other characteristic protected by applicable laws.

We invite you to review the Equal Employment Opportunity posters which include EEO is the Law and Pay Transparency Nondiscrimination Provision.

Reasonable Accommodation

Our goal is to create an accessible and inclusive experience for all candidates applying and interviewing at the Laboratory. If you need a reasonable accommodation during the application or the recruiting process, please use our online form to submit a request.

California Privacy Notice

The California Consumer Privacy Act (CCPA) grants privacy rights to all California residents. The law also entitles job applicants, employees, and non-employee workers to be notified of what personal information LLNL collects and for what purpose. The Employee Privacy Notice can be accessed here.",1952,National Agencies,$1 to $5 billion (USD),Government & Public Administration,5001 to 10000 Employees,Government,False
Senior Offensive Security Engineer – Data Center Systems,"NVIDIA
","Santa Clara, CA",$144K - $270K (Employer est.),4.6,"NVIDIA is searching for a highly motivated, creative engineer with experience in system software and background in security to join the Server Platform Software team. You will focus on offensive security efforts for our Data Center Systems, such as NVIDIA HGX, DGX, and MGX. NVIDIA is leading the way in groundbreaking developments in Artificial Intelligence, High-Performance Computing and Visualization. The GPU, our invention, serves as the visual cortex of modern computers and is at the heart of our products and services.
What you’ll be doing:
Identify vulnerabilities in our Data Center Systems, build proof of concepts, and work with development teams to remediate
Perform security reviews of software and hardware designs and assist others to ensure quality and robustness of our products
Evangelize and drive adoption of new or improved tools, practices, and plans to increase product robustness and reliability
What we need to see:
BS or MS degree in Computer Engineering, Computer Science, or related degree (or equivalent experience).
5+ years of meaningful software engineering experience
Demonstrate security experience in either a forensic or an offensive security focused role
Excellent C programming
Background with software development lifecycle best practices, e.g. threat modeling, unit testing, incident response, code audit, etc.
Experience with secure code quality practices and tooling to support quick engagements and rapid analysis - static analysis tools (Coverity, Checkmarx, or similar), dynamic scanning (Rapid 7, AppSider, or similar), Fuzzing (AFL, Peach, or similar) and code coverage (Bullseye, LDRA, etc)
Familiarity with modern server architectures
Effective written and verbal communication regardless of audience or issue complexity
Ability to work collaboratively and remotely with others to accomplish complex goals
Ways to stand out from the crowd:
Experience with System reversing and exploitation. Experience with penetration techniques and tools
Experience and familiarity with GPU accelerated computing systems
Familiarity with computer system architecture, microprocessor, and microcontroller fundamentals (caches, buses, memory controllers, DMA, etc.)
NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people on the planet working for us. If you're creative, passionate and self-motivated, we want to hear from you!
The base salary range is 144,000 USD - 270,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
. NVIDIA accepts applications on an ongoing basis.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",1993,Computer Hardware Development,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Software Engineer, Platform Data Science","Terray Therapeutics
","Monrovia, CA",$116K - $165K (Employer est.),2.7,"Company Overview

Terray is a biotechnology company with the technology, data, and mindset to radically change the way we discover and develop small molecule therapeutics. We explore molecules and targets broadly and deeply with a sophisticated integration of ultra-high throughput experimentation, generative AI, biology, medicinal chemistry, automation, and nanotechnology. Everything the company does is grounded in an iterative approach, producing massive amounts of precise, purpose-built data mapping interactions between small molecules and causes of disease that gets increasingly valuable with each cycle of design and experimentation. The company’s platform uniquely blends experimentation and computation to improve the cost, speed, and success rate of small molecule drug discovery and development.

Position Summary

Terray is currently seeking a motivated, creative, and experienced full-stack software engineer. As an integral member of our Computational and Data Science (CDS) team, the candidate will be responsible for developing and maintaining the data pipelines and user interfaces that power our tArray wet-lab experimentation platform. More specifically, the candidate will be a member of the Platform Data Science group within CDS, which handles the data for tArray workflows including library synthesis, image processing, chip decoding, and screening.

The core responsibilities of this position are:

Automate and productionize the data pipelines and tools used by the Platform Data Science group.
Design, build, and maintain user interfaces for wet-lab scientists to visualize and interact with their data.
Collaborate with the laboratory automation team to develop tools to ingest data from our microscope platform and other automated instruments.
Work with the DevOps team to deploy and monitor these pipelines and tools.
Experience and Qualifications

Part of Terray’s success is nurtured by a hands-on work environment where everyone is accountable, vested in a vision of excellence, and actively taking part in the success of the business. Terray supports a positive work environment where employees can feel engaged, recognized and empowered to be creative.

Required Qualifications
Proficiency in Python, the PyData stack (numpy, pandas, etc.), and web frameworks like Streamlit or FastAPI
Familiarity with wet-lab procedures and interest in learning more about this field · Experience in UI/UX design and soliciting feedback from end users (for an internally-facing product)
Experience in all phases of the software lifecycle from planning to maintenance
Familiarity with relational databases (MySQL) and proficiency in interacting with these via SQL and ORMs (Django)
Familiarity with batch processing (Slurm, AWS Batch), workflow management (e.g. Airflow), and AWS cloud resources.
Compensation Details

$116,000 - $165,000 (annually) depending on seniority; participation in the Company's option plan; 3% 401K contribution; full benefits.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,False
"Data Lake Engineer, Table Formats - Accelerated Apache Spark","NVIDIA
","Santa Clara, CA",$268K - $414K (Employer est.),4.6,"We are seeking experienced Distributed Systems Engineers to accelerate Apache Spark and related frameworks on GPUs. Apache Spark is the most popular distributed data processing engine in data centers. It is used for a wide variety of workloads, from data preparation, feature generation, reporting, analytics, and more. Data scientists spend a considerable amount of time exploring data and iterating over machine learning (ML) experiments. Every hour of compute required to sort through datasets, extract features and fit ML algorithms impedes an efficient business workflow. At NVIDIA, we are passionate about working on hard problems that have an impact. You will work with the open source community to enable Apache Spark data processing with GPUs. Data workflows can benefit tremendously from being accelerated, enabling data scientists to explore many more and larger datasets to achieve their business goals, faster and more efficiently.
What you'll be doing:
Extending the RAPIDS Accelerator for Apache Spark to work seamlessly with data lake table formats – including Delta Lake, Apache Iceberg, and Apache Hudi
Benchmarking and optimizing data lake table formats at scale with NVIDIA GPUs
Optimizing I/O operations on table layout formats and backing stores (distributed filesystems, object stores)
Engaging open source communities, including Apache Spark,
RAPIDS
, and for technical discussions and contributions around data lake table formats
Creating a collection of GPU accelerated libraries for data processing, data analytics and ML for compatibility with data lake table formats
Working with NVIDIA strategic partners on deploying sophisticated data analytics solutions in public cloud or on-premise clusters
Presenting technical solutions in industry conferences and meetups
What we need to see:
BS, MS, or PhD in Computer Science, Computer Engineering, or equivalent experience
15+ years of work or research experience in software development
5+ years working with key open source big-data projects as a contributor or committer including Delta Lake, Apache Iceberg, Apache Hudi, Apache Spark, Apache Hadoop, Apache Flink, Apache Kafka, Apache Storm and Apache Hive
Understanding of data management architecture and experience with table formats at large scale
Experience with Apache Parquet, Apache ORC, Apache Arrow
Outstanding technical skills in crafting and implementing high-quality distributed systems
Excellent programming skills in C++, Java, and/or Scala
Knowledge of distributed system schedulers: Kubernetes, Hadoop YARN, Spark standalone
Able to work successfully with multi-functional teams across organizational boundaries and geographies
Highly motivated with strong communication skills
Ways to stand out from the crowd:
Development work on one or more of Delta Lake, Apache Iceberg, Apache Hudi, preferably with contributions back to the open source community
Track record of contributions to major open source projects (such as Apache Spark, Apache Hadoop, Apache Flink, Apache Kafka, Apache Arrow)
Working experience with acceleration libraries (CUDA, RAPIDS, UCX)

We are widely considered to be one of the technology world’s most desirable employers, and as a result have some of the most forward-thinking and hardworking people in the world working for us. If you're passionate, creative, and driven, we'd love to have you join the team. With competitive salaries and a generous benefits package, we are widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us and, due to unprecedented growth, our exclusive engineering teams are rapidly growing. If you're a creative and autonomous engineer with a real passion for technology, we want to hear from you.
The base salary range is 268,000 USD - 414,000 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
. NVIDIA accepts applications on an ongoing basis.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",1993,Computer Hardware Development,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Senior Data Engineer,"ANDURIL INDUSTRIES
","Costa Mesa, CA",$136K - $204K (Employer est.),4.4,"Anduril Industries is a defense technology company with a mission to transform U.S. and allied military capabilities with advanced technology. By bringing the expertise, technology, and business model of the 21st century’s most innovative companies to the defense industry, Anduril is changing how military systems are designed, built and sold. Anduril’s family of systems is powered by Lattice OS, an AI-powered operating system that turns thousands of data streams into a realtime, 3D command and control center. As the world enters an era of strategic competition, Anduril is committed to bringing cutting-edge autonomy, AI, computer vision, sensor fusion, and networking technology to the military in months, not years.

As the first Data Engineer to join the Analytics Team, you will be collaborating with stakeholders across the company to design, build and implement data pipelines and models that enable our next generation of technology to be deployed around the world. You will have a hand in helping shape the data platform vision at Anduril.

We’re looking for software and data engineers who are seeking high impact collaborative roles focused on driving operational execution. Ideally you are looking to learn what it takes to build the next generation of defense technology.
What You'll Do
Lead the design and roadmap for our data platform infrastructure
Partner with operations, product, and engineering to advocate best practices and build supporting systems and infrastructure for the various data needs
Own the ingest and egress frameworks for data pipelines that stitch together various data sources in order to produce valuable data products that drive the business
Required Qualifications
5+ years of experience in a data engineering role building products, ideally in a fast-paced environment
You are motivated by our mission. We are working to solve the biggest problems in defense
Good foundations in Python or another object oriented language
Experience with Spark, PySpark, Glue, SQL, dbt and Redshift
Experience with AWS, Azure, or GCP security ecosystem, containerization, and associated tooling
Knowledge of data & visualization tools, such as Tableau
Understand the importance of engineering with security’s best practices in mind
You are empathetic: you are eager to see the world from your users’ perspective
You’re energized by business impact & a self-starter: you love to drive the direction of ambiguous projects
Must be able to obtain and hold a U.S. Top Secret security clearance.
$136,000 - $204,000 a year
For Full Time Employment Opportunities: The salary range for this role is an estimate based on a wide range of compensation factors, inclusive of base salary only. Actual salary offer may vary based on (but not limited to) work experience, education and/or training, critical skills, and/or business considerations. Highly competitive equity grants are included in all offers and are considered part of Anduril’s total compensation package. Additionally, Anduril offers top-tier benefits, including comprehensive medical, dental, and vision plans, employee life and disability, mental health and family planning benefits with all premiums paid by Anduril. Anduril provides fully paid medical leave, paid company holidays, and paid time off. A professional development stipend is available to all Andurilians and all on-site meals are fully subsidized during the work week through use of our gourmet kitchens. The recruiter assigned to this role can share more information about the specific compensation and benefit details associated with this role during the hiring process.

Anduril is an equal-opportunity employer committed to creating a diverse and inclusive workplace. The Anduril team is made up of incredibly talented and unique individuals, who together are disrupting industry norms by creating new paths towards the future of defense technology. All qualified applicants will be treated with respect and receive equal consideration for employment without regard to race, color, creed, religion, sex, gender identity, sexual orientation, national origin, disability, uniform service, Veteran status, age, or any other protected characteristic per federal, state, or local law, including those with a criminal history, in a manner consistent with the requirements of applicable state and local laws, including the CA Fair Chance Initiative for Hiring Ordinance. We actively encourage members of recognized minorities, women, Veterans, and those with disabilities to apply, and we work to create a welcoming and supportive environment for all applicants throughout the interview process. If you are someone passionate about working on problems that have a real-world impact, we’d love to hear from you!",2017,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,1001 to 5000 Employees,Company - Private,False
Staff Engineer - Nutanix Data Lens,"Nutanix
","San Jose, CA",$172K - $344K (Employer est.),4.1,"Hungry, Humble, Honest, with Heart.

The Opportunity

Nutanix combines its industry-leading software-defined storage technologies with a cloud-based multi-tenant solution (NDL) to build the best-in-breed data management and security solution.

You will join an impactful, fast-moving unified storage group team. You will be crucial in designing and developing reliable, efficient, and high-performance software for large-scale enterprise and hybrid cloud environments. Your work will involve understanding complex distributed systems and solving customer requirements by designing innovative solutions. Working closely with various teams, you will contribute to delivering high-quality products in a fast-paced environment. The role also offers the opportunity to engage with customers and support them in resolving production issues. You will have the opportunity to address technical debt and drive aggressive performance goals for the platform, while ensuring prompt resolution of customer issues by collaborating with support and SRE teams.

Engineering / R&D at Nutanix

Nutanix Data Lens, a new product offering, is a cloud-based data management, security and compliance solution for Nutanix unified storage - Files and Objects. The product not only supports Nutanix unified storage but also supports other storage systems. NDL helps developers build the integrated data pipeline with storage systems, utilizing the cloud platform for speedy feature rollout and better manageability and support. For business owners, NDL helps reduce data blindness and gives a comprehensive view of data on data complying with security and compliance standards. Some of these features are already available to our customers and need further improvements to make it enterprise-grade.

We are utilizing a primary tech stack of:

Go Lang and Python
Kubernetes
Cloud platform
Snowflake
Interface with storage system and build data pipeline.
APIs and Ui stack running on containers

Your Role

Design and develop the features that interface with the storage systems and build the comprehensive security analytics features.
Develop a good understanding of Cloud services, Snowflake, and building data pipelines that are performance and cost-effective
Suggest the cloud solution that can help optimize the cost and the performance.
Develop software features and unit tests designed as per Nutanix framework
Review and mentor Junior engineer's work and guide them with code design.
Work with the Nutanix Global (mainly India and USA) engineering and multi-functional teams

What You Will Bring

BS/MS degree in Computer science or equivalent
10-15 years of experience building products on distributed systems
Strong knowledge of Cloud platform, APIs, containers, Kubernetes, and Snowflake
Knowledge of building microservices-based applications.
Hands-on development in either Golang or Python
Strong development experience in Linux/Unix OS platform
Hands-on experience working with version control / DevOps tools – Git, Gerrit, or Jenkins
Working knowledge of security domain - Ransomware protection, Anomaly detection, data compliance

About the Team

Meet Pankaj Sinha

Joined Nutanix in 2015 and currently leading the Data Lens technical team. Grew the team organically from zero engineers to a team of 50+ with multiple engineering leaders.
Currently leading the charter to build scalable and enterprise-grade storage analytics solutions [Data pipeline, Smart Tiering, Ransomware protection, Scheduler] and NDL team in the US, Europe, and India
25+ Years of experience building and shipping products with startups, Nutanix, Cisco, and Applied Materials.

What The Team Says

“Pankaj is very dedicated and driven for the projects he works on. He takes his job seriously and he has owner's mindset. His intent is always to get the job done most efficiently. He also understands the challenges in peer teams and ready to cooperate and help..”
“Pankaj is a great person to work with; very logical in his approach, understands the quality aspect of the project really well, always willing to help. He also tries to hire the best.”
""Have bias for action is probably Pankaj's strongest asset - Just get heads down, and get things done. The sheer grit that goes along with it, and not worrying about what the noise in the rest of the org, is a great dependable behavior to lean on.""

How We Work

As a global team, we work in various regions worldwide and function asynchronously as much as possible. Every engineer is given full autonomy and responsibility to work on features while collaborating with other stakeholders. As we work on some of the industry-leading solutions, we are focused on learning and leading the way when it comes to infrastructure solutions for hybrid cloud. We mainly focus on getting our customers the most ROI and strive to be the best HCI solution in the world, whether from a performance or savings perspective.

The pay range for this position at commencement of employment is expected to be between USD $ 172000 and USD $ 344400 per year.

However, base pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position may also include other elements, including a sign-on bonus, restricted stock units, and discretionary awards in addition to a full range of medical, financial, and/or other benefits (including 401(k) eligibility and various paid time off benefits, such as vacation, sick time, and parental leave), dependent on the position offered. Details of participation in these benefit plans will be provided if an employee receives an offer of employment.

If hired, employee will be in an “at-will position” and the Company reserves the right to modify base salary (as well as any other discretionary payment or compensation program) at any time, including for reasons related to individual performance, Company or individual department/team performance, and market factors.",2009,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,5001 to 10000 Employees,Company - Public,False
Sr Principal UI Engineer (Data Visualization),"Palo Alto Networks
","Santa Clara, CA",$170K - $275K (Employer est.),4.1,"Company Description


Our Mission

At Palo Alto Networks® everything starts and ends with our mission:

Being the cybersecurity partner of choice, protecting our digital way of life.

Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.

Our Approach to Work

We lead with flexibility and choice in all of our people programs. We have disrupted the traditional view that all employees have the same needs and wants. We offer personalization and offer our employees the opportunity to choose what works best for them as often as possible - from your wellbeing support to your growth and development, and beyond!

At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!



Job Description


Your Career

Our NetSec UI Engineering team is set out to build best-in-class, novel data visualization experiences that are custom to the cybersecurity use cases, for all the product teams across Network Security vertical at Palo Alto Networks. As a Data Visualization Engineer at Palo Alto Networks, your work will directly reach, and empower our products that are revolutionizing the cybersecurity industry.

Your Impact

Collaborate cross functionally with designers, data visualization experts, and engineers on the NetSec UI team to implement and support the reusable, and customizable data visualization components
Implement an architecture for the data visualization library that is scalable to multiple JS frameworks, and in the future Web Components
Write quality, and meaningful tests, and documentation to ensure easy adoption of the data visualization library
Create a playground GUI with a custom settings bar that users can play around with to tweak the different properties of the visualization


Qualifications


Your Experience

Bachelor’s degree or higher in Computer Science, Information Technology, Engineering, or equivalent experience or equivalent military experience required
10+ years professional experience as a data visualization /front-end engineer
Portfolio showcasing data visualization development proficiency
Great team player, willing to take on new challenging tasks
Self-driven with ability to work both independently and within a team environment to accomplish goals and objectives
Expertise in JavaScript, D3, WebGL, and/or Shader language GL/SL, HTML, CSS
Experience massaging large raw datasets to work well with simple and intuitive data visualization
Familiarity with client-side modern build processes & tools - Webpack/Rollup
Comfortable with maintaining, and contributing to code repositories using git, GitHub/GitLab or other version control
Ability to create quick prototypes for data visualization projects with D3js

Bonus Points

Strong in frontend web development technologies, including ReactJS, TypeScript, with bonus points for experience with animation
Familiarity or willingness to learn data visualization technologies like VegaJS, ThreeJS, Observable Plot or new cutting edge libraries
Passion for building performant, interactive and accessible data visualization components

Additional Information


The Team

The NetSec UI team is responsible for delivering UI solutions to our customers at Palo Alto Networks. Our team has a unique position in driving efforts to create accessible, performant, and cutting edge UI and data visualization components/modules.

We foster a culture of innovation, authenticity, and collaboration. Our people make this possible. It’s in our everyday interactions, how we work together and treat each other, that sets Palo Alto Networks apart from other organizations.

Our Commitment

We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.

We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.

Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.

All your information will be kept confidential according to EEO guidelines.

The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000/yr to $275,000/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.",2005,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Distinguished Engineer, Advanced Data Analytics, Google Cloud","Google
","Sunnyvale, CA",-1,4.4,"Minimum qualifications:
Bachelor’s degree in Computer Science, Engineering, a similar technical field of study, or equivalent practical experience

15 years of professional software engineering experience

Experience in analytics, including generative AI, responsible AI and real time data processing


Preferred qualifications:
Experience as a thought leader in data analytics and AI/ML, and experience in technology innovation

Experience in AI/ML quality evaluation and improvement, including managing tuning techniques with cost/benefit tradeoffs

Ability to promote product excellence and collaboration driving a portfolio of concurrent engineering projects (e.g., short-term critical feature launches to long-term research initiatives)

Passionate about delighting enterprise customers, with an excellent understanding of enterprise workloads

About the job

In this role, you will define the long-term technical and innovation strategy for Data Analytics and bring your point of view on technology leadership, research, and industry trends. You will employ a hybrid approach of direct technical guidance, mentorship, high-level consulting, and risk/growth management. You will also collaborate with the Data Analytics leadership team.


Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.

The US base salary range for this full-time position is $316,000-$469,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.


Responsibilities
Co-lead the technology and innovation strategy for Data Analytics with a focus on Generative AI, Machine Learning and their connection to big data, realtime data, and Business Intelligence (BI) systems.

Assess long-term technological investments, and calibrate opportunities against each other and available bandwidth.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",1998,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer II (Hybrid Work Schedule),"Inland Empire Health Plan
","Rancho Cucamonga, CA",$64K - $92K (Glassdoor est.),3.6,"Job Requisition ID: 10068




Position Summary/Position




The Data Engineer II assists in the implementation of methods to improve data reliability and quality. This role is responsible for combining raw information from different sources to create consistent and machine-readable formats. The Data Engineer II must also develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling. The Data Engineer II will focus on data accessibility, which will enable the organization to utilize data for performance evaluation and optimization. The data Engineer II is also responsible for managing the entire back-end development life cycle for the company's enterprise data warehouse. In this role the incumbent will handle tasks associated with the implementation of ETL procedures, building warehouse databases, database performance management, and dimensional modeling and design of the table structures.

Major Functions (Duties and Responsibilities)




1. Design and develop data warehouse Extraction, Transformation and Loading (ETL) solutions using Microsoft SQL Server Integration Services (SSIS), Azure Data Factory, Synapse Analytics, Az Data Bricks, PySpark ETL.
2. Develop and implement data collection processes in conjunction with the data warehouse. Source data from legacy systems supporting a centralized data warehouse and reporting platform.
3. Develop technical solutions to meet the requirements for Data Warehouse, BI & Analytics
4. Work closely with the data engineering and BI & Analytics teams to design data and analytics solutions to increase the usability, completeness, and accuracy of enterprise data
5. Analyze user requirements and translate into database requirements and implement in database code
6. Create and maintain the optimal data pipeline architectures based on micro services based on platform and application requirements
7. Assemble large, complex data sets that meet functional / non-functional business requirements
8. Identify, design, and implement process improvements: automating manual pipeline processes, optimizing data ingestion and consumption, re-designing infrastructure for greater scalability, micro services, etc
9. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
10. Work closely with Data Warehouse Architect and Data Systems Architect to design data and analytics solutions to increase the usability, completeness, and accuracy of enterprise data
11. Create, maintain, and optimize SQL queries and routines
12. Analyze potential data quality issues to determine the root cause and create effective solutions.
13. Develop, adopt, and enforce Data Warehouse and ETL standards and architecture
14. Monitor and support ETL processes ensuring integrity and proper integration of all data sources
15. Create high throughput historical and incremental ETL jobs
16. Facilitate problem management, and communication among data architects, managers, informaticists and analysts
17. Provide detailed analysis of data issues; data mapping; and the process for automation and enhancement of data quality
18. Perform development activities such as source to target mapping validations, identify, document and execute unit test cases/scripts, peer and lead code reviews per code review checklist and document test and review results.
19. Collaborate and contribute to data integration strategies and visions
20. Provide ongoing proactive technical support for ETL and data warehouse system to ensure business continuity.
21. Work with Informaticists and Analysts to translate analytic requirements into technical solutions.

Supervisory Responsibilities
Leading: Self
Experience Qualifications




Four (4) years of relevant work experience. Experience and knowledge in logical, rational, dimensional, and physical data modeling. Background in database systems along with a strong knowledge of SQL. Experience with Orchestration tools, Azure DevOps, and CI/CD. Intermediate experience with the following tools and technologies:
a. Azure Data Catalogue / Purview
b. Azure Cloud
c. Databricks
d. Power BI Dataflows
e. Power Query
f. Azure Cosmos
g. Azure Monitor
h. PowerShell
i. Python

Preferred Experience




Development experience using PySpark, Spark, Hadoop, Kubernetes, and RDMIS is highly desired.

Education Qualifications




Bachelor's degree from an accredited institution required.

Preferred Education




Master’s degree from an accredited institution preferred.

Professional Certification




Azure Data Engineering Certification is preferred.

Drivers License Required
No
Knowledge Requirement




Multi-server environment knowledge such as linked servers, data replication, backup/restore with MS SQL Server 2008+. Knowledge of applicable data privacy practices and laws.

Skills Requirement




Highly skilled in developing and optimizing T-SQL (DDL, DML, DCL) queries, stored procedures, functions, and views for various applications that involve numerous database tables and complex business logic. Good written and oral communication skills. Strong technical documentation skills. Good interpersonal skills.

Abilities Requirement




Highly self-motivated and directed. Keen attention to detail. Proven analytical and problem-solving abilities. Ability to effectively prioritize and execute tasks in a high-pressure environment.

Commitment to Team Culture




The IEHP Team environment requires a Team Member to participate in the IEHP Team Culture. A Team Member demonstrates support of the Culture by developing professional and effective working relationships that include elements of respect and cooperation with Team Members, Members and associates outside of our organization.

Working Conditions




Word processing and programming involving computer keyboard and screens.

Position is eligible for Hybrid work location upon completing the necessary steps and receiving HR approval. All IEHP positions approved for telecommute or hybrid work locations may periodically be required to report to IEHP’s main campus for mandatory in-person meetings or for other business needs as determined by IEHP leadership.

Work Model Location
Hybrid
Physical Requirements
Hearing: One-on-One - FREQUENTLY
Communicate: Information/ideas verbally - FREQUENTLY
Near Visual Acuity - FREQUENTLY
Regular contacts: co-workers, supervisor - FREQUENTLY
Memory - FREQUENTLY
Understand and follow direction - FREQUENTLY
Regular and reliable attendance - CONSTANTLY
Keyboarding: 10-Key - FREQUENTLY
Keyboarding: Touch-Screen - FREQUENTLY
Keyboarding: Traditional - FREQUENTLY
Sitting - FREQUENTLY
Indoors - FREQUENTLY
Lighting - CONSTANTLY

A reasonable salary expectation is between $91,000.00 and $116,022.40, based upon experience and internal equity.

Inland Empire Health Plan (IEHP) is the largest not-for-profit Medi-Cal and Medicare health plan in the Inland Empire. We are also one of the largest employers in the region, designated as “Great Place to Work.” With a provider network of more than 5,000 and a team of more than 3,000 employees, IEHP provides quality, accessible healthcare services to more than 1.5 million members. And our Mission, Vision, and Values help guide us in the development of innovative programs and the creation of an award-winning workplace. As the healthcare landscape is transformed, we’re ready to make a difference today and in the years to come. Join our Team and make a difference with us! IEHP offers a competitive salary and stellar benefit package with a value estimated at 35% of the annual salary, including medical, dental, vision, team bonus, and state pension plan.",1996,Health Care Services & Hospitals,$1 to $5 billion (USD),Healthcare,1001 to 5000 Employees,Company - Public,False
"Data Engineer, Product Analytics","Meta
","Burlingame, CA",$109K - $166K (Employer est.),3.9,"As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match.



Data Engineer, Product Analytics Responsibilities:

Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
Design, build and launch new data models and visualizations in production, leveraging common development toolkits
Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
Support existing processes running in production and implement optimized solutions with limited guidance
Define and manage SLA for data sets in allocated areas of ownership




Minimum Qualifications:

Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
2+ years of work experience in data engineering
Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)




Preferred Qualifications:

Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy
Experience working with terabyte to petabyte scale data




About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.



Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",2004,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Integration Engineer: US Technology Team,"Apple
","Cupertino, CA",-1,4.2,"Summary
Posted: Nov 14, 2023
Weekly Hours: 40
Role Number:200519877
Imagine what you could do here. At Apple, new ideas have a way of becoming outstanding products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish! Apple’s Sales organization generates the revenue needed to fuel our ongoing development of products and services. This, in turn, enriches the lives of hundreds of millions of people around the world. We are, in many ways, the face of Apple to our largest customers. Apple's US Technology Team is looking for a talented individual who is passionate about crafting, implementing, and operating solutions that have a direct and measurable impact on Apple Sales and its customers. As a Data Integration Engineer, you will develop infrastructure, systems, services, and tools for automating sales processes. We’re looking for an exceptional engineer that lives at the intersection of development, operations, data, and systems engineering to build solutions for large-scale continuous data transformation and delivery.
Key Qualifications
Eagerness and ability to learn new skills and solve dynamic problems in an encouraging and expansive environment.
8+ years of experience building scalable micro services and integrations.
2+ years working with Channels and Sales teams
2+ years of customer-facing experience (e.g., sales / solutions engineering, technical consulting, system integration, project management for enterprise accounts, etc.)
Experience articulating and translating business questions into data solutions.
Proficiency in API development (REST, GraphQL, gRPC).
Broad knowledge of web standards relating to REST, HTTP, JSON, etc.
Strong understanding of data modeling, data warehousing, and ETL concepts (Dataiku experience is a plus).
Experience with data integration and data governance tools (e.g., Talend, Informatica, or Collibra)
Proficiency in SQL and experience with at least one major data analytics platform, such as Hadoop, Spark, or Snowflake.
Experience with basic frontend dev (HTML, CSS, JavaScript, Bootstrap, JQuery, etc).
Familiarity with cloud paradigms (e.g., AWS).
Familiarity with Salesforce platform is desirable
Proficiency in programming languages and tools such as Python, R, Git, Airflow, Notebooks.
Ability to lead development projects from start to finish.
Experience building and deploying semantic layers for analytics data is a plus
Able to balance competing priorities, long-term projects, and ad hoc requirements.
Ability to work in a fast-paced, dynamic, constantly evolving business environment.
Description
- Responsible for the development and design of data integrations and data ingestion processes for Apple internal and external data. - Collaborate with external partners including communicating requirements, building relationships with our Partners’ key decision makers, and serving as their technical point of contact. - Collaborate with Sales, Analytics, Data Science, other technical teams, and other internal business partners to understand and drive data-related requirements, to deliver the right solutions. - Develop data models and mapping rules to transform raw data into actionable insights and reports. - Collaborate with the analytics and data science teams to understand their requirements and deliver solutions that meet their needs. - Design and implement a semantic layer that integrates analytics data from multiple sources in an efficient and effective manner. - Play an active role in the development and maintenance of user documentation, including data models, mapping rules, and data dictionaries. - Ensure data quality and accuracy by developing data validation and reconciliation processes.
Education & Experience
BS or MS in Computer Science or equivalent industry experience
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",1976,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Data Engineer, TikTok Multimedia","TikTok
","San Jose, CA",$145K - $250K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices, including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the Team
The Multimedia Data Platform team is responsible for optimizing app experience related to performance for TikTok users by providing data support. Working in collaboration with various teams throughout TikTok, the data platform team focuses on the creation and consumption of video content to provide comprehensive optimization solutions. This includes end-to-end optimization solutions such as client, video shooting, uploading, video playback, video delivery and player, etc.

Responsibilities:
Our Multimedia data platform team work closely with our product managers and data analysts by building state of the art streaming and batch data processing solution. The entire data pipeline is not only supporting the core business at TikTok -- short video, but also horizontal business across TikTok. In this role, you will see a direct link between your work, and the company's business success. You will have opportunities to deal with Petabyte-level data warehouse. Some of the world's most challenging technical and business problems are waiting for you to solve.


Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to build systems that meet quality needs.
Build systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational and engineering excellence best practices.
Analyze systems, define transformation requirements, design suitable data models and document the design/specifications.
Demonstrate passion for quality and productivity by using efficient development techniques, standards and guidelines.
Drive the design, to build, execute, and maintain automated tests and/or manage deep data profiling runs to ensure data products and pipelines meet expectations
Partner with analysts, engineers, subject matter experts, and product managers to apply TikTok Multimedia analytical and quality methods to satisfy client needs.
Participate in the growth of the Data Quality Excellence practice by sharing knowledge and lessons learned, continually improving best practices, and contributing to methods that will systematically advance workforce capabilities
Effectively communicate through technical documentation, commented code, and interactions with stakeholders and adjacent teams
Contribute to building a vibrant workplace, where teams can thrive, and model the organization’s positive, supportive culture of respect and excellence
Qualifications

BS/BA in Technical Field, Computer Science or Mathematics.
3+ years experience in the data warehouse space.
3+ years experience in custom ETL design, implementation and maintenance.
2+ years experience working with big data technologies (Hadoop, Hive, Spark, Clickhouse, etc.) .
2+ years experience with schema design and dimensional data modeling.
3+ years experience in writing SQL statements.
Proficient in one of Programming languages (e.g., Python, Go, C++)
Communication skills, including the ability to identify and communicate data driven insights.
Ability in managing and communicating data warehouse plans to internal clients.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at gprd.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $145000 - $250000 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Principal Data Systems Engineer,"Neogene Therapeutics
","Santa Monica, CA",$114K - $166K (Glassdoor est.),5.0,"Pushing the frontier of solid cancer therapy, Neogene Therapeutics is a global, clinical stage biotechnology company built on the premise of innovation and novel paradigm-changing science. Using tumor mutation profiles to engineer fully individualized T cell therapies, Neogene is bringing new hope to address the current limitations of treatments available today.

We offer the opportunity to join a highly dynamic biotech with locations in Amsterdam, Netherlands and in Santa Monica, CA. You can expect a collaborative environment created by a team with deep scientific expertise and an industrial track-record in T cell therapies.

Neogene values pro-active team-players who pursue their goals with dedication, endurance, and a daring mindset. If you share our commitment to make a difference to patients in need, we can provide an exciting opportunity for your career.

Position Summary

The Principal Data Systems Engineer is responsible for leading data initiatives and serving as a fundamental member of our highly adaptable IT team. This role carries the dual responsibility of refining the data infrastructure and ensuring its seamless integration with essential applications crucial to our operations. It represents the synergy between robust data systems and application-level strategies. The role is based in Santa Monica, CA and reports to the Sr. Director, IT Applications and Data Analytics.

Essential Functions and Responsibilities

Lead the design, development, and deployment of business applications and analytical solutions to bolster our operations.
Collaborate closely with Technical Operations, Research & Discovery, and corporate functions to align IT strategies with our business objectives. Communicate complex concepts effectively, ensuring a shared understanding across departments.
Transform user stories into actionable, value-driven deliverables while championing Agile methodologies for streamlined development.
Create robust interfaces, APIs, and ELT/ETL pipelines to facilitate seamless data flow across diverse platforms.
Proficiently utilize AWS services, including EC2, Lambda, EMR, S3, and EKS, and employ DevOps tools to ensure efficient code migrations and deployments.
Define, promote, and uphold best practices and standards within the IT team.

Supervisory Responsibilities

None for this role.

Required Skills/Abilities

In-depth understanding of system development life cycles, methodologies, distributed computing principles, and best practices.
Proficient analytical skills, with the ability to collect, organize, analyze, and share extensive data while maintaining attention to detail and accuracy.
Familiarity with a wide range of tools, platforms, and technologies relevant to data systems and modern application development paradigms.

Education and Experience

BS in computer science or related field preferred, with a minimum of 8 years of experience.
Experience with data pipeline and workflow management tools like Azkaban, Luigi, Airflow, etc.
Exposure or understanding of the biotech or pharmaceutical industry is a plus.
Exposure to statistical modeling, machine learning, and deep learning techniques, and their practical applications in a business context is also preferred.

The anticipated salary range for candidates who will work in Santa Monica, CA is $145,000 to $170,000. The final salary offered to a successful candidate will be dependent on several factors that may include but are not limited to the type and length of experience within the job type and length of experience within the industry, education, etc.

Note: At this time, Neogene is not sponsoring VISAs.



At Neogene we celebrate the diversity of our employees and our leadership. Neogene is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status or any other characteristic protected by law.

DE&I Statement

Headline: We embrace our individual differences.

""Our mission is to build a workforce reflective of our communities to be receptive to patients' broad and unique perspectives, enabling us to empathize with their needs. Together, we strive to uphold a value system that promotes:

Opportunities for continuous learning to drive behavioral change and to be respectful of other points of view
A collaborative culture that leverages the diverse perspectives of employees and supports courage
Zero tolerance for discrimination

We are committed to an emotionally and psychologically safe workplace that trusts employees to boldly explore innovative solutions. We recognize that intentionally embracing diversity at Neogene, empowers us to better relate to patients, and advance our mission to deliver cures where none exist.""",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,False
Machine Learning Engineer - Data Cycling Center,"TikTok
","San Jose, CA",$144K - $300K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities

Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need

Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications

BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Sr Data Engineer - Knowledge Graph,"SAP
","Palo Alto, CA",$121K - $172K (Glassdoor est.),4.3,"We help the world run better

Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from. Apply now!


Summary:

At SAP, we amplify the strength of AI technology, fusing it with our robust industry-focused data and profound process knowledge. Our vision is to infuse every SAP application with sophisticated AI capabilities, revolutionizing the way businesses operate. Large Language Models (LLMs) hold immense potential to change the way we work and develop products. They are reshaping the landscape of Machine Learning across various domains. Our goal is to combine the power of LLMs with Knowledge Graphs for business AI problems in SAP applications.


Meet your team:

SAP's AI organization is dedicated to seamlessly infusing AI into all enterprise applications, enabling customers, partners, and developers to enhance business processes and generate remarkable business value. Join our international AI team where innovation thrives, opportunities for personal development abound, and exceptional colleagues collaborate globally.


The Role:

Unique opportunity to contribute to the development of Knowledge Graphs for leveraging LLM applications and for contributing semantics to SAP’s Foundation Model.
Design, develop, and manage the construction of large-scale Knowledge Graphs using structured business metadata.
Guide junior project members and shape collaborations with stakeholders.
Collaborate closely with domain experts and LLM use case providers to understand their requirements and ensure the delivery of high-quality Knowledge Graphs.
Make critical design decisions regarding the selection and implementation of underlying technologies.
Extract, clean, and analyze data from various sources to ensure quality and accuracy.
Contribute to thought leadership in an entirely new approach towards generative AI, using the combination of Knowledge Graphs and Foundation Models.


What you bring:

PhD or Master’s degree in Computer Science, Artificial Intelligence, or other relevant disciplines.
Proven expertise in designing and implementing data extraction and structuring strategies for complex business data.
Hands-on expertise in cloud stack (AWS, GCP, Azure), object stores, SQL databases is a big plus.
Proficiency in Python.
Background in Machine Learning is a plus.
Understanding of Knowledge Graph technology stacks (RDF, property graphs, data modeling, schema design) is a plus.
Developer experience with any SAP Application and its underlying data models is a plus.
5+ years of relevant professional experience. Leadership and strategic thinking skills. Strong communication and collaboration skills, with the ability to work effectively in cross-cultural teams.

#SAPAICareers


We build breakthroughs together


SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together.

We win with inclusion

SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.
SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com.
For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training.

EOE AA M/F/Vet/Disability

Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability.

Compensation Range Transparency: SAP believes the value of pay transparency contributes towards an honest and supportive culture and is a significant step toward demonstrating SAP’s commitment to pay equity. SAP provides the annualized compensation range inclusive of base salary and variable incentive target for the career level applicable to the posted role. The targeted combined range for this position is 132,300 - 275,200 USD. The actual amount to be offered to the successful candidate will be within that range, dependent upon the key aspects of each case which may include education, skills, experience, scope of the role, location, etc. as determined through the selection process. Any SAP variable incentive includes a targeted dollar amount and any actual payout amount is dependent on company and personal performance. Please reference this link for a summary of SAP benefits and eligibility requirements: SAP North America Benefits.

Requisition ID: 383650 | Work Area: Software-Design and Development | Expected Travel: 0 - 10% | Career Status: Professional | Employment Type: Regular Full Time | Additional Locations: #LI-Hybrid",1972,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Principal Data Engineer,"Blue Shield of California
","Oakland, CA",$145K - $218K (Employer est.),3.8,"JOB DESCRIPTION
Your Role

The Data Engineering development team Is responsible for the design, development, testing, and deployment of large enterprise data warehouse/BI data solutions using both on-prem and cloud technologies. The Principal Data Engineer will report to the Manager, Data Engineering Development. In this role, you will be responsible for the design, development, and implementation of data integration, data warehouse, and data mart (ELT/ETL) solutions using on-prem as well as Cloud technologies.


Your Work

In this role, you will:

Build data pipelines: Create, maintain, and optimize workloads from development to production for specific use cases
Be responsible for using innovative and modern tools, techniques and architectures listed below to drive automate of most-common, repeatable data preparation and integration tasks with goal of minimizing reducing defects and improving productivity
Develop and enforce data integration and data quality standards across all development initiatives according to the organization’s Enterprise information services policies as well as best practices
Provide technical expertise working with Analysts and Business Users to implement complex and varied functional specifications into technical designs.
Lead the team in monitoring and tuning application code to assure optimal availability, performance and utilization of resources
Execute and oversee the analysis and remediation of root causes, including deficiencies in technology, process, or resource capabilities
Work in Agile/DevSecOps pod model alongside solution leads, data modelers, analysts, business partners, and other developers in the delivery of data
Mentor junior data engineers/developers




QUALIFICATIONS
Your Knowledge and Experience

Requires a bachelor's degree or equivalent experience
Requires at least 15 years of prior relevant experience
Experience in Cloud platform preferably Azure (or AWS or GCP) and its related technical stack including ADLS, Synapse, Azure data factory, etc.
Experience in Snowflake and/or Databricks
Experience in on-prem appliances (Netezza)/database (Oracle, SQL Server, MongoDB) and expert knowledge in SQL, Python, and common data pipeline/data science libraries
Strong technical understanding of data modeling (data vault 2.0), data mining, master data management, data integration, data architecture, data virtualization, data warehousing and data quality techniques with hands-on experience using data management technologies like Informatica PowerCenter/IICS, Collibra, Reltio Master Data Management, DBT Cloud, Dbt core, Denodo and Golden Gate replication
Working knowledge of Git repositories (bitbucket, GitHub), CI/CD (Jenkins, Azure DevOps)and software development tools, including incident tracking, version control, release management, subversion change management(Atlassian toolset – Jira/Confluence), testing tools and systems and scheduling software (Tidal, Control-m)
Experience working with popular data discovery, analytics, and BI software tools like Tableau, Qlik, PowerBI, and others for semantic-layer-based data discovery
Basic experience in working with data governance and data security and specifically information stewards and privacy and security officers in moving data pipelines into production with appropriate data quality, governance and security standards and certification
Adept in agile methodologies and capable of applying DevOps and increasing Data Operations principles to data pipelines to improve the communication, integration, reuse, and automation of data flows between data managers and consumers across an organization


Pay Range:

The pay range for this role is: $ 145200.00 to $ 217800.00 for California.

Note:

Please note that this range represents the pay range for this and many other positions at Blue Shield that fall into this pay grade. Blue Shield salaries are based on a variety of factors, including the candidate's experience, location (California, Bay Area, or outside California), and current employee salaries for similar roles.






ABOUT THE TEAM
Blue Shield of California’s mission is to ensure all Californians have access to high-quality health care at a sustainably affordable price. We are transforming health care in a way that genuinely serves our nonprofit mission by lowering costs, improving quality, and enhancing the member and physician experience.

To fulfill our mission, we must ensure a diverse, equitable, and inclusive environment where all employees can be their authentic selves and fully contribute to meet the needs of the multifaceted communities we serve. Our continued commitment to diversity, equity, and inclusion upholds our values and advances our goal of creating a healthcare system that is worthy of our family and friends while addressing health disparities, promoting social justice, and integrating health equity through our products, business practices, and presence as a corporate citizen.

Blue Shield has received awards and recognition for being a certified Fortune 100 Best Companies to Work, Military Friendly Employer, People Companies that Care, a Leading Disability Employer, and one of California’s top companies in volunteering and giving. Here at Blue Shield, we strive to make a positive change across our industry and communities – join us!

Our Values:

Honest . We hold ourselves to the highest ethical and integrity standards. We build trust by doing what we say we're going to do and by acknowledging and correcting where we fall short.
Human . We strive to be our authentic selves, listening and communicating effectively, and showing empathy towards others by walking in their shoes.
Courageous . We stand up for what we believe in and are committed to the hard work necessary to achieve our ambitious goals.

Our Workplace Model:

Blue Shield of California is dedicated to making work-life balance a reality. Whether you prefer to work in an office or from home, we understand flexibility is more important than ever. That’s why Blue Shield is a hybrid company, offering you the opportunity to decide where you can do your best and most meaningful work.

Two ways of working: Hybrid (our default) and office

Hybrid – In a business unit approved office a few times per year to 3 days per week, on average
Office – In a business unit approved office 4+ days a week, on average. If the role you’re applying for is deemed an “Essential Role,” the company has determined that the role can only be performed in a Blue Shield office or in the field and would require your to meet the office worker classification.

Physical Requirements:

Office Environment - roles involving part to full time schedule in Office Environment. Due to the current public health emergency in California, Blue Shield employees are almost all working remotely. Based in our physical offices and work from home office/deskwork - Activity level: Sedentary, frequency most of work day.




Equal Employment Opportunity:

External hires must pass a background check/drug screen. Qualified applicants with arrest records and/or conviction records will be considered for employment in a manner consistent with Federal, State and local laws, including but not limited to the San Francisco Fair Chance Ordinance. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, national origin, sexual orientation, gender identity, protected veteran status or disability status and any other classification protected by Federal, State and local laws.",1939,Insurance Carriers,$10+ billion (USD),Insurance,5001 to 10000 Employees,Nonprofit Organization,False
"Senior Backend Engineer, Data Platform","Labelbox
","San Francisco, CA",$170K - $215K (Employer est.),3.6,"Labelbox is the leading data-centric AI platform for building intelligent applications. Teams looking to capitalize on the latest advances in generative AI and LLMs use the Labelbox platform to inject these systems with the right degree of human supervision and automation. Whether they are building AI products by using LLMs that require human fine-tuning, or applying AI to reduce the time associated with manually-intensive tasks like data labeling or finding business insights, Labelbox enables teams to do so effectively and quickly.

Current Labelbox customers are transforming industries within insurance, retail, manufacturing/robotics, healthcare, and beyond. Our platform is used by Fortune 500 enterprises including Walmart, Procter & Gamble, Genentech, and Adobe, as well as hundreds of leading AI teams. We are backed by leading investors including SoftBank, Andreessen Horowitz, B Capital, Gradient Ventures (Google's AI-focused fund), Databricks Ventures, Snowpoint Ventures and Kleiner Perkins.

About the Role

Join our team of world-class engineers and build the next generation of AI products!

As a Senior Engineer on our Data Platform team, you'll be leading development of various aspects of our core services for vector and metadata search, analytics, data processing with high throughput I/O and 99.99% availability.

Our Data Platform team maintains backend infrastructure for storage of large data sets in order to search, visualize, explore, and analyze all labeled and unlabeled data, metadata, and model inferences.

Your Day to Day
Design, build, deliver, and maintain complex backend systems and integrations that store billions of records, offer consistent query performance, and reasonable transactional guarantees at hundreds of thousands of operations per second.
Take the lead on customer escalations, drive them to resolution, and see them as opportunities to improve.
Own projects from design to implementation, and coordinate across teams of developers and other stakeholders in a fast-paced environment.
Play a key role in shaping our company's future by working closely with senior leaders and executive staff to define and execute our roadmap for the next couple of years.
About You
8+ years of experience as either a full-stack or backend software engineer
Experience in a modern programming language (Typescript, Python, Java)
Expertise in multiple storage systems (Relational Databases, Key-Value Stores, Cloud Buckets, etc.)
Experience with Google Cloud or AWS
Familiarity with DevOps technologies (ArgoCD, CodeFresh, Kubernetes, etc.)
Exposure to Google Spanner and ElasticSearch
Nice to Have
Building ETL pipelines
Kotlin
Asynchronous Messaging systems (e.g. Kafka, Google pub/sub, AWS SQS, etc.)
Microservices architecture
Engineering at Labelbox

We build a comprehensive platform and end-to-end tool suite for AI system development. We believe in providing the best user experience at scale with high quality. Our customers use our platform in production environments, daily, to build and deploy AI systems that have a real positive impact in the world.

We believe in collaborative excellence and shared responsibility with decision making autonomy wherever possible. We strive for a great developer experience with continuous fine tuning. How we work is one of the cornerstones of engineering excellence at Labelbox.

We learn by pushing boundaries, engaging in open debate to come up with creative solutions, then committing to execution. We continuously explore and exploit new technologies, creating new and perfecting existing techniques and solutions. Making customers win is our North Star.




Labelbox strives to ensure pay parity across the organization and discuss compensation transparently. The expected annual base salary range for United States-based candidates is $170,000 - $215,000. This range is not inclusive of any potential equity packages or additional benefits. Exact compensation varies based on a variety of factors, including skills and competencies, experience, and geographical location.

Excel in a Hub-centric Remote Model.

We’re committed to excellence and understand the importance of bringing our talented people together. While we continue to embrace remote work, we’ve transitioned to a Hub-Centric Remote Model with a focus on nurturing collaboration and connection within our dedicated hubs in the San Francisco Bay Area, New York City Metropolitan Area, Miami-Fort Lauderdale Area, and Warsaw, Poland. We encourage asynchronous communication, autonomy, and ownership of your tasks, with the added convenience of hub-based gatherings.

Your Personal Data Privacy: Any personal information you provide Labelbox as a part of your application will be processed in accordance with Labelbox’s Job Applicant Privacy notice.

Any emails from Labelbox team members will originate from a @labelbox.com email address. If you encounter anything that raises suspicions during your interactions, we encourage you to exercise caution and suspend or discontinue communications. If you are uncertain about the legitimacy of any communication you have received, please do not hesitate to reach out to us at recruiting@labelbox.com for clarification and verification.




#LI-Hybrid",2018,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
"Sr. Application Software Engineer, Data","SpaceX
","Hawthorne, CA",$160K - $220K (Employer est.),3.9,"SpaceX was founded under the belief that a future where humanity is out exploring the stars is fundamentally more exciting than one where we are not. Today SpaceX is actively developing the technologies to make this possible, with the ultimate goal of enabling human life on Mars.

SR. APPLICATION SOFTWARE ENGINEER, DATA

The application software team is the central nervous system of SpaceX – we create mission critical applications that are used throughout SpaceX to accelerate launch vehicle production and flight as well as systems that allow Starlink to grow into a worldwide fast, reliable Internet service. Our missions support scientific research, classified national security space, and commercial opportunities. Software engineering and innovation are at the core of these programs.

Our team is currently creating and evolving systems to enable rapid build and reuse of Starship as well as designing the next generation manufacturing software that will be used in high throughput factories for Starlink. Other applications range from platforms that support concurrent streams of data from many always-on assets to manage the world's largest satellite constellation to public facing systems where customers can join our Starlink network globally. We work closely with engineers throughout the company to create and update our systems with respect to crewed launches, Starship flights, changes to the Starlink network and much more.

Aerospace experience is not required to be successful here - rather we look for smart, motivated, collaborative engineers who love solving problems and want to make an impact on a super inspiring mission. You will have full ownership of challenging problems, working with a team of enthusiastic engineers to design and produce solutions that enable SpaceX to move towards our goals at a rapid pace. The success of the missions at SpaceX depends on the software that you and your team produce.

RESPONSIBILITIES:

Develop highly reliable software solutions that are used across SpaceX
Create new applications that improve how the business at SpaceX operates
Collaborate with peers on architecture, design, and code reviews
Build prototypes to prove out key design concepts and quantify technical constraints
Own all aspects of software engineering and product development
Deep dive into your users' problems, find efficient solutions

BASIC QUALIFICATIONS:

Bachelor's degree in computer science, engineering, math, or scientific discipline and 5 years of software development experience OR 7+ years of professional experience building software
Experience in full stack development

PREFERRED SKILLS AND EXPERIENCE:

Programming experience in Python, C#, Java, Scala, Go or similar languages
5+ years of rigorous experience building single page web applications
Experience working with in-stream, big data processing and analytics using Apache Kafka, Spark, Flink, SQL or similar
Experience with relational and non-relational databases, data lakes e.g. HBase, Hive, Delta Lake, PostgreSQL, CockroachDB or similar
Experience with data exploration tools like Grafana, Jupyter Notebooks, Metabase, PowerBI or similar
Good understanding of version control, testing, continuous integration, build, deployment and monitoring
Some front-end experience in Angular, React, or similar JavaScript framework
Good understanding of statistics, machine learning algorithms and frameworks
Active Top Secret or TS/SCI. Note that an active clearance may provide the opportunity for you to work on sensitive SpaceX missions. If so, you will be subject to pre-employment drug and random drug and alcohol testing

ADDITIONAL REQUIREMENTS:

Willing to work extended hours and weekends when needed
COMPENSATION AND BENEFITS:
Pay Range:
Software Engineer/Senior: $160,000.00 - $220,000.00/per year
Your actual level and base salary will be determined on a case-by-case basis and may vary based on the following considerations: job-related knowledge and skills, education, and experience.

Base salary is just one part of your total rewards package at SpaceX. You may also be eligible for long-term incentives, in the form of company stock, stock options, or long-term cash awards, as well as potential discretionary bonuses and the ability to purchase additional stock at a discount through an Employee Stock Purchase Plan. You will also receive access to comprehensive medical, vision, and dental coverage, access to a 401(k) retirement plan, short & long-term disability insurance, life insurance, paid parental leave, and various other discounts and perks. You may also accrue 3 weeks of paid vacation & will be eligible for 10 or more paid holidays per year. Exempt employees are eligible for 5 days of sick leave per year.

ITAR REQUIREMENTS:

To conform to U.S. Government export regulations, applicant must be a (i) U.S. citizen or national, (ii) U.S. lawful, permanent resident (aka green card holder), (iii) Refugee under 8 U.S.C. § 1157, or (iv) Asylee under 8 U.S.C. § 1158, or be eligible to obtain the required authorizations from the U.S. Department of State. Learn more about the ITAR here.

SpaceX is an Equal Opportunity Employer; employment with SpaceX is governed on the basis of merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status.

Applicants wishing to view a copy of SpaceX's Affirmative Action Plan for veterans and individuals with disabilities, or applicants requiring reasonable accommodation to the application/interview process should notify the Human Resources Department at (310) 363-6000.",2002,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,5001 to 10000 Employees,Company - Private,False
Senior Data and Controls Engineer (Hardware),"Relativity Space
","Long Beach, CA",$127K - $163K (Employer est.),3.8,"Company Overview:

A rocket company at the core, Relativity Space is on a mission to become the next great commercial launch company. Meeting the needs of a growing demand for space infrastructure, our rockets will revolutionize how we connect and communicate on Earth by getting satellites to space. We have developed a vertically integrated technology platform in which we leverage additive manufacturing, artificial intelligence, and autonomous robotics to 3D print rockets. Our unique approach enables rapid product iteration, allowing us to push the boundaries of what's possible today and unlock the full potential of 3D printing for tomorrow. Join us on this extraordinary journey, as we work together to transform our vision into reality.

Team:

The Factory Test team is responsible for all hazardous testing in our Long Beach facilities. We use our breadth of experience and collaborative engineering approach to support everything from very large structural tests to precise valve actuation. To that end, we design, build, and operate all test assets from initial concept to test execution. If you enjoy working on a multi-disciplinary team with a broad mandate and want to put hands-on hardware, then this is the team for you.

What you’ll do:

As a Data and Control System Hardware Engineer, you will be responsible for design, build, and integration of data systems at our Long Beach facilities. The projects you work on will run test systems across the factory ranging from quick and scrappy development test setups to large permanent infrastructure. You will be required to be hands on with the hardware, working side-by-side with our technician team to build and debug your projects. Once your hardware is built, you will also work closely with our operations and software teams to integrate it with our in-house data and controls platform.

Your projects will span a variety of construction methods, sizes, and applications. These could include anything from portable data systems to large motion control cabinets. The kinds of hardware you will develop may include:

Commercial Data Acquisition Specifications
Motion Control Cabinets
AC / DC Power Distribution Systems
Wiring Harnesses
Selection and Integration of Test Stand Instrumentation
Portable Data Systems
Motor and Pump Control Cabinets

What you need to know:

Bachelor’s degree in Electrical Engineering, Computer Engineering, or related field.
5+ years of experience designing, building, and testing control cabinets or data systems.
Strong electrical engineering fundamental knowledge.
Experience specifying, selecting, and integrating sensors and actuators such as pressure transducers, RTDs, strain gages, thermocouples, solenoid valves, accelerometers, microphones, etc.
Familiar with using technology such as, but not limited to, AC-DC Power Supplies, PLCs, VFDs.
Experience designing electrical control cabinets and wiring harnesses.
Ability to use signal generators, oscilloscopes, and other test equipment to test and verify hardware designs.
Demonstrated ownership, accountability, and success in delivering complex products with minimal guidance.

Nice to haves but not required:

Comfortable using schematic capture and PCB design tools such as Altium.
Circuit simulation experience (SPICE, PSPICE, LTSPICE, etc).
Experience using AutoCAD Electrical
Familiar with scripting languages such as Python or MATLAB for preforming analysis or writing automation tools.
Experience with embedded or systems programming in languages such as C, C++, or Rust.
Previous experience with COTS data acquisition systems such as NI, Dewesoft, Beckhoff etc.
Familiar with communications methods such as, but not limited to, SPI, Ethernet, EtherCAT, CAN, and Modbus.



No previous aerospace experience is required for this position.

Relativity Space offers competitive salary and equity, a generous vacation policy, an annual L&D stipend and more!

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.




The below-range represents Relativity Space’s current good-faith pay scale for this role. Relativity Space reserves the right to modify or update this range at any time.

Compensation is only one part of our entire total rewards package. To see some of the benefits & perks we offer, please visit here: https://px.sequoia.com/relativityspace
Hiring Range:
$127,000—$163,000 USD",2016,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,501 to 1000 Employees,Company - Private,False
"Senior CUDA Math Libraries Engineer, Data and Image Compression","NVIDIA
","Santa Clara, CA",$216K - $334K (Employer est.),4.6,"We are the CUDA Math Libraries team at NVIDIA - which was just named one of
America's Best Place to Work by Glassdoor
. Around the world, leading commercial and academic organizations are revolutionizing AI, scientific and engineering simulations, and data analytics, using data centers powered by NVIDIA GPUs. We are looking for a Senior Math Libraries Engineer to join our team to develop libraries that provide ground breaking GPU-accelerated data and image compression and decompression algorithms. Technologies that we develop are used in data science, healthcare, image processing, computer vision, deep learning, autonomous vehicles and countless others. If the idea of contributing to our technologies excites you, join our team and help us build GPU accelerated software libraries that are used by countless applications around world. We're looking for someone with strong programming skills, integrity, reliability, persistence and problem-solving ability.
What you’ll be doing:
Collaborate with internal and external partners to understand software use cases and requirements.
Design and implement compression and decompression algorithms on NVIDIA accelerated platforms (GPU and CPU)
Lead library architecture design to enable new use cases and increase adoption with customers
Providing technical leadership and guidance to other engineers in your team
Benchmark the performance of GPU or CPU implementations against industry standards, find opportunities for improvements and implement them.
Improve software development processes for flawless integration with NVIDIA key software products
What we need to see:
Masters, PhD, or equivalent experience in Computer Science, Applied Math, or related field
10+ years of related work experience
Experience in implementing software in research or industrial settings.
Excellent programming skills in C/C++
GPU programming experience (CUDA or OpenCL).
Strong focus on delivering high-quality and high-performance software.
Outstanding interpersonal skills, excellent teamwork, communication, and documentation habits.
Ways to stand out from the crowd:
Experience with high performance compression algorithms
Advanced skills in debugging, profiling, and testing for accuracy and performance.
Knowledge of CPU or GPU hardware architecture.
The base salary range is 216,000 USD - 333,500 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
. NVIDIA accepts applications on an ongoing basis.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",1993,Computer Hardware Development,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Staff Software Engineer, Data Platform","Tesla
","Palo Alto, CA",$162K - $220K (Glassdoor est.),3.6,"What to Expect

Data is deeply embedded in the product and engineering culture at Tesla. We rely on data – lots of it – to improve autopilot, to optimize hardware designs, to proactively detect faults, and to optimize load on the electrical grid. We collect data from each of our cars, superchargers, and stationary batteries and use it to make these products better and our customers safer.

We're the small but a core, high-impact team which is building and operating the IoT big data platform for the whole company. We collect massive amounts of IoT data, provide storage, access, and high-volume processing. Our stack is built on top of open source technologies, including Spark, Kafka, and related, and our own build from scratch technology.

We're looking for a talented engineer to join us as a foundational member of the team to deliver new and improved big data services and infrastructure. Your work will affect many hundreds of Tesla engineers daily, as well as improving the functionality of our cars, chargers, batteries, other connected devices worldwide, and enable new data-driven products such as Tesla Insurance.

What You’ll Do
Employ and improve industry-leading, scalable, distributed open-source technologies
Build back-end systems from scratch that are capable of handling 10s of trillions events per day
Facilitate operation of highly-available distributed systems at scale and across multiple locations
Facilitate others in deploying, operating, and extending upon your clean, tested code
Help define a platform that is highly leveraged, multi-tenant, and self-serviced
Work with data engineers and data scientists to drive efficient solutions from the platform
Help define the data story and enable data-driven solutions at Tesla, both technically and culturally


What You’ll Bring
5+ years of Software Development Experience
Expertise in Java, C++, or Rust
Strong programming fundamentals, particularly in data structures, concurrency

Deep understanding of a complex distributed system, such as Kafka, Spark, HBase, ElasticSearch
Have built and optimized highly available, scalable, distributed back-end services
Ability to break down and deeply understand complex problems and communicate complex matters efficiently
Strong problem solving skills, optimizing for the simplest, most robust yet practical solutions
Reliable, dependable, trustworthy, participating team member
Smart but humble, with a bias for action

Nice to Have

Proficiency in Python or Scala
Experience with cloud infrastructure such as AWS

Robust DevOps/SRE abilities",2003,Transportation Equipment Manufacturing,$1 to $5 billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Data Center Reliability Engineer,"NVIDIA
","Santa Clara, CA",$140K - $224K (Employer est.),4.6,"We are now looking for a Reliability Engineer. Your role identifies risks to the uptime of our assets and partners with multiple teams to improve efficiency and up-time. You should be passionate about technology, a team-player and eager to help NVIDIA succeed in a variety of new and exciting markets.
What you’ll be doing:
Develop standards and programs in support of reliability program
Define and maintain a health score of environments for reliability and availability
Lead root cause analysis for outages and adjust documentation, workflows, and operating procedures to avoid future incidents
Design testing methods to predict and isolate points of failure
Define and categorize spaces within an understandable reliability scale
Study failure data and work with machine learning and AI teams to predict future failures
Facilitate reliability studies such as critical assessments, RAM models, and RCM studies
Assess and advise on maintenance strategies
What we need to see:
Bachelor’s degree in related field or equivalent experience
8+ years of operations experience or environmental health and safety within data centers
Proficient in developing and driving reliability activities (modeling predictions, life cycle testing, stress testing, etc..)
Commercial and financial awareness, with a full comprehension on the impact of failure in translation to business costs, production targets and fulfillment of customer orders
Highly developed numeracy, statistical and reporting, ability to analyze, interpret and apply information, data and trends.
Result oriented and organized, able to plan and deliver against expectations.
Proficient in the use of asset database and DCIM solutions to extract data and develop meaningful insights
Ways to stand out from the crowd:
Proven experience in reliability engineering related to electrical or mechanical cooling systems
Certifications such as CMRP, CRL, CRE in Maintenance and Reliability
Knowledge of relevant ISO standards
Demonstrated expertise in statistics, forecasting, and management information methods and techniques.
Strong IT systems knowledge and skills including advanced Excel/G-Suite skills and the ability to learn new software packages.
With competitive salaries and a generous benefits package, we are widely considered to be one of the technology world’s most desirable employers; we have some of the most forward-thinking and talented people in the world working for us and, due to unparalleled growth, outstanding teams are rapidly growing. If you’re creative and autonomous with a real passion for your work, we want to hear from you!
The base salary range is 140,000 USD - 224,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
. NVIDIA accepts applications on an ongoing basis.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",1993,Computer Hardware Development,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Data Engineer II, Algorithm","Edwards Lifesciences
","Irvine, CA",$81K - $114K (Employer est.),4.0,"Innovation starts from the heart. At Edwards, we put patients first. We invest a significant proportion of our revenue towards research and development to drive and develop groundbreaking medical innovations for structural heart disease and critical care. As part of our R&D Engineering team, you will work closely with our Quality and Manufacturing teams to develop the latest tools and technologies to address significant, unmet clinical needs that impact patients’ lives around the world.

Throughout our history, Edwards has helped transform the way physicians monitor and take preventative measures for cardio patients. Our Critical Care business unit specializes in advanced hemodynamic monitoring solutions, including artificial intelligence algorithms to provide predictive readings to clinicians, helping them get patients home to their families faster. It’s our driving force to help patients live longer and healthier lives. Join us and be part of our inspiring journey.

You will make an impact by…

As a Data Engineer II, Algorithm this individual will be an experienced Data Engineer who will be responsible for expanding and optimizing our data ingestion, storage, and analytical platform in Cloud. Experienced data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support database architects and data scientists on various analytical initiatives.

Design, Build and maintain Modern Cloud Data warehouse schematics, Data Pipelines and Data Streams

Design data ingestion processes for a wide variety of unstructured and structured data sets

Automate ETL processes, optimize data delivery, re-designing of Data Warehouse for greater scalability

Design and implement Audit processes for Data ingestion and access

Work with AI, Machine Leaning and Algorithms team to assist with data-related technical needs

Design highly scalable cloud based analytical solutions

Generate scripts for statistical data analyses

Analyze and interpret moderately complex physiological and clinical data, animal model data, algorithm results data, etc.

Create tools for data analytics, mining, visualization and integrate them with data processing pipelines for model development

What you'll need:
Bachelor's degree in Computer Science, Statistics, Information Systems, Engineering or another quantitative field along with 2 years of industry experience in Data Engineering – OR-

Master’s Degree in Engineering or Scientific field with 1 year of industry experience or related experience.

Proven skills in usage of MATLAB and/or Python

Working knowledge of Cloud Services from AWS, Azure or GCP

Good SQL and ETL experience working with relational databases

What else we look for:
Experience building processes to support data transformations, data structures, dependencies and workload management.

Experience building and optimizing data ingestion pipelines for Unstructured and big data sets

Knowledge of Clinical data or Medical Device products is a huge plus

Good documentation, communication (e.g., written and verbal) and interpersonal relationship skills including consultative and relationship management skills

Basic understanding of machine learning and data mining techniques

Basic understanding of statistical techniques

Solid problem-solving, organizational, analytical and critical thinking skills

Strict attention to detail

Ability to interact professionally with all organizational levels

Ability to manage competing priorities in a fast paced environment

Experience supporting and working with cross-functional teams in a dynamic environment.

Ability to build productive internal/external working relationships

Adhere to all company rules and requirements (e.g., pandemic protocols, Environmental Health & Safety rules) and take adequate control measures in preventing injuries to themselves and others as well as to the protection of environment and prevention of pollution under their span of influence/control

Aligning our overall business objectives with performance, we offer competitive salaries, performance-based incentives, and a wide variety of benefits programs to address the diverse individual needs of our employees and their families.

For California, the base pay range for this position is $81,000 to $114,000 (highly experienced).

The pay for the successful candidate will depend on various factors (e.g., qualifications, education, prior experience).

About Edwards Lifesciences

Edwards Lifesciences is the global leader in patient-focused medical innovations for structural heart disease and critical care monitoring. We are inspired to help patients. We collaborate with the world’s leading clinicians and researchers to address unmet healthcare needs, working to improve patient outcomes and enhance lives. Join our team of over 19,000 dedicated, unique individuals and discover how you can make a difference.

COVID Vaccination Requirement

Edwards is committed to complying with the requirements and guidance from our government authorities and to protecting our vulnerable patients and the healthcare providers who are treating them around the world. As such, all Healthcare Interacting positions require COVID-19 vaccination, which includes anyone who directly interfaces with patients and those who interact with healthcare providers as part of their role. If hired, as a condition of employment, you will be required to submit proof that you have been fully vaccinated for COVID-19, unless you request and are granted a medical or religious accommodation for exemption from the vaccination requirement. This vaccination requirement does not apply in countries where it is prohibited by law to impose vaccination. In countries where vaccines are less available, or other requirements exist, we may institute alternate measures that optimize patient safety and healthcare provider safety, which may include regular COVID testing or specific masking requirements.

For United States Applicants Only:
Edwards is an Equal Opportunity/Affirmative Action employer including protected Veterans and individuals with disabilities.
Know your Rights: Workplace Discrimination is Illegal Poster
Disability accommodation for employment applicants
Edwards E-Verify
Family and Medical Leave Act (FMLA)
Employee Polygraph Protection Act (EPPA)
Pay Transparency Notice",1958,Health Care Products Manufacturing,$1 to $5 billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Research Data Center Engineer,"Stanford University
","Stanford, CA",$130K - $135K (Employer est.),4.3,"Research Data Center Engineer:




Facilities Engineer 3, 4353/K in terms of Stanford job classification




The expected pay range for this position is $130,000 to $135,000 per annum. Stanford University provides pay ranges representing its good faith estimate of what the university reasonably expects to pay for a position. The pay offered to a selected candidate will be determined based on factors such as (but not limited to) the scope and responsibilities of the position, the qualifications of the selected candidate, departmental budget availability, internal equity, geographic location and external market pay for comparable jobs.




This position will serve as a technical expert in the performance of facilities engineering responsibilities involving the operation and maintenance of a major campus facility, the Stanford Research Computing Facility Module 2 (SRCF2).




The position, reporting to the Research Computing (RC) Data Center Manager, will be to provide facilities support for data centers under the management of the Stanford Research Computing Center (Research Computing). Research Computing offers High Performance Computing (HPC) hosting services, computational and data systems, services, and support for researchers from a variety of Stanford and SLAC organizations. The data center facility that hosts the HPC systems themselves is the Stanford Research Computing Facility (SRCF1). The SRCF2 is a state of the art expansion of the original facility (SRCF1) and it is designed to accommodate high density computational infrastructure. The Facilities Engineer will assist in the operation of the SRCF2, monitoring temperatures, facilitating deliveries, racking servers, and storage devices, troubleshooting and repairing servers, install network wiring, installing, and securing racks. This position will also provide backup to the Facilities Engineer for SRCF1 and also for the Research Computing data center in Forsythe Hall on the Stanford campus. This position may also occasionally be responsible for interfacing with vendors, for installations, equipment repairs, and maintenance.




Core Duties

Ensure ongoing production facility operation to maximize the reliability, dependability and availability of it and systems hosted therein.
Serve as an expert, providing design and technical recommendations in areas of specialization. This includes interfacing and coordination with and across specialties and disciplines.
Work with groups or individual researchers from Stanford, Stanford Medicine, and SLAC who have equipment hosted at SRCF2 to ensure safe facility operation and standards are met.
Identify and resolve complex technical systems issues which may have high risk/consequences of failure.
Review and analyze projects’ technical plans and specifications for conformance with design guidelines and other related criteria, and pertinent codes and standards
Serve as a technical lead on projects in areas of expertise across multiple contractor activities, through all project phases.
Conduct risk assessments and develop contingency plans



Minimum Requirements




Education and Experience

Bachelor’s degree in relevant discipline. Ten years of relevant work experience or a combination of those attributes.



Knowledge, Skills and Abilities

Strong interpersonal skills
Demonstrated breadth of understanding of electrical and mechanical systems found in a data center environment such as: Power distribution systems, UPS, Variable Frequency Drives, Generators, Air Handlers, Chillers, PLC’s, Etc.
Knowledge and proficiency with engineering software related to assignment, specifically Building Control and Monitoring Systems
Deep technical knowledge in area of expertise
Understanding of the basics of high performance computing and associated networking features and functions.
Strong customer service focus
Excellent project management skills
Excellent written and oral communication skills
Working knowledge of computer systems and typical office productivity software
Ability to identify and mitigate potential project risk components



Certifications and Licenses:

Data center operation certification is highly desired.



Physical Requirements

Occasionally sitting, perform desk-based computer tasks, lift/carry/push/pull objects that weigh up to 10 pounds.
Occasionally stand/walk, twist/bend/stoop/squat, grasp lightly/fine manipulation, use a telephone, lift/carry/push/pull objects that weigh from 11 to 40 pounds,
Frequently kneel/crawl, climb (ladders, scaffolds, or other), reach/work above shoulders, grasp forcefully, writing by hand, sort/file paperwork or parts, lift/carry/push/pull objects that weigh >40 pounds.



- Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job



Working Conditions

Requires 24-hour response availability seven days per week for emergency situations.
Requires after hours and weekend work on occasion for maintenance and/or project related activities.
May be exposed to noise > 80dB TWA.
May work at heights 4 - 10 ft.



Work Standards

Interpersonal Skills: Demonstrates the ability to work well with Stanford colleagues, clients and with external organizations.
Promote Culture of Safety: Demonstrates commitment to personal responsibility and value for safety; communicates safety concerns; uses and promotes safe behaviors based on training and lessons learned.
Subject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University’s Administrative Guide, https://adminguide.stanford.edu/.



The job duties listed are typical examples of work performed by positions in this job classification and are not designed to contain or be interpreted as a comprehensive inventory of all duties, tasks, and responsibilities. Specific duties and responsibilities may vary depending on department or program needs without changing the general nature and scope of the job or level of responsibility. Employees may also perform other duties as assigned.




Stanford is an equal employment opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law.",1891,Colleges & Universities,$10+ billion (USD),Education,10000+ Employees,College / University,False
"Senior Systems Software Engineer, Data Center - CUDA","NVIDIA
","Santa Clara, CA",$144K - $270K (Employer est.),4.6,"NVIDIA is searching for world-class software engineers to join the CUDA driver team.
This team develops and supports NVIDIA's GPU administration tools for monitoring and managing our Compute GPU product line-up. The NVIDIA Data Center product line-up scales from single GPU add-in cards to full system DGX products, all built on developing technologies like PCI Express, NVLink, and NVSwitch. This work includes design, development, verification, and maintenance of new software features to monitor and manage this Compute product line-up on Linux & Windows Operating Systems. You will work with hardware and kernel driver engineers on exposing new GPU features to customers and system administrators.
What you'll be doing:
As a Compute Data Center Engineer at NVIDIA, you will work on the system management tools for our Compute Professional Solutions products.
this includes the C-based NVML (NVIDIA Management Library) API and NVIDIA-SMI (NVIDIA System Management Interface) tool.
Software design for the next generation Compute GPU solutions.
Develop and maintain software features targeted at enabling and supporting NVIDIA's GPU hardware:
Current and upcoming Linux and Windows based operating systems
Ensuring the best performance and feature set
Cross platform implementation
Supporting new hardware architectures.
Working with other internal worldwide teams (software, hardware, architecture, OEM support).
Working with customers on defining feature requirements and presenting new features.
What we need to see:
B.S. or M.S. equivalent in Computer Science, Computer Engineering, or Electrical Engineering (or equivalent experience).
5+ years ""hands on"" experience developing user space tools, especially for the Linux OS
Strong software engineering skills combined with a drive to solve hard problems are a must.
Strong programming skills in modern C, C++ and Python.
Experience with Data Center monitoring and management a plus.
Experience with developing and maintaining a C API a plus.
Strong English written and oral communication skills to collaborate with other engineers (worldwide)
A strong team player; self motivated and good attitude.
The candidate must be able to work independently with minimal direction.
Windows operating systems experience is a plus.
NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and talented individuals in the world working for us. If you're creative and autonomous, we want to hear from you!
NVIDIA’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing — with the GPU acting as the brain of computers, robots, and self-driving cars that can perceive and understand the world. Today, we are increasingly known as “the AI computing company.” We're looking to grow our company, and form teams with the smartest people in the world. Join us at the forefront of technological advancement.
The base salary range is 144,000 USD - 270,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
. NVIDIA accepts applications on an ongoing basis.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",1993,Computer Hardware Development,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Backend Software Engineer Graduate (TikTok Eng - Data Access Team) - 2024 Start (BS/MS),"TikTok
","San Jose, CA",$112K - $147K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

TikTok Data Access team is responsible for data access control to all online TikTok data, managing data schema in code for attribution and governing, layout foundation for modernized data tracking, deletion, retention, and linkage. We are building an Infrastructure as Code experience for all data models and storage systems and help automate the development and deployment process by providing frameworks and systems based on metadata and schema.

We are looking for talented individuals to join our team in 2024. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok

Successful candidates must be able to commit to one of the following start dates below:
1. January 15, 2024
2. February 5, 2024
3. March 4, 2024
4. May 20, 2024
5. June 10, 2024
6. July 15, 2024
7. August 12, 2024
We will prioritize candidates who are able to commit to these start dates. Please state your availability and graduation date clearly in your resume.

Applications will be reviewed on a rolling basis. We encourage you to apply early.

Candidates can apply for a maximum of TWO positions and will be considered for jobs in the order you applied for. The application limit is applicable to TikTok and its affiliates' jobs globally.

Candidates who pass resume evaluation will be invited to participate in TikTok's technical online assessment through HackerRank.

We are looking for motivated individuals interested in complex engineering challenges around one of the most important aspects of TikTok. You will have the opportunity to work closely with a multidisciplinary team of Mobile Engineers, Frontend Engineers, Site Reliability Engineers, Data Engineers, and Data Scientists in a high-impact and fast-paced environment.

As a Software Engineer on our TikTok Data Access team, you will:

Design new massive-scale software systems that demand low latency, high reliability, and resilience against disaster, by applying the concept of Infrastructure as Code and Schema as Code.
Develop systems to handle the next phase of growth TikTok's business and ensure high stability and performance.
Collaborate with multiple cross-functional teams to identify new investments, solve critical problems, and deliver high-quality work in rapid product development.
Qualifications

Bechelor/MS Degree in Computer Science or related major.
Proficient in at least one OOP language, such as Java, Go, C++, Python, etc.
Experience in building backend services for large-scale consumer-facing applications.
Familiar with common open source distributed middleware and components such as MySQL, MongoDB, Redis, and MQ.
Understanding of design ideas for distributed system and architecture, including but not limited to service-oriented, asynchronous, highly available, scalable, etc.
Deep understanding of computer architectures, data structures, and algorithms.
Good communication and collaboration skills.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at gprd.accommodations@tiktok.com

By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy.
Job Information
The base salary range for this position in the selected city is $112200 - $147000 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Engineer II - Data & Analytics,"Vuori, Inc
","Carlsbad, CA",$136K - $160K (Employer est.),3.8,"Company Description


Vuori is re-defining what athletic apparel looks like: built to move and sweat in but designed with a casual aesthetic to transition into everyday life. We draw inspiration from an active coastal California lifestyle; an integration of fitness, creative expression and life. Our high energy fast paced retail environment is reflected in the clothes we make. We aim to inspire others to take on all aspects of their lives with clarity, enthusiasm and purpose…while having a lot of fun along the way. We are proud to be an outlet for opportunity and for personal growth and success.



Job Description


Responsibilities include but are not limited to:

Data Pipeline Development:

Design, develop, and maintain scalable and efficient data pipelines.
Extract, transform, and load (ETL) data from various sources into our data warehouse.
Enable data quality and integrity throughout the ETL process.

Data Architecture:

Collaborate with cross functional tech leads and architects to design and optimize data models and database structures.
Implement best practices for end to end data pipe management on data lake.
Work on data warehousing solutions, such as Azure ADF, Snowflake etc.

Data Integration:

Integrate third-party data sources and APIs to enrich our datasets.
Enable processes for monitoring, exception management across end to end data pipe build to ensure integrity and reliability of data engineering solutions
Implement data connectors and data ingestion processes
Work on designing and defining new ways of data integrations while managing existing data integrations

Performance Optimization:

Monitor and optimize data pipelines and query performance.
Troubleshoot and resolve data-related issues in a timely manner.

Data Security and Compliance:

Ensure data security and compliance with relevant data protection regulations (e.g., GDPR, HIPAA).
Implement access controls and encryption mechanisms.

Collaboration:

Collaborate with analytics, product leads and business product owners to define and build best in class data ecosystem driving business analytic capabilities
Be part of agile operating model alongside analytics and business teams to drive collective data & analytics capabilities
Work alongside planning, master data and other teams looking for clean, connected data and provision datasets as API’s or onetime per need
Support data consumers by providing access to clean and well-organized datasets.

Documentation:

Maintain documentation for data pipelines, schemas, and data dictionaries.
Document end to end data pipes and ongoing enhancements to them
Create and update documentation on data engineering processes and standards.


Qualifications

Bachelor's degree in Computer Science, Information Technology, or a related field. Master's degree preferred.
5 years of experience as a Data Engineer or similar role.
Proficiency in data modeling, ETL development, and data warehousing.
Strong programming skills in languages like Python, Java, or Scala.
Experience with data pipeline orchestration tools
Knowledge of SQL and proficiency in working with relational and NoSQL databases.
Familiarity with cloud platforms (e.g., Azure, Snowflake) and associated data services.
Excellent problem-solving and communication skills.
Ability to work independently and as part of a cross-functional team.
Any specific certifications or additional qualifications preferred.
If you are a highly motivated and detail-oriented Data Engineer with a passion for working with data, we encourage you to apply and join our innovative team at Vuori. Help us drive data-driven decisions and make a meaningful impact in athletic performance apparel business.

Additional Information


Pay Range: $136,000-$160,000/yr

Benefits:

Health Insurance
Paid Time Off
Employee Discount
401(k)

All your information will be kept confidential according to EEO guidelines.",2015,"Department, Clothing & Shoe Stores",Unknown / Non-Applicable,Retail & Wholesale,501 to 1000 Employees,Company - Private,True
Process Engineer - Data Analyst (Hybrid),"MilliporeSigma
","Rocklin, CA",$50K - $149K (Employer est.),3.8,"Work Your Magic with us!

Ready to explore, break barriers, and discover more? We know you've got big plans - so do we! Our colleagues across the globe love innovating with science and technology to enrich people's lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That's why we are always looking for curious minds that see themselves imagining the unimaginable with us.

This role does not offer sponsorship for work authorization. External applicants must be eligible to work in the US.

Your Role:

MilliporeSigma in Rocklin, CA is seeking a Process Engineer - Data Analyst. As part of the Operations team, you are responsible for technology improvement projects, act as a site subject matter expert for IT issues and aid the Operations team in administration of site systems. We are looking for an individual who thrives in a dynamic and fast paced environment. As an individual contributor working independently, this role would bring together both end users (Scientists/Manufacturing/Production) and IT to guide, define, and continually enhance and maintain a robust solution across our key digital platforms.

Who You Are:

Minimum Qualifications:

Bachelor's degree in Biology, Chemistry, Computer Science, Software Engineering or other Scientific or Technical field
2+ years of experience in a technical role with ERP systems or supporting/administrating software applications or systems
Preferred Qualifications:

Technical hands-on experience with SAP strongly preferred
Ability to plan and execute projects with strong communication skills
Capacity to create and lead presentations to summarize key activities and processes related to architecture and digital platforms
Working knowledge and application of FDA and EU regulations (e.g. cGMP)
Advanced knowledge and application of data integrity regulatory guidance (e.g., FDA, MDSAP, ISO 13485, IVDR)
Proven ability to communicate on multiple levels of the organization across the business and IT teams
Strategic thinking and planning to translate user discussions and requirements into robust platform design and solutions
Highly organized, conscientious, and self-motivated
Strong organizational and time management skills
Ability to work and make decisions independently as well as with a team
Ability to work in technically and mentally demanding situations
Flexibility to work across time zones and in hours to support our global organization
Proven expertise overseeing multiple data integrations and complex requirements within analytics
Pay Range for this position - $49,500 - $148,900

Our ranges incorporate all levels and career types available within this specific role, and are derived from relevant industry market data. Should we decide to make an offer, we will consider several factors, including but not limited to your location, skills, experience, career level, and other job-related factors. This role may offer the following benefits: medical, vision, and dental insurance; life insurance; disability insurance; a 401(k) matching program; paid time off; and paid holidays; among other employee benefits. This role may also be eligible for short-term or long-term incentive compensation, including, but not limited to, cash bonuses.

What we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!

Apply now and become a part of our diverse team!

If you would like to know more about what diversity, equity, and inclusion means to us, please visit https://www.emdgroup.com/en/company/press-positions.html",2014,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Subsidiary or Business Segment,False
"Data Engineer, Experimentation & Evaluation-TikTok Data Platform","TikTok
","San Jose, CA",$136K - $280K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

Team Introduction
Our mission in experimentation and evaluation team is to build the next-gen A/B testing platform, that empowers the company to make data-driven decision for the products. The supported scenarios include recommendation, push, ads, search, mobile app, UI interaction and service upgrades etc. Our platform's capabilities cover the entire experiment life cycle, from experiment design, experiment creation, metrics calculation, statistical analysis to final evaluation and launch. In the process of rapid iteration, we provide reliable services for businesses to make bold hypotheses and cautious verification.

As a data engineer in experimentation and evaluation team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.


Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)
Design and implement reliable, scalable, robust and extensible big data systems that support core products and business
Establish solid design and best engineering practice for engineers as well as non-technical people
Qualifications

BS or MS degree in Computer Science or related technical field or equivalent practical experience
Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.)
Experience with performing data analysis, data ingestion and data integration
Solid communication and collaboration skills
Preferred Qualifications

Working industry experience with Big Data systems and projects
Experience in building large scale distributed systems in a product environment
Experience with ETL(Extraction, Transformation & Loading), architecting data systems, schema design, and data modeling
Experience in writing, analyzing and debugging SQL queries
Experience in data privacy and security related projects
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at dennis.chau@tiktok.com.
Job Information
The base salary range for this position in the selected city is $136000 - $280000 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Sr Staff Data Platform Software Engineer - Data Stream,"ServiceNow
","San Diego, CA",$166K - $291K (Employer est.),4.4,"Company Description


At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.

With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.

Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.

Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.


Job Description


Team:

The Data Streaming group has teams that provide streaming API for higher-layer applications and/or work to scale our application platforms. Depending on the nature of the data, the storage systems include data in motion, such as time-series databases or message bus systems. Our largest customers are constantly pushing the limits of the backend storage in terms of size of the data, speed of IO, and the number of concurrent transactions. Performance, reliability, and scalability are always at the core of our work.

Our largest customers are constantly pushing the limits of the backend storage in terms of size of the data, speed of IO, and several concurrent transactions. Performance, reliability, and scalability are always at the core of our work.


What you get to do in this role:

Design and build highly innovative interactive high performant solutions with scalability and quality.
Design software that is simple to use to allow customers to extend and customize the functionality to meet their specific needs.
Build high-quality, clean, scalable, and reusable code by enforcing best practices around software engineering architecture and processes (Code Reviews, Unit testing, etc.)
Design and develop tools, libraries, and frameworks with long term platform mindset thinking for high modularity, extensibility, configurability, and maintainability.
Lead and coordinate work cross functionally to improve architecture, developing process and mentoring junior members in the team.
Work with the product owners to understand detailed requirements and own your code from design, implementation, test automation and delivery of high-quality product to our users.
Contribute to the design and implementation of new products and features while also enhancing the existing product suite.
Manage projects with material technical risk at a team level.
Explorer and evaluate new technology and innovation to continuously improve platform capability and functionality.
Be a mentor for colleagues and help promote knowledge-sharing.

To be successful in the role:

Advanced knowledge and experience with fundamentals in distributed systems design and development
Strong fluency with Java programming as well as good understanding of Java memory model and garbage collection
Experience with JVM performance tuning and optimization as well as experience in diagnosing performance bottlenecks.
Advanced working knowledge of concurrency, sockets, networking, operating systems, memory management, runtimes, portability, etc
Has the experience and ability to diagnose issues and troubleshoot.

Nice to have:

Experience with streaming systems (Kafka, Pulsar, etc.)
Experience working with Kafka.
Experience working in a DevOps environment.
Experience with relational databases: Oracle, MySQL, MariaDB, MS SQLServer

Qualifications

10+ years of experience with Java or a similar OO language
Experience building and operating large-scale systems.
Experience with data structures, algorithms, object-oriented design, design patterns, and performance/scale considerations

For positions in California (outside of the Bay Area), we offer a base pay of $166,230 - $290,970, plus equity (when applicable), variable/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs (subject to eligibility requirements). Compensation is based on the geographic location in which the role is located, and is subject to change based on work location. For individuals who will be working in the Bay Area, there is a pay enhancement for positions located in that geographical area; please contact your recruiter for additional information.


Additional Information


ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.

At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.

If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.

For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.

Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.

From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.

Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",2004,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Carbon Market Data Program Engineer,"California Air Resources Board
","Sacramento, CA",$6K - $12K (Employer est.),4.1,"This is a repost. If you have previously applied for this position, there is no need to reapply.

Do you have an engineering background and experience with either designing programs to evaluate financial transactions or overseeing and implementing environmental programs using emissions data and forecasts? Are you interested in working at the forefront of global climate policy and helping to monitor and evaluate carbon market trading data and related greenhouse gas program activities?

The Market Monitoring Section of the Climate Change Program Evaluation Branch in the Industrial Strategies Division has an opening for an Air Resources Engineer (ARE) to serve in a critical role in the operation and oversight of the California Cap-and-Trade Program (Program), and to assist in the continued implementation and development of the Cap-and-Trade Regulation. The individual selected for this position should have an engineering background, programming expertise, and demonstrated abilities to perform market trade data analyses and to evaluate emissions data sets for compliance with the Program. The candidate will serve as the section’s market data engineer to help update existing monitoring programs and analyses used for surveilling transactions of carbon allowances and offset credits to ensure these transactions conform to Program market rules. The ARE will also draft market data reports, and develop automated market tools, such as data dashboards and data inventory checks, using R, SAS, or Python to develop written assessments and forecasts of the carbon market.

The Market Monitoring Section is responsible for overseeing the carbon market and tracking activities that occur in secondary markets, including derivatives and futures trading that can impact the behavior of entities registered to the Program. This position plays an integral role in the planning, evaluation, development, and implementation of market monitoring and market surveillance strategies. Under the direction of an Air Resources Supervisor I, the successful candidate will work as a member of a team to prepare carbon allowance supply and demand forecasts, investigate market transaction data, review business disclosures and filings, and surveil corporate structure and business relationships to protect the integrity of the carbon market as the market operator and State regulator.

The ARE will become a subject matter expert in the Cap-and-Trade Regulation and in evaluating entities registered in the carbon market for conformance with the Regulation and market rules and in developing the tools needed to perform such evaluations. The ARE will analyze an array of market data, including market transaction information, entity registration disclosures, and corporate associations and structures, and periodically update market analysis tools as necessary to respond to new market information that accounts for changing state, federal, and other jurisdiction program authority and requirements. The incumbent will work with a diverse group of authorities, including other California state agencies and federal agencies, to ensure robust oversight of the markets for compliance instruments. The ARE will assess entity behavior, auction participation information, and data on transfers and holdings of compliance instruments. This position will work with a diverse and highly skilled team to prepare internal briefing memos and market data reports, and, when necessary, work with CARB's Legal Office on investigations of potential market rule violations. The ARE may work with staff and stakeholders to develop regulatory amendments, conduct public consultations and workshops, and produce regulatory documents and guidance materials.

NOTE: IF SELECTED FOR THE POSITION, YOUR SALARY OFFER IS DETERMINED BY WHAT YOU INCLUDE ON YOUR STANDARD STATE APPLICATION (STD. 678). PLEASE INCLUDE A DETAILED DESCRIPTION OF ALL RELEVANT EXPERIENCE AND EDUCATION IN YOUR STATE APPLICATION (STD.678) WHEN APPLYING.

You will find additional information about the job in the Duty Statement.

Working Conditions

The positions at the CARB may be eligible for telework with in-person attendance based on the operational needs of the position under Government Code 14200 for eligible applicants residing in California, subject to the candidate meeting telework eligibility criteria set forth in the CalEPA telework policy and/or future program need. Employees not residing in California are not eligible for telework. Regardless of hybrid telework eligibility, all employees may be required to report to the position’s designated headquarters location at their own expense, as indicated on their duty statement.

Position located in a high-rise building.
Requires being stationary, consistent with office work, for extended periods.
Standard office environment (artificial lighting, controlled temperature, etc.).
Daily use of a personal computer, office equipment, and/or telephone.
Remote work is offered based on a telework agreement. This position requires some in-person office headquarters work.

Job Type: Full-time

Pay: $6,175.00 - $11,567.00 per month

Benefits:

Dental insurance
Health insurance
Paid time off
Retirement plan
Vision insurance

Schedule:

8 hour shift

Work Location: In person",1968,State & Regional Agencies,$100 to $500 million (USD),Government & Public Administration,1001 to 5000 Employees,Government,False
"Data Engineer (Senior, Lead, Principal)","Salesforce
","San Francisco, CA",$123K - $280K (Employer est.),4.0,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Software Engineering

Job Details

About Salesforce

We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.

Data Engineer

Note: By applying to the Data Engineer posting, recruiters and hiring managers across the organization hiring data engineers will review your resume. Our goal is for you to apply once and have your resume reviewed by multiple hiring teams.

Salesforce has a number of teams hiring Data Engineers with a variety of experience across, but not limited to, the following types of teams: Legal, Data Intelligence, Monetization Strategy, Marketing, and Data Science.

Each team is made up of data scientists, engineers, growth analysts, and information management authorities who are dedicated to driving product strategy with data-driven insights. Teams with executives, product managers, designers, developers, user researchers, marketers, and sales strategy team members across all Cloud businesses to discover new opportunities for growth and optimization, experiment with data, drive adoption, and provide useful insights that impact product strategy. This role involves making an impact by driving continuous improvements in moving, aggregating, profiling, sampling, testing and analyzing terabytes of data.

The Data and Analytics Organization (DnA) is Salesforce's cornerstone for fostering growth and margins through unparalleled data insights. From robust governance to strategic execution, we support data pioneers with an unbiased approach. Our Enterprise Data Strategy builds a solid data foundation, fostering a culture of data-driven decisions. We ensure end-to-end quality through a cohesive data supply chain. By deploying and integration platform tools, we enable seamless data access and automated data management driving efficiency and growth with actionable insights.

Your Impact:

Be responsible for the technical solution design, lead the technical architecture and implementation of data acquisition and integration projects, both batch and real time
Define the overall solution architecture needed to implement a layered data stack that ensures a high level of data quality and timely insights
Communicate with product owners and analysts to clarify requirements
Craft technical solutions and assemble design artifacts (functional design documents, data flow diagrams, data models, etc.)
Build data pipelines data processing tools and technologies in open source and proprietary products
Serve the team as a domain expert & mentor for ETL design, and other related big data and programming technologies
Identify incomplete data, improve quality of data, and integrate data from several data sources
Proactively identify performance & data quality problems and drive the team to remediate them. Advocate architectural and code improvements to the team to improve execution speed and reliability
Design and develop tailored data structures
Reinvent prototypes to create production-ready data flows
Support Data Science research by designing, developing, and maintaining all parts of the Big Data pipeline for reporting, statistical and machine learning, and computational requirements
Perform data profiling, sophisticated sampling, statistical testing, and testing of reliability on data
Clearly articulate pros and cons of various technologies and platforms in open source and proprietary products Implement proof of concept on new technology and tools to help the organization pick the best tools and solutions
Strong SQL optimization and performance tuning experience in a high volume data environment that uses parallel processing
Teams are using the following: SQL, Python, Airflow, AWS, Spark, Tableau, Hadoop
Participate in the team’s on-call rotation to address sophisticated problems in real-time and keep services operational and highly available

Required Skills:

4+ years experience in data engineering
Build programmatic ETL pipelines with SQL based technologies and platforms
Solid understanding of databases, and working with sophisticated datasets
Data governance, verification and data documentation using current tools and future adopted tools and platform
Work with different technologies (Python, shell scripts) and translate logic into well-performing SQL
Perform tasks such as writing scripts, web scraping, getting data from APIs etc.
Automate data pipelines using scheduling tools like Airflow
Be prepared for changes in business direction and understand when to adjust designs
Experience writing production level SQL code and good understanding of Data Engineering pipelines
Experience with Hadoop ecosystem and similar frameworks
Previous projects should display technical leadership with an emphasis on data lake, data warehouse solutions, business intelligence, big data analytics, enterprise-scale custom data products
Knowledge of data modeling techniques and high-volume ETL/ELT design
Experience with version control systems (Github, Subversion) and deployment tools (e.g. continuous integration) required
Experience working with Public Cloud platforms like GPC, AWS, or Snowflake
Ability to work effectively in an unstructured and fast-paced environment both independently and in a team setting, with a high degree of self-management with clear communication and commitment to delivery timelines
A related technical degree required



Benefits & Perks

Check out our benefits site which explains our various benefits, including wellbeing reimbursement, generous parental leave, adoption assistance, fertility benefits, and more.

Salesforce Information
Check out our Salesforce Engineering Site .

*IN SCHOOL OR GRADUATED WITHIN THE LAST 12 MONTHS? PLEASE VISIT FUTURE FORCE FOR OPPORTUNITIES *

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .

Posting Statement

At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .

Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce . ﻿

Salesforce welcomes all.

Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.

For Washington-based roles, the base salary hiring range for this position is $122,600 to $280,200.
For California-based roles, the base salary hiring range for this position is $133,800 to $305,600.

Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.",1999,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Senior ASIC Design Engineer, Memory Controller - Data Center","NVIDIA
","Santa Clara, CA",$124K - $247K (Employer est.),4.6,"NVIDIA is looking for a Senior ASIC Design Engineer for our Memory Controller team!
As a Senior ASIC Engineer, you'll join a group of hard-working engineers to craft and implement innovative Memory Controllers for our GeForce GPUs and Tegra SoCs! At Nvidia, you'll make a real impact in a multifaceted, technology-focused company. Your work will affect product lines ranging from consumer graphics to self-driving cars and the growing field of artificial intelligence. We've crafted a team of outstanding people stretching around the globe, whose mission is to push the frontiers of what is possible today and define the computing platforms of tomorrow.
What You'll Be Doing:
As a member of our Memory Subsystem Design team, you will collaborate with architects, software engineers, and circuit designers to and deliver an extraordinary solution. NVIDIA Memory controllers are among the industry's most sophisticated because of the many protocols that are supported and the stringent requirements of our high-end graphics controllers and SOCs.
In this position, you will have the opportunity to be responsible for the micro-architecture and design including RTL design, synthesis, functional verification, and timing analysis using groundbreaking CAD tools and using the latest process technologies.
What We Need To See:
BS, MS, or PhD in Electrical Engineering, Computer Engineer, or related degree required (or equivalent experience)
5+ years of relevant and proven experience and a background in ASIC design (Graphics, Microprocessors, Network Processors, or Mobile / Multimedia SOCs).
Relevant experience with all stages in the ASIC design flow including emulation, prototyping, DFT, timing analysis, floor planning, ECO, bring up & lab debug, and ATE test development.
Strong understanding with Verilog or VHDL.
Familiarity with board and system level issues.
Programming skills in Python, C, and/or PERL.
Good communication skills and interpersonal skills are required. A history of mentoring junior engineers and interns a huge plus.
Experience with Error Detection and Correction Algorithms
Knowledge of Security algorithms and standards - AES/SHA/etc
Way To Stand Out From The Crowd:
Knowledge of LPDDR and/or DDR
Experience with Data-Center memory-system RAS (Reliability, Availability, Serviceability)
The base salary range is 124,000 USD - 247,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
. NVIDIA accepts applications on an ongoing basis.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",1993,Computer Hardware Development,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Sr. Software Engineer - Data Engineer,"Capgemini Engineering
","Ontario, CA",$87K - $127K (Glassdoor est.),3.8,"Life at Capgemini

Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:

Flexible work
Healthcare including dental, vision, mental health, and well-being programs
Financial well-being programs such as 401(k) and Employee Share Ownership Plan
Paid time off and paid holidays
Paid parental leave
Family building benefits like adoption assistance, surrogacy, and cryopreservation
Social well-being benefits like subsidized back-up child/elder care and tutoring
Mentoring, coaching and learning programs
Employee Resource Groups
Disaster Relief
About Capgemini Engineering

World leader in engineering and R&D services, Capgemini Engineering combines its broad industry knowledge and cutting-edge technologies in digital and software to support the convergence of the physical and digital worlds. Coupled with the capabilities of the rest of the Group, it helps clients to accelerate their journey towards Intelligent Industry. Capgemini Engineering has more than 55,000 engineer and scientist team members in over 30 countries across sectors including Aeronautics, Space, Defense, Naval, Automotive, Rail, Infrastructure & Transportation, Energy, Utilities & Chemicals, Life Sciences, Communications, Semiconductor & Electronics, Industrial & Consumer, Software & Internet.

Capgemini Engineering is an integral part of the Capgemini Group, a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided every day by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.

Get the Future You Want | www.capgemini.com

Disclaimer

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.





Name of the position: Senior Data Engineer
Department/Project: Engineering

PURPOSE OF THE JOB

As a Senior Engineer, you will build distributed data processing solution and highly loaded database solutions for various cases including reporting, product analytics, marketing optimization and financial reporting. Give as part of self-organized team of experienced data engineers working in a complicated, innovative environment for our client, crafting the foundation for decision-making at a company dealing with billions of events per day.
Investigate, build, and implement the solutions for existing technical challenges. Provide mentorship, instruction, direction, leadership to a development team with the purpose of achieving project goals.

MAIN TASKS AND RESPONSIBILITIES

Acquires tasks from the project lead or Team Lead (TL), prepares functional and design specifications, approves them with all team members.
Ensures that assigned area/areas are delivered within required quality objectives.
Provides estimations, agrees task duration with the manager and gives to project plan of assigned area.
Analyzes scope of alternative solutions and makes decision about area implementation based on their experience and technical expertise.
Leads functional and architectural design of assigned areas. Makes sure design decisions on the project meet architectural and design requirements.
Addresses area-level risks, provides and implements mitigation plan.
Responsible for resolving crisis situations within their AOR.
Initiates and conducts code reviews, creates code standards, conventions and guidelines.
Suggests technical and functional improvements to make valuable contributions to the product;
Constantly improves their professional level.
Collaborates with other teams.
REQUIRED EDUCATION AND EXPERIENCE
Must have:

5+ years of professional experience
University degree or equivalent experience in Computer Related Sciences or similar
shown experience working in data engineering, business intelligence, or a similar role
Proficiency in programming languages such as Python
demonstrated ability in ETL orchestration and workflow management tool Airflow
Guide in Database fundamentals, SQL and distributed computing
proven experience with the Distributed data/similar ecosystem (Spark, Hive, Presto o and/or streaming technologies such as Kafka/Flink.
Experience working with Snowflake, Redshift, PostgreSQL and/or other DBMS platforms

Nice to have:

Experience in AWS (EC2/S2/IAM).",1967,Information Technology Support Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Senior Software Engineer, Data Science - LLM MLOps Platform","NVIDIA
","Santa Clara, CA",$144K - $270K (Employer est.),4.6,"NVIDIA has been transforming computer graphics, PC gaming, and accelerated computing for more than 25 years. It’s an outstanding legacy of innovation that’s fueled by phenomenal technology—and amazing people! Today, we’re tapping into the unlimited potential of AI to define the next era of computing. An era in which our GPU acts as the brains of computers, robots, and self-driving cars that can understand the world. Doing what’s never been done before takes vision, innovation, and the world’s best talent. As an NVIDIAN, you will be immersed in a diverse, encouraging environment where everyone is inspired to do their best work. Come join the team and see how you can make a lasting impact on the world.
What you'll be doing:
Build data cleaning and personally identifiable information (PII) removal Solutions by applying data science and related technologies.
Build and Operate sophisticated ML data analytics services to actively perform PII detections and removal, and policy recommendations.
Collaborate across high-performance software engineering teams to develop innovative ML solutions using NVIDIA Deep Learning Software and GPU stack.
Showcase leadership and lead the product development roadmap to align with business priorities and vision.
Build high performance data pipelines of Big Data solutions in real time for inferencing, training and ETL.
Utilizing Data Engineering, ETL, machine learning technologies for training, inferencing and deployment of ML models into production applications.
What we need to see:
Masters in Computer Science, Electrical Engineering or equivalent experience
5+ years of experience architecting, crafting and implementing software solutions, preferably in product development space and 3+ years hands-on experience in distributed computing, data engineering and data analytics
Experience using end-to-end MLOps platforms such as Kubeflow, MLFlow, AirFlow
Experience with data pipelines/analysis/visualization tooling such as PowerBI, Elastic stack, Logstash, Kibana, Kafka, Grafana, Splunk, Pandas, Message brokers, Data modeling etc.
Software development experience in any of the following core languages/frameworks: Python, Java, GO, Spring/Hibernate
Knowledge of parallel programming architectures or experience programming distributed systems.
Proven experience with log management, data analysis, data query approaches and dashboarding.
Experience with big data and related technologies (e.g. Hadoop, Spark, Cassandra).
Background with streaming architectures (e.g. NiFi, Streamz, ReactiveX) and pub/sub systems (e.g. Kafka, Pulsar)
Solid understanding of Amazon Web Services, Kubernetes, Docker is a plus
Ways to stand out from the crowd:
ML/DL/Cloud certifications
Knowledge of Cloud Based solutions like Kendra, SageMaker, Auto-ML, Big Query, RedShift, Glue, Athena, FireHose etc.
Excellent communication and teamwork skills
With highly competitive salaries and a comprehensive benefits package, NVIDIA is widely considered to be one of the technology industry's most desirable employers. We have some of the most forward-thinking and hardworking people in the world working with us and our engineering teams are growing fast in some of the hottest innovative fields: Deep Learning, Artificial Intelligence, and Large Language Models. If you're a creative engineer with a real passion for robust and enjoyable user experiences, we want to hear from you!
The base salary range is 144,000 USD - 270,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
. NVIDIA accepts applications on an ongoing basis.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",1993,Computer Hardware Development,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Site Reliability Engineer, Data Platform- USDS","TikTok
","Los Angeles, CA",$130K - $342K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

About USDS
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.

U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

Team Introduction
TikTok's Data Platform Team focuses on challenges in the areas of data infrastructure and data products. The team is in charge of various aspects including Query Engine, Logging and Data Ingestion Infra, Experimentation Platform, as well as Workflow Management Platform. The goal is to support ad-hoc/interactive queries, batch pipelines, logging and ingesting large amounts of realtime data, and supporting A/B testing for all product features launches.

In order to enhance collaboration and cross-functional partnerships, among other things, at this time, our organization follows a hybrid work schedule that requires employees to work in the office 3 days a week, or as directed by their manager/department. We regularly review our hybrid work model, and the specific requirements may change at any time.

Site Reliability Engineering (SRE) combines software and systems engineering to build and run large-scale, massively distributed services and infrastructures. As a site reliability engineer in the data platform area, you will have the opportunity to manage the services and infrastructures in one of the largest data platforms in the world. You'll need to ensure the data, services and infrastructures are reliable, fault-tolerant, efficiently scalable and cost-effective. You'll also have the opportunity to design, build and deliver all kinds of systems as a software engineer.


Engage in and improve the whole lifecycle of service, from inception and design, through to deployment, operation and refinement
Ensure reliable, fault-tolerant, efficiently scalable and cost-effective data, services and infrastructures
Maintain services once they are live by measuring and monitoring availability, latency and overall system health. Practice sustainable incident response and blameless postmortems.
Establish best engineering practice for engineers as well as non-technical people
Design and implement reliable, scalable, robust and extensible big data systems that support core products and business
Qualifications

BS or MS degree in Computer Science or related technical field or equivalent practical experience
Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.)
Experience with performing data analysis, data ingestion and data integration
Solid communication and collaboration skills
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at usds.accommodations@tiktokusds.com
Job Information
The base salary range for this position in the selected city is $129960 - $341734 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
"Senior Software Engineer, NGC Data Platform","NVIDIA
","Santa Clara, CA",$144K - $334K (Employer est.),4.6,"The NVIDIA GPU Cloud (NGC) Data Platform team is building a cloud-native stack of software services and tools for managing data on a hybrid and multi-cloud infrastructure. We are building the next-generation Data and Storage infrastructure to solve the most challenging problems - storage, access, and data management for exabyte-scale, high-performance GPU-based training and inference jobs. You will craft software services to deliver the functionality for NVIDIA internal platforms and our external-facing cloud infrastructure.
What you will be doing:
Design and build software code and cloud services for Data Management, including providing a catalog and metadata storage datasets
Connect with other technical leaders across NVIDIA to ensure you are using existing technologies where possible and that we are collaborating with their systems appropriately.
Collaborate with the NVIDIA research team to use new Storage and Compute innovations - GPU direct storage, DPU.
What we need to see:
BS in Computer Science, Information Systems, or Computer Engineering (or equivalent experience)
5+ years of proven experience
Experience building robust services at scale. Build and maintain high volume / low latency data platform services
Strong foundation in algorithms and data structures and their real-world use cases.
Experience with distributed systems, databases, and Big Data systems (Spark, Hadoop).
Experience building and shipping services around Kubernetes, Cloud Native, and Cloud Service Providers. Experience with one of the leading cloud providers: AWS, GCP, or Azure. Experience collaborating with teams to write software to support cloud services.
Experience with backend systems and software engineering. Programming experience in a relevant language, e.g., Go, Python, C/C++, Java.
Understanding of standard approaches to software engineering, software architecture, and design. Ability to document software and services. Break down projects into practical tasks.
Communicate design, status, and other sophisticated subjects in written, visual, and oral formats. Ability and passion for working across teams and with collaborators on all sides of the project
Ways to stand out from the crowd:
Hands-on experience in building and managing large-scale data platform services.
Experience building products and services to solve enterprise-grade customer data analytics problems.
Experience with Apache Spark, Object Storage, Metadata Management, Data lake tools (Apache Iceberg), Machine Learning infrastructure toolset (Feature Stores)
Computer science background with Distributed systems as a specialization
NVIDIA is leading the way in groundbreaking developments in Artificial Intelligence, High-Performance Computing, and Visualization. The GPU, our invention, serves as the visual cortex of modern computers and is at the heart of our products and services. Our work opens up new universes to explore, enables amazing creativity and discovery, and powers what were once science fiction inventions, from artificial intelligence to autonomous cars. NVIDIA is looking for great people like you to help us accelerate the next wave of artificial intelligence. NVIDIA offers highly competitive salaries and a comprehensive benefits package. We have some of the most forward-thinking and talented people in the world working for us and, due to unprecedented growth, our world-class engineering teams are growing fast. If you're a creative and autonomous engineer with real passion for technology, we want to hear from you.
The base salary range is 144,000 USD - 333,500 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
. NVIDIA accepts applications on an ongoing basis.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",1993,Computer Hardware Development,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Senior Data Engineer,"GSK
","San Francisco, CA",$132K - $178K (Glassdoor est.),4.1,"The Onyx Research Data Platform organization represents a major investment by GSK R&D and Digital & Tech, designed to deliver a step-change in our ability to leverage data, knowledge, and prediction to find new medicines. We are a full-stack shop consisting of product and portfolio leadership, data engineering, infrastructure and DevOps, data / metadata / knowledge platforms, and AI/ML and analysis platforms, all geared toward:

Building a next-generation data experience for GSK’s scientists, engineers, and decision-makers, increasing productivity, and reducing time spent on “data mechanics”
Providing best-in-class AI/ML and data analysis environments to accelerate our predictive capabilities and attract top-tier talent
Aggressively engineering our data at scale to unlock the value of our combined data assets and predictions in real-time

Data Engineering is responsible for the design, delivery, support, and maintenance of industrialised automated end to end data services and pipelines. They apply standardised data models and mapping to ensure data is accessible for end users in end-to-end user tools through use of APIs. They define and embed best practices and ensure compliance with Quality Management practices and alignment to automated data governance. They also acquire and process internal and external, structure and unstructured data in line with Product requirements.

A Senior Data Engineer is a leading technical contributor who can consistently take a poorly defined business or technical problem, work it to a well-defined data problem / specification, and execute on it at a high level. They have a strong focus on metrics, both for the impact of their work and for its inner workings / operations. They are a model for the team on best practice for software development in general (and data engineering in particular), including code quality, documentation, DevOps practices, and testing, and consistently mentor junior members of the team. They ensure robustness of our services and serve as an escalation point in the operation of existing services, pipelines, and workflows.

A Senior Data Engineer should be deeply familiar with the tools of modern data engineering (e.g. Spark, Kafka, Storm) and of their customers, and engaged with the open source community surrounding them – potentially, even to the level of contributing pull requests.

Key responsibilities for the Senior Data Engineer include:

Designs, builds, and operates data tools, services, workflows, etc that deliver high value through the solution to key business problems by leveraging modern data engineering tools (e.g. Spark, Kafka, Storm, …) and orchestration tools (e.g. Google Workflow, AirFlow Composer)
Confidently optimizes design and execution of complex solutions in data ingestion and data transformation
Produces well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Diverse problem solver who surfaces opportunities to reuse modular code and develop microservices to drive efficiencies
Provides input into the roadmaps of upstream teams (e.g. Data Platforms, DataOps, DevOps) to help improve the overall program of work
Ensure consistent application of platform abstractions to ensure quality and consistency with respect to logging and lineage
Fully versed in coding best practices and ways of working, and participates in code reviews and partnering to improve the team’s standards
Adhere to QMS framework and CI/CD best practices and helps to guide improvements to them that improve ways of working
Provide leadership to team members to help others get the job done right

Please view this video to get a better understanding of this role-

Why you?

Basic Qualifications:

We are looking for professionals with these required skills to achieve our goals:

Bachelor’s Degree in Data Engineering, Computer Science, Software engineering or related field
5+ years of data engineering experience
Experience with at least one common programming language: e.g., Python, Scala, Java, including toolchains for documentation, testing, and operations / observability
Cloud experience (e.g., AWS, Google Cloud, Azure, Kubernetes)
Experience in automated testing and design
Experience with DevOps-forward ways of working

Preferred Qualifications:

If you have the following characteristics, it would be a plus:

Deep expertise in modern software development tools / ways of working (e.g. git/GitHub, devops tools, metrics / monitoring, …)
Extensive cloud experience (e.g., AWS, Google Cloud, Azure, Kubernetes), including infrastructure-as-a-code
Application experience of CI/CD implementations using git and a common CI/CD stack (e.g. Jenkins, CircleCI, GitLab, Azure DevOps)
Demonstrated excellence with agile software development environments using tools like Jira and Confluence
Deep familiarity with the tools, techniques, etc of modern data engineering (e.g. Spark, Kafka, Storm, …) and orchestration (e.g. Google Workflow, AirFlow Composer), including engagement with the open source community (and potentially making contributions to such tools)
Strong experience in data modelling, database concepts and SQL
Familiarity with orchestrating tooling

Why GSK?

Our values and expectations are at the heart of everything we do and form an important part of our culture.

These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance, and trust, the successful candidate will demonstrate the following capabilities:

Agile and distributed decision-making – using evidence and applying judgement to balance pace, rigour and risk
Managing individual and team performance. Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.
Implementing change initiatives and leading change.
Sustaining energy and well-being, building resilience in teams.
Continuously looking for opportunities to learn, build skills and share learning both internally and externally.
Developing people and building a talent pipeline.
Translating strategy into action - a compelling narrative, motivating others, setting objectives and delegation.
Building strong relationships and collaboration, managing trusted stakeholder relationships internally and externally.
Budgeting and forecasting, commercial and financial acumen.

#LI-GSK

#GSKOnyx

The annual base salary for new hires in this position ranges from $145,877 to $197,363 taking into account a number of factors including work location, the candidate’s skills, experience, education level and the market rate for the role. In addition, this position offers an annual bonus and eligibility to participate in our share based long term incentive program which is dependent on the level of the role. Available benefits include health care and other insurance benefits (for employee and family), retirement benefits, paid holidays, vacation, and paid caregiver/parental and medical leave.

Please visit GSK US Benefits Summary to learn more about the comprehensive benefits program GSK offers US employees.

Why Us?

GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.

Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.

If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).

GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK’s compliance to all federal and state US Transparency requirements. For more information, please visit GSK’s Transparency Reporting For the Record site.",1830,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Company - Public,False
Software Engineer - Synthetic Data & Annotations,"Applied Intuition
","Mountain View, CA",$65K - $400K (Employer est.),4.0,"About Applied Intuition

Applied Intuition is a vehicle software supplier that accelerates the adoption of safe and intelligent machines worldwide. Founded in 2017, Applied Intuition provides a simulation and validation platform for various industries such as automotive, trucking, construction, and more. 17 of the top 20 global automakers rely on Applied Intuition's solutions to shorten development cycles, deliver high-quality systems, and accelerate the production of modern vehicles with confidence. Applied Intuition is headquartered in Mountain View, CA, with offices in Ann Arbor, MI, Washington, DC, Munich, Stockholm, Seoul, and Tokyo. Learn more at https://applied.co.

About the role

We are looking for a software engineer with expertise in computational geometry, simulation, and machine learning. As a software engineer focused on synthetic data and annotations, you'll build systems to generate labeled data that is suitable for training a variety of machine learning systems. This position will join an existing team of engineers with expertise in computer vision, sensor modeling, rendering, and data infrastructure.

At Applied Intuition, you will:

Design and implement core components of our sensor simulation and data generation pipeline
Develop systems for programmatically generating ground-truth-labeled data from a simulated world
Work with machine learning pipelines to understand and improve synthetic datasets
Work with top autonomy companies to understand and solve unique challenges in perception with synthetic data

We're looking for someone who has:

Strong software engineering skills in Python and C++
Familiarity with Unreal Engine
Competent skills & experience in computational geometry, linear algebra, optics, electro-optics, and physics
Familiarity with synthetic data and its applications in perception systems

Nice to have:

Experience with applying synthetic data to machine learning tasks
Detailed knowledge of game pipelines and Unreal Engine
Hands-on experience with characterization of models for Lidar, Radar, and Camera

The salary range for this position is $65,000 USD to $400,000 USD annually. This salary range is an estimate, and the actual salary may vary based on the Company's compensation practices.

Don't meet every single requirement? If you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.

Applicants will be required to be fully vaccinated against COVID-19 upon commencing employment. Reasonable accommodations will be considered on a case-by-case basis for exemptions to this requirement in accordance with applicable federal and state law. Applicants should be aware that for external-facing roles that involve close contact with Company employees or other third parties on the Company's premises, accommodations that involve remaining unvaccinated against COVID-19 may not be deemed reasonable. The Company will engage in the interactive process on an individualized basis taking into account the particular position.

Applied Intuition is an equal opportunity employer and federal contractor or subcontractor. Consequently, the parties agree that, as applicable, they will abide by the requirements of 41 CFR 60-1.4(a), 41 CFR 60-300.5(a) and 41 CFR 60-741.5(a) and that these laws are incorporated herein by reference. These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. These regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability. The parties also agree that, as applicable, they will abide by the requirements of Executive Order 13496 (29 CFR Part 471, Appendix A to Subpart A), relating to the notice of employee rights under federal labor laws.",2017,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
"Data Engineer, Data Platform - USDS","TikTok
","Mountain View, CA",$137K - $360K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About USDS
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.

U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

Team Introduction
Tiktok's Data Platform Team focuses on challenges in the areas of data infrastructure and data products. The team is in charge of various aspects including Query Engine, Logging and Data Ingestion Infra, Experimentation Platform, as well as Workflow Management Platform. The goal is to support ad-hoc/interactive queries, batch pipelines, logging and ingesting large amounts of realtime data, and supporting A/B testing for all product features launches.

As a data engineer in the data platform team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world that directly supports the TikTok app. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.


Design, build and maintain data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)
Design, implement and maintain reliable, scalable, robust and extensible big data systems that support core products and business
Establish solid design and best engineering practice for engineers as well as non-technical people
Qualifications

Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience
Experience in performing data analysis, data ingestion and ETL(Extraction, Transformation & Loading)
Experience with the Big Data technologies is a plus (Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc)
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at USRC@tiktok.com
Job Information
The base salary range for this position in the selected city is $136800 - $359720 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
"Site Reliability Engineer, Data Analytics","Apple
","San Diego, CA",-1,4.2,"Summary
Posted: Nov 7, 2023
Weekly Hours: 40
Role Number:200515498
At Apple, our Data Analytics team focuses on improving the user experience by improving operating system stability, gathering feature usage telemetry, and evaluating device performance. This requires capturing data from customers who have given consent, utilizes strong privacy preserving techniques, and entails aggregating information, all to help inform direction. We develop and operate a variety of Big Data infrastructure products and applications in support of these goals. Ways to increase its reliability, and improve its development lifecycle.
Key Qualifications
Demonstrable experience of production experience managing and supporting large scale distributed Big Data applications (from development to production)
Experience with at least one of the following languages and related development tools: (Python, Ruby, Java, Scala)
Experience with one or more of the following platforms: HDFS, Yarn, Spark, Impala, Hbase, MapReduce, Kubernetes, other cloud services
Passion for quality and attention to detail
Excellent written and verbal communication skills
Description
We are looking for Site Reliability Engineer to be a member of our team. If working on large scale problems excites you then we’re excited to talk to you! Our team helps Apple engineers answer mission critical questions about their hardware, firmware, and software. We work with engineers across Apple to help keep our suite of analytics applications available and to ensure the integrity of their data. The successful candidate will write code to automate our processes to ensure reliability and manage thousands of compute and storage instances across large heterogeneous infrastructure. You'll dive into complex data and application issues to drive root cause analysis of large scale problems. You'll partner with your teammates and peers to solve problems, applying critical thinking skills and understanding of complex distributed systems. The candidate will have to opportunity to contribute to the development of Apple's applications such as Mail and Safari, in addition to help to improve the performance of macOS and iOS. Build, monitor, troubleshoot complex data infrastructure at the petabyte scale - Support the continuous development and deployment of multi service analytics applications - Develop tools and processes to automate the management of our systems and data
Education & Experience
Technical/Engineering BS or equivalent industry experience
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $131,500 and $243,300, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",1976,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer,"Balbix
","San Jose, CA",$110K - $165K (Glassdoor est.),4.3,"WHO WE ARE
Balbix is the world's leading platform for cybersecurity posture automation company. The Balbix Security Cloud uses AI and automation to reinvent how the World's leading organizations reduce their cyber risk. With Balbix, security teams can accurately inventory their cloud and on-prem assests, conduct vulnerability management and quantify their cyber risk in monetary terms.



Balbix counts many global 1000 companies among its rapidly growing customer base. We are backed by John Chambers (the former CEO and Chairman of Cisco), top Silicon Valley VCs and global investors. We have been called magical, and have received raving reviews as well as customer testimonials, numerous industry awards, and recognition by Gartner as a Cool Vendor, and by Frost & Sullivan.



ABOUT THIS ROLE
As a senior data engineer you will work on complex data pipelines dealing with petabytes of data. Balbix platform is used as one of the critical security tools by the CIOs, CISOs, and the sec-ops teams of small, medium and large sized enterprises including Fortune 10 companies around the world. You will solve problems related to massive cybersecurity and IT data sets. You will collaborate closely with our data scientists, threat researchers and network experts to solve real-world problems plaguing cybersecurity. This role requires excellent algorithm, programming and testing skills as well as experience in large-scale data engineering projects.
You Will
Design and implement the features and own the modules for ingesting, storing and manipulating large data sets for a variety of cybersecurity use-cases
Write code to provide backend support for data-driven UI widgets, web dashboards, workflows, search and API connectors
Design and implement web services, rest APIs, and microservices
Build production quality solutions that balance complexity and meet acceptance criteria of functional requirements
Work with multiple-interfacing teams, including ML, UI, backend and data engineering
You Are
Driven to experience and learn more about design, architecture, and take on progressive roles
Collaborative and comfortable working with across teams including data engineering, front end, product management, and DevOps
Responsible and like to take ownership of challenging problems
An effective communicator, including good documentation practices and articulating thought processes in a team setting
Comfortable with working in an agile environment
Curious about technology and the industry, and a constant learner
You Have
MS/BS +2 years in Computer Science or a related field
Expert programming experience with Python, Java, or Scala
Good working knowledge of SQL databases such as Postgres and NoSQL databases such as MongoDB, Cassandra, Redis
Experience with search engine database such as ElasticSearch is preferred
Time-series databases such as InfluxDB, Druid, Prometheus
Strong computer science fundamentals: data structures, algorithms, and distributed systems
Life @ Balbix
At Balbix, we have built a culture that aligns to our values of ownership, customer focus, curiosity, tenacity, innovation, judgement, teamwork, communication, honesty and impact. In joining our team you’ll work with very motivated and knowledgeable people, build pioneering products and utilize cutting-edge technology. Our Balbix team members see rapid career growth opportunities stemming from our culture of alignment, bottom up innovation, our clarity of goals and unrelenting mission. Last but not least, developing the world's most advanced platform to address what the most important (and hardest) technology problem facing mankind today is exceptionally rewarding!

Benefits & Perks
Balbix offers comprehensive medical, dental, vision, life insurance and long-term disability coverage for you and your family. Our Flex Time Off policy encourages you to take time off when you need it because we know and value how hard you work. When it comes to our offices it’s location, location, location we’re right next door to Santana Row so you can enjoy your time in (and out) of the office!

More information at https://www.balbix.com/company/careers/

Please reach out if you want a seat on our rocket-ship and are passionate about changing the cybersecurity equation.

At Balbix we’re proud to be an equal opportunity workplace dedicated to equality, fairness and human kindness.
APPLY FOR THIS JOB",2015,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,False
Data Engineer,"Kumo
","Mountain View, CA",$95K - $146K (Glassdoor est.),5.0,"Come and change the world of AI with the Kumo team!

The creation of the data warehouse emerged to solve the analytics problem of large amounts of data. Now, we’ve moved from megabytes to gigabytes to terabytes of data storage with no end in sight and companies invest millions of dollars to store and organize that data and only leverage a fraction of it for machine learning.

With Kumo, we are building the first data platform to seamlessly allow machine learning over data warehouses for faster, simpler, and smarter predictions to combat data waste and maximize data value. Query the future with Kumo.

The global data management software market is set to reach $137.6 billion by 2026, and we're on a mission to make a significant impact. We're seeking intellectually curious and highly motivated Data Engineers to become foundational members of our Machine Learning and Data Platform team.
Required Qualifications for Ideal candidate
4+ years of professional experience in SaaS/Enterprise companies
Strong experience with data ingestion and connectors
Experience in building end-to-end production-grade data solutions on AWS or GCP
Experience in building scalable ETL pipelines.
Ability to plan effective data storage, security, sharing, and publishing within an organization.
Experience in developing batch ingestion and data transformation routines using ETL tools.
Familiarity with AWS services such as S3, Kinesis, EMR, Lambda, Athena, Glue, IAM, RDS.
Proficiency in several programming languages (Python, Scala, Java).
Familiarity with orchestration tools such as Temporal, Airflow, Luigi, etc.
Self-starter, motivated, with the ability to structure complex problems and develop solutions.
Excellent communication skills and ability to explain data and analytics strengths and weaknesses to both technical and senior business stakeholders.
Preferred Qualifications - good to have
Deep familiarity with Spark and/or Hive
Understanding of different storage formats like Parquet, Avro, Arrow, and JSON and when to use each
Understanding of schema designs like normalization vs. denormalization.
Proficiency in Kubernetes, and Terraform.
Azure, ADF and/or Databricks skills
Experience with integrating, transforming, and consolidating data from various data systems into analytics solutions
Good understanding of databases, SQL, ETL tools/techniques, data profiling and modeling
Strong communications skills and client engagement
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Company - Public,False
Business Data Engineer,"Latham & Watkins LLP
","Los Angeles, CA",$110K - $130K (Employer est.),4.3,"About Latham & Watkins:
Latham & Watkins is a global law firm consistently ranked among the top firms in the world. The success of our firm is largely determined by our commitment to hire and develop the very best and brightest, creating a team that provides our clients with the highest quality of work and service. We are driven by our core values: respect, innovation, and collaboration.
About the Role:

The Business Data Engineer is an integral part of Latham’s Technology team. This role will be responsible for developing, researching, and implementing data analysis projects including but not limited to data reporting, data visualizations, data design, and ad-hoc research projects, while working with firm management to further Enterprise Analytics and Business Intelligence visualization and reporting capabilities. This role will be located in our Global Services Office, located in downtown Los Angeles. Please note that this role may be eligible for a flexible working schedule that allows for a hybrid and in-office presence.

Responsibilities & Qualifications:
Other key responsibilities include:


Working with senior management on research projects to design, develop, and deploy advanced data modeling systems
Analyzing and verifying internal consistency, completeness, and accuracy of data systems and making required adjustments
Acting as a resource to the firm on various data related questions for staff and other users; responding to user questions and issues in a timely manner and assisting with solutions
Working with vendors in order to resolve complex issues
Staying abreast of current and new development processes, tools, technologies, and market trends as they relate to systems development and implementation in support of the legal industry


We’d love to hear from you if you:




Possess strong development experience with Business Intelligence Tools (such as Tableau, SAP Business Objects, Microsoft Power BI, SAS)
Display strong skills in dashboard and report development, including but not limited to the ability to create meaningful dashboards to customers' satisfaction
Demonstrate strong SQL skills including but not limited to data profiling skills to identify and understand anomalies

And have:

A Bachelor’s degree, preferably in Computer Science, Data Science, Math, Economics, or a related field
A minimum of seven (7) years of experience with professional BI development
Benefits & Additional Information:

Successful candidates will not only be provided with an outstanding career opportunity and welcoming environment, but will also be provided with a generous total compensation package with bonuses awarded in recognition of both individual and firm performance. Eligible employees can participate in Latham’s comprehensive benefit program which includes:




Healthcare, life and disability insurance
A generous 401k plan
At least 11 paid holidays per year, and a PTO program that accrues 23 days during the first year of employment and grows with tenure
Well-being programs (e.g. mental health services, mindfulness and resiliency, medical resources, well-being events, and more)
Professional Development programs
Employee discounts
And more!


Additionally, we have a range of diversity programming including Global Affinity Groups. These groups provide a firmwide platform to share experiences and advice as well as an opportunity to participate in a supportive network with common interests to help make life at the firm even better.


Latham & Watkins is committed to diversity, equal opportunity, sustainability, and pro bono legal services. We draw from a remarkable wealth of talent to create one of the world's leading law firms, and advance these commitments through the work of our Global Citizenship department. Our lawyers, paralegals, and professional staff worldwide comprise a rich mixture of different races, ethnic backgrounds, religions, sexual orientations, cultures, and primary languages. Our diversity makes us who we are.


Latham & Watkins LLP will consider qualified applicants with criminal histories in a manner consistent with the City of Los Angeles Fair Chance Initiative for Hiring Ordinance (FCIHO). Please click the link below to review the Ordinance.


Please click here to review your rights under U.S. employment laws. #LI-JG2

Pay Range: USD $110,000.00 - USD $130,000.00 /Yr.",1972,Legal,$1 to $5 billion (USD),Legal,1001 to 5000 Employees,Company - Private,False
"Security Engineer, Data Protection, 3+ years of experience","Snapchat
","Los Angeles, CA",$140K - $196K (Employer est.),3.7,"Snap Inc.
is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are
Snapchat
, a visual messaging app that enhances your relationships with friends, family, and the world;
Lens Studio
, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses,
Spectacles
.
Snapchat
is a camera and messaging app that connects people to their friends and the world. Every day around the globe, millions of people use Snapchat to communicate with friends, build relationships, play, and learn. No matter where you are or how you express yourself, it’s always the fastest way to share a moment!
We’re looking for a Security Engineer to join the Data Protection team at Snap Inc!
What you’ll do:
Design and implement robust security measures to fortify Snap’s data and infrastructure across multiple cloud platforms, especially in identity and access management.
Conduct in-depth security reviews of new platforms and services, and build tools to enhance data privacy and security throughout its lifecycle.
Perform code reviews and ensure exceptional code quality
Be a champion for security and user privacy
Knowledge, Skills & Abilities:
Excellent programming and software design skills, including debugging, performance analysis, and test design.
Experience with microservices architecture, distributed systems and cloud security technologies.
Excellent verbal and written communication skills, with high attention to detail.
Security knowledge in one or more team-relevant domains and technologies:
Identity and access management in GCP or AWS.
Balancing the principle of least privilege with productivity and security.
Implementing large-scale data privacy and security policies.
Minimum Qualifications:
BS/BA degree in a technical field such as Computer Science or equivalent years of experience.
3+ years of software development experience.
Experience designing, securing, and deploying large systems to Google Cloud or AWS.
""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office at least 80% of the time (an average of 4 days per week).
At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at
accommodations-ext@snap.com
.
Our Benefits
: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!
Compensation
In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These pay zones may be modified in the future.
Zone A (CA, WA, NYC)
:
The base salary range for this position is $165,000-$230,000 annually.

Zone B
:
The base salary range for this position is $157,000-$219,000 annually.
Zone C
:
The base salary range for this position is $140,000-$196,000 annually.
This position is eligible for equity in the form of RSUs.",2011,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,5001 to 10000 Employees,Company - Public,False
Data Engineer,BXGI,"Palo Alto, CA",$97K - $170K (Glassdoor est.),-1.0,"Overview

We are conducting a search for a Data Engineer to join our client’s engineering team in Palo Alto, CA or remotely anywhere in the United States.

Interested in shaping the future of pediatrics behavioral health? Our client is looking for a skilled Data Engineer to join their Engineering team who has in-depth experience with a variety of databases and maintaining data repositories from multiple data sources using different schemas.

Come join a world-class company delivering AI-powered diagnostics and therapeutics to dramatically improve the outlook of young children with cognitive and behavioral conditions.

Ability to work remotely is possible, with quarterly visits to Palo Alto.



Responsibilities
Create and maintain a data repository for analytics by combining multiple data sources using different schemas.
Work with various groups in Engineering to source the necessary data.
Implement industry best practices including quality assurance and compliance standards related to Protected Health Information (HIPAA).
Develop and maintain ETL processes to populate the data warehouse.
Deploy utility applications to Amazon AWS EC2, Fargate or Kubernetes.
Qualifications
BS in Computer Science, Engineering or related discipline.
4+ years experience with two of MySQL, Oracle SQL, Postgres.
Deep understanding of relational database structure and performance.
Past experience maintaining data repositories with disparate data sources.
Past experience building visualizations of underlying data.
Experience with Linux, Python, REST API.
Excellent verbal and written communication skills.
Excellent organizational skills and attention to detail.
Nice to Have
Experience with Amazon Web Services (RDS)
Experience building/supporting HIPAA-compliant software.
Understanding of underlying technologies of Tableau (Hyper databases, Hyper API, server extracts, prep flows, Python libraries.
Deep understanding of dimensional data warehouses
Experience with design star and snowflake schemas
Ability to come into the office every so often (once we actually can).




If interested, please send your resume to lana@bxgi.com.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,False
Software Engineer - Data (US),Gauss Labs,"Palo Alto, CA",$110K - $157K (Glassdoor est.),-1.0,"As a Gaussian Software Engineer - Data, you will be responsible for leading the architecture, design, and development of the data systems within our AI products for the semiconductor industry. You will be working with other passionate and talented Software Engineers, AI Engineers, and Applied Scientists and have opportunities to learn about various AI technologies and how they are applied to the semiconductor industry. You will have significant influence on our overall strategy by helping define these product features, drive the data architecture, and spearhead the best practices that enable a quality product. You are the ideal candidate if you are passionate about new opportunities and have a demonstrated track record of success in delivering new features and products. A commitment to teamwork and strong communication skills with both business and technical partners are important requirements. Creating reliable, scalable, and high-performance products requires exceptional technical expertise, a sound understanding of the fundamentals of computer science, and practical experience building large-scale systems.
Responsibilities
Design and develop the scalable data architecture for Gauss Lab’s AI products which include time series and image data for semiconductor industry.
Design and build data infrastructure systems, services, and tools to handle Gauss Labs’s data-intensive products and business requirements that securely scale over terabytes of data.
Define the schemas, layout, storage format, and database technologies that will be used to store, retrieve and process the data for our products. Build databases, object stores, data warehouses, and lakes for time series, images, and structured data.
Develop robust, well-instrumented near real-time stream processing data pipelines that can scale to handle future growth and adhere to SLAs. Design and develop stream processing features to execute on various event-driven ETL and AI pipelines.
Evolve Gauss Lab’s data infrastructure and tools and technical lead for the design, building, and launching of new data models and data pipelines within our products.
Work closely with product/program managers to understand the product’s needs, business problems, and domain.
Work cross-functionally with various engineering and data science teams to identify and execute data-infrastructure challenges.
Key Qualifications
BS/MS degree in Computer Science and Engineering or strong industry experience in software development.
3+ years of experience as a hands-on Data Engineer/Architect including ETL jobs, data pipelines, and Big Data analytics.
5+ years of industry experience in building large-scale production systems
Startup spirit with the ability to be flexible and wear multiple hats.
Proficient in large-scale data processing including batch and streaming, query engines, tooling, and storage formats.
Experience working with Terabytes of data.
Preferred experience in time series data storage and processing as well as image data processing.
Experience in distributed systems design, common data platform architecture, and open source data processing frameworks
Experience in technologies such as Hadoop, Spark, Kafka, Redis, Cassandra, Pandas, Dask, Airflow, Apache Beam, MongoDb, Hive, Impala, Hazelcast, Athena, Presto.
Experience in at least one modern programming language such as Python, Java, Go, Rust, and proficiency in SQL.
Experience architecting and implementing large operational data stores.
Excellent verbal and written communication skills, able to collaborate cross-functionally.
Plus: Experience in Kubernetes, Kubeflow, Docker, and container technologies, as well as infrastructure as code and CI/CD technologies .",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,False
Data Engineer,"E2 Consulting Engineers, Inc.
","San Diego, CA",$90K - $110K (Employer est.),4.1,"About the Organization:
E2 Consulting Engineers, Inc. (E2) is a professional services firm established in 1988 specializing in a full spectrum of engineering services including, project engineering and design, federal base operations and infrastructure support services, gas pipeline construction and inspection services, environmental consulting and remediation, and information technology services. At E2, we value safety, innovation and collaboration, and we are dedicated to excellence.
Overview:
E2 is seeking a highly motivated Data Engineer to join our team and partner with our client to design, develop, and implement highly functional and scalable data analytics solutions. The successful candidate will thrive on delivering production-quality data pipelines, process automation, and automated reporting solutions. The right person for this role has a strong background in data mining/data engineering/data visualization, loves problem-solving, and is a great communicator.
Responsibilities:
The Data Engineer will support the development and management of our data pipelines and data storage environment, specifically in the following areas:
Raw data ingestion and validation
Data processing/transformation (ELT)
Storage and modeling of cleaned data
SQL script development for reporting and analytics
Data science and/or process automation script development
Additional core responsibilities include:
Collaborating with stakeholders to define key metrics, assess/validate data, propose solutions to key problems, and provide overall data analytics strategy.
Designing and managing automated Power BI/Excel reports to provide key stakeholders with relevant and actionable insights.
Developing predictive and/or machine learning models to support business decisions.
Completing ad-hoc requests for analysis, data validation, and reporting by connecting to diverse data sources, implementing the appropriate method of analysis, and offering relevant insights.
Partnering with our IT team, Operations team, and Web App Development team to ensure overall alignment and successful technology implementation.
Preparing technical documentation and/or presentations to support the rollout of new data-focused initiatives within the organization.
Participate in special projects, as requested.
Other duties as assigned.
Qualifications:
Education
Bachelor’s degree in Statistics, Data Science, Engineering, Mathematics, Business, or related field. (Required)
Master’s degree in Statistics, Data Science, Engineering, Mathematics, Business, or related field. (Preferred)
Data science and/or data analytics-related certifications. (Preferred)

Experience
3+ years of data engineering, analytics, and business intelligence experience. (Required)

Skills and Abilities
Strong Excel skills, including pivots, VLOOKUPs, conditional formatting, macros, large record sets. VBA experience a plus.
Strong Power BI skills (including Power Query, DAX) and experience developing high-quality automated reports and dashboards.
Strong experience with database design, data warehousing, data integration, data engineering, and ETL/ELT processes.
Strong experience with large datasets, querying, data wrangling, and coding (SQL, R, Python, VBA).
Knowledge and/or experience in machine learning and predictive analytics (Deep Learning, Python, R, Neural Networks, applied Data Science) a plus.
Cloud platform development experience (AWS/Azure preferred).
Excellent interpersonal and written/oral communication skills.
Strong sense of ownership and ability to lead.
Ability to work under pressure and with tight timelines.
Able to present complex ideas and/or problems in a simple and organized way.
Proven ability to build strong relationships and effectively influence peers/management.
Benefits:
E2 Consulting Engineers, Inc. offers an excellent benefits package including health, dental, vision, and life insurance, 401(k) with employer match, paid time off.
Wage Data Per State Requirements:
Salary range for this position is $90,000 - $110,000. The starting salary will be commensurate with skill, education, experience, and working environment.
Work Environment/Physical Demands:

Work Environment

This job operates in a professional office environment and uses standard office equipment such as computers and phones.


Physical Demands

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Ability to sit/ stand for up to 8 hours per day.
Ability to move freely for up to 8 hours per day.
Drug Free Workplace:
E2 Consulting Engineers, Inc. is a Drug Free Workplace. After accepting an offer of employment, applicants may be required to undergo background checks, drug testing, and/or fit-for-duty physical examination. Drug screens will include, but not be limited to, Amphetamines, Cocaine Metabolites, Marijuana Metabolites (THC), Opiates, and Phencyclidine (PCP). As a federal contractor, E2 cannot permit employees in certain positions to use medical marijuana, even if prescribed by an authorized physician.
Solicitation:
Please no solicitation of any kind from agencies, staffing, or recruiting firms.
EEO Statement:
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.",1988,Architectural & Engineering Services,$25 to $100 million (USD),"Construction, Repair & Maintenance Services",501 to 1000 Employees,Company - Private,False
Senior Software Engineer - Data Security,"ByteDance
","San Jose, CA",$187K - $280K (Employer est.),3.8,"Founded in 2012, ByteDance's mission is to inspire creativity and enrich life. With a suite of more than a dozen products, including TikTok, Helo, and Resso, as well as platforms specific to the China market, including Toutiao, Douyin, and Xigua, ByteDance has made it easier and more fun for people to connect with, consume, and create content.

Why Join Us
Creation is the core of ByteDance's purpose. Our products are built to help imaginations thrive. This is doubly true of the teams that make our innovations possible.
Together, we inspire creativity and enrich life - a mission we aim towards achieving every day.
To us, every challenge, no matter how ambiguous, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At ByteDance, we create together and grow together. That's how we drive impact - for ourselves, our company, and the users we serve.
Join us.

Security Team at ByteDance
The team is missioned to build infrastructures, platforms and technologies, as well as to support cross-functional teams to protect our users, products and infrastructures. In this team you'll have a unique opportunity to have first-hand exposure to the strategy of the company in key security initiatives, especially in building scalable and secure-by-design systems and solutions. Our challenges are not your regular day-to-day technical problems; you'll be part of a team that's developing new solutions to new challenges of a kind not previously addressed by big tech. It's working fast, at scale, and we're making a difference.

Responsibilities

Design and implement reliable, scalable, robust and extensible data systems that support the company's core security systems and products
Establish solid design and best engineering practice for engineers as well as non-technical people
BS or MS degree in Computer Science or related technical field or equivalent practical experience
Experience in performing data analysis, data ingestion and data integration
Experience with the Big Data technologies (Hadoop, Hive, Spark, Presto, Flume, Kafka, ClickHouse, Flink etc.)
Experience in building large scale distributed systems in a product environment is a plus
Experience in the design and implementation of security solutions, systems and mechanisms is a plus.
ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

ByteDance Inc. is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at rd.accommodations@bytedance.com.",2012,Internet & Web Services,Unknown / Non-Applicable,Information Technology,10000+ Employees,Company - Private,False
"Senior Software and Data Engineer - SIML, ISE","Apple
","Cupertino, CA",-1,4.2,"Summary
Posted: Nov 10, 2023
Weekly Hours: 40
Role Number:200452999
Do you believe Machine Learning and AI can change the world? We truly believe it can. We are the Data Team of the System Intelligence and Machine Learning (SIML) group at Apple. We are responsible for building high quality datasets at scale. Every year, our team produces datasets used in the training of ML and AI-centric features for many Apple products, including iPhone, iPad, Mac, Apple Watch and even AirPods. Our work is used in very visible and important features, from the wallpaper on your iPhone Lock Screen, to the models that highlight the faces of your loved ones in your photos app, to the memories that your Apple products create from your photos, videos and music. We value collaboration and team-work. Our engineers are not afraid to manually browse the data to identify and troubleshoot problems. We expect the same from our new members. This is an exciting time to join us and have an impact on multiple key features at Apple!
Key Qualifications
5+ years of industry experience in building data pipelines, data processing infrastructure or data operations teams
Demonstrated prior experience in large language models, or generative AI
Proficient in Python, or another modern programming language
Proven track record of handling complex data projects with contributions to hiring, mentoring and growing engineers, establishing and enforcing the right software engineering culture for a software team
Experience in building data processing pipelines for curating data, training and evaluating models (experience in Airflow, KubeFlow or other pipelining tools)
Passionate about supporting day-to-day data operations and able to work efficiently with members of the team who are not engineers
Self-starter, able to handle ambiguity, navigate uncertainty, identify risks, and find the right people and tools to get the job done
We value collaboration and team-work. Our engineers are not afraid to manually browse the data to identify and troubleshoot problems. We expect the same from our new members.
Description
Our team works in close interaction with R&D, infrastructure and client teams, as well as with other groups and other functions across Apple (legal, privacy) and externally. This position focuses on designing and implementing flexible data pipelines and data tools based on advanced computer vision technology, NLP and humans in the loop. You will be responsible for the design and development of the data pipelines, automation, visualization and tools that constitute the end-to-end process for building models, from raw data to trained model to evaluation to deployment. You'll partner with data infrastructure and other teams to ensure that we have high quality, representative data. You'll work with ML engineers to refine the modeling process to enable faster iteration and better modeling decisions and deploy models more rapidly to customers. You'll collaborate with data scientists and analysts to build insights from customer analytics and feedback into the process to complete the cycle of continuous improvement. Your work will impact hundreds of millions of Apple's customers and help people communicate more easily in the languages and modalities of their choice.
Education & Experience
Bachelors, Masters or PhD in Computer Science, Mathematics, Physics, or a related field (or equivalent practical experience).
Additional Requirements
Strong understanding of applied machine learning topics is desirable
Experience with ETL frameworks like Airflow is desirable
Kubernetes and Docker experience is desirable
Strong knowledge of either NLP or Computer Vision is desirable
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",1976,Computer Hardware Development,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Science Engineer,"Smart Energy Water
","Irvine, CA",$94K - $131K (Glassdoor est.),3.1,"PRIMARY RESPONSIBILITIES
Create and maintain optimal data pipeline architecture,
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Experience/knowledge of employing statistical, data science and machine learning algorithms on real-world problems.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs
Work with product team, data science team and data engineer team to analyze product features, track user behaviors to drive feature enhancement or new feature development.
Identify and develop data collection strategies to support reporting on key performance indicators that directly measure online campaigns, website and conversion funnel performance
Designing and implementing automated reporting solutions across multiple teams and stakeholders. Translate the reports into business values and provide suggestions to drive effective business decisions.
Work with data engineer team on daily data quality monitoring and data validation. Create documentation and reports on data quality and data validation)
Supporting cross-functional teams on the day-to-day reporting/ visualization/ data analysis execution of different implementations.
QUALIFICATIONS
Master’s degree in Machine Learning, Data Science, Computer Science, Mathematics, Statistics, or related engineering field or a bachelor’s degree with a significant amount of relevant work experience.
Retrieving and analyzing data using SQL/Python from SQL or NoSQL database such as SSMS, Postgres, MongoDB, Cassandra, etc.
Hands-on knowledge of data modelling tools, data mapping tools, and data profiling tools.
Experience with and theoretical understanding of algorithms for supervised and unsupervised modeling such as classification, regression, clustering, recommendation engine and anomaly detection
Experience in Python programming and familiarity with python libraries such as numpy, pandas, scikit-learn etc.
Expertise with statistical data analysis. (e.g. linear models, multivariate analysis, stochastic models, sampling methods, A/B testing)
Experience in deploying machine learning products in production using docker is a plus.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with object-oriented/object function scripting languages: Python preferable.
Strong in BI technologies: e.g. Microsoft Power BI (preferable), Tableau, Google Analytics.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets, Azure Cloud experience preferred.",2012,Computer Hardware Development,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,False
Data Engineer Leader,"Synopsys
","Mountain View, CA",$117K - $204K (Employer est.),4.0,"44867BR
USA - California - Mountain View/Sunnyvale

Job Description and Requirements

The Synopsys Central Engineering team is tasked to digitize Synopsys product development activities. We will achieve it by identifying areas of improvement and correlating various aspects of the product development and providing all levels of management visibility for action. The domain areas we are focused on relate to Quality, Productivity, and Operational Efficiency,

We are looking for an experienced Data Engineer who will contribute to building the next-generation Data Platform. As a Data Engineer, you will be working on modern, large-scale big data technologies to build data platforms on Snowflake and toolset. The goal is to create an effective and efficient data pipeline to facilitate data exchange between various applications.

In this role, you will be partnering with data providers to enable them to make available volumes of data and integrate in a common data platform. You will also interact with Data analysts to transform data into information and insights driving data-based strategic outcomes. This is a hands-on role, and you are joining the team near the beginning of our journey where you can help shape our way to manage big data.

Responsibilities:
Incorporate state-of-the-art practices in Data Engineering to scale the value we deliver in transforming data into insights.
Identify, design and implement internal process improvements, including data infrastructure, for scalability, optimizing data delivery, and automating manual processes.
Leverage your experience and proficiency in all aspects of data modeling, data management, data cataloging, analytics solution architecture & design, and implementation roadmap.
Help drive strategic goal of data consolidation to enable cross-domain analytics.
Help establish Center of Excellence for Data Engineering practices by defining architecture, rules, and capabilities. This includes data loading, quality control, transformation, Data Contracts, and high availability.
Champion data quality, governance, security, to ensure high-quality data.
Support and mentor fellow engineers and data team members through collaborative processes.
Build data cataloging infrastructure and metadata platform to enable data discovery, data observability, and federated governance.
Drive cross-team projects to integrate data from numerous separate sources into a unified data environment.

Expertise & Skills:
Must be detailed-oriented with a passion for data accuracy and reliable solution development.
Must have hands-on experience in Data Modeling, Design, implement and maintain data models that support all business analytics needs.
Experience in designing and building high performance data pipelines to move and process data using modern tools, such as dbt, Airflow, HVR/FiveTran, Airbyte, etc.
Proficiency in advanced SQL scripting, query optimization.
Experience in Data Engineering Architecture and Design.
Experience in at least one prominent programming language, such as Python (preferred), Java, JavaScript, etc.
Experience in ELT (Extract-Load-Transform) process with hands-on experience on Data Lakehouse, such as Snowflake, etc.
Experience in cross-teams collaboration, especially working with different internal stakeholders, etc.
The ability to work with other team members, drive projects to completion, and work autonomously.
Excellent written and verbal communication, work autonomously, and have proven organizational and planning skills.
Exemplify high quality software engineering practices by designing, developing, and operating data infrastructure and business critical pipelines at scale.

We also value:
Prior experience in leading Data Engineering teams
Experience in database design and management, such as MS SQL Server, Oracle, MySQL, Cassandra, MongoDB, etc.
Familiarity and experience in Snowflake toolset or similar alternatives are a proven asset for this position.
Experience in cloud deployment with Kubernetes, Docker
Experience with Power BI and/or Tableau or other visualization tools

Requirements:
Bachelor's or Master's Degree in a quantitative field
> 5-10 years of relevant experience
5+ years’ experience data engineering and operationalizing data pipelines with large and complex datasets
3+ years’ experience working with Data Lakehouse such as Snowflake

At Synopsys, we’re at the heart of the innovations that change the way we work and play. Self-driving cars. Artificial Intelligence. The cloud. 5G. The Internet of Things. These breakthroughs are ushering in the Era of Smart Everything. And we’re powering it all with the world’s most advanced technologies for chip design and software security. If you share our passion for innovation, we want to meet you.

Stay Connected: Join our Talent Community

The annual range across the U.S. for this role is between $117,000 - $204,000. In addition, this role may be eligible for an annual bonus, equity, and other discretionary bonuses. Synopsys offers comprehensive health, wellness, and financial benefits as part of a comparative total rewards package. The actual compensation offered will be based on a number of job-related factors, including location, skills, experience, and education. Your recruiter can provide more specific details on the total rewards package upon request.

Inclusion and Diversity are important to us. Synopsys considers all applicants for employment without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, military veteran status, or disability.

#LI-DNI



Job Category

Engineering

Country

United States

Job Subcategory

R&D Engineering

Hire Type

Employee

Base Salary Range

$117,000 - $204,000",1986,Computer Hardware Development,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer 4,"Intelliswift Software, Inc.
","San Jose, CA",$91.55 Per Hour (Employer est.),4.0,"Title - Data Engineer

Location • San Jose, CA

Duration • 8 Months

Pay rate • $91.55 per hour on w2

Write complex SQL queries that help Adobe identify and measure the non-genuine software base. Apply business logic to determine categorize the non-genuine base into opportunities Use Big Data best practices to help scale the piracy conversion program Create dashboards in tableau Apply statistical methodologies and data mining skill sets on large volume of data Analyze data and provide insights to senior executives

SQL Expertise. Hadoop expertise. Can work in hive, pig etc Create dashboards in tableau and excel Modelling in Excel. Power Pivot expertise a must Understanding of statistics concepts Ability to interpret data and present Excellent written and verbal communication skills",2001,Software Development,$100 to $500 million (USD),Information Technology,1001 to 5000 Employees,Company - Private,False
"Senior Data Engineer, Seller Experience","Afterpay
","San Francisco, CA",$130K - $193K (Glassdoor est.),3.5,"Company Description
Since we opened our doors in 2009, the world of commerce has evolved immensely, and so has Square. After enabling anyone to take payments and never miss a sale, we saw sellers stymied by disparate, outmoded products and tools that wouldn’t work together.

So we expanded into software and started building integrated, omnichannel solutions – to help sellers sell online, manage inventory, offer buy now, pay later functionality through Afterpay, book appointments, engage loyal buyers, and hire and pay staff. Across it all, we’ve embedded financial services tools at the point of sale, so merchants can access a business loan and manage their cash flow in one place. Afterpay furthers our goal to provide omnichannel tools that unlock meaningful value and growth, enabling sellers to capture the next generation shopper, increase order sizes, and compete at a larger scale.

Today, we are a partner to sellers of all sizes – large, enterprise-scale businesses with complex operations, sellers just starting, as well as merchants who began selling with Square and have grown larger over time. As our sellers grow, so do our solutions. There is a massive opportunity in front of us. We’re building a significant, meaningful, and lasting business, and we are helping sellers worldwide do the same.
Job Description

Square’s Growth team builds intelligent and scalable solutions that empower various communication channels, like Sales and Account Management, to drive seller growth and retention.

As a Data Engineer on the Growth team, you will be the expert on the data solutions that enable the team to build and roll out scalable go-to-market processes, effectively design and launch experimentation, and provide stakeholders with direct visibility into program business impact.

You will:

Partner closely with data scientists, business intelligence analysts and machine learning engineers to power GTM operations, experimentation and a suite of analytical data products
Work with channel specific teams to build a roadmap for foundational data sets and metrics that are aligned with business goals and that enable self-service
Architect, build, and launch scalable data pipelines to support the Growth team’s growing experimentation needs across multiple channels
Understand and implement data logging best practices to support our data flow
Build integrations with 3rd party data vendors
Identify opportunities to streamline, automate tasks, and build reusable components across multiple use cases and teams
Create dashboards that help our stakeholders understand the performance of the experiments and help them make decisions
Qualifications

You have:

5+ years of experience as a Data Engineer or related specialization (e.g. Business Intelligence, Data Science, etc.) with a track record of delivering large scale data solutions
Expert knowledge of data warehouse architecture and hands on experience of data modeling design, building complex, scalable ETLs using SQL and Python for a variety of different business and product use cases (batch and/or streaming).
Experience with ingesting and transforming data from application APIs preferred
Hands on experience on cloud-based computing services and data warehouses like Snowflake, Redshift, Azure, or similar
Experience using job orchestration platforms like Airflow, Prefect, or similar
Experience building reports with Looker or similar BI visualization tools
Excellent communication skills with strong business intuition and ability to articulate complex technical concepts and explain data problems in concise language; versatility and willingness to learn new technologies on the job
Salesforce (SFDC) experience a plus
Databricks/Spark experience a plus
Additional Information

Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.

Zone A: USD $152,100 - USD $185,900
Zone B: USD $144,500 - USD $176,700
Zone C: USD $136,900 - USD $167,300
Zone D: USD $129,300 - USD $158,100

To find a location’s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information.

Full-time employee benefits include the following:

Healthcare coverage (Medical, Vision and Dental insurance)
Health Savings Account and Flexible Spending Account
Retirement Plans including company match
Employee Stock Purchase Program
Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance
Paid parental and caregiving leave
Paid time off (including 12 paid holidays)
Paid sick leave (1 hour per 26 hours worked (max 80 hours per calendar year to the extent legally permissible) for non-exempt employees and covered by our Flexible Time Off policy for exempt employees)
Learning and Development resources
Paid Life insurance, AD&D, and disability benefits
Additional Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources

These benefits are further detailed in Block's policies. This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans.

We’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.

We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we’re doing to build a workplace that is fair and square?

Additionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.




Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.",2014,Internet & Web Services,$5 to $10 billion (USD),Information Technology,501 to 1000 Employees,Company - Public,False
Information Technology Analyst IV (Data Engineer),"County of Solano
",United States,$113K - $138K (Employer est.),3.5,"Enjoy great benefits, job security and contribute to your community at Solano County!




Department of Information Technology


The Department of Information Technology (DoIT) at Solano County provides customer-oriented and convenient access to information and services through the use of technology; anytime - anywhere. The County strives for a cost-effective use of technology, with interactive exchange and sharing of data within departments, with constituents, with other government organizations and business partners.




Find out more about the Department of Information Technology by clicking on the following link: Department of Information Technology


THE POSITION
Information Technology Analyst IV
(Data Engineer)


As an Information Technology Analyst IV (Data Engineer) you will apply advanced levels of specialized and technical analytical skills and knowledge while serving as team leader/project manager for designated major systems. You will perform the most difficult tasks within the Information Technology Analyst series, including providing advanced technical support to system users. You will provide lead direction to software development, network/systems administration, service desk, or security and database systems, other Information Technology Analysts, and/or consultants on assigned systems design, or infrastructure and maintenance projects. Supervision will be from our Information Technology Analyst (Principal) as well as our Information Technology Manager. You may also receive functional direction from the Assistant Director and/or Chief Information Officer.


The Data Management Team!
As an Information Technology Analyst IV (Data Engineer), you will be a prominent member of our Data Management team supporting the Central IT Department of the County of Solano, two (2) data centers, and eighteen (18) departments with over 3,000 employees across multiple industries, ultimately providing service to over 447,643 constituents.
As a member of our Data Management Team, you will primarily support our Health and Social Services Department which includes Public Health, Social and Behavioral Health Services, and has the highest demand for data use and reporting requirements. You will profile and use data sources to build a data model to generate clean and accurate data for report writers and data users across the County. You will also work with data users to identify and anticipate reporting and data needs, extract data from the source systems, profile and load it into a model, and generate reports and analytics.




Education and Experience Requirements


Education
Equivalent to an Associate’s degree, preferably in information technology, or a closely related field.


Experience
Depending upon assignment, five (5) years of experience performing progressively responsible software development, or infrastructure management duties and functions.


Note: A Bachelor’s degree from an accredited college or university, preferably in information technology, management information systems may be substituted for two years of experience.


Note: Additional experience may substitute on a year for year basis for the educational
requirement.


Please click on the following link to access the job description:
Information Technology Analyst IV




The Ideal Candidate


The ideal candidate is an excellent communicator; they are collaborative, motivating, entrepreneurial, and comfortable working autonomously. They will form meaningful partnerships within the Department and with stakeholders throughout the County. Our ideal candidate embraces change and looks for opportunities for improvement. They enjoy examining data, visualizing, and creating a story, and can project practical applications for the data in multiple scenarios.


Desired Advanced Knowledge and Experience
Modern Data warehouse
Azure Data Lake
Azure Synapse
Data Modeling with Kimball Methodology
Facts and Dimensions
ETL, SSIS, Data Factory
SQL, Python, R, SA
Power BI
DevOps
Purview
Dynamics CRM




Desired Certifications
Azure Data Engineering
Azure Solution Architect
DAMA certified (CDMP)
Power BI Data Analyst


BENEFITS/ WHAT'S IN IT FOR YOU?




Benefits Summary




Solano County offers a cafeteria-style medical package with health benefits, offered through CalPERS. The County contribution for family coverage is $1,900.58 per month for 2023. The County offers a cash back provision for those who choose employee-only or who waive medical insurance coverage. The County may offer a supplemental contribution for employees enrolled in Employee plus Two or More coverage.


Dental and vision insurances for the employee and eligible dependents are paid 100% by the County.


Solano County participates in CalPERS retirement and contributes to Social Security.
The County observes twelve (12) full day fixed and two (2) half day fixed paid holidays per year. Additionally, employees in this bargaining unit receive two (2) floating paid holiday(s) per year. Vacation is accrued at approximately ten (10) days per year. Sick leave accrues at approximately 12 days per year. Effective July 1 of each year, 80 hours of administrative leave is granted.


Employees are eligible to receive an additional 2.5% longevity pay, per level, after the completion of continuous service at 10, 15, 20, 25, 30 and 35 years.


Please click on the following link to access the benefits summary:
Benefits Summary




Learning and Development Culture


Solano County is committed to “Invest In and For the Future” by providing training resources to encourage employee professional development and growth within our organization. While employed with Solano County, employees have the opportunity to pursue their career goals, interests, and develop the competencies on the Solano County Leadership Development Model by participating in the following programs:


Tuition Reimbursement Program
Annual Education Fair
County Mentoring Program
Leadership Academy
Supervisory Trainings
Skill Development Trainings
Self-paced learning opportunities
SELECTION PROCESS
12/01/2023 - Deadline to submit application along with educational documents.


Based on the information provided in the application documents, the qualified applicants may be invited for further examination and will either be pre-scheduled by the Department of Human Resources or be invited to self-schedule. All applicants meeting the minimum qualifications are not guaranteed advancement through any subsequent phase of the examination. Depending upon the number of applications received, the selection process may consist of an initial application screening, a mandatory information meeting, a supplemental questionnaire assessment, a written and/or practical exam, an oral board exam, or any combination listed. Responses to supplemental questions may be used as screening and testing mechanisms and will be used to assess an applicant’s ability to advance in the process; as such, responses to supplemental questions should be treated as test examination responses. Information contained herein does not constitute either an expressed or implied contract.


A minimum score of 70% is required to continue in the selection process, unless otherwise announced. All potential new hires and employees considered for promotion to management, confidential positions or unrepresented positions will be subject to a background and reference check after contingent job offer is accepted. These provisions are subject to change.


RETIREES - Solano County invites all to apply for positions; however pursuant to Government Code Section 21221(h) and 21224, hiring restrictions may apply to California Public Sector Pension Plan Retirees.",-1,National Agencies,Unknown / Non-Applicable,Government & Public Administration,1001 to 5000 Employees,Government,False
Senior Data Engineer,"Zoox
","Foster City, CA",$143K - $300K (Employer est.),3.9,"The Data team leverages data from our autonomous vehicles and operations to determine autonomy and service readiness. We provide the foundation for strategic decision-making at Zoox. You will develop and implement the next generation of our data pipeline to ensure visibility into our business as we scale toward the launch of an autonomous mobility service. You will define the system and build the pipeline to enable Zoox to develop and scale with a data-first culture.

You will join a diverse, experienced team with rapidly growing scope and responsibility while also having access to one of the most unique data sets in the autonomous vehicle industry. Hence, we are seeking all skill levels to grow with the team.
Responsibilities
Designing, building, and maintaining the infrastructure that transforms autonomous vehicle data at scale to support analytics throughout the company
Defining and executing on how data from perception, prediction, planning and other parts of the autonomous stack is consumed to generate valuable insights by data scientists, engineers, and business users
Establishing robust data integrity monitoring so that company-wide metrics are based on accurate data
Partnering with engineering and product teams to define data consumption patterns and establish best practices
Qualifications
Experience designing and building complex data infrastructure at scale
Exceptional Python or Scala skills
Advanced SQL and data warehousing experience
Experience operating a workflow manager such as Airflow
Experience with large scale streaming platforms (e.g. Kafka, Kinesis), processing frameworks (e.g. Spark, Hadoop) and storage engines (e.g. HDFS, HBase)
A strong DataOps mindset and opinions on next-generation warehousing tools
Bonus Qualifications
Basic fluency in C++
Familiarity with or exposure to experimentation platforms
Compensation
There are three major components to compensation for this position: salary, Amazon Restricted Stock Units (RSUs), and Zoox Stock Appreciation Rights. The salary will range from $143,000 to $300,000. A sign-on bonus may be part of a compensation package. Compensation will vary based on geographic location, job-related knowledge, skills, and experience.

Zoox also offers a comprehensive package of benefits including paid time off (e.g. sick leave, vacation, bereavement), unpaid time off, Zoox Stock Appreciation Rights, Amazon RSUs, health insurance, long-term care insurance, long-term and short-term disability insurance, and life insurance.

ABOUT ZOOX

Zoox is developing the first ground-up, fully autonomous vehicle fleet and the supporting ecosystem required to bring this technology to market. Sitting at the intersection of artificial intelligence, robotics, and design, Zoox aims to provide the next generation of mobility-as-a-service in urban environments. We’re looking for top talent that shares our passion and wants to be part of a fast-moving and highly execution-oriented team.

Follow us on LinkedIn

About Zoox
Zoox is developing the first ground-up, fully autonomous vehicle fleet and the supporting ecosystem required to bring this technology to market. Sitting at the intersection of robotics, machine learning, and design, Zoox aims to provide the next generation of mobility-as-a-service in urban environments. We’re looking for top talent that shares our passion and wants to be part of a fast-moving and highly execution-oriented team.

Follow us on LinkedIn

A Final Note:
You do not need to match every listed expectation to apply for this position. Here at Zoox, we know that diverse perspectives foster the innovation we need to be successful, and we are committed to building a team that encompasses a variety of backgrounds, experiences, and skills.",2014,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Sr. Staff Software Engineer - Data/ML (Hybrid),"Panasonic Avionics Corporation
","Irvine, CA",$128K - $215K (Employer est.),3.1,"Our new global headquarters is conveniently located in Irvine, CA near John Wayne Airport in the Park Place development. For our onsite and hybrid employees you will be able to enjoy amenities such as access to many restaurants and shops, running trails, a fitness deck, outdoor seating, dry cleaning, car wash, free garage parking, car charging stations, shuttle service for train commuters, outdoor games like bocce, horseshoes, gaming tables, pickle ball, and basketball. For more information on Park Place visit www.parkplaceirvine.com

Who We Are:

Ever wonder who brings the entertainment to your flights? Panasonic Avionics Corporation is #1 in the industry for delivering inflight products such as movies, games, WiFi, and now Bluetooth headphone connectivity!

How exciting would it be to be a part of the innovation that goes into creating technology that delights millions of people in an industry that’s here to stay! With our company’s history spanning over 40 years, you will have stability, career growth opportunities, and will work with the brightest minds in the industry. And we are committed to a diverse and inclusive culture that will help our organization thrive! We seek diversity in many areas such as background, culture, gender, ways of thinking, skills and more.

If you want to learn more about us visit us at www.panasonic.aero
And for a full listing of open job opportunities go to www.panasonic.aero/join-us/

Job Summary:




As a Senior Software Engineer, you will collaborate closely with the data engineering team and work on developing and maintaining data pipelines, data processing applications, and data integration solutions. Your expertise in software development, data engineering, machine learning, and inferencing will be instrumental in enhancing our data infrastructure.

What you will be doing:


Software Development: Design, develop, and maintain data processing applications and data pipelines, with a focus on efficiency, scalability, and reliability.
Collaboration: Work closely with the data engineering team and cross-functional teams to integrate data from various sources, ensuring data quality, consistency, and accuracy.
Real-Time Data Processing: Develop real-time data processing components to support our data analytics and reporting needs.
Machine Learning Integration: Incorporate machine learning models into data pipelines and applications for predictive analytics and decision support.
Inferencing: Implement inferencing engines and optimize the execution of machine learning models for real-time and batch processing.
Technology Stack: Utilize a variety of data engineering technologies, frameworks, and cloud-based platforms to build robust data and machine learning solutions.
Code Quality: Maintain high coding standards, implement best practices, and participate in code reviews to ensure data engineering and machine learning quality.
Documentation: Create and maintain comprehensive documentation for data processes, applications, machine learning models, and inferencing.
Problem-Solving: Identify and troubleshoot data-related and machine learning issues, proposing effective solutions and optimizations.
Self-Service Data Analytics: Collaborate with the data engineering team to enable self-service data analytics for business users.
Data Governance: Contribute to the implementation of data governance and data management best practices.


The salary range of $128,000 - $215,000 is just one component of Panasonic’s total package. The final offer amount may vary based on factors including but not limited to individual’s knowledge, skills, experience, and location. In addition, this role may be eligible for discretionary bonuses and incentives.

Base pay offered may vary depending on skills, experience, job-related knowledge and location.

What we are looking for:

Required:

Minimum 12 years of professional experience as a data software engineer
Bachelor's or master’s degree in computer science or a related field.
Proven experience as a software engineer with a strong focus on data engineering and machine learning.
Strong programming skills in languages such as Python, Java, or Scala.
Experience in data engineering technologies, ETL processes, and data integration.
Familiarity with real-time data processing, data streaming frameworks, and machine learning libraries.
Proficiency in cloud-based data platforms (e.g., AWS, Azure, GCP).
Excellent problem-solving skills and attention to detail.
Ability to collaborate effectively with cross-functional teams.
Strong commitment to code quality, documentation, machine learning best practices, and data governance.

Our Principles:

Contribution to Society | Fairness & Honesty | Cooperation & Team Spirit | Untiring Effort for Improvement | Courtesy & Humility | Adaptability | Gratitude

What we offer:

At Panasonic Avionics Corporation we realize the most important aspects in leading our industry are the bright minds behind everything we do. We are proud to offer our employees a highly competitive, comprehensive and flexible benefits program.

Paid time off: Exempt Salaried employees receive unlimited PTO. This means that there is no fixed number, range, or limit to the amount of Personal and Vacation Days that may be taken for exempt employees. Non-exempt hourly employees accrue 14 vacation days per year + 7 sick days + 3 personal days. Accrual rate increases with tenure. All employees receive 11 company paid holidays per year plus a paid company-wide shut down in the U.S. between Christmas and New Year.
Insurance: Medical insurance offerings from Aetna and Kaiser (CA &HI). Options for Employee Only, Employee + Spouse/Domestic Partner, Employee + Children, or Family. Dental PPO and DMO options & Vision insurance through EyeMed or VSP.
401K with 50% match on up to 8% contribution, full vested from day 1
Other offerings include: Wellness Program, Counseling services, FSA & HSA, Life Insurance for employee, spouse and child, AD&D Insurance, Long-term and Short-term disability, Critical Illness Insurance, Accident Insurance, Legal Assistance, Pet Insurance, Identity Theft Protection, Dependent Care FLSA, Education Assistance, Commuter Program, Employee Purchase Program, Service Award Program.

All applicants are subject to Company policies, third party customer and worksite requirements, and government requirements, regarding vaccination and/or testing for COVID-19. Where permitted by applicable law, applicants may be required to be fully vaccinated with an authorized COVID-19 vaccine as a condition of employment, unless they are eligible for and obtain an exemption based on a reasonable accommodation because of a disability or a sincerely held religious belief, practice, or observance. While the Company strongly encourages COVID-19 vaccinations, it may require vaccination and/or testing for positions in which third party customer, worksite, or government requirements apply, in accordance with applicable law. At those locations where requirements apply, exemptions will be considered based on applicable law.

Panasonic is proud to be an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, national origin, disability status, protected veteran status, and any other characteristic protected by law or company policy. All qualified individuals are required to perform the essential functions of the job with or without reasonable accommodation. Pre-employment drug testing is required for safety sensitive positions or as may otherwise be required by contract or law. Due to the high volume of responses, we will only be able to respond to candidates of interest. All candidates must have valid authorization to work in the U.S. Thank you for your interest in Panasonic Avionics Corporation.

#LI-WS1",1979,Aerospace & Defense,$100 to $500 million (USD),Aerospace & Defense,1001 to 5000 Employees,Subsidiary or Business Segment,False
"Data Center Facilities Engineer, Dojo","Tesla
","Palo Alto, CA",$122K - $175K (Glassdoor est.),3.6,"What to Expect

The Dojo team is seeking an experienced Facilities Engineer to play a critical role in ensuring the smooth operation of our data center infrastructure. The ideal candidate will possess mechanical or electrical engineering technical expertise, proven troubleshooting skills, and an attention to detail. As a Facilities Engineer, you will be responsible for ensuring the efficient and reliable functioning of our data center facilities, including power distribution, cooling systems, and related infrastructure.

What You’ll Do



Monitor and maintain critical infrastructure systems, including power distribution, cooling systems, fire suppression, and environmental monitoring
Implement and enforce operational procedures, maintenance schedules, and safety protocols to ensure compliance with industry standards and best practices
Conduct regular inspections and audits to identify potential issues, proactively address maintenance needs, and ensure the facility's compliance with regulatory requirements
Coordinate with vendors, suppliers, and contractors to schedule and oversee maintenance, repairs, and upgrades
Collaborate with cross-functional teams, including IT, engineering, and security, to ensure seamless operations and resolve any infrastructure-related issues
Identify and diagnose equipment failures, system malfunctions, and other issues, employing technical expertise to resolve them promptly
Analyze data center performance metrics, identify trends, and implement corrective actions to optimize efficiency and reliability
Maintain accurate records of maintenance activities, inspections, and repairs, ensuring compliance with documentation standards and procedures
What You’ll Bring



Bachelor's degree or equivalent in mechanical engineering, electrical engineering, or equivalent
Minimum of 5 years of experience in managing facilities operations, preferably within a data center environment
Strong technical knowledge and experience with mechanical and/or electrical systems, e.g. HVAC, power distribution, generators, UPS systems, and fire suppression systems
Strong analytical and problem-solving skills
Excellent communication and documentation skills with ability to understand complex problems and distill the message into a clear plan
Ability to work in a fast-paced environment and make sound judgments under pressure",2003,Transportation Equipment Manufacturing,$1 to $5 billion (USD),Manufacturing,10000+ Employees,Company - Public,False
"Site Reliability Engineer, Data Platform- USDS","TikTok
","Mountain View, CA",$137K - $360K (Employer est.),3.4,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

About USDS
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.

U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

Team Introduction
TikTok's Data Platform Team focuses on challenges in the areas of data infrastructure and data products. The team is in charge of various aspects including Query Engine, Logging and Data Ingestion Infra, Experimentation Platform, as well as Workflow Management Platform. The goal is to support ad-hoc/interactive queries, batch pipelines, logging and ingesting large amounts of realtime data, and supporting A/B testing for all product features launches.

In order to enhance collaboration and cross-functional partnerships, among other things, at this time, our organization follows a hybrid work schedule that requires employees to work in the office 3 days a week, or as directed by their manager/department. We regularly review our hybrid work model, and the specific requirements may change at any time.

Site Reliability Engineering (SRE) combines software and systems engineering to build and run large-scale, massively distributed services and infrastructures. As a site reliability engineer in the data platform area, you will have the opportunity to manage the services and infrastructures in one of the largest data platforms in the world. You'll need to ensure the data, services and infrastructures are reliable, fault-tolerant, efficiently scalable and cost-effective. You'll also have the opportunity to design, build and deliver all kinds of systems as a software engineer.


Engage in and improve the whole lifecycle of service, from inception and design, through to deployment, operation and refinement
Ensure reliable, fault-tolerant, efficiently scalable and cost-effective data, services and infrastructures
Maintain services once they are live by measuring and monitoring availability, latency and overall system health. Practice sustainable incident response and blameless postmortems.
Establish best engineering practice for engineers as well as non-technical people
Design and implement reliable, scalable, robust and extensible big data systems that support core products and business
Qualifications

BS or MS degree in Computer Science or related technical field or equivalent practical experience
Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.)
Experience with performing data analysis, data ingestion and data integration
Solid communication and collaboration skills
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at usds.accommodations@tiktokusds.com
Job Information
The base salary range for this position in the selected city is $136800 - $359720 annually.

​

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

​

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

​

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

​

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

​

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",2016,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
Cyber Security Engineer - Metrics and Data Analytics,"NVIDIA
","Santa Clara, CA",$128K - $201K (Employer est.),4.6,"NVIDIA is seeking for a highly analytical and hands-on Cyber Security specialist who will lead the development of data-driving metrics dashboard, visualization or correlation analysis to continuously measure and mature Zero Trust program effectiveness. Primary scope starting with Identity and Access Management (IAM), Privileged Access Management (PAM) and Service Account Governance, and will expand into other aspects such as service integration and dependency, zero trust access policy coverage and effectiveness. Passion, curiosity, attention to details, and collaborative will be essential for success in this role. You will be encouraged to keep automating repeatable workflows and exploring AI to optimize everything we do.
What you'll be doing:
Drive the continuous enhancement of metrics dashboard and data-driven analysis of Zero Trust program effectiveness.
Run meetings and forums involving the right subject matter experts to capture analysis objectives, and data engineering requirement.
Collaborate with enterprise data lake, AIOps, security monitoring and other teams to develop data pipeline and deliver metrics dashboard, visualization or correlation analysis.
Proficiently use data and visualization to deliver actionable insight.
What we need to see:
4+ years of experience supporting security monitoring, data analysis or business analyst roles required.
Bachelors degree or equivalent experience.
Hands-on experience with commercial or open source data lake, data streaming, dashboarding and event correlation tools required.
Proficiency in data analysis and AI/ML related coding languages (e.g. Python, Golang, Splunk Search Processing etc) required.
Ability in scripting languages, automation and REST-API development preferred.
A self-initiated fast-learner to research, explore and pickup new tools or new languages when needed.
Attention to details, strive for data quality and output accuracy, curiosity of dig into data for insights.
Ability to layer insights into higher strategic level and drill-in detail levels.
Excellent team-player and communication skills.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment some of which include generous holidays, unlimited PTO and tuition reimbursement.
The base salary range is 128,000 USD - 201,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
. NVIDIA accepts applications on an ongoing basis.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",1993,Computer Hardware Development,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer,"National Funding
","San Diego, CA",$101K - $151K (Employer est.),4.1,"Data Engineer - San Diego, CA or Orange County, CA

Hybrid 3 days/week, Full time M-F 8am-5pm PST

Being authorized to work in the U.S. is a precondition of employment.

National Funding does not consider candidates requiring 1099 or C2C.

Exempt/Salary: $101,000-$151,000 + Bonus

National Funding is continuing to grow its Data Analytics Department and has an exciting opportunity for a Data Engineer. Reporting to the Director of BI, the Data Engineer will help implement a new Snowflake Data Warehouse initiative.

Responsibilities:

The data engineer will participate in the data warehouse implementation and work closely with the DW team including analysts, BI developers, and SME experts. This includes the full DW lifecycle of requirements gathering, data modeling, data mapping, ETL, reporting and QA.
The primary responsibility will be ETL work using dbt integrating data, applying business rules and transformations, creating both normalized and de-normalized data.
They will be creating various ETL frameworks in dbt to semi-automate data transformation. This includes the full life cycle of ETL: applying business rules, data aggregation, data cleansing, and QA.
Other responsibilities include supporting other data engineers working on administration, data sourcing, data orchestration, notifications, data lineage, and related aws work

Knowledge, Skills and Abilities Required:

3+ years' experience working as a Data Engineer and 5+ years in Data warehouse, ETL, BI projects.
Must have experience in dbt, or related ETL products.
Expertise in data modeling, ELT using SQL, implementing complex stored Procedures and standard DWH and ETL concepts.
Expertise in advanced concepts like setting up resource monitors, RBAC controls, virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understanding how to use these features.
Preferably having experience with aws data storage and management technologies such as S3.

Nice to have skills:

Hands-on experience with Snowflake utilities, SnowSQL, SnowPipe, techniques using UDFs.
Deep understanding of relational data stores, methods, and approaches (star and snowflake, dimensional modeling).
Snowflake certification a plus.
Experience in creating frameworks in Snowflake:
SCD framework
Business Rules Engine
Jobs Scheduling
Capture Data Errors
Data Transformations
Snapshot data capture

Physical Demands:

Working in a temperature-controlled office environment
Sitting at a desk for prolonged periods of time while viewing multiple computer screen monitors
Potential lifting of boxes around 5-10lbs

Why National Funding?

Positive, energetic, passionate, business casual environment with management who commits to your success
Fantastic benefits package: Our current benefit package includes medical, dental, vision, life, LTD and AD&D insurance as well as a 401(k) Retirement Savings plan with an employer match. Eligibility for all benefits will start at the first of the month following 60 days of employment.
Numerous employee events throughout the year, including our annual traditions such as a Day at the Del Mar Racetrack, Del Mar Mud Run, Bring Your Kid to Work Day, Holiday Party, Employee and Family Picnic, sporting events and more.

National Funding is one of the leading providers of short-term loans and equipment leasing for small businesses across the United States. In both 2013 and 2014, we were ranked by the San Diego Business Journal as one of the 100 Fastest Growing Private Companies in San Diego and listed on the Inc. 5000 List of America's Fastest Growing Private Companies. We serve the small business community nationwide by offering a range of financial services and products. Since 1999, we have been in the forefront of the equipment leasing business, working with businesses in hundreds of communities and industries to expand and upgrade their business equipment. As we have grown, so too has our product line, and now we are one of the country's largest private lenders of small business loans. Our customers call on us to get working capital, merchant cash advances, credit card processing, and of course, equipment leasing.

National Funding is an Equal Opportunity Employer.",1999,Banking & Lending,Unknown / Non-Applicable,Financial Services,201 to 500 Employees,Company - Private,True
Software Engineer Lead - Data Scientist,"Capgemini
","San Francisco, CA",$120K - $160K (Glassdoor est.),3.7,"Job Description:

A Data Scientist with advanced SQL, R, and Python skills and experience carrying out statistical analysis of large datasets to drive measurement and marketing strategies for a technology client. You will be working with client data to develop data science solutions that enable stakeholders to understand the effects of marketing on business goals, while driving optimization recommendations for existing campaigns. This includes reporting, analytics, modeling, and measurement of marketing campaigns, monthly and quarterly revenue performance reviews, projections, ad hoc deep-dives, and more.

Requirements:

5+ years of data science/analytics experience, preferably using Big Data (Hadoop, Hive, Spark, etc.) and/or digital data sources (Facebook, Instagram, Claravine, DV360, etc.)
Advanced SQL, Python, and R programming, working with complex queries, partitions, and CTEs and/or ability to quickly learn new programming languages/frameworks/technologies
Experience with SQL platforms or MPP databases, such as Teradata, Redshift, Snowflake, etc.
Experience in Python and/or R (preferably both) using notebooks as well as IDEs, performing feature engineering, leveraging sklearn/statsmodels/R extensions for model-building, leveraging visualization packages (seaborn, ggplot2, etc), and working with conflicting namespaces in R
Experience performing statistical analyses, including significance testing and power analysis, familiarity with different statistical distributions, enabling measurement by matching, interpreting regression and classification models, developing parametric assumptions for regression models, general model interpretation, and analyzing marginal effects
Experience with data warehousing, pipelining, ETL, and data QA
Experience with translating data trends and results into actionable insights and recommendations to drive business outcomes
Experience developing Measurement Plans to guide marketing execution and analytics
Experience with A/B test reads and measuring success using statistical tools
Strong communication skills, particularly when speaking with stakeholders to gather business requirements
Ability to translate business requirements into actionable next steps to deliver a working solution that meets business needs
Ability to navigate a complex, matrixed organization to gather detailed information about existing processes and any gaps therein
Creative thinking skills to find solutions for complex, multi-layered data problems
Strong collaboration skills, particularly in building relationships with stakeholders and partners on the client side
Ability to manage client expectations and concerns with realistic goal-setting, prioritization, and communication of progress



Life at Capgemini

Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:

Flexible work
Healthcare including dental, vision, mental health, and well-being programs
Financial well-being programs such as 401(k) and Employee Share Ownership Plan
Paid time off and paid holidays
Paid parental leave
Family building benefits like adoption assistance, surrogacy, and cryopreservation
Social well-being benefits like subsidized back-up child/elder care and tutoring
Mentoring, coaching and learning programs
Employee Resource Groups
Disaster Relief
About Capgemini

Capgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.

Get The Future You Want | www.capgemini.com

Disclaimer

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.




Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.



Capgemini discloses salary range information in compliance with state and local pay transparency obligations. The disclosed range represents the lowest to highest salary we, in good faith, believe we would pay for this role at the time of this posting, although we may ultimately pay more or less than the disclosed range, and the range may be modified in the future. The disclosed range takes into account the wide range of factors that are considered in making compensation decisions including, but not limited to, geographic location, relevant education, qualifications, certifications, experience, skills, seniority, performance, sales or revenue-based metrics, and business or organizational needs. At Capgemini, it is not typical for an individual to be hired at or near the top of the range for their role. The base salary range for the tagged location from $120,000 to $145,000. This role may be eligible for other compensation including variable compensation, bonus, or commission. Full time regular employees are eligible for paid time off, medical/dental/vision insurance, 401(k), and any other benefits to eligible employees. Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, or any other form of compensation that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.
Job Programmer/Analyst
Schedule Full-time
Primary Location US-CA-San Francisco
Organization I&D",1967,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Center Network Engineer,"Meta
","Menlo Park, CA",$143K - $204K (Employer est.),3.9,"The scale of the network and its continuous expansion presents an opportunity to work on and solve interesting engineering challenges in the datacenter network domain. We constantly push the boundaries of what is possible. We create new and innovative ways of designing and operating our global datacenter networks and do it at scale with efficiency. We imagine what our tomorrow is going to be and make it a reality.Data Center Network Engineers at Meta are hybrid software and network engineers who design, build, and operate our worldwide Data Center network. This team owns the complete lifecycle of the Data Center network, which includes areas of planning, design, product definition, QA, deployment, and monitoring. Simple, elegant, and scalable network design, automation, and data analytics are the keys to meeting our demands. In this role, you will be part of a team that is responsible for conceiving design solutions, developing and deploying network software, systems, and tools that keep the Data Center network operating at maximum reliability, scalability, and efficiency.



Data Center Network Engineer Responsibilities:

Design network topologies and configuration for the DC Fabric networks
Develop IP addressing and routing policy intent in the DC
Create deployment packages and maintain as-built documentation for installed network gear
Establish and implement global best practices and contribute to the design of new scalable network solutions
Define and partner with network hardware, software, and vendor teams on the development of network platforms (switch and optics)
Partner with the in-house SWE, Tooling, Planning, Simulation, and Delivery teams to codify the network designs
Participate in an on-call rotation to support the global datacenter network infrastructure 24x7
10% of travel required




Minimum Qualifications:

5+ years of work experience responsible for designing, deploying and operating large-scale networks
Experience configuring and troubleshooting routing and switching protocols (BGP, IS-IS, OSPF, MPLS, RSVP-TE)
Working knowledge of network protocols (TCP/UDP, DHCP, DNS) and experience with IPv4 and IPv6
Experience working in a multi-vendor environment with hands-on experience with networking hardware
Experience in at least one programming language like Python, Go, C/C++ for developing automation software or tooling
Working knowledge of physical infrastructure design including structured cabling and fiber-optic cabling
Experience managing multiple projects simultaneously and deliver against deadlines
Experience working in global team environments and solve problems
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.




Preferred Qualifications:

Working knowledge of 40/100/400G Ethernet and CWDM, DWDM and optical transport network technologies
Understanding of different Optics and internals of a switch ASIC
Familiarity with the Linux based systems
Technical leadership experience




About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.



Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",2004,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Lead data engineer – R01530706,"Brillio
","San Ramon, CA",$96K - $133K (Glassdoor est.),3.6,"Lead data engineer - R01530706

About Brillio:
Brillio is the partner of choice for many Fortune 1000 companies seeking to turn disruption into a competitive advantage through innovative digital adoption. Backed by Bain Capital, Brillio is one of the fastest growing digital technology service providers. We help clients harness the transformative potential of the four superpowers of technology - cloud computing, internet of things (IoT), artificial intelligence (AI), and mobility. Born digital in 2014, we apply Customer Experience Solutions, Data Analytics and AI, Digital Infrastructure and Security, and Platform and Product Engineering expertise to help clients quickly innovate for growth, create digital products, build service platforms, and drive smarter, data-driven performance. With delivery locations across United States, Romania, Canada, Mexico, and India, our growing global workforce of over 6,000 Brillians blends the latest technology and design thinking with digital fluency to solve complex business problems and drive competitive differentiation for our clients. Brillio was awarded ‘Great Place to Work’ in 2021 and 2022

Lead data engineer
Primary Skills
SNS, SQS, Athena, CloudWatch, Kinesis, Redshift
Specialization
AWS Data EngineerIng Advanced: Associate Data Engineer
Job requirements

Role: Lead Data Engineer
Years of Experience: 10+ years
Travel Required: Yes
Location: Remote
As a consultant within the DIE team, you will work with our clients to define their digital strategy and execution roadmap, and design and implement differentiated digital solutions to help deliver measurable value.
Your responsibilities in this role will include:
Primary focus is on Glue, S3, Redshift, Lambda, PySpark, Spark.
Then added skillset which could add value are AWS Step function, NoSQL DB like Dynamo DB and AWS Data Migration Service in that order of priority.
Data engineer should have at least 2 years of relevant AWS experience with their services mentioned above.
Experience in data security or governance and performance improvement is an added benefit
Only focus is on AWS services and tech stack.""

Why should you apply for this role?
As Brillio continues to gain momentum as a trusted partner for our clients in their digital transformation journey, we strive to set new benchmarks for speed and value creation. The DIE team at Brillio is at the forefront of leading this charge by reimagining and executing how we structure, sell and deliver our services to better serve our clients.
DAE: https://www.brillio.com/services-data-analytics/

Know what it’s like to work and grow at Brillio:https://www.brillio.com/join-us/

Equal Employment Opportunity Declaration
Brillio is an equal opportunity employer to all, regardless of age, ancestry, colour, disability (mental and physical), exercising the right to family care and medical leave, gender, gender expression, gender identity, genetic information, marital status, medical condition, military or veteran status, national origin, political affiliation, race, religious creed, sex (includes pregnancy, childbirth, breastfeeding, and related medical conditions), and sexual orientation.
#LI-RJ1
Know what it’s like to work and grow at Brillio: Click here",2014,Information Technology Support Services,$100 to $500 million (USD),Information Technology,1001 to 5000 Employees,Company - Private,False
Data Engineer/Analyst,"BayOne
","Santa Clara, CA",$91K - $146K (Glassdoor est.),3.9,"Responsibilities

Lead and participate in design discussions and meetings

Mentor data engineers and analysts

Design, automate, build, and launch scalable, efficient and reliable data pipelines into production using Python

Perform root cause analysis and resolve production and data issues

MINIMUM QUALIFICATIONS:
7+ years experience in data engineering

7+ years experience in custom ETL design, implementation and maintenance

Experience building real-time data solutions and processes

Advanced skills with Python/Java and SQL are a must

Strong computer science fundamentals including data structures and algorithms

Experienced in working collaboratively across different teams and departments

Strong technical and business communication",2012,Information Technology Support Services,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,False
Data Engineer,"FutureSoft IT
","Sunnyvale, CA",$103K - $145K (Glassdoor est.),5.0,"**Please Read**







Local candidates only. This opportunity does not provide Visa sponsorship. No corp to corp applicants please. Candidate must be available to work on our W2.







Data Engineer







Data applications are critical to our success, powering many aspects of our marketplace and supporting products. We are looking for data engineers who will build, migrate and maintain data pipelines. In this role, you’ll expand and refactor the data sets that generate and transform data into applications, insights, and experiences for our users.







The work includes:
? Refactoring existing and build new data pipelines
? Migrating existing data sets into next-gen reporting frameworks and tools
? Using existing data tools and frameworks to configure reports and metrics
? Developing and automating large scale, high-performance data processing systems to drive our business growth and improve the product experience
? Building and refactoring scalable data pipelines on top of Hive and Spark leveraging Airflow scheduler/executor framework







We are looking for engineers with:
? Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and drive effective product solutions
? Experience designing and deploying high performance systems with robust monitoring and logging practices
? Experience building high performance data pipelines
? Nice to have: proven ability to think critically about team direction and use analysis to inform that
? Experience using machine learning is a plus, but not required.
? Excellent communication skills, both written and verbal",-1,Staffing & Subcontracting,Unknown / Non-Applicable,Human Resources & Staffing,Unknown,Company - Public,True
Principal Data Scientist/AI Engineer,DeepVu,"Berkeley, CA",$120K - $191K (Glassdoor est.),-1.0,"This role is based in Canada or France. Currently, we are looking for highly innovative energetic principal data scientsts with experience in enterprise scale deep learning, forecasting and decisioning model. You are an awesome problem solver who is both methodical and creative. You can learn any new technology, are not ashamed of admitting errors, love to take on new challenges, and a great team player. Strong algorithmic background is required and will be thoroughly evaluated. Strong at-scale experience building decisioning models using Deep Reinforcement Learning or other approaches is a must. Experience building and deploying high performance deep-learning models using either Tensorflow or PyTorch on significant complexity industrial/commercial data-sets is a must. Preference will be given to candidates with significant time-series modeling experience.



We'd love to chat if you have:



A PhD or MS in an analytical field such as CS, EE, Statistics, Math, or Physics, from a top 10 AI university is required, along with a minimum 6 years industry experience building reference-able work.


Proficiency in Python and machine learning libraries such as Scikit-learn, Pandas, Tensorflow, PyTorch, etc


Demonstrated strong experience with Deep Reinforcement Learning


Experience building large scale models with Reinforcement learning, LSTMs, CNNs, GANs, and Gradient Boosting is required.
Experience deploying end-to-end ML models to production
Experience with time-series data analysis


Efficient communicator with customers as well as across all levels of the organization


Comfortable with remote work and distributed team



Extra Brownie Points:



Experience with Docker, and Kubernetes


""Big Data"" solutions such as Spark, and Kafka
Experience with cloud environments such as AWS/GCP/Azure

If you want to get into the founding engineering team of one of the valley's top teams developing one of the most innovative and unique cloud AI SaaS in multi-trillion USD industry sectors with massive global implications on the planet and humanity, you've found it and we would love to hear from you very soon.



Sound exciting? please submit your resume to resumes@deepvu.co",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,False
Data Analytics Engineer,"The Marlin Alliance
","San Diego, CA",$87K - $122K (Glassdoor est.),4.8,"The Marlin Alliance, Inc. is seeking a highly qualified and motivated Data Analytics Engineer to join our team. This individual will play a critical role in supporting various technical initiatives and projects. This role requires a Bachelor's or Master's degree in Computer Science, Data Science, or a related field and an active Secret Clearance.

Established in 2002, The Marlin Alliance is seeking to hire highly skilled individuals to support mission critical projects within the Navy. We are looking for motivated individuals to lead and support digital transformation, data science and analytics, and automation projects for variety of Navy clients. Individuals must be able to function in a fast-paced work environment and able to adapt quickly to rapidly changing requirements and technologies. Using your comprehensive knowledge of various technologies, you will design, develop, and implement solutions to support Navy mission owners in their digital transformation journey.

Duties and Responsibilities:

Collaborate with stakeholders to gather requirements and understand business objectives.
Design, develop, and maintain predictive analytics tools using Power BI and Power Apps.
Create interactive and visually appealing dashboards and reports to present insights effectively.
Implement data cleansing, transformation, and modeling processes to support predictive analytics.
Utilize machine learning algorithms and statistical techniques to build predictive models.
Ensure data accuracy and consistency throughout the analytics process.
Perform data analysis to identify trends, patterns, and anomalies.
Optimize and fine-tune predictive models for accuracy and performance.

Qualifications:

Bachelor's or Master's degree in Computer Science, Data Science, or a related field.
5 years experience using Power BI and Power Apps.
Strong proficiency in data analysis, data visualization, and data modeling.
Expertise in machine learning, statistical analysis, and predictive modeling.
Excellent problem-solving and analytical skills.
Ability to translate business requirements into technical solutions.
Knowledge of best practices in data governance and security.
Relevant certifications (e.g., Microsoft Certified: Power BI, Azure AI Engineer) are a plus.
U.S. Citizenship is required for this position.

Work Environment and Mental/Physical Demands

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this position. Reasonable accommodations may be made to enable individuals with disabilities to perform the functions.

Typical office environment with no unusual hazards.
The noise level in the work environment is usually moderate.
Constant sitting while using the computer terminal.
Constant use of sight abilities while reviewing documents.
Constant use of speech/hearing abilities for communication.
Occasional reaching, stooping, kneeling, or crouching may be required.
Occasional lifting up to 20 pounds.
Constant use of mental alertness.
Frequent work under deadlines.

Job Classification:
Associate II
$85,000 - $140,000

Disclaimer:

This job description in no way states or implies that these are the only duties to be performed by the employee(s) incumbent in this position. Employees will be required to follow any other job-related instructions and to perform any other job-related duties requested by any person authorized to give instructions or assignments. All duties and responsibilities are essential functions and requirements and are subject to possible modification to reasonably accommodate individuals with disabilities.

To perform this job successfully, the incumbents will possess the skills, aptitudes, and abilities to perform each duty proficiently. Some requirements may exclude individuals who pose a direct threat or significant risk to the health or safety of themselves or others. The requirements listed in this document are the minimum levels of knowledge, skills, or abilities.

This document does not create an employment contract, implied or otherwise, other than an “at-will” relationship.

An Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities.",2002,Business Consulting,Less than $1 million (USD),Management & Consulting,1 to 50 Employees,Company - Private,False
