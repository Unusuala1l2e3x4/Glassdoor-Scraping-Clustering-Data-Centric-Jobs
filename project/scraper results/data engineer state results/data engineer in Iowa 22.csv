Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply
SOFTWARE ENGINEER - DATA MANAGEMENT,"Grinnell Mutual Reinsurance
",Iowa,-1,4.2,"Overview:

Software Engineers are responsible for engineering software and/or complex integrations of existing software using current technologies to support the business objectives of Grinnell Mutual Reinsurance Company and their customers. Serves as a member of a cross functional Agile Software Development Team, completing any/all tasks to ensure team success.

This position qualifies for our flexible workplace options. Work at our Grinnell, Iowa, headquarters or from a home office in any of the following states: Alabama, Arizona, Florida, Georgia, Illinois, Indiana, Iowa, Maine, Minnesota, Missouri, Montana, Nebraska, New Mexico, North Carolina, North Dakota, Ohio, Oklahoma, Pennsylvania, South Dakota, Tennessee Texas, Virginia, Wisconsin, and Wyoming. Please note that candidates must be eligible to work in the U.S. without Grinnell Mutual sponsorship.

Responsibilities:
Develops and supports new and existing data solutions utilizing software such as SAP Data Services and/or Cognos, code reviews and modularity for hosting on-premises and in the cloud.


Supports existing software, including keeping versions current by implementing new business needs and technology updates.


Demonstrates proficiency in software development tools, programming languages and software development techniques that adhere to the best practices specific to Grinnell Mutual.


Maintains and promotes a security driven mindset, ensuring software meets the criteria of the Grinnell Mutual Security Team. This includes adherence to OWASP and applicable regulations.


Remains current with changes in technology and evaluates the feasibility of incorporating development techniques into new and supported applications.


Communicates and updates teams and stakeholders to ensure transparency and alignment with project priorities. Occasionally works with outside vendors or contractors to create solutions and timelines for assigned projects and software issues.


Collaborates with third party vendors and Grinnell Mutual technology professionals, including Architecture, Infrastructure and Operations, to ensure technologies used are relevant to the current and future state of software engineering. Takes ownership of team delivery to ensure highest probability of success for team.


Leverages automation and DevOps techniques to reduce overall technical maintenance, monitor system performance, improve system quality and reduce manual business process of Grinnell Mutual.


Provides support as needed when software outage incidents occur, restoring service in the quickest and most stable manner possible. Knowledge of ITIL methodology is preferred.


Contributes to product planning using Agile methodologies. Ensures stories are complete, accurate and ready to be developed before the team commits to them.


Adheres to work intake, prioritization, change management, architecture governance and other required best practices of Grinnell Mutual.


Performs all other duties as assigned.
Qualifications:
Bachelors’ degree from an accredited college/university in programming related field with significant course work and/or experience in design, development and analysis of technology solutions.


Proficient with Structured Query Language (SQL): Oracle and/or PostgreSQL.


Skilled at understanding inter-dependencies and relationships of complex technical data sets with ability to be a creative problem-solver with strong analytical skills.


Attain and keep current necessary certifications for position.


Contributes to the growth of technology at Grinnell Mutual by sharing expertise with others. Educates others, adding to the total technical capabilities of Grinnell Mutual.


Demonstrated ability to effectively plan, schedule and meet deadlines while concurrently managing multiple tasks. Must be able to work with multiple interruptions.


Working knowledge of Property and Casualty Insurance preferred. Willingness to develop a working knowledge of industry and Grinnell Mutual specific business practices. Must be able to appropriately apply learned knowledge as it relates to responsibilities of the position.


Ability to work with mathematical concepts such as, probability and statistical inference and applying concepts such as, fractions, percentages, ratios, and proportions to practical situations as required for programming to simplify work of end user.


Ability to interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract/concrete variables.


Recognizes processing/application inefficiencies and recommends improvements.


Demonstrated enthusiasm and commitment towards assignment and problem solving.


Demonstrated oral, written, and presentation skills to both technical and non-technical personnel. Exhibits self-assurance and a creative aptitude.


Ability to understand basic insurance terminology applicable to personal lines and commercial lines of insurance.


Occasional overnight travel for training or conferences.


Requires regular and predictable attendance to meet the customer needs of the position.


Must be able to maintain confidentiality and propriety information.


Demonstrated ability to adhere to all Grinnell Mutual policies.


Demonstrated ability to incorporate Grinnell Mutual core values in all areas work.

Working conditions and physical efforts

To perform this job successfully, an individual must be able to perform each job duty and responsibility satisfactorily. Reasonable accommodations may be made to enable individuals with disabilities to perform job duties and responsibilities.
The position is physically located in an agreed upon location per the Grinnell Mutual Work from Anywhere policy. All work arrangements must put the business needs of the organization first and ensure the coverage of all job duties.


The position requires an individual to sit for long periods of time, use repetitive motion, and possess visual acuity demanded by work with computer and other LCD screen devices.


The work may be fast paced, especially when managing multiple projects or when faced with tight deadlines. Meeting schedule could be heavy. May be required to work outside of normal business hours at times to accomplish work.

This job description is not intended to describe, in detail, the multitude of tasks that may be assigned, but rather to give the employee a general sense of the responsibilities and expectations of his/her position. As the nature of the business demands change, so too may the job duties and responsibilities.",1909,Insurance Carriers,$500 million to $1 billion (USD),Insurance,501 to 1000 Employees,Company - Private,False
Data Engineer,"Robert Half
","Cedar Rapids, IA",$87K - $118K (Glassdoor est.),3.8,"This role focuses on the evolution and optimization of data exchange platforms to be more data centered in decision making. You will be part of the development, maintenance, integration, and enhancement of systems, workflows, and processes to ensure seamless data exchange. You will need to be detailed oriented, analytical, and have the ability to apply input into the new data system. The position demands collaboration with internal stakeholders, department heads, and external vendors to deliver high-quality solutions that meet the needs of internal users and 3rd party clients. To learn more about this new opportunity being added to a growing team, please apply now, call 319-362-8606, or email your resume direct to myself: Shawn M Troy - Technology Practice Director with Robert Half (additional contact information is on LinkedIn)

Primary Responsibilities:
Stakeholder Collaboration: Collaborate effectively with relevant stakeholders to translate business logic and procedures into technical tools and processes.
Workflow Automation: Design, develop, and implement automation workflows to enhance staff productivity by streamlining manual processes.
Data Analysis and Extraction: Develop data analysis and extraction processes to deliver accurate and timely information to business partners.
Interdepartmental Coordination: Coordinate with various departments to implement workflows between different systems based on organizational needs and priorities.
Data Integrity Management: Cultivate and maintain data integrity across Auxiant processes and datasets.
Data Reporting and User Interface Design: Distill complex data from multiple sources into usable reports, file outputs, and user interfaces for effective operational procedures and data exchange.
Process Improvement: Identify and develop improvements or additions to existing data processes.
Legacy System Migration: Lead efforts to migrate legacy software and data management systems to more scalable and robust solutions.

ETL - Extract Transform Load, MS SQL Server, MySQL, Complex Datasets, REST API, C Sharp Programming (C#), PowerShell, Git version control, VB/VBA programming

Technology Doesn't Change the World, People Do. ®

Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.

Robert Half works to put you in the best position to succeed. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity - whenever you choose - even on the go. Download the Robert Half app and get 1-tap apply, notifications of AI-matched jobs, and much more.

All applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals, including medical, vision, dental, and life and disability insurance. Hired contract/temporary professionals are also eligible to enroll in our company 401(k) plan. Visit roberthalf.gobenefits.net for more information.

© 2023 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to Robert Half’s Terms of Use .",1948,HR Consulting,$5 to $10 billion (USD),Human Resources & Staffing,10000+ Employees,Company - Public,True
Data Integration Engineer,"LCS
","Des Moines, IA",$100K - $115K (Employer est.),3.9,"As a Clinical Data Integration Engineer at LCS, you will be responsible for designing, developing, and maintaining robust data integration solutions that bridge the gap between various data sources, including healthcare data, and our analytical systems. You will work closely with cross-functional teams to ensure the seamless flow of data and contribute to the success of our data-driven initiatives. This role will also involve expertise in HIPAA compliance and Electronic Health Record (EHR) integration.


Experience is Everything;

At LCS, experience is everything. We provide you the opportunity to use your talents in a progressive, growing organization that makes a positive difference in the lives of the seniors we serve. If you are seeking an organization that gives back, you’ll love working here. Our principles and hospitality promises define our company culture. LCS employees can be found participating in volunteer activities, getting involved in our committees or collaborating with team members in our innovative work space. You’ll find several opportunities to grow as a professional, serve the community, and enhance the lives of the seniors.


The Role:

Design and architect data integration solutions that meet business requirements, including the integration of healthcare data from Electronic Health Records (EHRs), ensuring data quality, consistency, and reliability.
Develop, implement, support, and maintain data integrations from diverse sources, including EHR systems, into our data warehouse.
Design and develop reporting, both from within the EHR systems and from data extracted from the EHR, clinical systems, and data warehouse.
Collaborate with EHR systems and vendors to establish efficient data extraction processes and maintain data source connections, while adhering to HIPAA regulations.
Ensure that all healthcare data integration processes are fully compliant with the Health Insurance Portability and Accountability Act (HIPAA) regulations and other relevant healthcare data security and privacy standards.
Implement data validation and quality checks to guarantee the accuracy, integrity, and consistency of healthcare data throughout the integration process.
Maintain comprehensive documentation of data integration processes, data flows, and solutions to facilitate knowledge transfer and troubleshooting.
Proactively identify and resolve data integration issues and provide timely support to resolve any data-related incidents.
Work closely with data engineers, data scientists, the Health Services Division, and other stakeholders to understand their data needs.


Experience:

BS or BA degree in Computer Science, Information Systems or related field or equivalent years of experience
Minimum 5 years of experience working as a functional analyst or 3 years as a System Engineer
5+ years of professional experience in data integration, ETL, or related field, preferably with a focus on healthcare data, HIPAA compliance, and EHR integration.


Knowledge & Experience:

Proficiency in data integration tools and technologies.
Strong SQL skills.
Analytical skills with the ability to collect, organize, analyze, and distribute significant amounts of information with attention to detail and accuracy.
In-depth knowledge of database systems and data warehousing.
Experience working with EHR / EMR data and vendors strongly preferred.
Excellent problem-solving skills and attention to detail.
Strong communication and collaboration skills.
Expertise in healthcare data and healthcare data security.
Knowledge of Jira, Confluence and agile methodologies.
Strong problem solving ability with focus on quality and urgency.
Excellent verbal, written and interpersonal skills; organization and team skills.
Strong documentation and technical writing skills.
Ability to provide quality customer service.
The ability to prioritize tasks and meet deadlines.
Ability to work independently and use good judgment in making routine decisions.
Thorough and detail-oriented.
Performs work under minimal supervision.


Why LCS?

Industry leader. The Nation’s third-largest senior living operator, ranked number one in customer satisfaction among senior living communities.

Inclusive and collaborative culture. We’re dedicated to diversity, equity, and inclusion and have an engaged Diversity and Inclusion Council focused on creating awareness and educating employees on inclusivity. In addition, LCS creates a collaborative culture that provides an exceptional experience for every employee.

Top Workplace USA: LCS has earned the 2021 Top Workplaces USA award and is recognized for our strong company culture and engaged workforce. In addition, LCS earned ten culture excellence awards in areas such as DE&I practices, top managers, professional development and clued-in leaders, to name a few.

Top Workplace Iowa: LCS employees truly believe we are an employer choice. This recognition, for 4 years running, is in large part due to the culture of excellence that our employees help deliver every single day.

Competitive pay, great benefits and vacation time. We are an equal opportunity employer with benefits including medical, dental, life insurance, disability, 401(k) with company match and paid parental leave.

Charity and community involvement. We are recognized as a national team for the Alzheimer’s Association and consistently a top contributor to United Way. We also support our employee’s individual community contributions and provide opportunities to get involved at our corporate locations and in our communities.

Outstanding advancement opportunities. LCS is growing and we think you should too. Our company growth allows for internal growth opportunities across all of our business lines.

Ongoing career development. Onsite education opportunities, education assistance, and continuing education credits allow LCS employees to keep their knowledge of current industry changes relevant.


LCS creates living experiences that enhance the lives of seniors. You’ll see this commitment in our people. They’re talented, dedicated professionals who truly care about residents, with each conducting his or her work with integrity, honesty and transparency according to the principles of LCS. We strive to help every community succeed—strengthening available resources, establishing proven practices that lead to long-term growth and creating lasting value for those living in, working for and affiliated with the community. Check us out on our website: www.lcsnet.com


Travel Frequency: 0-10%

Job Level: B

Estimated Salary Range: $100,000 - $115,000

The actual salary offer will carefully consider a wide range of factors, including your skills, qualifications, experience and other relevant factors.


A POST-OFFER BACKGROUND CHECK, INCLUDING REFERENCES, IS REQUIRED

LCS IS AN EQUAL OPPORTUNITY EMPLOYER",1971,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,501 to 1000 Employees,Company - Private,False
Data Engineer - 5050304,"Accenture
","Des Moines, IA",-1,3.9,"Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.

As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.

You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.

Utilize strong SQL Python skills to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features.

Build reporting dashboards and visualizations to design, create and track campaign program KPIs.

Perform analyses on large data sets to understand drivers of operational efficiency.

Manage end to end process of analytic tooling feature development, including request intake, requirements evaluation, cross functional team alignment, feature execution, QA testing, and stakeholder communication.

Consult with business analysts, technical data SMEs, and cross functional partners to understand their reporting and data needs, serving as the point of contact for requests, inquiries, and actions.

Interface with other data engineering, product, and data science teams to implement client needs and initiatives.




Basic Qualifications:

Minimum 2 years experience with Python.

Minimum 3 years experience SQL.

Minimum 3 years experience Big Data Analytics.

High School Diploma or GED.

Preferred Qualifications:

Experience with large enterprise data sets.

Bachelors Degree

Compensation at Accenture varies depending on a wide array of factors, which may include but are not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York, or Washington as set forth below.

Information on benefits is here.

Role Location

California: $61.53 to $71.53/hour

Colorado: $61.53 to $71.53/hour

New York: $61.53 to $71.53/hour

Washington: $61.53 to $71.53/hour


What We Believe


We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.


Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here


Equal Employment Opportunity Statement


Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.


All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.


Accenture is committed to providing veteran employment opportunities to our service men and women.


For details, view a copy of the Accenture Equal Employment Opportunity and Affirmative Action Policy Statement.


Requesting An Accommodation


Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.


If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.


Other Employment Statements


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.


Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.


Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.


The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",1989,Business Consulting,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Engineer,"ARAG North America
","Des Moines, IA",$67K - $103K (Glassdoor est.),3.8,"Purpose:
Do you have a passion for developing solutions to integrate and transform data? Do you have experience with relational databases like Azure SQL and data integration tools such as Talend and Azure Data Factory? Are you service-minded and detail oriented?

ARAG is hiring a data engineer! This person will collaborate with analysts, developers, and business users to build data pipelines and marts to support reporting and analytics.
Essential Duties and Responsibilities:
Develops Azure-based solutions to load and integrate on-premise and cloud data sources and transform data to meet data warehouse reporting requirements.
Designs and develops data integration and automation processes, ensuring solutions align with best practices for performance, data integrity, security and code reusability.
Provides maintenance support for existing ETL processes, including performing root cause analysis and resolving issues that arise.
Collaborates with cross-functional partners to understand complex business problems; propose and implement technical solutions to address.
Translates business requirements into functional technical requirements, providing accurate estimates on level of effort and timelines.
Maintains an understanding of ARAG’s audiences, processes, systems, and tools to identify gaps, quality concerns and performance issues; recommend and implement enhancements.
Unit test codes to an acceptable defect level prior to handoff to quality assurance and business testers and provide support throughout testing process.
Helps with database optimization, integrity, consistency, and security.
Assists in creating and maintaining documentation of data flows and integration processes.
Serves as positive role model by representing ARAG at its Best.
Other duties as assigned.
Qualifications:
Knowledge
Knowledge of Azure cloud services, including Azure SQL database, Data Lake Gen 2, and Data Factory
Demonstrated understanding of data modeling, data warehouse and ETL strategies
Strong knowledge of relational databases (Azure SQL experience preferred)
Demonstrated understanding of Data Governance principles and practice
Working knowledge of agile methodology and project management tools
Skills
Experience developing data flows and relational data stores in Azure cloud services strongly preferred
Experience with Azure Data Factory, Talend, Informatica, or similar ETL tool (Azure Data Factory and Talend preferred)
Demonstrated background in data design, workflow, integrations, standards, and complex business rules
Problem-solving and analytical skills to gather and analyze data, identify and interpret trends, and create solutions to solve complex challenges
Excellent interpersonal skills to collaborate and gain buy-in across multiple functions and levels of the organization
Strong written and verbal communication skills with ability to translate technical issues to the business
Highly organized with ability to effectively manage workload across multiple projects
Ability to troubleshoot and resolve issues
Ability to effectively operate and remain positive in a fast-paced, ever-changing environment
Ability to think beyond “what is” and ask “what could be?”
Ability to take initiative and advocate for purposeful change and constant improvement that sets ARAG apart from the rest
Willingness to maintain a “fail fast, move forward” mindset
Ability to translate complex data and concepts into language and visualizations that can be readily understood by business stakeholders
Education
Four-year college degree in computer science, information technology, data science, business, or related field from an accredited college or university or equivalent experience.
Experience
3+ years of experience in ETL/ELT development, including experience with Azure SQL¸ Talend, Azure Data Factory, and Data Lake Gen 2, or comparable technologies.
Certifications
None required.
Physical
Minimal travel required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
#LI-DNI",1935,Insurance Carriers,$1 to $5 billion (USD),Insurance,1001 to 5000 Employees,Company - Public,False
Data Engineer (Cloud) – Des Moines,"Object Partners
","Des Moines, IA",$81K - $122K (Glassdoor est.),4.4,"Why consider OPI, and why do people dig working here?

Variety of consulting; new technologies, projects, and people on a regular basis.
Stability; we’ve been around since 1996 and have a diverse mix of clients and technologies to keep us busy, very busy. And we keep a bench. If you’re not on a project, you’re writing software for our internal business functions or you’re learning new technologies. It’s beneficial to make our consultants as marketable as possible. That’s good for your career.
No politics or management; we don’t get in the way. Why sit in meetings all day when you can code and be productive?
Awesome benefits; robust healthcare plan, 28 days of PTO, semi-annual profit sharing bonuses, you get paid OT, company trips, various quarterly company events, new MacBook Pro’s, free beer/soda, chips, candy, and so much more.
You work with the best. Do an Object Partners search on LinkedIn and see the types of talent we hire. You truly get to work with intelligent, passionate engineers that share the same goal of building great software the right way.
Low company overhead. It all means more money back into our consultants pockets (profit sharing) or company trips and events to share in the financial success.
Data Engineer

As a Data Engineer, you’ll be working with the latest cloud and technology stacks to help clients implement and mature their modern data architecture. You will work with tools/platforms like Kafka, Snowflake, and Databricks to help clients get the most out of their data that may be in systems like Salesforce, SAP, SQL Server, or file storage. With a variety of projects, technologies, and clients, you will constantly be growing, and never bored.


Qualifications
At least 4 years of experience as a hands-on software or data engineer
At least 1-2 years building production-grade data solutions (Example: ETL/ELT, Spark, Azure Data Factory, AWS Data Migration Services, streaming systems)
Demonstrated aptitude for problem-solving and creativity
Ability to learn new technologies and apply learnings to production-grade solutions
Experience with at least one prominent cloud provider (e.g.: AWS, Azure, GCP)
Strong working knowledge of a querying language like SQL
Understanding of CI/CD, automated testing, and the DevOps culture
Effectively communicate complex technical solutions to a variety of audiences through oral and written mediums
Preferred Skills
Production experience with at least one distributed data system like Snowflake, Databricks, Cassandra, DynamoDb, Elastic, or Hadoop
Production experience with at least one messaging technology like Kafka, Kinesis, Pulsar, or RabbitMQ
Certification on at least one relevant platform/tool (AWS, Azure, GCP, Snowflake, Databricks, Spark)
Can translate business needs into optimized and efficient data models in SQL or NoSQL
Service frameworks such as Spring Boot, Ratpack, Vert.x, or Play
Knowledge of data analytics, visualization and governance
Experience working in an agile development framework like Scrum or Kanban",1996,Business Consulting,$5 to $25 million (USD),Management & Consulting,51 to 200 Employees,Company - Private,False
Data Center Network Engineer,"Sira Consulting Inc
","Altoona, IA",$30.60 - $40.00 Per Hour (Employer est.),3.6,"Key Skills:

• Experience working with Fiber optic.

• Experience in RJ45 and other connectors

• Experience with switch directories

Need CLI/Linux knowledge.

Job Description:

● Culture / Team fit

● Ambitious / Hard working / Go getter / Coachable / Mentor

● Physical layer: fiber optic connections, contamination, cleaning

● Understand ESD best practices

● Comfortable with text based CLI

● Familiar with IP based networking

● A+/Network+ level of knowledge required

● Good understanding of OSI layer and network principles

● 2+ years of DC experience required

● 4+ years of IT related experience required

● Familiarity with the Linux based systems and experience with scripting and automation (Bash, Python, Perl)

● Understanding BGP routing protocols, spanning tree, VRRP, LACP

● Nvidia IB understanding is a nice to have skill

● Good organization, multitasking and communication skills

● Microsoft Office Tools: Word, Outlook, Excel

● Understanding of network procedures, environmental and safety management in a DC environment

Responsibilities:

● Physical hardware swaps: (Fabric and Backbone)

○ Optical transceiver swaps / Circuit diagnosis

○ Line card swap

○ TOR Replacement

○ Work with vendors for RMA's

○ Must be able to lift 50lbs

● Asset Management

● Tools and Ticket management

● Build relationships with partner teams within the DC

● Ability to review hardware logs, isolate and identify root cause

● Remote link troubleshooting

Ability to mentor and guide L1 resources

Job Type: Contract

Pay: $30.60 - $40.00 per hour

Benefits:

Health insurance
Vision insurance

Schedule:

8 hour shift
Monday to Friday

Ability to commute/relocate:

Altoona, IA 50009: Reliably commute or planning to relocate before starting work (Required)

Experience:

Computer networking: 1 year (Preferred)
LAN: 1 year (Preferred)

Security clearance:

Confidential (Preferred)

Work Location: In person",2012,Information Technology Support Services,$5 to $25 million (USD),Information Technology,1 to 50 Employees,Company - Private,True
Data Engineer,"Berkley
","Urbandale, IA",$74K - $105K (Glassdoor est.),4.0,"Company Details:
Berkley Technology Services (BTS) is the dynamic technology solution for W. R. Berkley Corporation, a Fortune 500 Commercial Lines Insurance Company. With key locations in Urbandale, IA and Wilmington, DE, BTS provides innovative and customer-focused IT solutions to the majority of WRBC’s 60+ operating units across the globe. BTS’s wide reach ensures that ideas and opinions are considered at every level of the organization to guarantee we find the best solutions possible.

Driven by a commitment to collaboration, BTS acts as consultants to our customers and Operating Units by providing comprehensive solutions that not only address the challenge at hand, but proactively plan for the “What’s Next” in our industry and beyond.

With a culture centered on innovation and entrepreneurial spirit, BTS stands as a community of technology leaders with eyes toward the future - leaders who truly care about growing not only their team members, but themselves, and take pride in their employees who shine. BTS offers endless ways to get involved and have the chance to grow your career into a wide range of roles you'd never known existed. Come join us as we push forward into the future of industry leading technological solutions.

Berkley Technology Services: Right Team, Right Technology, Simple and Secure.
Responsibilities:
The Data Engineer will be providing support for multiple operating units within WR Berkley on the Guidewire ClaimCenter platform. The position involves the ability to gather business requirements; the development of custom reports, databases, scripts, and queries; communication and interaction with both internal and external resources; strong support and understanding of Guidewire ClaimCenter initiatives including conversions, data modeling, and data fixes; understanding of the Guidewire ClaimCenter data model.


Demonstrates the capability to resolve routine data problems within the Guidewire ClaimCenter system or process
Ability to modify existing functionality or provide minor improvements with limited direction.
Demonstrates solid development processes including code review, documentation, and unit testing.
Demonstrates understanding of data processes and/or structures of the Guidewire ClaimCenter platform and ODS.
Demonstrates understanding of data processes through integrations with Guidewire.
Will be required to communicate and coordinate with multiple Operating Unit Claim’s team and with BTS IT teams.
Assists in the development, maintenance, and oversight of various databases, software, and other tools.
Provides support for claims analyses through data set up, interrogation, and observations.Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Qualifications:
3+ years of experience in a data engineering role; insurance experience preferred.
3+ years of experience with relational databases (such as SQL Server is required).
1+ year of experience working with or understanding formal ETL tools
Bachelor’s degree or equivalent; preferably in actuarial science, math or computer science
Ability to respond to common inquires or complaints from members of the business communities.
Strong analytical, critical thinking and problem-solving skills.
Strong project management, organization and planning skills.
Ability to quickly assimilate and learn new systems and technologies.
Guidewire Product Suite knowledge and experience strongly preferred.
Multi line property and casualty insurance knowledge preferred.
Demonstrated experience in effective collaboration and providing a high degree of customer satisfaction.
Ability to effectively work in an environment with competing demands resources, time, and priorities.
Behavioral Core Competencies
Critical Thinking
Self-Starter
Technically Astute
Managing Information
Customer Service Oriented
Business Knowledge

The Company is an equal employment opportunity employer.",2012,Commercial Printing,$25 to $100 million (USD),Manufacturing,1 to 50 Employees,Company - Private,False
Data center Engineer (contractor),UPPER LLC,"Des Moines, IA",$35.00 - $45.00 Per Hour (Employer est.),-1.0,"As a data center engineer you perform work on server and network equipment in data centers in your region. UPPER is a nationwide provider of remote-hands services and as such, our clients hit us up to get work done by us on their behalf.

UPPER holds a database of qualifying engineers. Whenever work is ordered through UPPER, a suitable Engineer is selected to get the job done. Whether it’s a short and sweet order to push a button, rack/stack, etcetera or a larger project, UPPER selects the Engineers based on criteria like quality, accuracy availability and location.

Note carefully, as a qualifying Engineer, you are offering your services to UPPER as an independent contractor. That means that you have a lot of freedom. It also means that you have a lot of responsibility. Because when you accept an order, we expect you to execute the order in accordance with our guidelines. In short, these guidelines describe how important a professional demeanor is.

We are always looking to add smart and hard-working Engineers to our team. Because thanks to our Engineers we form a nationwide, 24×7 workforce of professionals. The word ‘professional’ is key and paramount with everything that our Engineers do.

If this is for you, we welcome you to go ahead and apply.

Job Types: Part-time, Temporary

Pay: $35.00 - $45.00 per hour

Schedule:

On call

Application Question(s):

This job is subject to a thorough background check.

Experience:

data center: 1 year (Required)

Work Location: On the road",-1,-1,-1,-1,-1,-1,True
Data Engineer,"Cottingham & Butler
","Dubuque, IA",$76K - $104K (Glassdoor est.),3.9,"Data Engineer

Location: Dubuque, IA office


We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have a passion for data and a strong background in building scalable data pipelines and data infrastructure. The Data Engineer will work closely with our analysts, engineers, and IT team members to build and maintain our data platform.

Responsibilities:

Design, build, and maintain scalable and robust data pipelines to process large volumes of data
Implement data models and data structures to support analytical needs
Develop and maintain data integration workflows between internal and external systems
Optimize data storage and retrieval for performance and efficiencies
Develop and maintain data quality and data governance processes
Collaborate with analysts to provide access to high-quality data and insights
Keep up-to-date with emerging technologies and trends in data engineering

Qualifications:

Bachelor's or Master's degree in Computer Science, Data Science, or a related field
3+ years of experience in data engineering or a related field
Strong experience in designing and implementing data pipelines and ETL processes
Experience with data lakes and data warehouses
Strong understanding of database design and SQL
Excellent problem-solving and communication skills

If you are a highly motivated and talented data engineer looking for an exciting opportunity, we encourage you to apply for this position. Please submit your resume for consideration.",1887,Insurance Agencies & Brokerages,$100 to $500 million (USD),Insurance,1001 to 5000 Employees,Company - Private,False
AZURE DATA ENGINEER,CapB InfoteK,"Des Moines, IA",$83K - $119K (Glassdoor est.),-1.0,"CapB is a global leader on IT Solutions and Managed Services. Our R&D is focused on providing cutting edge products and solutions across Digital Transformations from Cloud, AI/ML, IOT, Blockchain to MDM/PIM, Supply chain, ERP, CRM, HRMS and Integration solutions. For our growing needs we need consultants who can work with us on salaried or contract basis. We provide industry standard benefits, and an environment for LEARNING & Growth.

For one of our going on project we are looking for an AZURE DATA ENGINEER. The position is based out of Des Moines, IA. Locals preferred but can be done remotely for the time being this year.

Responsibilities:

Create functional design specifications, Azure reference architectures, and assist with other project deliverables as needed.
Design and Develop Platform as a Service (PaaS) Solutions using different Azure Services
Create a data factory, orchestrate data processing activities in a data-driven workflow, monitor and manage the data factory, move, transform and analyze data
Design complex enterprise Data solutions that utilize Azure Data Factory Create migration plans to move legacy SSIS packages into Azure Data Factory
Build conceptual and logical data models
Design and implement big data real-time and batch processing solutions
Design, build, and scale data pipelines across a variety of source systems and streams (internal, third-party, as well as cloud-based), distributed / elastic environments, and downstream applications and/or self-service solutions.
Develop and document mechanisms for deployment, monitoring and maintenance
Skills and Experience:

Bachelor's degree or higher in Computer Science Engineering/ Information Technology, Information Systems
3+ years experience with Microsoft Cloud Data Platform: Azure Data Factory, Azure Databricks, Python, Scala, Spark SQL, SQL Data Warehouse
3+ years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL, data lake solutions
Expertise with SQL, database design/structures, ETL/ELT design patterns, and DataMart structures (star, snowflake schemas, etc.)
Functional knowledge of programming scripting and data science languages such as JavaScript, PowerShell, Python, Bash, SQL, .NET, Java, PHP, Ruby, PERL, C++, R, etc.
Creation of descriptive, predictive and prescriptive analytics solutions using Azure Stream Analytics, Azure Analysis Services, Data Lake Analytics, HDInsight, HDP, Spark, Databricks, MapReduce, Pig, Hive, Tez, SSAS, Watson Analytics, SPSSA
Experience in Azure Data Factory (ADF) creating multiple pipelines and activities using Azure for full and incremental data loads into Azure Data Lake Store and Azure SQL DW
Experience for Azure Data Lake Storage and working with Parquet files and partitions
Experience managing Microsoft Azure environments with VM's, VNETS, Subnets, NSG's, Resource Groups, etc.
Experience in Creation & Configuration of Azure Resources & RBAC
Experience with Git/Azure DevOps
Azure certification would be desired
Must have an ability to communicate clearly and be a team player",-1,Business Consulting,Unknown / Non-Applicable,Management & Consulting,Unknown,Company - Private,True
Hybrid Work - Need Senior Data Platform Engineer-Azure in Des Moines IA,Steneral Consulting,"Des Moines, IA",$82K - $119K (Glassdoor est.),-1.0,"Senior Data Platform Engineer-Azure

Des Moines, IA - Hybrid 3 days a week - locals are highly preferred but will consider someone from Midwest who will relocate from day one to work onsite.

Communication and collaboration are key. They must be easily understood and able to speak well to their projects and technical experience.

Must have valid LinkedIn and Photo ID required with submission

Must Have's: Must have everything or please do not send them to me.

Azure Microsoft Fabric - end to end lifecycle. Azure Azure SQL Database: Provisioning, performance tuning, scaling, and security. Azure Cosmos DB: Understanding of NoSQL databases, partitioning, consistency models. Azure Data Factory: Data integration and ETL processes. Azure Blob Storage and Data Lake Storage: Management, performance, security, and data lifecycle. Azure Stream Analytics: Real-time data streaming and analytics. Azure Databricks & HDInsight: Big data analytics solutions. (lower priority) Azure Synapse Analytics: Knowledge of data warehousing, data integration, and analytics.
SQL: Writing, optimizing, and debugging SQL queries. Data modeling: Normalization, star schema, snowflake schema Familiarity with SDKs and APIs associated with Azure data services. Integration with other Azure services or third-party applications. Experience in one or more programming languages like C#, Python, or Java can be beneficial. Azure Monitor, Azure Log Analytics, and Application Insights. DP-203 certification Financial/Investment industry experience.

Job Description:
Here are the skills sets for building out the Microsoft Azure Data Platform.

Azure Fundamentals:
Understanding of Azure subscriptions, resources, and resource groups. Familiarity with Azure regions, availability zones, and the Azure portal.
Azure Data Services Knowledge of tool set: Azure Microsoft Fabric
- end to end lifecycle. Azure Azure SQL Database: Provisioning, performance tuning, scaling, and security. Azure Cosmos DB: Understanding of NoSQL databases, partitioning, consistency models. Azure Data Factory: Data integration and ETL processes. Azure Blob Storage and Data Lake Storage: Management, performance, security, and data lifecycle. Azure Stream Analytics: Real-time data streaming and analytics. Azure Databricks & HDInsight: Big data analytics solutions. (lower priority) Azure Synapse Analytics: Knowledge of data warehousing, data integration, and analytics.
Skills:
SQL: Writing, optimizing, and debugging SQL queries. Data modeling: Normalization, star schema, snowflake schema Familiarity with SDKs and APIs associated with Azure data services. Integration with other Azure services or third-party applications. Experience in one or more programming languages like C#, Python, or Java can be beneficial. Azure Monitor, Azure Log Analytics, and Application Insights. DP-203 certification
Optional but helpful:
Azure Active Directory and role-based access control (RBAC) Tools like Azure Data Migration Service, SSIS (SQL Server Integration Services). Strategies for migrating data from on-premises or other clouds to Azure.",-1,-1,Unknown / Non-Applicable,-1,51 to 200 Employees,Company - Private,False
"Experienced Software Engineer, Enterprise Data and Applications","Principal Financial Group
","Des Moines, IA",$77K - $182K (Employer est.),4.0,"What You'll Do:
We're looking for a Software Engineer to join our Enterprise Data and Analytics (EDA) team. In this role, you’ll join a group of engineers in our data space focusing on our Master Data Management platform. Here in EDA, we are at the intersection of many strategic and digital initiatives that impact the enterprise! This provides a unique opportunity to provide highly valuable and critically important solutions to Principal as an enterprise while gaining exposure to cross functional engineers and teams.

If you like working with data and understanding how data flows through our various systems, then this is just the team for you. If you don't know the specific tools that we use, that's fine as we are happy to mentor and train someone who knows a thing or two about object-oriented development and has an innate curiosity and eagerness to learn and grow. As a software engineer in our data space, you'll be performing many functions, but not limited to eliciting requirements, developing software and integrating data for new vendor based and in-house systems, and providing operational support.

You'll have the opportunity to:
Embrace a Product Mentality by focusing on outcomes over outputs, pursue fast feedback loops, and deliver solutions iteratively with low risk and low cost
Grow our DevOps approach and culture by continuously maturing and optimizing our SDLC through automation and safe/frequent delivery
Engage in all facets of software engineering from understanding the problem, evaluating designs, creating the solution, validating the outcome, etc.
Understand and continue driving our journey to a cloud-first technology community
Appreciate and promote Cloud Engineering – AWS PaaS, cloud integration patterns, cloud security, cloud operations, etc.
Network and communicate with cross-functional teams and collaborate with both IT and non-IT partners
Learn new technology and continuously grow through creative solutioning
Operating at the intersection of financial services and technology, Principal builds financial tools that help our customers live better lives. We take pride in being a purpose-led firm, motivated by our mission to make financial security accessible to all. Our mission, integrity, and customer focus have made us a trusted leader for more than 140 years.

As Principal continues to modernize its systems, this role will offer you an exciting opportunity to build solutions that will directly impact our long-term strategy and tech stack, all while ensuring that our products are robust, scalable, and secure!
Who You Are:
Associate's or bachelor's degree (preference in a computer science, technology, engineering or math-related field) or equivalent work experience
3+ years of engineering experience in modern object oriented technologies
Experience/exposure to data and/or data technologies (more specifically, how that data moves from system to system)
Strong motivation for continuous learning, mentoring, problem solving, analytical thinking, and helping others grow along with you
Passion for working in a highly collaborative environment to solve problems and deliver customer value
Rotational on-call support is required
Skills That Will Help You Stand Out
Cloud technologies (AWS)
Enterprise level environment experience
Experience with the following technologies and tools
Programming (preference Java)
Master Data Management (Informatica)
ETL (PowerCenter)
Data engineering (data management, data transformation, data modeling, SQL, data lake, data warehousing)
DevOps practices (TDD, CI/CD, etc.)
Salary Range Information: Salary ranges below reflect targeted base salaries. Non-sales positions have the opportunity to participate in a bonus program. Sales positions are eligible for sales incentives, and in some instances a bonus plan, whereby total compensation may far exceed base salary depending on individual performance. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Salary Range: $77350 - $182400 / year Additional Information:
Our Engineering Culture
Through our product-driven Agile/Lean DevOps environment, we’ve fostered a culture of innovation and experimentation across our development teams. As a customer-focused organization, we work closely with our end users and product owners to understand and rapidly respond to emerging business needs.

Collaboration is embedded into everything we do – from the products we develop to the quality service we provide. We’re driven by the belief that diversity of thought, background, and perspective is critical to creating the best products and experiences for our customers.

Job level
We’ll consider talent at the next levels with the right experiences and skills.
Hours
This team has Tuesday-Thursday meetings starting at 7:30am CST.
Work Environments
This role offers in-office, hybrid (blending at least three office days in a typical workweek), and remote work arrangements (only if residing more than 30 miles from Des Moines, IA, or Charlotte, NC). You’ll work with your leader to figure out which option may align best based on several factors.
Work Authorization/Sponsorship
At this time, we're not considering applicants that need any type of immigration sponsorship (additional work authorization or permanent work authorization) now or in the future to work in the United States. This includes, but IS NOT LIMITED TO: F1-OPT, F1-CPT, H-1B, TN, L-1, J-1, etc. For additional information around work authorization needs please use the following links.

Nonimmigrant Workers and Green Card for Employment-Based Immigrants
Investment Code of Ethics
For Principal Asset Management positions, you’ll need to follow an Investment Code of Ethics related to personal and business conduct as well as personal trading activities for you and members of your household. These same requirements may also apply to other positions across the organization.
Experience Principal
At Principal, we value connecting on both a personal and professional level. Together, we’re imagining a more purpose-led future for financial services – and that starts with you. Our success depends on the unique experiences, backgrounds, and talents of our employees. And we support our employees the same way we support our customers: with comprehensive, competitive benefit offerings crafted to protect their physical, financial, and social well-being. Check out our careers site to learn more about our purpose, values and benefits.
Principal is an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.
Posting Window: We will be accepting applications for at least 3 days from when the job was originally posted, after which we may keep open or remove the posting based upon applications we receive. Please submit applications in a timely manner as there is no guarantee the posting will be available beyond 3 days of the original posting date. Date First Posted (TTF): 11/20/2023

LinkedIn Remote Hashtag

: #LI-Remote

LinkedIn Hashtag

: #LI-EW1",1879,Investment & Asset Management,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
Data Scientist and Algorithm Engineer,College Raptor,"Coralville, IA",$85K - $131K (Glassdoor est.),-1.0,"Overview

Company Name
:
College Raptor
Location
:
Coralville, IA
Type
:
Full Time




We have a career opportunity for a Data Scientist who will focuses on the design, analysis, implementation and optimization of computer algorithms.



What you'll be doing

You will bridge the gap between algorithm theory and application engineering by writing code usable in the College Raptor applications. We're about to launch new products and need a self-starter who can architect machine learning models and design platforms that give College Raptor competitive advantages in the marketplace. You'll need to develop a data processing pipeline that will provide Product and Marketing teams real-time visibility into College Raptor member usage as they interact with the services.



What you'll need

7+ years of engineering experience using C# and .NET Framework.




4+ years of data analysis using R, Matlab, Julia, or Python (NumPy, SciPy, pandas, and scikit-learn).




Ability to write code and implement algorithms in the College Raptor applications.




A data wrangler, unintimidated by petabytes, who can move data from any datastore or API and transform it into a ROC curve, chart or other human-readable or format.




Experience with SQL, Hadoop and environments such as Kafka, Spark or Storm.




A fearless action-oriented attitude that allows you to solve undefined problems independently or on a team, including remote office colleagues.




MS or PhD in Computer Science or related field.




Great to have

Any experience shipping product in the Education vertical.




How to apply

Please send a resume and a cover letter explaining why you are a great match for this role to careers@CollegeRaptor.com. Please include URLs to relevant writing, design or video samples.



Job Segment

Computer Engineering, Software Development, Mobile Engineering, Product Development



About College Raptor

College Raptor is a technology company working to make higher education more affordable and accessible for every student. We're building next-generation college search and planning tools that help students and families make smarter decisions, save money and be more successful in their college careers.




We also partner with colleges and universities to provide data and tools that help them be more strategic, effective and efficient in their recruitment and financial aid.




We offer a fast-paced environment working alongside a cross-functional team of product, technology and marketing minds to solve complex problems and simplify the experience for users and clients. We offer competitive salaries based on experience and a full suite of employee benefits including health insurance, life insurance, and a 401(k) retirement plan with a company match.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,False
Sr Data Engineer,"Pella Corporation
","Pella, IA",$90K - $125K (Glassdoor est.),3.6,"JOB SUMMARY:
This role will be embedded on a cross-functional product Agile scrum team as the primary data engineer. Work with Data Architect(s) and other DAI personnel and takes the lead to develop and maintain data flows, data workflows and other code/logic to gather, create and deliver high quality reliable data to meet the needs of Pella’s business. These efforts will support Pella’s analytics and transactional needs. Additionally, this position will support Pella’s Data Enablement Technologies and Data Users with on-call responsibilities, direct end-user tickets and addressing performance or quality issues.
ESSENTIAL RESPONSIBILITIES:
Design and develop data pipelines to manage how data flows between disparate systems
Build data pipelines to feed analytics use cases, KPI or enterprise apps.
Develop data quality metrics and performs QC tests (system and visual) to verify data integrity.
Interface with architects, product managers/SMEs and product analysts to understand data needs and support the implementation of the business rules into transformation.
Document the data blending process along with the specifications and workflow/data lineage.
Perform continuous integration to ensure that every step of the pipeline is testable and automated
Lead cloud data migration, transformation and modeling projects, developing project plans and communicating project status through Agile process and in Jira for the cross-functional team
Collaborate with the business to understand backlog and refine use cases related to data management, BI reporting and data science deliverables. Research source system data, architecture and transactions.
Takes lead to perform detailed design (the Physical Data Model and transformations), based on understanding of the Logical Data Model (the business requirements)
Create design documents for data integration or data reporting projects
Develop new and improve existing processes to ensure service levels are being met
Support development of new or modify existing analytical reports
Analyze data integration problems, provide solutions and recommend corrective actions.
Analyze source system data structures and map them to target data warehouse schemas.
Must have excellent skills in requirements analysis, logical/physical modeling, data transformation and data modeling and technical governance design concepts.
Serve as a technical expert to data warehouse project teams and key business individuals for support of applications, tools, data integration, and ad-hoc analytics.
Participate in design and code reviews, documentation of design, and implementation of methodologies to ensure high quality deployments
Analyze application and data integration problems, provide solutions and recommend corrective actions.
#LI-NK1
EDUCATION/EXPERIENCE
BS degree in Computer Science, Data Engineering, Software Engineering, or a related field. MBA beneficial.
5+ years' experience in data engineering / software development
QUALIFICATIONS:
Technical / functional skills (includes computer skills):
Expertise in Azure cloud technologies specifically Synapse, ADF, Delta Lake, Databricks or comparable technology experience within AWS, Snowflake and/or GCP
Experience working with architectural fabric of Salesforce or comparable CRM applications
Understanding of architecture of Data Quality, Metadata Management and Master Data Management
Understanding of Data Governance and Data Stewardship concepts
Understanding of dimensional data modeling and design as well as data population techniques for target structures such as Star Schemas.
Skilled in Python, SPARK and SQL to build production-grade data pipelines and tools
Experience navigating a modern data environment and working between on-prem & cloud technologies
Knowledge of the data science process and understanding of/experience with Data Engineering support for Data Science
Strong grasp of CI/CD operating practices
Experience operating within a Product Scrum Agile team
Experience with MS Office, Outlook, Jira
Leadership Skills: Strong communication and collaboration skills, good project management methodology
Certifications or licenses: None
Travel Expected: 5-10% of time",1925,Consumer Product Manufacturing,Unknown / Non-Applicable,Manufacturing,5001 to 10000 Employees,Company - Private,False
Java/AWS Cloud Data Engineers on W2,Amplify Systems,"Cedar Rapids, IA",$82K - $112K (Glassdoor est.),-1.0,"Type: Contract Duration: 06 to 18 Months Rate: DOE

Company Overview:

Amplify Systems has its business focus in providing IT consulting services, resource augmentation services and packaged product implementation services. Amplify Systems’ industry experience and technology expertise helps in delivering world class business and technology services to our clients. Our experience and deep technical knowledge enable the clients to exploit information technology to meet their business goals. We believe in simplified development processes, optimal tool selection and quality recruitment to harness value from intellectual resources.

Job Description:
Deep skills in designing and developing Cloud Native applications using JAVA, Microservices and Amazon Web Service Cloud Computing Products.Data Dictionary, Interface Mapping, Staging/Transformation, ETL Experience.


Experience on Cloud Databases: AWS RDS/Aurora, Dynamo DB, Redshift.Building data lake on AWS using S3 for storage and Glue/EMR for compute .


Experience implementing server less Big data pipelines using AWS lambda, AWS Glue, AWS Kinesis.


Experience implementing Big Data architecture in DevOps - Continuous IntegrationContinuous Delivery (CICD) Mindset.


Experience with cloud automation tools like Cloud formation templates, Terraform.Strong development experience in at-least 2 of the languages – Java, Python, Scala, JavaScript.


Working experience with TCS Bancs is a huge PLUS




For more information on how Amplify Systems can assist in your Job Search, please call (603) 791- 4428 or Email: hr@amplifysystems.com or visit www.amplifysystems.com",-1,Information Technology Support Services,Less than $1 million (USD),Information Technology,1 to 50 Employees,Company - Public,False
"Lead Software Engineer, Data Engineering","S&P Global
","Carlisle, IA",$85K - $170K (Employer est.),4.1,"The Role: Data Engineer
Location: Team is in Boston, but is available for remote or on-site throughout CST and EST Time zones
GL (for internal use only): 11

Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.
Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy!
Job Description
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.

You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets.
You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use.
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.

Responsibilities
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers
Optimizing slow-running database queries and data pipelines
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency

Qualifications
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience
7+ years of experience working with data-at-scale in a production environment
Experience designing and implementing large-scale, distributed systems
Experience in multi-threaded software development (or some form of parallelism)
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale
Strong understanding of relational databases and proficiency with SQL
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript)
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go)
Experience developing software on Linux-based operating systems
Experience with distributed version control systems
Nice-to-Haves
Familiarity with relational database internals (especially PostgreSQL)
Proficiency with cloud computing platforms, specifically AWS
Working knowledge of probability & statistics
Contributions to open-source software
Experience building customer-centric products

Compensation/Benefits Information (US Applicants Only):
S&P Global states that the anticipated base salary range for this position is $85,300 - $170,000 . Base salary ranges may vary by geographic location.
In addition to base compensation, this role is eligible for an annual incentive bonus plan.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires .
About S&P Global
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 277527
Posted On: 2023-09-21
Location: Cambridge, Massachusetts, United States",1860,Research & Development,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Senior Software Engineer – API & Data Integration,"Object Partners
","Des Moines, IA",$101K - $136K (Glassdoor est.),4.4,"Variety of consulting; new technologies, projects, and people on a regular basis.
Stability; we’ve been around since 1996 and have a diverse mix of clients and technologies to keep us busy, very busy. And we keep a bench. If you’re not on a project, you’re writing software for our internal business functions or you’re learning new technologies. It’s beneficial to make our consultants as marketable as possible. That’s good for your career.
No politics or management; we don’t get in the way. Why sit in meetings all day when you can code and be productive?
Awesome benefits; robust healthcare plan, 28 days of PTO, semi-annual profit sharing bonuses, you get paid OT, company trips, various quarterly company events, new MacBook Pro’s, free beer/soda, chips, candy, and so much more.
You work with the best. Do an Object Partners search on LinkedIn and see the types of talent we hire. You truly get to work with intelligent, passionate engineers that share the same goal of building great software the right way.
Low company overhead. It all means more money back into our consultants pockets (profit sharing) or company trips and events to share in the financial success.
Qualifications
You are passionate about the software development process and solving big problems. You dive in regardless of the tools, tech, team, and business at hand.

Experience designing and implementing highly available/scalable backend services
Enjoy developing clean, testable code
Proficient in deploying, monitoring, and maintaining said code
Actively share knowledge across the team
Can discuss one or more projects that utilize technologies from the following categories:
Language: Java, Kotlin, Groovy, Golang, Python, C#, etc.
Automated Testing: Spock, JUnit, go testing package, Geb, etc.
Frameworks: Spring Boot, Micronaut, Quarkus, .NET, etc.
Reactive Libraries: RxJava, Ratpack, Reactor, Akka, Vert.x, etc.
Data:
Relational: MySQL, Postgres, Oracle, etc.
NoSQL: Cassandra, DynamoDB, MongoDB, Elastic, etc.
Platform:
Environment: AWS, Azure, GCP, Containerized On-Prem
CI/CD: Jenkins, Gitlab, CircleCI, AWS CodePipeline, etc.
Observability: Log Aggregation, Metrics, Tracing, etc.
Alerting on the observability data
Dashboarding the observability data

A consultant does not know everything, but they should have the motivation and means to learn anything. The best consultant isn’t the most technical (although that sure helps), but someone who will do whatever it takes to see a client succeed, no matter what gets thrown at them.",1996,Business Consulting,$5 to $25 million (USD),Management & Consulting,51 to 200 Employees,Company - Private,False
Data Operations Engineer,"Global Atlantic Financial Group Opportunities
","Des Moines, IA",$65K - $125K (Employer est.),4.0,"All offices are currently open, and our employees are back 4 or 5 days a week in Hudson Yards, NY and 3 days a week in all other offices. If you have questions on this policy or the application process, please contact recruiting@gafg.com.

COMPANY OVERVIEW

Global Atlantic Financial Group is a leader in the U.S. life insurance and annuity industry, serving the needs of individuals and institutions. Global Atlantic is a majority-owned subsidiary of KKR, a leading global investment firm that offers alternative asset management across multiple strategies and capital markets solutions.

Global Atlantic is looking for a diverse team of talented individuals who reinforce our culture of collaboration and innovation. We are dedicated to the career development of our people because we know they are critical to our long-term success. Join our team and come grow with us.

We use Greenhouse as our scheduling tool and communicate through their systems. At times, your email may block our communications. Please be sure to check your SPAM so that you do not miss critical information about our process, including scheduling.

Job Summary:

In this role, you will be responsible for expanding and evolving the cloud-based enterprise data platform. You will ensure the technology components of the platform are correctly configured and optimized to meet the functional, non-functional, and operational requirements. This role requires a highly motivated individual with strong technical ability, data capability, excellent communication and collaboration skills including the ability to develop and troubleshoot a diverse range of problems. Support end-to-end ML workflow pipeline. The candidate must be self-directed with the ability to own and execute the platform improvement activities while collaborating with other team members and stakeholders.

Be willing to work non-standard business hours on an on-call basis in a 24x7 environment few days a month.

This role must sit in New York City, Boston or Des Moines.

Responsibilities:

Triage problems across the data platform to help address development, test, and production issues.
Assist in evaluating the reliability, accuracy, and cost-effectiveness of machine learning models and work with Business IT Teams to identify areas of improvement
Testing Data pipelines at staging/QA environments and help deploying them at production.
Work with business, product and technical stakeholders on data or report issues.
Create and manage Incident and Change Requests as needed for data pipelines.
Assist with data architecture, pipeline development, automation and planning
Develop and maintain documentation, departmental technical procedures, and user guides
Maintain best practices to facilitate optimized software development and continuous improvement/continuous delivery (CI/CD)

Qualifications:

Degree in computer science, engineering, or a related discipline preferred.
Must have 4-5 years of software development experience or must demonstrate significant experience of applying software engineering best practices (system design for scale, modularity, version control, unit testing, documentation etc.) on real-world projects
2+ MLOps experience automating processes, using data to make better decisions, using software to make processes more efficient, improving the quality of the product or service.
2+ years of Tableau or similar BI dashboards build debugging.
Ability to code in multiple languages (Python and SQL; R, Java, or others as well)
Strong foundation in the AWS Cloud Services: S3, Redshift Spectrum, EC2
Solid understanding and experience working with Gitlab, JIRA and Confluence

Various jurisdictions have passed pay transparency laws that require companies provide salary ranges for any positions for which they are accepting applications. Global Atlantic has offices in Atlanta, Batesville, Bermuda, Berwyn, Boston, Des Moines, Hartford, Indianapolis, and New York City. The base salary range posted below is inclusive of the lowest cost of living geography to the highest in which we have a Global Atlantic office.

Global Atlantic's base salary range is determined through an analysis of similar positions in the external labor market. Base pay is just one component of Global Atlantic's total compensation package for employees and at times we hire outside the boundaries of the salary range. Other rewards may include annual cash bonuses, long-term incentives (equity), generous benefits (including immediate vesting on employee contributions to a 401(k)), as well as a company match on your contributions), and sales incentives. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Compensation for our more senior positions have a larger component of short-term cash bonus and long-term incentives. The base salary range for this role is $65,000 to $125,000

#LI-AO1

#LI-Hybrid


TOTAL REWARDS STATEMENT

Global Atlantic's total rewards package is reflective of our corporate values, particularly diversity, excellence and innovation, with a focus on inclusion, pay equity, and flexibility. We are proud to support your personal and professional growth and well-being through programs such as educational assistance, virtual physical therapy, remote/onsite fitness reimbursement, a medical second opinion program, pet insurance, military leave, parental leave, adoption assistance, fertility and family planning coverage. We strive to foster a culture of total well-being through community outreach and charitable giving programs.

We are active in our communities:

New York: Red Hook Conservancy, Girls Who Invest, Outward Bound, Teach for America, StreetWise Partners,
Boston: Catie's Closet, Project Bread, Thompson Island Outward Bound Education Center, Cradles to Crayons, and many others
Hartford: Braids and Company, Junior Achievement
Indianapolis: Elevate Indianapolis, Gleaners Food Bank and the Juvenile Diabetes Research Foundation
Batesville: So Loved Ripley County Foster Closet, Southeastern Indiana YMCA, Batesville Community Education Foundation, Southeastern Indiana Voices for Children, local area youth sports, as well as many others
Des Moines: United Way of Central Iowa, Meals from the Heartland, Oakridge Neighborhood, Community Support Advocates, and many others
Wayne: For Pete's Sake, Chester County Food Bank, Habitat for Humanity Chester County, Brandywine SPCA, as well as others
Bermuda: Transformational Living Centre for Families

Social platforms provide an environment to collaborate with others and participate in friendly competitions towards achieving physical, emotional and financial well-being. Our highly competitive health, retirement, life and disability plans can be tailored to best suit your needs and those of your whole family.

Global Atlantic is committed to creating an inclusive environment where everyone can meaningfully contribute to our success. We are proud to be an equal opportunity employer and we do not discriminate in employment on any basis that is prohibited by federal, state or local laws. More than that, we strive to be inclusive of all backgrounds and experiences, which we feel gives us a competitive advantage in the market and within our firm. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status.

Employees who require an accommodation to perform the essential functions of their job will participate in an interactive process which may include providing documentation. If you are hired and require an accommodation for any protected status, please email benefits@gafg.com.

Please click on the below links to learn more about Global Atlantic.

Global Atlantic Privacy Statement",2004,Insurance Carriers,Unknown / Non-Applicable,Insurance,1001 to 5000 Employees,Company - Private,False
Data Engineer/Sr. Data Engineer (Remote) - EVOLVE Intelligence,"DNV
","Des Moines, IA",$105K - $150K (Employer est.),4.0,"Local Unit & Position Description

EVOLVE Intelligence accelerates the transition towards a carbon-free future through software and analytics.We are looking for a Data Engineer/Sr. Data Engineer to help us accomplish this mission.The Analytics & Data Science team in DNV Energy Management s Technology group is a remote-first team. We offer more than just a job; we provide a community where you can learn, grow, and thrive your way. Join a dynamic and diverse technology team that values relationships and the environment as much as results. Help us create software that empowers utility clean energy customers to combat climate change!

This is a remote position open to any location in the continental United States.

What You ll DoAs a Data Engineer/Sr. Data Engineer, you will design, develop, and maintain data architecture, pipelines, and systems that play a vital role in how our utility partners steward clean energy programs. Your impact will be immediate and will directly enable pathways to decarbonization through energy efficiency, demand response, storage, electric vehicles, and renewable energy technologies. You will solve a variety of problems that leverage your deep understanding of data engineering principles.How You ll Succeed

Collaborate with cross-functional teams, including machine learning engineers, software developers, analytics engineers, and product managers to translate business requirements into highly available data solutions
Leverage your creative problem-solving skills to architect, develop, and maintain scalable and efficient data processing pipelines using PySpark and other distributed computing technologies
Create and optimize data models that support reporting, analytics, artificial intelligence, and software
Optimize data storage and retrieval by designing and implementing efficient storage systems that use technologies such as Timescale and Apache Spark
Apply data validation, data profiling, and data cleansing to ensure data quality and integrity
Write clean, efficient, maintainable code, and actively engage with team members in code reviews
Create and maintain technical documentation covering data models, flows, views, dictionaries, and mapping schemes
Serve as a mentor and resource to other members of the team
Position Qualifications

What is Required

An undergraduate or advanced degree in a quantitative field
Proven professional experience as a Data Engineer
Strong proficiency in SQL, Python, and Spark/PySpark
Hands on experience with distributed computing frameworks such as Apache Spark
Familiarity with working in Azure experience with Data Factory is strongly desired
Experience with version control systems (e.g., Git) and familiarity with agile development practices
Excellent communication and teamwork skills, with the ability to effectively collaborate with cross-functional teams
Experience working on an agile product team is a bonus
Someone who is eager to learn new things and is coachable
Most importantly, this team member should display a positive, team-oriented attitude to match our friendly and enthusiastic work environment
Willingness and the ability to undergo a background investigation and drug screening
Excellent written and verbal English communication skills
We conduct pre-employment drug and background screening

*Immigration-related employment benefits, for example visa sponsorship, are not available for this position*

What We Offer

Generous paid time off (vacation, sick days, company holidays, personal days)
Multiple Medical and Dental benefit plans to choose from, Vision benefits
Spending accounts FSA, Dependent Care, Commuter Benefits, company-seeded HSA
Special programs Employee Assistance Program, ID theft protection, and accident and critical illness options for you and your family
Employer-paid, therapist-led, virtual care services through Talkspace
Company provided life insurance, short-term, and long-term disability benefits
Tuition assistance
Flexible work schedule with hybrid/remote opportunities
Advancement opportunities

**Benefits may vary based on position, tenure, location, and employee election

How We Do ItWe Care, We Dare, We ShareDNV is a proud equal opportunity employer committed to building an inclusive and diverse workforce. All employment is decided on the basis of qualifications, merit or business need, without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.DNV is committed to ensuring equal employment opportunity, including providing reasonable accommodations to individuals with a disability. US applicants with a physical or mental disability who require a reasonable accommodation for any part of the application or hiring process may contact the North America Recruitment department (hrrecruitment.northamerica@dnv.com). Information received relating to accommodations will be addressed confidentially.DNV is proud to announce being named one of Houston s best places to work in the 2022 Houston Business Journal Best Places to Work competition.For more informationhttps://www.eeoc.gov/know-your-rights-workplace-discrimination-illegal-posterRead more here

Diversity at DNV

Meet our Employees

About DNV

Careers in DNV

As required by the Colorado Equal Pay Transparency Act and New York City Salary Transparency Law, DNV provides a reasonable range of compensation for roles that may be hired in Colorado or New York City. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado and New York City, NY only, the range of starting yearly salary for this role is $105,000.00- $150,000.00.

Please visit our website at www.dnv.com

Company & Business Area Description

DNV is the independent expert in assurance and risk management, operating in more than 100 countries. Through our broad experience and deep expertise, we advance safety and sustainable performance, set industry benchmarks, and inspire and invent solutions. We provide assurance to the entire energy value chain through our advisory, monitoring, verification, and certification services. As the world's leading resource of independent energy experts and technical advisors, we help industries and governments to navigate the many complexes, interrelated transitions taking place globally and regionally, in the energy industry. We are committed to realizing the goals of the Paris Agreement and support all stakeholders to transition faster to a deeply decarbonized energy system.


Requisition #cln28d7yt000908mk8ioh3rb7",1864,Energy & Utilities,$1 to $5 billion (USD),"Energy, Mining & Utilities",10000+ Employees,Company - Private,False
Commissioning Project Engineer Data Center Construction (Traveling),"The Weitz Company / Contrack Watts, Inc.
","Des Moines, IA",$60K - $79K (Glassdoor est.),4.3,"Our Company views employees as our most valuable asset, and the key to our success. We are committed to growing a diverse and inclusive culture that inspires, motivates, and continuously improves. Community involvement, employee empowerment, and strong relationships makes The Weitz Company a great place to work.


The Weitz Company is currently accepting applications for an outstanding Commissioning Project Engineer to join our Mission Critical business unit building data centers!




The Project Engineer is responsible for several functions throughout the duration of assigned projects including planning, buyout, management and closeout. This role actively assists the project team in monitoring project status and identifying issues that may impact the project schedule and/or budget. The Project Engineer typically reports to the Project Manager.


What You'll Do:

Organize, review, update, maintain and post construction documents and drawings
Collaborate with project team to complete requests for information (RFI)
Review submittals and other project documents for accuracy against plans and specifications
Assist in preparing inspections, compliance audits and the non-conformance log
Monitor material and equipment delivery status
Maintain and distribute accurate project logs (i.e. buyouts, subcontractor material status reports, submittals, RFIs)
Understand scopes of work to be included in subcontracts and/or purchase order agreements
Track subcontractor requests for change; solicit pricing and draft change orders within delegated authority
Understand and assist with project schedule management
Attend regular project meetings; record and distribute meeting minutes
Obtain closeout information; gather punch list items; prepare as-built drawings; assist with warranty process
Perform other duties as assigned



What We're Looking For:




To perform the job successfully, an individual must be able to perform each previously stated duty satisfactorily. The requirements listed below are representative of the knowledge, skills, and ability necessary to succeed in the role.

Education: Industry related college degree is required.
Experience: A minimum of two (2) years of project engineering experience is required. Previous construction internship experience is preferred.
Skills: Good engineering and construction management skills are important. Individual must have good communication skills and the ability to communicate effectively with the owner, architect, and The Weitz Company project team. A high level of integrity is required. Good time management and project organization skills are essential. Microsoft Office proficiency is important.
Systems: Must be proficient in basic computer software programs such as Microsoft Office products (Outlook, Work, PowerPoint, Excel), and must be able to learn project management software (JDE, Procore, Asta, Bluebeam, etc.).



What We Offer:

Competitive Pay
Rewarding Bonus Program
Comprehensive Benefits Package with Tax-Advantaged HSA and FSA offerings
Employer-Paid Short- and Long-Term Disability Programs
Employer-Paid Life Insurance
Generous Paid Time Off Provisions
401K Retirement Savings Plan with Company Match
Tuition Reimbursement
Fully Paid Parental Leave
Voluntary Products including Critical Illness Insurance and Accident Insurance
Corporate Wellness Program with Wellness Time Off and Rewards


Visa sponsorship is not available for this position at this time.




The Company is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment (minorities, females, veterans, individuals with disabilities, sexual orientation, gender identity, or other protected categories in accordance with state and federal laws). The Company is a drug and alcohol-free workplace and background checks are required if applicable. Click here to review our Privacy Notice.


#LI-AH1",1855,Construction,$1 to $5 billion (USD),"Construction, Repair & Maintenance Services",1001 to 5000 Employees,Company - Private,True
"Mechanical Commissioning Engineer II, Data Center Services","CAI
","Des Moines, IA",$90K - $115K (Employer est.),4.1,"CAI seeks Mechanical Commissioning Engineers with a minimum of two years' experience in Data Center Commissioning to support development and execution of all mechanical aspects of commissioning projects.

Position Description:
This position supports development and execution of all mechanical aspects of assigned commissioning projects from initial engagement, design reviews, checklists, safety support, script development, vendor coordination, testing and report development through turn over to the client. The Mechanical Commissioning Engineer will support the development of the mechanical test schedule, finalize mechanical test procedures, review project submittals for consistency with the design intent, basis of design and the owner’s project requirements, and maintain project cadence for the mechanical systems testing and associated Building Automation Systems. The Mechanical Commissioning Engineer is to support the planning and execution of commissioning for the mechanical infrastructure of the mission critical facility. They will be expected to execute against the project schedule through the coordination of contractors and/or vendors to complete the desired mechanical systems testing.
CAI DC Mechanical Commissioning Engineer will be exposed to cutting edge technologies in the Hyperscale and other spaces. You will have an opportunity to work with recognized subject matter experts allowing YOU to be a key player in bringing data technologies to market. As part of our company culture, we invest in YOUR future, and commit to hands on certifications as well as professional training. Our collaborative culture ensures that our customers benefit from exemplary work across our entire range of professional services.

Responsibilities:
Support and contribute to all aspects of safety for all mechanical tests.
Support complete commissioning and performance acceptance testing of the mechanical infrastructure systems.
Development of all mechanical test procedures, MOPS, SOO’s and checklists.
QA/QC of all mechanical test procedures.
Provide input and insight to the overall commissioning plan.
Develop reports for the mechanical testing and contribute to a daily report to the Commissioning Project Manager.
Attend and be an active participant of customer equipment Factory Witness Test
Assist with vendor coordination and management.
Perform equipment inspection to ensure build adherence to vendor submittal.
Provide test documentation that equipment is delivered, installed, and tested correctly and set to function properly for the customer.
Support and perform design specification review, manufacturer submittals, one line drawing sets, and project schedule documentation.
QA/QC of mechanical equipment installation\startup
Execute test scripts to confirm equipment and system operation to design specification.
Ensure safe work practices are followed by the commissioning team and customer site.
Engage with customers and vendors to ensure positive experience, goals achievement, and schedule adherence.
Provide daily status reports for mechanical commissioning team status.
Conduct facility walk downs, turnover, and punch list reviews.
General understanding of LEED specifications and requirements.
Look for new opportunities for CAI to provide service and value to customer.
Duties may be increased as experience and skill allow.

Requirements include:
Position Requirements:
Bachelor’s degree or equivalent experience
Minimum of 2 years Data Center Commissioning experience.
Knowledge of OSHA safety requirements.
Good written and verbal communication skills.
Ability to read and interpret mechanical drawings, P&ID’s and specifications.
Knowledge of mission critical design concepts.
Knowledge of various Building Automation/Monitoring Systems (BAS/BMS), Air Handlers, Humidifiers, Variable Refrigerant Flow, Computer Room Air Conditioners/Handlers (CRAC/CRAH), Evaporators, Adiabatic Coolers, Pressure/Temperature/Humidity sensors & Flowmeters.
Knowledge of basic thermodynamics and heat transfer and fluid flow.
Knowledge of the Test, Adjust and Balance (TAB) process.
Knowledge of mechanical trend analysis.
Strong experience with Word, Excel and PowerPoint. Can effectively create final products in all three programs.
Work under construction site conditions

Other Requirements:
Excellent oral and written English is required
Extensive travel may be required (75%)
Candidates must have a Passport or the ability to immediately get a Passport
Able to work in the US without sponsorship now or any time in the future.

About CAI
CAI is a 100% employee-owned company established in 1996, that has grown year over year to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and consulting services related to operational readiness to FDA regulated and other mission critical industries.

Meeting a Higher Standard
Our approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.
As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:
We act with integrity
We serve each other
We serve society
We work for our future

With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a can-do attitude. That is how we have grown exponentially.



Benefits
Our full-time positions offer competitive compensation and benefits which include: up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.
#LI-MR1
Average salary range, not including benefits or compensatory time and possible discretionary bonuses.
We are an equal opportunity employer; we are proud to employ veterans and promote a diverse culture in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.
This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FCO.",1996,Architectural & Engineering Services,$25 to $100 million (USD),"Construction, Repair & Maintenance Services",501 to 1000 Employees,Company - Private,True
