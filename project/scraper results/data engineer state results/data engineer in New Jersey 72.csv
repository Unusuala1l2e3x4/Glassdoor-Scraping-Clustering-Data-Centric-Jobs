Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply
Senior Electrical Engineer - Data Center Facilities,"BRUNS-PAK, Inc.","Edison, NJ",$75K - $110K (Employer est.),-1.0,"Job Title: Senior Electrical Engineer - Data Center Facilities (This is not a remote position)

Job Type: Full-time

Company Overview:

BRUNS-PAK helps clients strategize, implement, and provision innovative, resilient solutions for mission-critical data center infrastructure that support operations in an always-on world flooded by data and demanding information connectivity through an ever-expanding array of devices.

Job Description:

BRUNS-PAK is seeking an experienced and highly skilled Senior Electrical Engineer specializing in the design of electrical systems for Data Centers and Mission Critical Facilities. The ideal candidate should possess a solid background in designing appropriately sized Electrical Service, Generators, Switchgear, UPS Systems, transformers, PDU’s, and other Mission Critical equipment, incorporating reliability and redundancy into their designs.

Key Responsibilities:

· Design and develop electrical systems for Data Center Facilities, ensuring reliability, redundancy, and efficiency.

· Utilize AutoCAD and potentially Revit for effective design and documentation.

· Apply diversified knowledge of engineering principles and practices to a variety of assignments in related fields.

· Make informed and independent decisions regarding engineering methods and techniques.

· Consult with supervisor on critical issues, new concepts, and policy matters, seeking guidance as needed.

· Develop test procedures and provide support during the commissioning of electrical equipment.

Qualifications:

· Minimum of 7-10 years of relevant experience in electrical engineering, preferably in the field of Data Center Facilities.

· Proficiency in AutoCAD 2D design is essential, and experience with Revit design is a plus.

· Registration as a licensed Professional Engineer (PE) is usually required for this position.

Requirements:

· Extensive experience in designing electrical systems for Data Center Facilities.

· Strong knowledge of Generators, Switchgear, UPS Systems, transformers, PDU’s, and other Mission Critical equipment.

· Ability to integrate reliability and redundancy into electrical system designs.

· Excellent problem-solving skills and ability to apply engineering principles to diverse assignments.

· Ability to effectively communicate technical solutions to diverse audiences both orally and in writing.

Job Type: Full-time

Pay: $75,000.00 - $110,000.00 per year

Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance
Life insurance
Paid time off
Tuition reimbursement
Vision insurance

Experience level:

7 years

Schedule:

Monday to Friday

Ability to commute/relocate:

Edison, NJ 08817: Reliably commute or planning to relocate before starting work (Required)

Application Question(s):

Do you have Data Facility and Mission Critical Equipment experience?
Are you proficient in AutoCAD 2D design?
Are you proficient in Revit Design?
This is not a remote position. Candidate must be able to travel to the office in Edison , NJ for in office work detail

Education:

Bachelor's (Required)

Experience:

Mechanical engineering: 7 years (Required)

Language:

English (Required)
Applicant must be fluent in English (Required)

License/Certification:

Professional Engineer License (Required)

Willingness to travel:

25% (Required)

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Data Platform - Data Engineer,"Tradeweb Markets LLC
","Jersey City, NJ",$100K - $250K (Employer est.),3.9,"The Data Platform team manages a portfolio of applications and platforms in the data and analytics space, serving the reporting needs for both internal and external consumers. These applications include scripted reports/flat files (Python, Perl), self-service analytics platforms (Tableau, MS Analysis Services) and automated data quality tooling (Collibra DQ). Working with both business and technology partners, we are responsible for maintaining the consistency, availability and accuracy of the data within these systems, ensuring that we provide high quality views into our enterprise data for all customers.

This team truly sits at the intersection between the business and technology and this role provides an opportunity to learn both technical and commercial domain knowledge in a highly dynamic environment.

Tradeweb Technology jobs are fully remote. The Tradeweb Technology hub is located in our Jersey City office which can be used for team meetings and collaboration efforts. There may be days where travel to the Jersey City office is recommended for organizational off-sites.

Job Responsibilities

Transforming data from various internal sources into actionable insights.
Work closely with product managers and the sales managers to develop data solutions for internal stakeholders or external clients globally.
Develop solutions and automated reports utilizing Tableau, Python, or Excel
Develop and manage Quality Control solutions for Tradeweb Market Data products
Platform support including problem solving and debugging, especially for production issues.
Work closely with Technology and Analytics teams to help create efficient data solutions for each project.
Rigorous unit and integration testing.

Qualifications

Education: at least Bachelor's Degree, preferably in Computer Science
At least 3 years' professional application development experience
Proficient in writing, debugging and maintaining complex SQL queries and stored procedures
Proficient in Python and Tableau
Experience in automating code tests and deployment
Production operations experience
Advanced analytical and problem-solving ability

Nice to have

Knowledge of Financial Services Industry
Working knowledge of orchestration platforms like Airflow/Prefect
Working knowledge of Perl
Working knowledge of Windows/Linux server infrastructure, database administration and networks

Additional Information

Tradeweb is committed to providing valuable and competitive benefits. In addition to working in our culture of innovation and collaboration, we offer:

Health Insurance: Highly competitive medical, dental, and vision programs
Hybrid Environment: Our employees have the flexibility of working in the office and from home.
Health Care and Dependent Care Flexible Spending Accounts: You may elect to set aside pre-tax earnings to pay for eligible health care and dependent day care expenses for you and your eligible family members.
Maven Family Building Benefit: Maven offers support for fertility and preconception; pregnancy and post-partum; adoption; surrogacy and pediatrics for children up to age 10. Tradeweb provide a $10,000 lifetime reimbursement towards fertility, egg freezing, adoption and surrogacy expenses.
Building Wealth - 401(k) Savings Plan: Employees are immediately eligible for the 401(k) plan. Participants may contribute up to 75% of eligible compensation into a traditional 401(k) and/or Roth 401(k). Tradeweb will match 100% of the first 4% of compensation that you contribute.
The current pay range for this role if performed in the city of New York is currently $100,000 to $250,000 per year, based on a regular, full-time schedule. The amount of pay offered will be determined by a number of factors, including but not limited to qualifications, market data, geographic location, and internal guidelines.

Other Benefit Programs

Pre-Tax Commuter Benefits Program
ARAG Legal Services
Employee Assistance Program
Tuition Reimbursement
Financial Wellness Tools
Travel Assistance Benefits
Pet Insurance
Corporate Gym Subsidies
Wellness Perks
Paid Time Off and Parental Leave

Company Description

Tradeweb Markets is a world leader in the evolution of electronic trading. A fintech company serving approximately 2,500 clients – including the world’s largest banks, asset managers, hedge funds, insurance companies, wealth managers and retail clients - in more than 65 countries across the globe. Since our first trade in 1998, we have helped transform and electronify the fixed income markets. Tradeweb is a culture built on innovation, creativity and collaboration. Through a combination of very talented and driven people, innovative products and solutions, cutting-edge technology, market data, and a vast network of clients, we continue to work together to improve the way financial markets trade.

Mission: Move first and never stop. Collaborate with clients to create and build solutions that drive efficiency, connectivity, and transparency in electronic trading.

Tradeweb Markets LLC (""Tradeweb"") is proud to be an EEO Minorities/Females/Protected Veterans/Disabled/Affirmative Action Employer.
https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf",1996,Financial Transaction Processing,$1 to $5 billion (USD),Financial Services,1001 to 5000 Employees,Company - Public,False
Principal Data Engineer,"Verizon
","Basking Ridge, NJ",$112K - $153K (Glassdoor est.),3.8,"When you join Verizon

Verizon is one of the world’s leading providers of technology and communications services, transforming the way we connect around the world. We’re a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together—lifting up our communities and striving to make an impact to move the world forward. If you’re fueled by purpose, and powered by persistence, explore a career with us. Here, you’ll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife.

What you’ll be doing...

The role will be responsible for expanding and optimizing our data assets, data pipeline architecture, data flow and data curation to enable network programs including but not limited to Network Performance Experience, Operational Excellence and Workforce Optimization. This role folds IT expertise with architecture and design with a comprehensive understanding of network service assurance, and network operations data that will be consumed for Business Analytics, Operational Analytics, Text Analytics, Data Services and build Big Data Solutions for various Verizon Business units.

Defining and driving end to end Data pipeline deployments including roadmap, design and ensure execution excellence with business outcome-oriented metrics.

Driving data harmonization components to enable business value generation for network services and operations to take proactive action on time.

Supporting the building prototypes and proof of concepts to prove out integrated technologies and products and then driving these POCs forward through implementations.

Providing oversight and collaborating on pipeline implementations to ensure governance, quality and observance.

Leading junior team members on technical and functional skills.

Utilizing in-depth understanding of data warehousing technologies as well as a wide breadth of knowledge spanning on prem and cloud deployments to shape the future of enterprise wide network big data ecosystem.

Meeting business objectives by delivering high quality, on-time and on-budget solutions utilizing a global talent pool spanning employees, T&Ms and SOW labor.

Working with onshore teams to oversee execution of tasks such as development and population of data/ETL pipeline, testing results with end users and providing operational (production) support

What we’re looking for...

You’ll need to have:

Bachelor's degree or four or more years of work experience.

Six or more years of relevant work experience.

Strong communication, presentation and influencing skills.

Experience in collaborating across a wide range of internal/external teams with data engineers, architects, data scientists and enterprise platform teams in designing and deploying data products.

Even better if you have one or more of the following:

Bachelor’s degree in Computer Science major or related Engineering field and 10+ years of work experience. Even better if you have a BS/MS in Computer Science, Information Science, Engineering or other related fields.

Programming experience in Back End Systems Development with database technologies (SQL, NOSQL). Hands on experience in designing and building data pipelines leveraging Python, Spark, Flink, or Java

Fluent understanding of best practices for building Data Lake and analytical architectures on any Cloud Big Data toolset (Google Cloud Platform most preferred) and Hadoop.

Strong ability to apply business mindset to data issues and initiatives. Ability to integrate cross-business strategies and manage enterprise-wide global development resources.

Knowledge of data governance practices, emerging trends and issues, business and technology.

Familiarity with Agile Development methodologies (example SAFE Scaled Agile) and enabling tools (Jira, CI/CD and other DevOps functions).

Experience identifying potential areas of performance improvement, problem avoidance, capacity limitation and work with Engineering/Planning/Operations organizations for appropriate and timely action.

If Verizon and this role sound like a fit for you, we encourage you to apply even if you don’t meet every “even better” qualification listed above.

This role is eligible to be considered for the Department of Defense SkillBridge Program.

Where you’ll be working
In this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.

Scheduled Weekly Hours
40

Equal Employment Opportunity

We’re proud to be an equal opportunity employer - and celebrate our employees’ differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.",2000,Telecommunications Services,$10+ billion (USD),Telecommunications,10000+ Employees,Company - Public,False
Data Engineer,"Tradeweb Markets LLC
","Jersey City, NJ",$100K - $250K (Employer est.),3.9,"The Billing Technology team is responsible for the overall ownership of our internal billing and invoicing systems including the development, quality assurance and operations of the platform.

As a member of this team, you will be able to take in a set of complex requirements and use your own engineering and architectural skills to analyze them and distill a clear plan. You will develop a strong partnership with our business counterparts, proactively identifying problems they face and apply creative technological solutions to solve them.

Trust is fundamental to our trading platforms and our business overall and an invoice is a critical touchpoint between us and our customers. Therefore, the accuracy of the calculations and system outputs are paramount. This means that quality and stability will be fundamental to all changes made within the platform and that unit testing will play a critical role in the SDLC.

Tradeweb Technology jobs are fully remote. The Tradeweb Technology hub is located in our Jersey City office which can be used for team meetings and collaboration efforts. There may be days where travel to the Jersey City office is recommended for organizational off-sites.

Job Responsibilities

Liaising with finance team members and product managers to craft requirements
Enumerating the necessary datasets and designing the data model and schemas to support the billing and revenue processes.
Core engineering including implementing the necessary ETL, mediation code and rating algorithms to calculate revenue and generate invoices within an enterprise third party SaaS billing platform.
Platform support including problem solving and debugging, especially for production issues.
Hosting and participating in code reviews and QA issue tracking/remediation
Rigorous unit testing.
Moving trade and financial data between trade reporting repositories and financial systems

Qualifications

BS or higher in a technical field: CS, Physics, Math etc.
3 + years of experience working with Python
Proficient in writing and debugging complex SQL queries
Experience building ETL and stream processing pipelines using Kafka, Spark, Flink, Airflow/Prefect, etc.
Familiarity with data science stack: e.g. Juypter, Pandas, Scikit-learn, Dask, Pytorch, MLFlow, Kubeflow, etc.
Strong proclivity for automation and DevOps practices
Experience with managing increasing data volume, velocity and variety
Agile, self-starter and is focused on getting things done
Strong communication

Nice to have

Experience with JavaScript

Additional Information

Tradeweb is committed to providing valuable and competitive benefits. In addition to working in our culture of innovation and collaboration, we offer:

Health Insurance: Highly competitive medical, dental, and vision programs
Hybrid Environment: Our employees have the flexibility of working in the office and from home.
Health Care and Dependent Care Flexible Spending Accounts: You may elect to set aside pre-tax earnings to pay for eligible health care and dependent day care expenses for you and your eligible family members.
Maven Family Building Benefit: Maven offers support for fertility and preconception; pregnancy and post-partum; adoption; surrogacy and pediatrics for children up to age 10. Tradeweb provide a $10,000 lifetime reimbursement towards fertility, egg freezing, adoption and surrogacy expenses.
Building Wealth - 401(k) Savings Plan: Employees are immediately eligible for the 401(k) plan. Participants may contribute up to 75% of eligible compensation into a traditional 401(k) and/or Roth 401(k). Tradeweb will match 100% of the first 4% of compensation that you contribute.
The current pay range for this role if performed in the city of New York is currently $100,000 to $250,000 per year, based on a regular, full-time schedule. The amount of pay offered will be determined by a number of factors, including but not limited to qualifications, market data, geographic location, and internal guidelines.

Other Benefit Programs

Pre-Tax Commuter Benefits Program
ARAG Legal Services
Employee Assistance Program
Tuition Reimbursement
Financial Wellness Tools
Travel Assistance Benefits
Pet Insurance
Corporate Gym Subsidies
Wellness Perks
Paid Time Off and Parental Leave

Company Description

Tradeweb Markets is a world leader in the evolution of electronic trading. A fintech company serving approximately 2,500 clients – including the world’s largest banks, asset managers, hedge funds, insurance companies, wealth managers and retail clients - in more than 65 countries across the globe. Since our first trade in 1998, we have helped transform and electronify the fixed income markets. Tradeweb is a culture built on innovation, creativity and collaboration. Through a combination of very talented and driven people, innovative products and solutions, cutting-edge technology, market data, and a vast network of clients, we continue to work together to improve the way financial markets trade.

Mission: Move first and never stop. Collaborate with clients to create and build solutions that drive efficiency, connectivity, and transparency in electronic trading.

Tradeweb Markets LLC (""Tradeweb"") is proud to be an EEO Minorities/Females/Protected Veterans/Disabled/Affirmative Action Employer.
https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf",1996,Financial Transaction Processing,$1 to $5 billion (USD),Financial Services,1001 to 5000 Employees,Company - Public,False
Lead Data Engineer- Oracle / Cloud Services,"JPMorgan Chase & Co
","Jersey City, NJ",$138K - $185K (Employer est.),4.0,"JOB DESCRIPTION


Join us as we embark on a journey of collaboration and innovation, where your unique skills and talents will be valued and celebrated. Together we will create a brighter future and make a meaningful difference.

As a Lead Data Engineer- Oracle / Cloud Services at JPMorgan Chase within Asset Wealth Management, GPB Technology, you are an integral part of an agile team that works to enhance, build, and deliver data collection, storage, access, and analytics solutions in a secure, stable, and scalable way. As a core technical contributor, you are responsible for maintaining critical data pipelines and architectures across multiple technical areas within various business functions in support of the firm’s business objectives.

Job responsibilities

Generates data models for the team using firmwide tooling, linear algebra, statistics, and geometrical algorithms
Delivers data collection, storage, access, and analytics data platform solutions in a secure, stable, and scalable way
Implements database back-up, recovery, and archiving strategy
Evaluates and reports on access control processes to determine effectiveness of data asset security with minimal supervision
Drives initiatives on the Data domain and is subject matter expert on data on the platform
Creates Functional and Technical Specifications, Epics, User Stories, Process Flows, Data Analysis, Mapping Documents, Implementation Plan, Agile artifacts
Creates complex SQL queries to support data analysis
Develops secure high-quality production code and reviews and debugs code written by others
Identifies opportunities to eliminate or automate remediation of recurring issues to improve overall operational stability of software applications and systems
Leads evaluation sessions with external vendors, startups, and internal teams to drive outcomes-oriented probing of architectural designs, technical credentials, and applicability for use within existing systems and information architecture
Leads communities of practice across Software Engineering to drive awareness and use of new and leading-edge technologies

Required qualifications, capabilities, and skills

Formal training or certification in software engineering concepts and 5+ years of Database experience, preferably in Oracle
Working experience with both relational and NoSQL databases
Experience and proficiency across the data lifecycle
Experience with database back-up, recovery, and archiving strategy
Proficient knowledge of linear algebra, statistics, and geometrical algorithms
Familiar with Data Science concepts and applying them to analyze large volumes of data
Comfortable with streaming and big data concepts: Oracle, Java, Python, Spark, Flink, Kafka, HDFS, AirFlow, Elastic Search, Cassandra and AWS Cloud Services (MSK, Aurora, DynamoDB, Redshift, etc.)
Advanced understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security
Experience in ETL pipelines, both batch and real-time data processing
Preferred qualifications, capabilities, and skills
Knowledge in Machine Learning, Data Mining, Information Retrieval, Statistics is a big plus; Exposure in at least one of the following areas: Natural Language Processing, Computer Vision, Speech Recognition, Reinforcement Learning, Ranking and Recommendation, or Time Series Analysis; Exposure to machine learning frameworks: Tensorflow, Caffe/Caffe2, Pytorch, Keras, MXNet, Scikit-Learn
Cloud computing: Google Cloud, Amazon Web Service, Azure, Docker, Kubernetes
Experience in distributed system design and development
ABOUT US

JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)

We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.

JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans







ABOUT THE TEAM

J.P. Morgan Asset & Wealth Management delivers industry-leading investment management and private banking solutions. Asset Management provides individuals, advisors and institutions with strategies and expertise that span the full spectrum of asset classes through our global network of investment professionals. Wealth Management helps individuals, families and foundations take a more intentional approach to their wealth or finances to better define, focus and realize their goals.



Our Asset and Wealth Management division is driven by innovators like you who are driven to create technology solutions that make us work more efficiently and help our businesses grow. It’s our mission to efficiently take care of our clients’ wealth, helping them get, and remain properly invested. Our team of agile technologists thrive in a cloud-native environment that values continuous learning using a data-centric approach in developing innovative technology solutions.",1799,Banking & Lending,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
Lead Software Engineer- Python / Big Data / AWS,"JPMorgan Chase & Co
","Jersey City, NJ",$147K - $215K (Employer est.),4.0,"JOB DESCRIPTION


We have an opportunity to impact your career and provide an adventure where you can push the limits of what's possible.

As a Lead Software Engineer- Python / Big Data / AWS at JPMorgan Chase within Consumer and Community Banking, Data Technology, you are an integral part of an agile team that works to design and build, enterprise grade technology products, infrastructure offerings and services in order to deliver next gen Advanced Analytics Platform that run ML Workflows capable of processing batch and streaming data at scale. As a core technical contributor, you are responsible for implementing critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.

Job responsibilities

Leads the design and development of the cloud infrastructure offerings, platform tools and services, ensuring that they are secure, scalable, and reliable
Implements creative software solutions, design, development, and troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Develops secure high-quality production code, and reviews and debugs code written by others.
Identifies opportunities to eliminate or automate remediation of recurring issues to improve overall operational stability of software applications and systems
Leads evaluation sessions with external vendors, startups, and internal teams to drive outcomes-oriented probing of architectural designs, technical credentials, and applicability for use within existing systems and information architecture
Leads communities of practice across Software Engineering to drive awareness and use of new and leading-edge technologies
Adds to team culture of diversity, equity, inclusion, and respect

Required qualifications, capabilities, and skills

Formal training or certification on software engineering concepts and 5+ years applied experience
Hands-on practical experience delivering system design, application development, testing, and operational stability
Advanced knowledge of creating API’s.
Strong experience with Python, PySpark, SQL, & Java;
Advanced understanding of agile methodologies, CI/CD, Data Management, Application Resiliency, and Security
Hands-on experience with Airflow, AWS services EKS, EMR, Lambda, SQS, SNS, Athena, Glue; Data Lake, Terraform as Cloud Infra Provisioning Tools and experience delivering system design, testing, and operational stability
Experience writing Splunk or Cloudwatch queries, DataDog metrics,

Preferred qualifications, capabilities, and skills

Experience with Hadoop nice to have.
Experience with table formats: iceberg, Delta Lake preferred.
Familiarity with modern front-end technologies NodeJS, and with various automated testing and tools
Financial industry experience with exposure in large scale/ high-volume industry
ABOUT US

JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)

We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.

JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans







ABOUT THE TEAM

Our Consumer & Community Banking Group depends on innovators like you to serve consumers, small businesses, municipalities and non-profits. You’ll support the delivery of award winning tools and services that cover everything from personal and small business banking as well as lending, mortgages, credit cards, payments, auto finance and investment advice. This group is also focused on developing and delivering cutting edged mobile applications, digital experiences and next generation banking technology solutions to better serve our clients and customers.",1799,Banking & Lending,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
Data Engineer with strong python development,"Combined Computer Resources
","Newark, NJ",$65.00 - $75.00 Per Hour (Employer est.),3.2,"Looking for a data engineer with python( very heavy Python development), java( able to read legacy code), sql, 10 plus years in development with last 5 in cloud, AWS, data warehouse (snowflake preferred), and ETL tools ( Apache spark preferred). Will support the cloud migration team and be mostly building cloud based applications. The role is development, design and support. Fixed income or asset management experience needed.

Job Type: Contract

Pay: $65.00 - $75.00 per hour

Schedule:

8 hour shift

Ability to commute/relocate:

Newark, NJ 07102: Reliably commute or planning to relocate before starting work (Required)

Experience:

Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)

Work Location: Hybrid remote in Newark, NJ 07102",-1,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,Unknown,Company - Private,True
Senior Data Engineer,"Brother USA
","Bridgewater, NJ",$125K - $145K (Employer est.),3.2,"Let's Grow Together

Our mission is to live our “at your side” promise and simplify and enrich the lives of our customers, employees, and communities. ""At your side"" is more than a slogan to us; it’s the purpose we do our best to fulfill every day. With a legacy spanning over a century, this is a great place to launch or expand any career and push the boundaries of what comes next. We're committed to achieving shared success, and we provide opportunities for you to develop through experience, exposure and education. Our people have always leveraged their unique perspectives to keep us on the right track for a lasting future. If you want to innovate, learn, and grow with a global leader that builds products, services, and a company people love, then we’ll be “at your side” every step of the way.

The Senior Data Engineer is dedicated to advancing analytics capabilities to support our business. This role plays a crucial part in acquiring, cleaning, and transforming data from various sources to facilitate advanced analytics. The responsibilities include data preparation, ML pipeline development, data integration, modeling, performance tuning, data governance, and collaborative documentation. The role's expertise contributes to the success of data-driven initiatives and help drive optimal project outcomes for our stakeholders.

Duties and Responsibilities

Data Engineering - Data Enablement Support

Data Preparation and Cleaning: Acquire, clean, and transform data from various sources, ensuring data quality and suitability for advanced analytics. Handle missing data, outliers, and validate data

Machine Learning Pipeline Development: Collaborate closely with Data Scientists to design, build, and maintain machine learning pipelines. Develop data preprocessing and feature engineering workflows for accurate model training

Data Integration: Integrate data from diverse sources, including databases, APIs, and external data providers, using tools like Alteryx, Databricks, and Azure. Design and implement Extract, Transform, Load (ETL) processes to harmonize data for analytical purposes

Data Modeling and Optimization: Assist in creating data models supporting analytical needs, including data warehousing and data marts. Optimize data structures and databases for query performance.

Performance Tuning: Ensure efficient data processing systems and timely execution of analytical workloads through indexing, query optimization, and parallel processing

Data Governance and Compliance: Incorporate data governance policies and compliance into data engineering processes to maintain data integrity and security. Capture data lineage to meet governance requirements

Collaboration and Documentation: Collaborate with cross-functional teams, documenting data sources, transformations, and data lineage to ensure transparency and reproducibility in analytics projects

Business Knowledge Utilization: Utilize business acumen to contribute to project success and align data engineering efforts with stakeholder objectives. Understand the business problem and how data is used for decision-making

Data Quality Assurance: Develop and implement data quality checks and validation procedures to maintain data accuracy

Data Monitoring: Continuously monitor data pipelines and proactively address issues to ensure data availability and reliability

Technology Evaluation: Stay updated on emerging data engineering technologies and recommend their adoption where appropriate to enhance our capabilities.

Data Security: Implement and enforce data security measures to protect sensitive information throughout the data lifecycle

Business Consultation

Facilitate meetings and/or projects, determine audience and tactics appropriate for a particular discussion

Analyze raw data to find opportunities to implement artificial intelligence into the current business processes

Perform statistical analysis to determine gaps that critically affect the performance of the process and prioritize for review

Identify options to streamline and/or eliminate manual processes, where applicable, by developing innovative solutions

Education

Bachelor's Degree (or equivalent experience) Computer Science, Information Technology, Business Administration, or related field Required

Experience

Minimum 5 years

Experience in data management disciplines demonstrating knowledge of analytics delivery and data integration best practices Required

Experience working in cross-functional teams and collaborating with business stakeholders in support of a departmental and/or multi-departmental data management and analytics initiative Required

Software/Technical Skills

Strong knowledge of database systems (SQL and NoSQL) and data warehousing Required

Experience with data integration/ETL tools like Alteryx, Databricks, etc. Required

Proven experience in data engineering and ETL processes Required

Proficiency in programming languages such as Python, Java, or Scala Required

Knowledge of data governance and compliance practices Required

Familiarity with machine learning frameworks and concepts Preferred

Experience with data security practices and tools Preferred

Knowledge of Visualization Tools (Tableau, PowerBI, etc.) Preferred

Other Skills/Knowledge/Abilities

Data-driven approach with the ability to aid business transformation Required

Strong critical thinking skills Required

Strong communication skills with ability to adapt facilitation style in order to engage a variety of group settings Required

Business acumen and ability to collaborate effectively with cross-functional teams Required

Ability to effectively convey complex and detailed technical information in a timely manner Required

Ability to challenge the status quo and foster shared understanding, transparency, and mastery of the process and/or system Required

Ability to balance multiple priorities and act with resolve in an ambiguous Required

Excellent problem-solving and troubleshooting skills Required

Strong communication and documentation abilities Required

This role will be a hybrid role. Subject to business needs, employees may work remotely up to two days per week. Assigned office days will be determined by managers.

#LI-Hybrid

The salary (or hiring) range for this position is $125,000-$145,000 per year

Starting salary to be determined by the education, experience, knowledge, skills and abilities of the applicant, internal equity, location, and alignment with market data

Benefits include, but are not limited to, healthcare and wellness coverage, life and disability insurance, 401K, tuition reimbursement, and Paid Time Off. Details are available at https://mybenefits.nfp.com/Brother/2023/guidebook/

Brother International Corporation has earned its reputation as a premier provider of home office and business products, home appliances for the sewing and crafting enthusiast as well as industrial solutions that revolutionize the way we live and work. Brother International Corporation is a wholly-owned subsidiary of Brother Industries Ltd. With worldwide sales exceeding $6 billion, this global manufacturer was started more than 100 years ago. Bridgewater, New Jersey is the corporate headquarters for Brother in the Americas. It has fully integrated sales, marketing services, manufacturing, research and development capabilities located in the U.S. In addition to its headquarters, Brother has facilities in California, Illinois and Tennessee, as well as subsidiaries in Canada, Brazil, Chile, Argentina, Peru and Mexico. For more information, visit www.brother.com.

Brother International Corporation (""Brother"") is an equal opportunity employer and does not discriminate or make employment decisions on the basis of race, color, religion, sex, disability, or any other characteristic protected by applicable state or federal laws. If you require any physical or other assistance in completing this application, a reasonable accommodation will be made upon request.",1954,Electronics Manufacturing,Unknown / Non-Applicable,Manufacturing,501 to 1000 Employees,Company - Private,False
Data Engineer (Analytics),"Roche
",United States,-1,4.2,"The Position

At Roche, we believe it’s critical to deliver medical solutions now – even as we develop innovations for the future. We are passionate about transforming patients’ lives and we are fearless in both decision and action. And we believe that good business means a better world.

That is why we come to work each day. We commit ourselves to scientific rigour, unassailable ethics, and access to medical innovations for all. We do this today to build a better tomorrow.

Who you are

As Data Engineer, you will play a key role in implementing Global Operations advanced data analytics strategy for breakthrough insights. You are motivated to continuously find ways to simplify and automate our data pipelines. You will work with various domain experts as needed to gain an understanding of unique technology and to integrate disparate data sources. Working within the Data Engineering team and alongside members of the Data Analytics team, you will deliver data automation by setting up ETL for new data sources, contribute to data warehouse code development, and support data analytics and data science use cases. You have demonstrated your understanding of object-oriented programming in a previous project. You are an engineer with a strategic and methodical approach to developing elegant solutions to complex problems. You are a skilled communicator with a proven ability to employ good software engineering practices.

The opportunity
Gains understanding of Global Operations technology and data structures
Identifies opportunities for data acquisition, develop and implement data collection systems, and develop integrated data pipelines to support the production teams to strategically steer and continuously deliver on quality improvement initiatives
Integrates heterogeneous and complex data sets to provide deeper insight into company data, interacting cross-functionally as necessary
Delivers automation for data access and processing to enable efficient use of relevant information
Sets up and maintains ETL for new data sources
Contributes to the development of the data warehouse code library
Supports the development of data analytics and data science use cases
Demonstrates competency and enthusiasm for advancing our analytics strategy
Communicates clearly and effectively and uses good software engineering practices
Other Duties as assigned by management

Your Key Qualifications and Experience

Bachelor's Degree in Engineering, Mathematics, Data Science and Engineering, or Computer Science and 2 years of directly related experience required

Or Master's degree in Engineering, Mathematics, Data Science and Engineering, or Computer Science and 1 years of directly related experience preferred.

Equivalent combination of education and experience will be considered, with three years of experience required for each year of required education.

Other Knowledge, Skills and Abilities

Proficiency in Python required (pandas, numpy, watchdog, multiprocessing)
Proficiency in SQL required
Experience querying and manipulating large datasets
Experience with data parsing, scripting and automation
Experience with ETL Solutions (SSIS, Talend, Airflow)
Experience with cloud resources (Snowflake, GCP, AWS), strongly preferred
Familiarity with heterogeneous data structures (json, xml, images, gsheets)
Familiarity with database structures and schemas (MySQL, NoSQL)
Familiarity with command line and programming interfaces
Strong understanding of engineering principles and concepts
Motivated to create solutions to problems in healthcare with the goal of improving patient outcomes and clinician experiences
Ability to both guide and accept guidance from team members
Demonstrates potential for success in technical proficiency, scientific creativity, productive collaboration, as well as independent thought
Applies foundational understanding of engineering principles to work
Exhibits a professional attitude and conduct appropriate for R&D in a regulated industry

Relocation benefits are not available for this job posting.

Who we are

At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we’ve become one of the world’s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.

Roche is an equal opportunity employer and strictly prohibits unlawful discrimination based upon an individual’s race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, mental/physical disability, medical condition, marital status, veteran status, or any other characteristic protected by law.

If you have a disability and need an accommodation in relation to the online application process, please contact us by completing this form Accommodations for Applicants.",1896,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,5001 to 10000 Employees,Company - Public,False
Sr. Data Engineer,"ConnectiveRx
","Hanover, NJ",$102K - $137K (Glassdoor est.),3.2,"Teammates must meet the following criteria in order to apply for a new internal position:


Must be a current full-time employee of ConnectiveRx
Must be in their current role for 12 months
Must be in good standing with the Company
Must meet the minimum job requirements for the position
Please submit a resume with your application

Before applying, please read our Internal Job Application Policy and Internal Job Application FAQs by clicking: The Link

​​​​​​​*Director-level and below roles will be posted to the internal careers site.

Job Description

What you will do:
Looking for a seasoned Senior Data Engineer to help us continue to build out our new Enterprise Data Platform. This person must have a strong understanding and demonstrated experience with data streaming architectures that leverage microservice & message-oriented integration patterns and practices within AWS cloud native technologies. This person will help to scale our data ingestion pipelines which are at the core of our Enterprise Data Platform which supports our client reporting as well as our internal analytics & operational teams.

The successful candidate will:

Work with senior leadership, architects, engineers, data analysts, product managers and cloud infrastructure teams to deliver a new features and capabilities.
Write clean, robust, and well-thought-out code with an emphasis on quality, performance, scalability, and maintainability.
Demonstrate strong end to end ownership & craftsmanship - analysis, design, code, test, debug, and deploy
Your ability to traverse the full stack within AWS server-less technologies will be an asset to us as we evaluate the tradeoffs inherent in software engineering. You have the product driven development mindset and can work closely with BA’s and Product teams to breakdown requirements and translate business workflows into scalable technical solutions.

What we’d like from you:

Strong Python & strong SQL
Extensive relational DB experience (Redshift, SQL Server, PostgresSQL) with exposure to document DBs such as DynamoDB. ElasticSearch.
Experience with designing solutions that run in AWS cloud technologies (Lambda, ECS, DynamoDB etc), docker containers
Message oriented architectures, patterns and tools, CQRS, event streaming, Kafka, SQS
Change data capture concepts, Database Triggers, AWS DMS
Data lake concepts, data catalogs, meta data etc
CICD Pipelines
Event store processing, data validation, operational logging via AWS Cloud Watch
Why work with us?

Excellent company culture, fun events, and volunteer opportunities
Competitive benefits (medical, dental, vision & more)
401k package with dollar-for-dollar match-up
Generous PTO and paid holidays days offered
Opportunities to grow professionally and personally
Team-oriented atmosphere
#LI-BJ1

Equal Opportunity Employer: This employer (hereafter the Company) is an equal opportunity employer and does not discriminate in recruitment, hiring, training, promotion, or other employment policies on the basis of age, race, sex, color, religion, national origin, disability, veteran status, genetic information, or any other basis that is prohibited by federal, state, or local law. No question in this application is intended to secure information to be used for such discrimination. In addition, the Company makes reasonable accommodation to the needs of disabled applicants and employees, so long as this does not create an undue hardship on the Company or threaten the health or safety of others at work. This application will be given every consideration, but its receipt does not imply that the applicant will be employed.",2015,Biotech & Pharmaceuticals,Unknown / Non-Applicable,Pharmaceutical & Biotechnology,1001 to 5000 Employees,Company - Private,True
Senior Data Engineer (Snowflake) - Contractor,"EY
",United States,$90.00 - $130.00 Per Hour (Employer est.),3.9,"The primary responsibility for the Sr. Data Engineer / Tech Lead is to ensure data accessibility, quality, and reliability within the client's data platform ecosystem.

RESPONSIBILITIES

Design and develop end-to-end data pipelines and ETL processes using Snowflake, Denodo, DBT Cloud, Fivetran, and AWS Glue, ensuring seamless data integration, transformation, and loading.
Collaborate with cross-functional teams to gather data requirements and implement scalable data models and schemas within Snowflake and Denodo, ensuring optimal performance and data consistency.
Implement and maintain data orchestration workflows using Stonebranch, ensuring efficient and reliable scheduling and automation of data processes.
Work with EnterpriseDataLake for ingestion and storage of data from various sources, ensuring the availability and accessibility of data for analytics and reporting purposes.
Utilize Azure DevOps and Teraform to implement and manage infrastructure as code, ensuring streamlined deployment and scalability of data engineering solutions.
Skills

snowflake

denodo

dbt cloud

fivetran

Qualifications

REQUIREMENTS

Proficiency in Snowflake and Denodo: Strong understanding and hands-on experience in working with Snowflake and Denodo for data integration, transformation, and analysis.
Knowledge of DBT Cloud: Familiarity with DBT Cloud, including experience in building and maintaining efficient data transformation workflows and deploying reliable data pipelines.
Experience with Fivetran: Demonstrated experience in utilizing Fivetran for data ingestion, source connectivity, and ensuring data accuracy and completeness.
Understanding of EnterpriseDataLake: Knowledge of EnterpriseDataLake principles and practices, including data ingestion, storage, and organization for analytics and reporting purposes.
Familiarity with Stonebranch: Proficiency in using Stonebranch for data orchestration and scheduling, ensuring efficient and reliable execution of data pipelines and workflows.
Proficiency in Azure DevOps and Teraform: Experience in leveraging Azure DevOps and Teraform for infrastructure as code, enabling streamlined deployment and scalability of data engineering solutions.

The expected pay rate range for this contract assignment is $90 to $130 per hour. The exact pay rate will vary based on skills, experience, and location. The position is approximately 65-70% remote and 30-35% travel to the client as needed.

#GigNowTechOpportunities

GigNowOpportunities

Equal Employment Opportunity Information
EY provides equal opportunities to applicants, employees, contractors, vendors, and stakeholders without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. If you are an individual with a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please email gignow.recruiting@ey.com.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,False
Data Engineer,Metrohm Spectro,"Plainsboro, NJ",-1,-1.0,"Metrohm Spectro is an advanced mobile spectroscopic instrumentation leader, developing, manufacturing, and servicing state-of-the-art analytical devices, including portable and handheld Raman analyzers.We provide solutions for the pharmaceutical, biomedical, safety and security, chemical, and academic research industries. We are constantly growing with new products and new opportunities, and are always looking for talented, dedicated employees to join us and grow together as a team.

With the fast growth of our business, we have an immediate vacancy for a full-time Data Engineer for our Plainsboro, NJ location.

Job Description

In this role, you will take responsibility for developing and maintaining databases within software products. You will be required to have hands-on problem solving, from the upkeep and generation of database, to data validation as well as the capability of data processing and analysis, and will be able to perform data processing algorithm validation with the knowledge of data science. To excel in this role, you need to be very organized with a fine eye for detail, and openness to learn new skills to meet growing business needs.

Education

· Bachelor’s of Science degree from an accredited university or college in chemistry, physics, mathematics or computer science.

Experience:

· High-level proficiency in Microsoft Excel or other automated data management tool.

· Experienced in database programming and familiar with all popular database types. Good understanding of MySQL is a plus;

· Knowledge in MATLAB, R, Python or SAS tools for data processing and analysis;

· Knowledge in AI/machine learning and data mining basics;

· Knowledge in C/C++ programming for data processing algorithm;

· High-level proficiency in Microsoft Excel or other automated data management tool;

· Knowledge in Network/Cloud infrastructure will be a plus.

ROLE AND JOB RESPONSIBILITIES

· Develop and maintain database for cross-platform software implementation on all BWTEK spectroscopic products.

· Assist in data process and analysis algorithm design and validation.

· Collaboration with entire software team for product enhancement and new product.

Job Type: Full-time

Application Question(s):

What are your salary expectations?

Work Location: Plainsboro, NJ - on site

Can you commute to this location?

Job Type: Full-time

Benefits:

401(k)
Dental insurance
Health insurance
Paid time off
Tuition reimbursement
Vision insurance

Schedule:

8 hour shift
Monday to Friday

Ability to commute/relocate:

Plainsboro, NJ 08536: Reliably commute or planning to relocate before starting work (Preferred)

Application Question(s):

Will you need sponsorship to work in US?

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Entry level Data Engineer/Python,Cloud Resources,"Iselin, NJ",-1,-1.0,"```Duties```
- Collaborate with a team of engineers to design and develop software solutions
- Write and maintain code using various programming languages such as Python, Java, and shell scripting
- Analyze user requirements and translate them into technical specifications
- Develop and implement data warehouse solutions using Hadoop and Informatica
- Perform server maintenance and troubleshooting tasks
- Follow Agile methodologies to ensure efficient project delivery
- Conduct testing and debugging of software applications
- Document software design, coding, and testing activities

```Experience```
- Bachelor's degree in Computer Science or a related field
- Strong knowledge of programming languages such as Python, Java, and shell scripting
- Familiarity with data warehouse concepts and tools like Hadoop and Informatica
- Experience with server maintenance and troubleshooting
- Understanding of Agile methodologies for software development
- Ability to analyze user requirements and translate them into technical specifications

This is an entry-level position that offers the opportunity to gain valuable experience in software engineering. We provide a supportive work environment where you can grow your skills and advance your career. Join our team of talented engineers and make an impact in the field of technology.

Note: This job description is intended to provide a general overview of the position. It is not an exhaustive list of all responsibilities, skills, or qualifications required for the role.

Job Types: Full-time, Contract

Pay: From $100.00 per year

Benefits:

401(k)
Dental insurance
Health insurance

Compensation package:

Yearly pay

Experience level:

3 years
4 years
5 years

Schedule:

8 hour shift

Ability to commute/relocate:

Iselin, NJ 08830: Reliably commute or planning to relocate before starting work (Required)

Experience:

Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)

Work Location: Hybrid remote in Iselin, NJ 08830",-1,-1,-1,-1,-1,-1,True
DATA ENGINEER III,"United States Cold Storage Inc
","Camden, NJ",$94K - $131K (Glassdoor est.),3.8,"Job Title: Data Engineer III
USCS’s is the third largest 3PL in the US and leading provider of third-party logistics solutions. The Center of Digital Excellence or CoDE is the IT department for USCS that supports our mission critical warehouse operations and our various corporate systems (HR, Accounting, Finance, etc.) with custom technology solutions alongside many vendor solutions.
Job Overview:
We are looking for a self-motivated Data Engineer to join our data engineering and data science practice. This group is responsible for sourcing data from our internal systems, partners, industry datasets, etc. and delivering it into a consumable and maintainable data warehouse to facilitate decision making by our internal stakeholders using various analytics tools.
The Job Details:
Create and maintain an optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Design and implement various data flow automations using various tools and technologies.
Build optimal ETL jobs and pipelines from a variety of data sources using SQL, REST APIs, Azure Data technologies, Microsoft Power Platform technologies and Python
Build analytical dashboards and reports using BI and reporting tools to provide actionable insights
Work with various stakeholders to gather requirements and provide operational support for our data warehouse, reports and dashboards
Keep our data separated and secure across national boundaries through multiple data centers and Azure and OCI cloud regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
The Job Specifics:
Location, Department and Work Hours: Camden NJ, work hours may vary.
Reports To: Sr Software Development Manager
Travel Amount: 10%
Job Type, EEO, and Job Code: Full-Time,


What We Are Looking For:
Education
Bachelors degree in computer science or related field or equivalent experience
Experience
5-7 years of experience as a Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Other Abilities You Will Need to Have: The physical demands described below are representative of those required of an individual performing the essential duties of this position. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.
Good arithmetic, reading, and typing skills
Sit and/or stand for extended periods of time
Be able to see, speak and hear
Ability to work overtime as needed
May require physical effort associated with using the computer to access information, or occasional standing, walking, lifting needed to carry out everyday activities.
Understand and follow verbal instruction, written instruction and company policies.
A starter that can work independently and coordinate with others
Follow safety procedures at all times.
Ability to manage stress and productivity guidelines
The Standard Details:
Always maintain a professional manner in appearance and communications.
Participate in staff and/or customer meetings if required.
Initiate action to prevent the occurrence of any non-conformities relating to product, process, and quality systems.
Identify and record any issues relating to product, processes and/or quality.
Initiate, recommend, or provide solutions through appropriate channels.
Verify the implementation of solutions.
Follow posted security procedures at all times while in the building.
Participate in Safety and Educational Training.


What’s In It For You:
A great company with great people. Full-time employees not under contract are offered: 401K and Educational Assistance after 1 year; If elected, Blue Cross Blue Shield after 30 days of service; Company Life Insurance; and a bunch of other great perks.
Things We Need To Mention:
The above job description may not include all tasks necessary to complete the job.
Job functions may vary based on area of operation. The job description is a listing of the most common tasks the associate will be required to perform in that job area.
Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.",1899,Shipping & Trucking,$500 million to $1 billion (USD),Transportation & Logistics,1001 to 5000 Employees,Company - Private,True
Data Engineer,"SoHo Dragon
","Bridgewater, NJ",$90K - $126K (Glassdoor est.),4.4,"SoHo Dragon is looking to hire a Data Engineer for a contract opportunity.


Should be able to create Spark , EMR jobs
Should have worked on NF-Core, AirFlow, Nextflow
Should be able to create data management pipeline in Airflow
Should have good working knowledge of AWS (AWS Glue, AWS Omics, AWS Batch, Athena, EMR Serverless)
Should have domain knowledge of Genomics, bioinformatics and life sciences",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,True
Data Engineer,"Appsintegration INC
","Union, NJ",$45.00 - $50.00 Per Hour (Employer est.),3.7,"Job Title: GCP Data Engineer

Location: Houston TX ( Day One Onsite )

Job Type: Contract

Visa: H1B H4EAD,GC , USC

Job Description:

Skills Required: GCP experience, SQL, Python, Cloud run, BigQuery

Nice to haves: JavaScript, DataFlow

Job Summary:

Client is looking for an accelerator or available application that utilizes the statistics generated by relevant GCP sinks and present them as a realtime dashboard.

Roles & Responsibilities:

GCP data engineer needs to work with client team and current AMS support team to develop a solution to present GCP relevant statistics in a real time dashboard, including the following component: Jobs failures, Usage analysis, Cost overview by project, user and type of objects, Code migration between different projects

Job Types: Full-time, Contract

Salary: $45.00 - $50.00 per hour

Benefits:

401(k)
Dental insurance
Health insurance

Experience level:

10 years
6 years
7 years
8 years
9 years

Work Location: In person",-1,-1,Unknown / Non-Applicable,-1,1001 to 5000 Employees,Company - Public,True
Data Engineer - 5050304,"Accenture
","Florham Park, NJ",-1,3.9,"Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.

As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.

You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.

Utilize strong SQL Python skills to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features.

Build reporting dashboards and visualizations to design, create and track campaign program KPIs.

Perform analyses on large data sets to understand drivers of operational efficiency.

Manage end to end process of analytic tooling feature development, including request intake, requirements evaluation, cross functional team alignment, feature execution, QA testing, and stakeholder communication.

Consult with business analysts, technical data SMEs, and cross functional partners to understand their reporting and data needs, serving as the point of contact for requests, inquiries, and actions.

Interface with other data engineering, product, and data science teams to implement client needs and initiatives.




Basic Qualifications:

Minimum 2 years experience with Python.

Minimum 3 years experience SQL.

Minimum 3 years experience Big Data Analytics.

High School Diploma or GED.

Preferred Qualifications:

Experience with large enterprise data sets.

Bachelors Degree

Compensation at Accenture varies depending on a wide array of factors, which may include but are not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York, or Washington as set forth below.

Information on benefits is here.

Role Location

California: $61.53 to $71.53/hour

Colorado: $61.53 to $71.53/hour

New York: $61.53 to $71.53/hour

Washington: $61.53 to $71.53/hour


What We Believe


We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.


Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here


Equal Employment Opportunity Statement


Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.


All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.


Accenture is committed to providing veteran employment opportunities to our service men and women.


For details, view a copy of the Accenture Equal Employment Opportunity and Affirmative Action Policy Statement.


Requesting An Accommodation


Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.


If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.


Other Employment Statements


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.


Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.


Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.


The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",1989,Business Consulting,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
AVP Enterprise MS SQL Data Engineer,"Kforce
","Whitehouse Station, NJ",$55.00 - $78.00 Per Hour (Employer est.),3.9,"RESPONSIBILITIES:
Kforce's client, one of the largest global insurance organizations is seeking to hire an Assistant Vice President Enterprise MS SQL Data Engineer in Philadelphia (PA) or Whitehouse Station (NJ). This is a long-term fulltime opportunity with client.

Summary:
The Global Actuarial Systems team is a small, agile group of technology enthusiasts. We are tasked with solving the complex data needs of both US and International reserving and pricing actuaries. Our group is responsible for collating data from several disparate systems and platforms to provide analytic solutions for the world's largest publicly traded property and casualty insurer. Our systems are the foundation for the loss triangles which are reported externally and ensure we have the capital to pay future claims.

What you will be working on:

Expanding our new claim data warehouse responsible for producing actuarial loss triangles
Implementing BI processes so end users can quickly and easily derive value from billion row datasets
Creating of new ETL process to accurately stitch data together
Helping to design the future cloud architecture and migration of the warehouse
Investigating, diagnosing, and actioning on business questions and requests
Direct handling of production support and maintenance of existing financial feeds
Delivering solutions on time and within budget, meeting both internal change management standards and external SOX controls
REQUIREMENTS:

Microsoft SQL Server guru with strong data warehousing fundamentals - 80% of time & work; All coding in Server, ETL process knowledge needed - not tool knowledge; Experience in running and maintaining a Data Warehouse that pulls from 20/30 data sources including supporting audit and security needs; Day-to-day of role; Explaining data, tracing data numbers & claims and pulling Actuarial Claims from several data systems
Strong communication skills, comfortable interfacing with senior business users
Enterprise Domain knowledge is a key must; Ideal hire would come from a #1 Property & Casualty Insurance, #2 Health Insurance, #3 Financial Services/Banking Domain
Secondary to key-plus skills:

R and 1b. Python
DevOps tools (GIT, Jenkins, Octopus)
BI solutions (e.g., Shiny, Cognos, Power BI)
Actuarial Data and Actuarial Systems knowledge
Agile project management ideologies
Extensive technical analysis and investigative capabilities
Biggest challenge is the mix of skills needed:

Communication ability with high level actuaries
Ability to act as BA/PM/developer
Legacy corporate data systems can pose steep learning challenges with years of company-specific logic
Sizzle of Role:
Working with the top actuaries, who are some of the smartest minds in the company. Their work is critical to the statutory reporting, making this team indispensable. Compare this to some other digital/technical initiatives, which may or may not materialize into long-term pillars of the company. Team size is small allowing for minimal internal bureaucracy (but at the same time requiring several hats to succeed).

The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",1962,Business Consulting,$1 to $5 billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
"Data Engineer, Americas","LVMH Perfumes & Cosmetics
","East Brunswick, NJ",$120K - $131K (Employer est.),3.6,"Company Description


LVMH Beauty activities benefit from exceptional dynamism that relies on both the longevity and development of key lines, and on the boldness of new creations.

All are driven by the same values: a quest for excellence, creativity, innovation, and perfect mastery of their image.

The brands cultivate what makes them unique and is guaranteed to make them stand out in a highly competitive global market. The success of the Beauty division depends on finding the right balance between major historic Houses such as Parfums Christian Dior, Parfums Givenchy, Acqua di Parma, Guerlain, and newer brands with strong potential like Kenzo Parfums, Fresh, and Make Up For Ever.

LVMH Beauty invites you today to join its North America teams.

LVMH Beauty is part of the LVMH Group.

The position is with LVMH Beauty Tech within the regional Americas team managing the Data platform and applications

LVMH Beauty Tech regional team is split between the North America LVMH Beauty Shared Service Center, the Mexico LVMH Beauty Shared Service Center and its San Francisco offices, servicing all major LVMH Beauty Brands for the region: Acqua di Parma, Benefit Cosmetics, Fresh, Guerlain, Kendo, Kenzo, Maison Francis Kurkdjian, MAKE UP FOR EVER, Parfums Christian Dior, Parfums Givenchy and Stella.



Job Description


Within the Data team, the role will be to participate in the design and the development of the Data platform (based on Google Cloud Platform and Dataiku).

Provide business teams with standardized, reliable, up-to-date and actionable data.

Work in close collaboration with other members of the WW Data team (Data tech lead, data engineers, data scientists) and other Beauty Tech teams (especially CRM, retail and e-commerce) to build a reliable, scalable and secure data platform.

Work on the entire data production chain by implementing data ingestion pipelines (from multiple sources and in different formats), storage, transformation ... then their provision: datamarts, reports, datasets to feed models scoring (data science), API, ... mainly using Dataiku and Google Big query
Ensure that the integration pipelines are designed in a manner consistent with the overall data framework in collaboration with the data tech lead and according to best practices.
Be part of a continuous improvement approach by optimizing and reusing existing assets.
Take part in data integration processing aspects of data quality controls, monitoring, alerting and technical documentation, as well as data management (data models and mapping, data documentation, repositories, description of the transformations applied, etc.)
Acquire a good understanding and analysis of business challenges and be able to translate the needs into the design of concrete technical solutions and gradually extend the functionalities and scope of our data platform based on Google cloud platform and Dataiku.
Provide reliable estimates of workloads and planning according to the level of complexity and other activities to allow a good coordination of the activities of the team.
Perform unit development tests and support business users in their tests before final validation.
Contribute to the design and management of the data model, as well as to the orientations in terms of the architecture of our data platform (repositories, APIs, etc.)
Set up pipeline monitoring and monitoring of the data platform and APIs (from a functional point of view and data quality)
Analyze incidents, points of weakness and support requests related to the use of the data platform or APIs
Provide timely and accurate support to the business teams on issues
Propose improvements to optimize the data platform (optimization of existing processes, data restructuring, factorization, etc.)

Reports to the Data Domain Director based in East Brunswick, NJ



Qualifications


Key competencies:

Mastery of the data stack components in Google Cloud Platform (certifications appreciated) including but not limited to: Google Big Query (nested fields, partitioning, merge SQL, authorized views, RLS, …), Cloud storage, Cloud functions, Cloud composer, Google Firestore, Google data catalog.
Proficiency of Dataiku (on Google big query): development of dataiku flows, implementation of scenarios, scheduling, management of versioning, releases into production, administration etc.
Mastery of complex SQL queries
Good knowledge of Python is a plus
Development practices with data exchange architectures: webservice, API, streaming. Salesforce MuleSoft a plus.
Development in an agile team and the tools used in CI / CD (Azure devops, Jira, Confluence)
Knowledge of Microsoft Power BI, data catalog tool, data quality, data management
Knowledge of Terraform and the administration of Google Cloud Platform appreciated (rights management, API activation, network settings, etc.)

Personal skills:

Autonomous and proactive
Perseverance
Curious and a desire to learn
Rigorous, organized and attentive to detail
Team spirit and knows how to work collectively in multidisciplinary teams
Problem solver
Very good communication, in particular the capacity of synthesis and popularization to make oneself understood simply
Solution designer, knows how to argue and make recommendations when several technical options are possible
Proactive team player

Profile:

Bachelor’s degree in Management, Computer Science or related field
Bi-lingual English/French is a plus
Minimum of 3 years’ experience in IT development roles such as data integration on Google Cloud & Dataiku

Additional Information


Normal and Main Office Environment: LVMH Beauty New Jersey or San Francisco office

Occasional travels to New York, San Francisco, Canada, Miami or South America

LVMH Inc. uses the published salary range as a guideline to provide our employees with market competitive pay while allowing for flexibility to recognize and reward various levels of expertise, performance and tenure.

While the published salary range is a good faith reflection of the targeted salary level for the position, LVMH Inc. reserves the right to pay outside of the published salary range of $120,000.00 - $130,916.00.

This job description is intended to cover the core accountabilities of the position and is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee. Duties, responsibilities, and activities may change, or new ones may be assigned at any time with or without notice.

All your information will be kept confidential according to EEO guidelines.",1987,Beauty & Personal Accessories Stores,$10+ billion (USD),Retail & Wholesale,10000+ Employees,Company - Public,True
Data Engineer - Azure Data Bricks,"N Consulting Ltd
","Weehawken, NJ",$60.00 - $70.00 Per Hour (Employer est.),5.0,"Job description

This is a Data Engineer role with Minimum 12 years of experience in a hybrid work arrangement in Weehawken, US. The Data Engineer needed to have Experience in Azure Data Bricks, Azure SQL, ADF, Kafka, Java programming and should have migration experience on Azure Cloud. Should have experience in day-to-day tasks associated with data engineering including data modeling, ETL, data warehousing and data analytics processes. The Data Engineer will also be responsible for ensuring high-quality data architecture solutions for our clients.

Qualifications

Data engineering, data modeling and ETL expertise
Data warehousing and data analytics skills
Strong programming skills in SQL, and Java programming.
Experience with cloud platforms Azure.
Experience in creating highly scalable and optimized data architectures.
Bachelor's degree in computer science, Data Science or a related field
Excellent problem solving and analytical skills.
Self-motivated and able to work independently or as part of a team.
Experience in the financial services industry is a plus.

Job Type: Contract

Salary: $60.00 - $70.00 per hour

Expected hours: 40 per week

Schedule:

8 hour shift
Monday to Friday

Ability to commute/relocate:

Weehawken, NJ 07086: Reliably commute or planning to relocate before starting work (Required)

Experience:

total: 10 years (Required)
Azure Data Factory: 7 years (Required)
Azure data bricks: 7 years (Required)

Work Location: In person",2012,Information Technology Support Services,$1 to $5 million (USD),Information Technology,1 to 50 Employees,Company - Private,True
Data Engineer,"Vydia
",New Jersey,$120K - $135K (Employer est.),4.3,"About Vydia:

Vydia is an end-to-end music technology platform and services company that provides labels with the infrastructure and tools to power their business. The company’s innovative solutions in rights management, automated royalty accounting, advanced payments, and daily performance analytics provide leaders in music and culture with the unfettered ability to publish, distribute, and monetize their audio-visual content on a global scale. Vydia is a wholly-owned division of gamma., the artist-first multimedia platform providing creative and business services across all artistic and commercial formats founded by CEO Larry Jackson and President Ike Youssef. To learn more, please visit vydia.com

Description:

This position is dedicated to keeping our data at the highest quality, integrity, efficiency, and scalability. The ideal candidate holds high personal standards for thorough and accurate work, achieving business needs, and submitting deliverables within timelines.

You will be a key player in delivering a robust suite of services that our Labels and Artists use to distribute, monetize, and analyze content that we deploy to all of the top industry music streaming platforms and social platforms, such as YouTube, Spotify, Apple, and Tiktok.

You will be joining a small, but growing team, with the opportunity to provide high-impact results for various initiatives the company will outline over the next few years. This position will work alongside fellow engineers, business intelligence, and product managers to bring our data to the highest standards and support ongoing scale.

Responsibilities:

Plan, design, implement, and test ETL/ELT DAGs using Airflow and AWS cloud services like ECS, S3, Redshift, EC2, RDS, EKS, etc.
Integrate with data & reporting APIs to collect data and normalize across multiple sources
Work closely with product engineers to make application data available for product features
Work closely with business analysts to orchestrate Business Intelligence reporting using Looker
Work alongside your fellow data engineers and BI engineers in accomplishing business, product, and technical goals
Uphold, introduce, and refine data quality standards, engineering best practices, and KPIs
Challenge existing structures and thought processes
Clearly and concisely communicate ideas to both technical and non-technical stakeholders and peers
Share knowledge and expertise with teammates and vice versa
Contribute to documentation coverage and test coverage
Constantly strive to improve engineering workflows and efficiency, and heavily utilize automation whenever applicable
Optimize data pipelines for performance, scalability, and data quality
Work closely with DevOps to optimize cloud infrastructure performance and scalability
Participate in code reviews

Qualifications:

4+ years of experience as a Data Engineer
Strong Python 3 skills (classes, closures, OOP, unit testing)
Efficient SQL with an eye for readability and good style (PostgreSQL and Redshift experience is a plus. DBT or Airflow is also a plus.)
4+ years of AWS (or related, GCP) experience
Experience with data warehousing
Passionate about the latest developments in technology
A friendly, collaborative, and passionate team player
Fast at learning and seeks constructive criticism; experience with Code Reviews
Can dive into a fast-paced environment.
Collaborative team player with the ability to adapt to change quickly; Scrum/Agile methodologies
Can intuitively extract values and insights from data.
Experience interfacing with REST API’s; Oauth, and Rate Limiting
You can articulate the merits and pitfalls of the different approaches when discussing potential solutions.
Data quality is always top of mind.
High personal code/development standards (peer testing, unit testing, documentation, etc.)
Excellent communication skills

Nice to Haves:

AWS Certified DevOps Engineer - Professional
Certified Kubernetes Administrator (CKA)
Docker Certified Associate
Helm

The Vydia Development Experience:

Join an environment where there is an emphasis on individual growth, experimentation, and ownership. You’ll find a team that is focused on creating a great experience for our clients, partners, and coworkers alike. From technical education to career growth, you will be given the resources needed to excel.

Reasons to work with us:

Vydia is certified as a Great Place to Work™ company and has been named Best Place to Work in NJ by NJBIZ 5x (2023 most recent) due to its collaborative, fast-paced, fun, thriving environment. Additionally, Vydia has been named a 2023 Fortune Best Workplaces in New York.
Vydia was honored with the 2023 TechUnited Catalyst of Technology Award for our cutting-edge technology and scalable platform that provides global music entrepreneurs and their labels the ability to stay independent. Vydia was also named the 2022 winner of the NJBIZ Business Of The Year award (51-100 employees) which recognizes the state’s most dynamic businesses and business leaders who share a commitment to professional excellence, business growth, and the community.
Major growth opportunities alongside the growth of the company; Vydia has been identified as an Inc 500 Fastest Growing Company in America and by Entrepreneur Magazine as one of the most Entrepreneurial companies in America
Join a mission-based culture that enjoys giving back to the community through a variety of initiatives that are meaningful to our team members
Full medical/dental/vision package, 401k retirement with employer matching, and financial wellness plans
We invest in your growth and development, providing a professional development stipend for continued education and mentorship to support your career goals
Hybrid flexibility to work from home (depending on role)
Generous vacation policy including paid maternity/paternity leave
Vydia provides equal employment opportunities to all applicants and employees and strictly prohibits any type of harassment or discrimination in regard to race, religion, age, color, sex, disability status, national origin, genetics, sexual orientation, protected veteran status, gender expression, gender identity, or any other characteristic protected under federal, state, and/or local laws.
Consistent with the Americans with Disabilities Act (ADA), it is the policy of Vydia to provide reasonable accommodation when requested by a qualified applicant or employee with a disability, unless such accommodation would cause an undue hardship. The policy regarding requests for reasonable accommodation applies to all aspects of employment, including the application process. If reasonable accommodation is needed, please contact HR@Vydia.com
Your employment with Vydia is on an at-will basis, meaning either you or the Company can terminate the employment relationship, at any time, for any or no reason, and with or without cause or notice. As an at-will employee, your employment with Vydia is not guaranteed for any length of time.

For all California residents, to learn more about how Vydia processes your personal information when you apply for a job, please visit our California Job Applicant Privacy Policy at https://vydia.com/california-job-applicants-privacy-policy/",2013,Broadcast Media,$5 to $25 million (USD),Media & Communication,51 to 200 Employees,Company - Private,True
Azure Data Engineer,iShare Inc,"Florham Park, NJ",$60.00 - $90.00 Per Hour (Employer est.),-1.0,"Must Have
1. Good Azure Experience
2. Ready to go onsite in New Jersey ateleast 3 days / week
3. Ready to work on a W2 and not requiring any visa sponsorship now or in the future

Job Purpose:

Data Engineer will be critical to design, develop, and maintain the infrastructure and systems necessary for the collection, storage, processing, and analysis of large volumes of data. Data Engineers play a critical role in enabling organizations to make data-driven decisions and derive valuable insights from their data assets. Data Pipeline development, Data Modeling and Architecture. The Data Engineer will support our software developers, database architects, data analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Data Engineer will play a crucial role in the development and support of cloud database systems for our new customer platform. Collaborates with cross-functional teams using the Agile methodology and Azure Cloud to create modern software applications, implement new technologies, and deliver end-to-end solutions utilizing DevOps and engineering practices.

Essential Duties & Responsibilities:

Expertise in designing, building, and maintaining scalable data pipelines and ETL (Extract, Transform, Load) processes.
Experience with data modeling and database design principles.
Knowledge of data warehousing concepts and tools.
Understanding of data governance, data quality, and data integration techniques.
Proficiency in Microsoft Azure cloud services, including Azure Data Factory, Azure Databricks, Azure SQL Database, Azure Data Lake, etc.
Proficiency in data visualization tools like Power BI, Sisense
Experience with managing and optimizing cloud-based data storage and processing solutions.
Knowledge of Azure DevOps for CI/CD (Continuous Integration/Continuous Deployment).
Understanding of cloud security and compliance principles
Familiarity with data integration tools (e.g., Apache Kafka, Apache Nifi)
Understanding of machine learning concepts and experience with ML platforms like Azure Machine Learning or TensorFlow
Minimum Qualifications & Competencies:

A bachelor's or master's degree in computer science, data science, or a related field.
Strong programming skills, particularly in languages like Python, Java, or Scala.
Proficiency in SQL and experience with relational databases (e.g., MySQL, PostgreSQL).
Familiarity with distributed computing frameworks, such as Apache Hadoop and Apache Spark.
Experience with version control systems like Git.
Knowledge of software engineering principles and best practices
Strong problem-solving skills and the ability to work independently and in a team environment.
Effective communication skills to collaborate with stakeholders, data scientists, and other teams.
Attention to detail and ability to prioritize tasks in a fast-paced environment.
Continuous learning mindset to keep up with the evolving data engineering landscape.

Internal Responsibilities:

Adheres to all company policies and procedures including, but not limited to those identified within the Standards of Business Conduct and the Employee Handbook, as may be amended from time to time. Adheres to all applicable laws and regulations and the company's governance/compliance program.
Responsible for reporting violations of the company's policies and procedures, Standards of Business Conduct, governance program, laws and regulations through the company or other mechanism that may be available at the time of the violation. Assists with internal control failure remediation efforts.
Becomes knowledgeable of internal control responsibilities through training and instruction. Responsible and accountable for internal control performance within their area of responsibility. Participates in the internal controls self-assessment process. Logging of work details and progress made towards assigned responsibilities ensuring our software capitalization and commitment timelines are met.
Ensures concerns with internal control design or performance and process changes that impact internal control execution are communicated to management.

Job/Functional Knowledge
Understands duties and responsibilities, has necessary functional and technical knowledge for task completion, keeps job knowledge current, applies knowledge and skills that lead to success in the job.

Effectively applies background & experience to current role.
Demonstrates a comprehensive knowledge of particular field.
Keeps informed of latest trends, developments, and best and current practices in particular field

Use of Technology
Adapts to new technology, keeps abreast of changes and keeps knowledge up-to-date, learns new programs quickly, follows technology practices and standards.

Creativity/ Innovation
Generates new ideas, challenges the status quo, takes risks, supports change, encourages innovation, solves problems creatively.

Culture Fit
Demonstrates integrity and ethics in day-to-day tasks and decision-making, adheres to core values of doing what is right, exceeding customer expectations, driving results and value, innovate to improve, treat people with respect, embrace teamwork and collaboration and have fun while achieving business goals.

Sincerely passionate for and committed to the mission of Managed Health Care Associates
Exhibits integrity in all actions and communication.
Works well autonomously, while acting as a team-player
Demonstrates a vested interest in self-development.


Travel: N/A

Physical Demands:
The physical demands and work environment characteristics described here are representative of those that an employee must meet to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Physical Demands: While performing the duties of this job, the employee is occasionally required to move around the work area; sit; perform manual tasks; operate tools and other office equipment such as computer, computer peripherals and telephones; extend arms; kneel; talk and hear. The employee must occasionally lift and/or move up to 15 pounds.
Mental Demands: the employee must be able to follow directions, to get along with others, and handle stress.
Work environment: The noise level in the work environment is usually minimal.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,True
"Union Bldg Engineer, Data Center","CBRE
","Rutherford, NJ",-1,4.0,"Posted
17-Nov-2023
Service line
GWS Segment
Role type
Full-time
Areas of Interest
Building Management, Data Centers
Location(s)
Rutherford - New Jersey - United States of America
JOB SUMMARY

This role utilizes advance skills to perform preventative maintenance and corrective repairs in a Data Center operation. Oversight of electrical and mechanical systems, including but not limited to: Universal Power Supply (UPS) systems, generators, chillers, Electrical Distribution, HVAC systems, Building Management Systems (BMS) systems, and CMMS Work Dispatching.

ESSENTIAL DUTIES AND RESPONSIBILITIES

Perform daily site inspections of all Mechanical & Engineering (M&E) systems and technical equipment, including servicing and maintenance.

Under close supervision, complete assigned work according to established processes and procedures in accordance with CBRE's Environment, Health and Safety Policy - ensuring all safety processes and PPE requirements are followed. Also, ensure all regulatory requirements and quality standards are met.

Oversee third-party vendors, ensuring compliance with CBRE's developed processes, procedures, and all applicable laws/regulations.

Accompany vendors on site visits on an as needed basis, and ensure site standards are met.
Help create and develop work processes, Job Hazard Analysis reports, and SOPs for critical work with risk assessment. Ensure that CERM documents and logbooks are updated.

Complete all required training in order to ensure successful completion of all job-related responsibilities

SUPERVISORY RESPONSIBILITIES

No formal supervisory responsibilities in this position.
May provide informal assistance such as technical guidance and/or training to coworkers.
May coordinate work and assign tasks.
QUALIFICATIONS
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required.
Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

EDUCATION and EXPERIENCE
High School Diploma/GED required.
Knowledge of emergency response/standby/call out activities and protocols. Background in either HVAC or Electrical, preferred.

CERTIFICATES and/or LICENSES
None

COMMUNICATION SKILLS
Ability to comprehend and interpret instructions, short correspondence, and memos and ask clarifying questions to ensure understanding. Ability to respond to common inquiries or complaints from clients, co-workers, and/or supervisor.

FINANCIAL KNOWLEDGE
Requires basic knowledge of financial terms and principles. Ability to calculate simple figures such as percentages.

REASONING ABILITY
Ability to understand and carry out general instructions in standard situations. Ability to solve problems in standard situations. Requires basic analytical skills.

OTHER SKILLS and/or ABILITIES
Ability to comprehend and interpret instructions, short correspondence, and memos. Also, ability to ask clarifying questions to ensure understanding.
Ability to write routine reports and correspondence.
Ability to respond to common inquiries or complaints from clients, co-workers, and/or supervisor.
Ability to effectively present information to an internal department and/or large groups of employees.

SCOPE OF RESPONSIBILITY
Decisions made with general understanding of procedures and company policies to achieve set results.
CBRE is an equal opportunity employer that values diversity. We have a long-standing commitment to providing equal employment opportunity to all qualified applicants regardless of race, color, religion, national origin, sex, sexual orientation, gender identity, pregnancy, age, citizenship, marital status, disability, veteran status, political belief, or any other basis protected by applicable law. We also provide reasonable accommodations, as needed, throughout the job application process. If you have a disability that inhibits your ability to apply for a position through our online application process, you may contact us via email at recruitingaccommodations@cbre.com or via telephone at +1 866 225 3099 (U.S.) and +1 866 388 4346 (Canada).

NOTE: Some, but not all, of our positions may have an additional requirement to comply with COVID-19 health and safety protocols, including COVID-19 vaccination proof and/or rigorous testing. If you have questions about the requirement(s) for this position, please inform your Recruiter.",1906,Real Estate,Unknown / Non-Applicable,Real Estate,10000+ Employees,Company - Public,False
Data Engineer,"EmpiRx Health
","Montvale, NJ",$85K - $115K (Glassdoor est.),4.3,"Who we are:

EmpiRx Health is a disruptor in an ever-changing healthcare industry, offering a market-differentiating, value-based pharmacy benefits management solution. We are bold and fearless in our approach to healthcare, how we talk about ourselves, and our use of advanced technology and analytics.

What we do:

We partner with HR and Benefits managers nationwide ensuring our membership has access to the best pharmacy benefits available. We place more emphasis on member care than any other PBM by focusing on health outcomes first. Our pharmacists and clinicians are at the center of everything we do―and our population health solution delivers tailored strategies for our clients. Every day, our pharmaceutical staff is consulting with physicians to drive the greatest clinical and financial outcomes.

The employee experience:

EmpiRx Health has become a category creator and an award-winning leader in the healthcare space because we invest in our people. Our leadership teams drive the employee experience with strengths-based learning and development. Using Gallup’s CliftonStrengths assessment, our managers ensure employees have opportunities to excel by maximizing their top strengths and infinite potential. At EmpiRx, every employee is empowered to bring the best version of themselves to a safe environment where their voice is heard, and their talents are developed. We’ve eliminated formal performance reviews, opting to rely on the manager-employee relationship to drive individual and organizational performance. Fostering collaboration, open dialogue, and continuous improvement is how we’ve created a talent-driven, nimble organization where ground-breaking ideas are celebrated. Recognized by Inc. 5000 and the Validation Institute, EmpiRx Health is also certified as a Great Place to Work, and winner of Fortune’s Best Workplaces and Modern Healthcare’s Best Places to Work.

EmpiRx Health is experiencing explosive growth and is seeking a Data Engineer to be a part of our special team. It’s an exciting time to be a part of EmpiRx Health. Come grow with us!

Who you are:

The candidate will be instrumental in optimizing our data architecture, ensuring data accuracy, and building scalable solutions to support the company's business needs. You will be responsible for generating high quality data extracts for clients, vendors, and partners. You will be instrumental in the developing, testing, and maintenance of internal applications. You will support business users to allow for business continuity. You have an extensive knowledge of the software development life cycle and proven track record for automating tasks.

What you will be doing:

Deep knowledge and experience designing, building, testing, and maintaining cloud pipelines and leverage Azure Databricks for data processing.
Good understanding and working experience of Databricks Unity catalog and relational databases using Databricks Lakehouse, Datawarehouse and SQL server.
Develop and maintain ETL workflows, including data transformation, validation, and loading.
Proficiency in different coding languages. Specifically, Python, SQL, and C#
Work with several different APIs to and from external vendors as well as Low/no code development tools such as PowerApps and Power Automate, logic apps, functions.
Able to work with agile teams as they perform feature level design, development, testing, and performance analysis.
Develop and maintain data lake, data models, views, tables, and data marts to make healthcare data more liquid.
In depth knowledge of Azure cloud services and Azure Data Factory and Databricks workflows
Experience working with BI reporting platforms like Domo and familiarity with Power BI and SSRS
Develop and harmonize healthcare clinical and claims data models, and data feeds.
Manage sftp connectivity between EmpiRx Health and clients/vendors/partners for the purposes of data (Rx Claims, Medical claims) exchange via GoAnywhere MFT.
Managing Sftp users, create new users or modify existing users as required to enable colleagues/coworkers to securely exchange data with third parties (clients, vendors, partners, etc.)
Automate data retrieval and data posting via GoAnywhere MFT to support business needs.
Manage inventory of Incoming and Outgoing data feeds to enable the team and the business keep up with operational and compliance requirements.
Experience with Google SDK to connect and download Json from Google buckets preferred.
Develops and implements new and measurably efficient ways of doing work.
Assess data ingestion/extraction pipelines/procedures on a regular basis to evaluate effectiveness and identify problems, and initiate corrective actions as needed.
Ensure there are no errors or omissions (for a given process (Data Ingestion/Extraction, program), etc.)
Serve as subject matter expert by providing reliable, correct information/assistance to colleagues/coworkers/clients/vendors/partners/etc. are related to Data/Data processes.
Stay current with developments and trends in Data field and find opportunities to apply in the processes.
Collaborate with cloud architects, tech leads to facilitate Azure SQL Server to Databricks migration.
Ensure Data procedures/guidance/documentation is well communicated, understood, and carried out, with limited assistance.
Communicates issues and outages to team in a timely manner.
Respond to all stakeholders’ inquiries and collaborate with them in a timely manner.
Anticipate colleagues/coworkers, client, vendor, etc. needs and requests and take proactive action to address and clarify received requests to make sure what is needed is available in a timely and cost-effective way.
Consistently identify the need for information necessary to understand issues, evaluate problems and opportunities for improvement; collects that information and uses it in analyzing and evaluating potential or actual changes

What you need:

Minimum of 3+ years of RDBMS experience
Demonstrable expertise working with Python programming language.
Demonstrable experience with Azure Databricks or ADF
Familiarity with source code management in Git, Azure DevOps etc.
Familiarity with software such as SSMS, Visual Studio, Visual Studio Code, GoAnywhere
Excellent written and verbal communication skills
Excellent critical thinking and time-management skills
Ability to think critically and have time management skills
Familiarity and working knowledge of the Microsoft office suite

Preferred Background:

Bachelor’s or higher degree in Computer Science or related discipline (preferred)
Databricks certification is a plus
5+ years of RDBMS experience
3+ years of hands-on experience in programming languages such as Python, SQL, PowerShell scripting, C# etc.
2+ years of experience working with Azure Databricks or ADF
3+ years of hands-on experience in programming languages such as Python, SQL, PowerShell scripting, C# etc

Benefits and Perks:

Our family and LGBTQ-friendly benefits reflect our commitment to supporting a diverse workforce. Our benefits include medical, prescription, vision, dental, life, and disability insurance with coverage for domestic partnerships. Additionally, we offer a 401K program, parental leave for childbirth and adoption, and student loan reimbursement. Additional perks include flexible PTO, flexible work arrangements, online wellness resources with complimentary tools and access to counselors and advocates, and bi-weekly “take a break” sessions.

Location: Remote or Montvale, NJ office location

EmpiRx Health is an Equal Opportunity Employer

P075iYeVLr",2014,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,51 to 200 Employees,Company - Private,True
"JR. DATA ENGINEER | (w2/ own Corporation) | GC, USC || Below 6 years ||",Resourcesys Inc,"Piscataway, NJ",$45.00 - $55.00 Per Hour (Employer est.),-1.0,"NEW JERSEY/ New York CANDIDATES ONLY, VISA - GC & Citizen,

Role: JR. DATA ENGINEER (Marketo and Alteryx)

Location: Piscataway, NJ – 3 days onsite a week
6 month C2H

Skills Needed:

Job Description:

1. Do they have a minimum of 5 years of IT experience?

2. Do they have experience with Tableau reporting?

3. Experience with Alteryx?

4. Experience with Marketo or other email marketing platforms?

5. Have they ever worked with difficult stakeholder? How did they handle them?

Job Description:

Position Overview:
As a Junior Data Engineer with a specialization in Marketo and Alteryx, you will play a crucial role in extracting, transforming, and delivering valuable data insights to support our business initiatives. You will work closely with cross-functional teams, serving as a bridge between technical data operations and business stakeholders.

Key Responsibilities:

Data Integration: Collaborate with the IT and Marketing teams to design and implement data integration pipelines that connect Marketo with our data infrastructure.
Data Manipulation: Leverage Alteryx to transform, cleanse, and manipulate raw data from various sources into formats suitable for analysis, reporting, and visualization.
Data Quality: Ensure data accuracy, consistency, and completeness through data profiling, validation, and data cleansing techniques.
ETL (Extract, Transform, Load): Develop ETL processes to move, transform, and load data from source systems to data warehouses.
Reporting and Visualization: Create and maintain dashboards and reports to provide business stakeholders with actionable insights derived from Marketo data.
Collaboration: Work closely with marketing and sales teams to understand their data requirements and help them make data-driven decisions
Documentation: Maintain clear and comprehensive documentation for data processes, data models, and transformation workflows.
Data Security: Ensure compliance with data privacy and security regulations and best practices.
Adaptability: Stay current with industry trends and new data technologies, providing suggestions for improvements and optimization.

Job Type: Contract

Salary: $45.00 - $55.00 per hour

Experience:

Marketo: 4 years (Preferred)
Alteryx: 4 years (Preferred)
Tableau reporting: 5 years (Preferred)

Work Location: On the road",-1,-1,-1,-1,-1,-1,True
Python Data Engineer,"Euclid innovations
","Jersey City, NJ",$65.00 - $70.00 Per Hour (Employer est.),4.4,"Title: Python Data Engineer

Location: Iselin, NJ(Hybrid)

Client: Large Financial Group

Job Description:

Duties

Integration engineers responsible for daily support and project-based development of credit risk management systems.

ETL developers are responsible for designing and creating the data warehouse and all related extraction, transformation and load of data functions.

This is an opportunity to gain experience in risk management processing using new technologies.

Skills

5 years of full-time development experience using Python
Experience building data piplines using Azure Data Factory and Databricks
Experience with Python application frameworks (Django, Flask, Pyramid, Tornado)
Experience with Python testing and code analysis tools (Pytest, Pylint)
Strong SQL skills
Familarity with SSIS
Strong troubleshooting skills
On-point communication skills

Job Type: Contract

Salary: $65.00 - $70.00 per hour

Expected hours: 40 per week

Experience level:

8 years

Schedule:

8 hour shift

Experience:

Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)

Ability to Commute:

Jersey City, NJ 07302 (Required)

Ability to Relocate:

Jersey City, NJ 07302: Relocate before starting work (Required)

Work Location: In person",2009,Information Technology Support Services,$5 to $25 million (USD),Information Technology,201 to 500 Employees,Company - Private,True
Temporary - Business Intelligence Data Engineer,"IEEE Corporate
","Piscataway, NJ",$78K - $111K (Glassdoor est.),4.1,"Job Summary

The overall purpose of this position is to support business and data-related initiatives taken on by the department. The incumbent in this position is expected to play an active role in the support, design, and implementation of data repositories, data pipelines, applications, and APIs that enable innovative and optimal ways of utilizing IEEE data in the Enterprise Data Warehouse and the Adobe Marketo Engage application. The role would be ideally suited for a competent Data Engineer who is looking to move into data ingestion pipelines, data visualizations, and data analytics applications.


You are responsible for responding to incoming requests for data services and recommending solutions with respect to target lists.
You will apply your passion for detail and understanding of business data and data architecture to providing data-based solutions to address various use cases presented by our customers.
Superior Service delivery requires a conceptual understanding of business ownership of various customer departments as well as an ability to verify and validate results.
Service delivery is managed through our team activity tracking system.
Your work is largely directed at incoming requests from customers. Proposed solutions and resolution delivery are observable by email cc and the request management system. Work volume is self-managed and in collaboration with peers and their managers.
This role has no reports.


The successful candidate will work under supervision and should be a self-starter with good technical, analytical, and problem-solving skills and a passion for learning and adopting innovative technologies to support business needs efficiently. The candidate should also have strong skills in communication and collaboration with peers and internal customers.


Key Responsibilities
Respond to work requests that result in carefully constructed Business Intelligence reports, target lists, ad hocs, and counts based on internal customer needs.
Perform data querying and validating functions.
Write general queries, views, stored procedures, and functions.
Provide best practices support and guidance to end users regarding usage of data output.
Collaborate with business stakeholders and internal customers to understand their needs and define or enhance reporting requirements.
Demonstrate outstanding communication skills to translate reporting requests in order to accurately meet the actual information and deadline needs of users.
Analyze data in the data warehouse and related sources to establish knowledge of data for accurate retrieval and use in data outputs.
Assist in troubleshooting and facilitating solutions for data issues.
Design, develop, and deploy visualizations built using the Tableau business intelligence tool.
An ability to grasp the fundamentals of converting data that is not natively intuitive and converting or ""wrangling"" it into a usable format.
Understanding of data warehousing concepts such as data migration and data integration in cloud platforms such as AWS and Azure.
Excellent data troubleshooting skills.
Ability to draft simple business documents describing processes, data investigation results, and confirmation of business requests involving data.
Ability to describe challenges and solutions in both technical and business terms.
Ability to develop and maintain excellent working relationships at all organizational levels.


Qualifications

Education
Bachelor's degree or equivalent experience in Computer Science, Mathematics, Engineering, or similar discipline preferred. Req

Work Experience

2 to 4 years of Relevant experience with data structures, queries, and BI tools such as Tableau, QlikView, Cognos, Python, SQL, etc. Req
2 years of Basic understanding of analysis and/or data ETL tools. (Ability to question and evaluate data quality in reports. Req
2 years of Familiarity with relating data from different and disparate data sources. Plus
4 years of Experience with data visualization tools. Plus
2 years of Experience in a collaborative Agile environment. Pref



Skills and Requirements

Advanced Excel skills
Solid MSWord, PowerPoint, Visio (for workflow documentation), and Google skills
Solid presentation, public speaking, and communication skills
Solid analytic, problem-solving, conceptual, and data interpretation skills
Strong written and verbal communication skills including the ability to communicate complex information effectively to technical and non-technical users.
Demonstrated understanding of business intelligence best practices
Ability to work successfully in a team environment and independently, effectively handling detail-oriented work while meeting schedules and deadlines.
Ability to prioritize and manage time effectively, thrive in a fast-paced work environment, and manage multiple projects simultaneously.
Ability to take ownership and initiative on projects.
Exhibits professional demeanor, interpersonal skills, and excellent customer service
Demonstrates a willingness and ability to learn and contribute.
Must be a technologically and communications-savvy knowledge worker who seeks out technology solutions to business challenges and processes.
Foundation in database technologies and related query languages.

Other Requirements:

Data cleansing, analysis, and visualization skills, with the ability to grasp complex data relationships and patterns.
Good communication skills, with the ability to understand complex business user requirements and present solutions clearly and concisely.
Demonstrable history of seeking, acquiring, and applying new skills and remaining current on emerging data engineering technologies.
Sound problem-solving and critical thinking skills


As defined in IEEE Policies, individuals currently serving on an IEEE board or committee are not eligible to apply.
PLEASE NOTE: This position is not budgeted for employer-sponsored immigration support, this includes all persons in F (both CPT and OPT), J, H, L, or O status.


For information on work demands and conditions required for this position, please consult the reference document, ""Physical, Mental, and Work Environment Standards for IEEE Positions."" This position is classified under ' + Category I - Office Positions + '.
IEEE is an EEO/AAP Employer/Protected Veteran/Disabled

============================================== 'Disclaimer: This job description is proprietary to IEEE. It outlines the general nature and key features performed by various positions that share the same job classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties and qualifications required of all employees.


Job: Data & Analytics
Primary Location: United States-New Jersey-Piscataway
Schedule: Full-time
Job Type: Temporary
Job Posting: Nov 2, 2023, 5:51:20 AM",1963,Grantmaking & Charitable Foundations,$100 to $500 million (USD),Nonprofit & NGO,1001 to 5000 Employees,Nonprofit Organization,False
Data Engineer,"Princeton University
","Princeton, NJ",$79K - $111K (Glassdoor est.),4.5,"Overview:
The Department of Sociology at Princeton University seeks applicants for a full-time Data Engineer position in the Eviction Lab. Successful candidates will have a background in data science and/or computer science.

The data engineer will contribute to the Eviction Lab at Princeton University’s mission to create data and research products to help researchers, policymakers, and community members understand the eviction crisis.


Salary is competitive and is benefits-eligible. Applicants should submit a dossier including: (1) a complete vita, (2) a cover letter of interest, (3) names and contact information of up to three persons who can serve as references, (4) a coding sample or data product that speaks to applicant’s experience with relevant tasks. All materials should be submitted as 1 continuous PDF. Applications will be considered on a rolling basis. Start date is flexible. Materials submitted by regular mail or email will not be accepted.
Responsibilities:
The responsibilities of the position include leading the development, maintenance, and testing of pipelines for eviction record data; writing production-ready R and SQL code to support the team’s internal and external data products, including the Eviction Tracking System (ETS); ensuring ETS and other internal data products are operational and accurate; streamlining existing data systems; and working with research and communications staff to make data accessible to external and internal users. This is a one year term position with the possibility of renewal.

Qualifications:
Essential Qualifications:
Bachelor's degree or equivalent
3+ years experience
Extensive experience writing reproducible, functional, and literate data pipelines written in R using a tidy framework
Writing production ready SQL
Operational data store (ODS), APIs, (extract transform load processes), ETLs, as well as complementary tools
Database management tools (dbt)
Git
Demonstrated ability to lead a small data engineering team, create an automated production-ready data pipeline

Preferred Qualifications:
Stata
Python
ArcGIS or other GIS software
Experience parsing administrative court data
Regular expressions (regex)

Princeton University is an Equal Opportunity/Affirmative Action Employer and all qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity or expression, national origin, disability status, protected veteran status, or any other characteristic protected by law. KNOW YOUR RIGHTS
Standard Weekly Hours: 36.25 Eligible for Overtime: No Benefits Eligible: Yes Probationary Period: 180 days Essential Services Personnel (see policy for detail): No Estimated Appointment End Date: 12/1/2024 Physical Capacity Exam Required: No Valid Driver’s License Required: No Experience Level: Mid-Senior Level : #Ll-DP",1746,Colleges & Universities,Unknown / Non-Applicable,Education,5001 to 10000 Employees,College / University,False
Sr. Data Engineer,"Mondelēz International
","East Hanover, NJ",$96K - $136K (Glassdoor est.),4.0,"Job Description

Are You Ready to Make It Happen at Mondelēz International?

Join our Mission to Lead the Future of Snacking. Make It With Pride.

Together with analytics team leaders you will support our business with excellent data models to uncover trends that can drive long-term business results.

How you will contribute

Looking for a savvy Sr Data Engineer to join team of Modeling / Architect experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.

The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.

The Data Engineer will support architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Experience

8+ years of overall industry experience and minimum of 6-7 years of experience in building and deploying large scale data processing pipelines in a production environment using GCP.

Qualification

Science or Engineering Degree with master’s in computer science (desirable)
A master’s in computer science, Computer, Electrical Engineering, or a related field.
Self-reflective, has a hunger to improve, has a keen interest to drive their own learning. Applies theoretical knowledge to practice
Ability to work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues
Ability to think creatively, plan and prioritize work in a fast-paced environment.
Experience working with Google Cloud Platform (Big Query, GCS, Cloud Function, Composer etc.)
GCP Professional Data Engineer certification (desirable)
Having Experience of business domains like FMCG/ CPG /Retail /Supply Chain will be added advantage.

What extra ingredients you will bring:

Data engineering Concepts : Experience in working with data lake, data warehouse, data mart and Implemented ETL/ELT and SCD concepts.
ETL or Data integration tool : Experience in Talend is highly desirable.
Analytics: Fluent with SQL, PL/SQL and have used analytics tools like Big Query for data analytics
Cloud experience: Experienced in GCP services like cloud function, cloud run, data flow, data proc and big query.
Data sources : Experience of working with structure data sources like SAP, BW, Flat Files, RDBMS etc. and semi structured data sources like PDF, JSON, XML etc.
Programming: Understanding of OOPs concepts and hands-on experience with Python/Java for programming and scripting.
Data Processing : Experience in working with any of the Data Processing Platforms like Dataflow, Databricks.
Orchestration: Experience in orchestrating/scheduling data pipelines using any of the tools like Airflow and Alteryx

Nice to have

Visualization : Exposure of reporting tools like Tableau, Looker and PowerBI.
API : Experience in implementing solutions involving REST APIs, Graph QL etc.
DevOps: Worked with framework involving CI-CD pipelines, like Jenkins and Git setup. Should have understanding about Identity and Access Management (IAM) from cloud standpoint.
Data Quality: Exposure of all the phases of testing, data validation and data reconciliation.
Have Built analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.

No Relocation support available

Business Unit Summary

The United States is the largest market in the Mondelēz International family with a significant employee and manufacturing footprint. Here, we produce our well-loved household favorites to provide our consumers with the right snack, at the right moment, made the right way. We have corporate offices, sales, manufacturing and distribution locations throughout the U.S. to ensure our iconic brands—including Oreo and Chips Ahoy! cookies, Ritz , Wheat Thins and Triscuit crackers, and Swedish Fish and Sour Patch Kids confectionery products —are close at hand for our consumers across the country.

Mondelēz Global LLC is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected Veteran status, sexual orientation, gender identity, gender expression, genetic information, or any other characteristic protected by law. Applicants who require accommodation to participate in the job application process may contact 847-943-5460 for assistance.

Job Type

Regular

Analytics & Modelling

Analytics & Data Science",2012,Food & Beverage Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Data Migration Engineer,"ELLKAY, LLC
","Elmwood Park, NJ",$72K - $119K (Glassdoor est.),3.9,"ELLKAY is a nationwide leader in healthcare connectivity, providing innovative, customizable solutions and unparalleled services for over a decade. We empower diagnostic laboratories, PM/EMR vendors, ACO and HIE companies, hospitals, and other healthcare organizations with cutting-edge technologies and solutions that improve their bottom lines.

Our 'Client-first' focus has made ELLKAY one of the most respected healthcare IT companies in the nation. We value our clients and believe that strong relationships are the foundation for a strong company, and we're dedicated to providing connectivity to the healthcare industry.

Company Culture: We deal with medical data and we take our work very seriously, but not ourselves. If you’re a smart, hard-working, dedicated individual who thrives in a laidback, friendly work environment, ELLKAY may be the place for you. We’re committed to attracting good people who are passionate about the work they do.

ELLKAY was founded over a decade ago on the values of innovation, efficiency, and service created in a collaborative work culture. As we have grown, we are proud to still possess the same energy and passion for what we do. We strive to provide exceptional customer experiences to our clients, which begins with first employing amazing people. ELLKAY is proud to maintain a high-quality, innovative, and diverse workforce.

Job Description

ELLKAY has been rated the #1 data migration and transformation company in the U.S. healthcare market, and we’re looking to expand our EMR Data Migration!

We’re looking for a detail-oriented, problem-solving team players with a strong technical background to fill our Data Migration Engineer position.

You will be responsible for performing data extraction of discrete and non-discrete data from various EMR Systems and migrate these datasets to other EMR systems and Archive. Qualified candidate will serve as the primary point of contact for EMR data migration process for assigned projects and will be responsible to meet project timelines.

Essential Duties and Responsibilities:

Assess client’s desired scope, analyze client data and design project plan.
Proactively identifies issues and works on resolution plan to alleviate impact on project.
Set up environment for EMR data Migration and performs ETL for desired databases
Performs data validation and testing to ensure accuracy
Evaluate and identify opportunities to drive continuous process improvements
Manage multiple projects simultaneously and prioritize tasks to ensure timely delivery
Coordinate deliverables with various internal departments.
Set and manage appropriate expectations for successful project execution.

Qualifications:

Bachelor’s degree Computer Science, Data Analytics or related field
2+ years Experience with data analysis and SQL
Knowledge of healthcare data & workflow preferred
Strong problem solving and analytical skills
Ability to exercise effective decision-making capabilities in a fast-paced environment.
Excellent communication and organizational skills

Benefits:

ELLKAY offers a comprehensive and competitive benefit package that starts day one!

Including:

A Competitive salary
401k w/ matching – once eligibility is met
Work/life balance
Paid Volunteer Program
Flexible working hours
Flexible time off
Remote work options
Employee Discounts
Parental Leave

Our awesome culture includes:

Working with talented, collaborative, and friendly people who love what they do
Professional growth within
Innovation environment
On site in HQ Free daily lunches

Additional information

This is a full time position for our Elmwood Park, NJ HQ. Remote work may be available within the US.

For more information on our company, visit www.ELLKAY.com.

Interested applicants should submit a letter of interest with salary requirements and resume.

ELLKAY LLC is a Smoke-Free Workplace.

ELLKAY, LLC provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",2002,Enterprise Software & Network Solutions,$5 to $25 million (USD),Information Technology,51 to 200 Employees,Company - Private,True
Hybrid Jr. Data Engineer,"firstPRO Inc.
","Willingboro, NJ",$90K - $115K (Employer est.),4.7,"Hybrid Jr. Data Engineer Opening

5+ Years of experience required

Looking for someone with strong experience in cloud orchestration platforms, especially Azure Data Factory and Databricks.
Expertise with SQL, database design and data structures (star/snowflake schemas, de/normalized design)
Familiarity with DevOps tools such as git, TFS, CI/CD, Jira

Hybrid in office a few days a week in Willingboro, NJ.

Role is Full-Time, Direct-Hire.

Job Type: Full-time

Pay: $90,000.00 - $115,000.00 per year

Compensation package:

Yearly pay

Experience level:

5 years

Schedule:

Monday to Friday

Ability to commute/relocate:

Willingboro, NJ 08046: Reliably commute or planning to relocate before starting work (Required)

Experience:

Data Engineering: 5 years (Required)
Azure: 5 years (Required)
Data Bricks: 5 years (Preferred)

Work Location: In person",1986,HR Consulting,$25 to $100 million (USD),Human Resources & Staffing,51 to 200 Employees,Company - Private,True
"Associate Director, Data Engineer (Hybrid)","Otsuka
","Princeton, NJ",$113K - $157K (Glassdoor est.),4.0,"Job Description
About Otsuka
We defy limitation, so that others can too. In going above and beyond—under any circumstances—for patients, families, providers, and for each other. It’s this deep-rooted dedication that drives us to uncover answers to complex, underserved medical needs, so that patients can push past the limitations of their disease and achieve more than they thought was possible each and every day.
About the Role
The Omnichannel Center of Excellence (CoE) is dedicated to driving innovation, building and delivering capabilities that enhance Otsuka’s opportunity make an impact in the lives of those we serve. We achieve this through our relentless focus on customer centricity, patient empathy, expertise in enabling pathways for disease education and awareness of management options, and our unwavering commitment to supporting access to treatment.
We are looking for an Omnichannel Data Engineer will design, build, and maintain a secure, scalable, and efficient data infrastructure that supports the data needs of the Omnichannel Advanced Analytics team. By designing and implementing efficient and reliable data systems, the data engineer will help Otsuka make data-driven decisions that inform customer engagement.
Job Expectations/Responsibilities:
Design, develop, and maintain data architecture and pipelines to support the analytics platform / decision engine of the Omnichannel CoE, including infrastructure to reconcile business rules with decision engine recommendations.
Collect and integrate common pharmaceuticals data (e.g., claims) from multiple sources, adhering to ETL principles to prepare the data for analysis.
Engineer features for the decision engine by partnering with brand Omnichannel leads to find new ways to combine disparate data sources to better understand customers.
Design and implement scalable data systems that can handle large amounts of data, while also accommodating future growth
Optimize data processing performance to reduce processing times and improve data retrieval speeds.
Collaborate with internal & external cross-functional business partners and IT to ensure that the data infrastructure meets Otsuka’s goals and objectives.
Collaborate on MLOPS life cycle experience with MLOPS workflows traceability and versioning of datasets.
Collaborate, coach, and learn with a growing Omnichannel Analytics team, identifying and developing long-term processes, frameworks, tools, methods and standards.
Ensure that data is properly managed, governed, and secured, following industry best practices and regulatory requirements.
Stay connected with external sources of ideas through conferences and community engagement and leverage emerging tools and processes to improve data engineering.
Build and maintain familiarity with Otsuka data engineering tech stack including Python, PySpark, SQL, and Snowflake
Leverage powerful tools and fundamental principles of engineering and data science to contribute to engineering solutions in a dynamic, team-focused environment.
Build and maintain familiarity with Otsuka Machine Learning tech stack including AWS, Kubernetes, Snowflake, and Dataiku
Model Otsuka’s core competencies (Accountability for Results, Strategic Thinking & Problem Solving, Patient & Customer Centricity, Impact Communications, Respectful Collaboration & Empowered Development) that define how we work together at Otsuka. Key matrixed partners included: Brand Marketing, Creative / CRM / Digital agencies, Media, Market Research, Analytics, Otsuka Information Technology (OIT), Sales Operations, and Medical/Regulatory/Legal integrated business partners.
Minimum Qualifications:
Bachelor’s degree in data sciences, computer science and 4+ years of relevant experience
Preferred Knowledge, Skills, and Abilities:
Demonstrated experience with scripting and implementing data analytics algorithms and models. Hands on experience using a modeling and simulation software (e.g. Python, Matlab, R, NONMEM, SAS, S-Plus, etc) is a plus
Knowledge/Experience in the usage of machine learning/AI tools in life science area(s) and handling life science datasets is preferred
Excellent interpersonal, technical, and communication skills to lead cross-functional teams
Profound grasp of Machine Learning lifecycle - feature engineering, training, validation, scaling, deployment, scoring, monitoring, and feedback loop.
Have implemented machine learning projects from initiation through completion with particular focus on automated deployment and ensuring optimized performance.
Ability to work in a fast-paced environment and strong technical communication skills
Our Benefits:
Comprehensive medical, dental, vision and prescription drug coverage
Company provided Basic Life, AD&D, Short-term and Long-term Disability insurance
Tuition reimbursement
401(k) match
PTO allotment each calendar year, paid holidays, and paid leave programs as well as other company provided benefits
#LI-Hybrid
Competencies
Accountability for Results - Stay focused on key strategic objectives, be accountable for high standards of performance, and take an active role in leading change.
Strategic Thinking & Problem Solving - Make decisions considering the long-term impact to customers, patients, employees, and the business.
Patient & Customer Centricity - Maintain an ongoing focus on the needs of our customers and/or key stakeholders.
Impactful Communication - Communicate with logic, clarity, and respect. Influence at all levels to achieve the best results for Otsuka.
Respectful Collaboration - Seek and value others’ perspectives and strive for diverse partnerships to enhance work toward common goals.
Empowered Development - Play an active role in professional development as a business imperative.
Come discover more about Otsuka and our benefit offerings;
https://www.otsuka-us.com/careers-join-otsuka
.
Disclaimer:

This job description is intended to describe the general nature and level of the work being performed by the people assigned to this position. It is not intended to include every job duty and responsibility specific to the position. Otsuka reserves the right to amend and change responsibilities to meet business and organizational needs as necessary.

Otsuka is an equal opportunity employer. All qualified applicants are encouraged to apply and will be given consideration for employment without regard to race, color, sex, gender identity or gender expression, sexual orientation, age, disability, religion, national origin, veteran status, marital status, or any other legally protected characteristic.

If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation, if you are unable or limited in your ability to apply to this job opening as a result of your disability. You can request reasonable accommodations by contacting
Accommodation Request
.
Statement Regarding Job Recruiting Fraud Scams
At Otsuka we take security and protection of your personal information very seriously. Please be aware individuals may approach you and falsely present themselves as our employees or representatives. They may use this false pretense to try to gain access to your personal information or acquire money from you by offering fictitious employment opportunities purportedly on our behalf.
Please understand, Otsuka will never ask for financial information of any kind or for payment of money during the job application process. We do not require any financial, credit card or bank account information and/or any payment of any kind to be considered for employment. We will also not offer you money to buy equipment, software, or for any other purpose during the job application process. If you are being asked to pay or offered money for equipment fees or some other application processing fee, even if claimed you will be reimbursed, this is not Otsuka. These claims are fraudulent and you are strongly advised to exercise caution when you receive such an offer of employment.
Otsuka will also never ask you to download a third-party application in order to communicate about a legitimate job opportunity. Scammers may also send offers or claims from a fake email address or from Yahoo, Gmail, Hotmail, etc, and not from an official Otsuka email address. Please take extra caution while examining such an email address, as the scammers may misspell an official Otsuka email address and use a slightly modified version duplicating letters.
To ensure that you are communicating about a legitimate job opportunity at Otsuka, please only deal directly with Otsuka through its official Otsuka Career website
https://vhr-otsuka.wd1.myworkdayjobs.com/en-US/External
.
Otsuka will not be held liable or responsible for any claims, losses, damages or expenses resulting from job recruiting scams. If you suspect a position is fraudulent, please contact Otsuka’s call center at: 800-363-5670. If you believe you are the victim of fraud resulting from a job recruiting scam, please contact the FBI through the Internet Crime Complaint Center at:
https://www.ic3.gov
, or your local authorities.
Otsuka America Pharmaceutical Inc., Otsuka Pharmaceutical Development & Commercialization, Inc., and ODH, Inc. (“Otsuka”) does not accept unsolicited assistance from search firms for employment opportunities. All CVs/resumes submitted by search firms to any Otsuka employee directly or through Otsuka’s application portal without a valid written search agreement in place for the position will be considered Otsuka’s sole property. No fee will be paid if a candidate is hired by Otsuka as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position specific. Please, no phone calls or emails.",1989,Biotech & Pharmaceuticals,Unknown / Non-Applicable,Pharmaceutical & Biotechnology,1001 to 5000 Employees,Company - Private,False
Senior Data Engineer - U.S. Based Remote,"Anywhere Real Estate
","Madison, NJ",$130K - $160K (Employer est.),3.5,"It's an exciting time to be a part of Anywhere's team! We're working to build and improve a platform that will deliver modern, flexible solutions for our real estate professionals to work more efficiently while simultaneously crafting a one of a kind experience for home buyers and sellers. Combining great technology with phenomenal people drive our goals, and we are looking for a Senior Data Engineer to join our team to reach them.

We're looking for:
Dedicated and Creative: You thrive on developing powerful, stable, and intuitive applications. Working alongside a team of passionate individuals, you bring your creativity to the forefront.
Big Data and Java Mastery: Your validated experience has honed your skills in Big Data and Java2. Now, you’re eager to elevate your expertise to new heights.
Ambitious Projects: You relish in bold projects that involve large data sets. Even under pressure, you remain cool and focused.
Agile Environment: Fast-paced environments and agile development methodologies are your comfort zone. You embrace them wholeheartedly.
Analytical Skills: Your analytical prowess is unmatched, ensuring quality and precision in your work.
Collaborative Work Ethic: You thrive in collaborative settings, working closely with product managers, designers, and fellow engineers to achieve greatness at Anywhere Real Estate.

What you’ll do:

Build high-performance, scalable data solutions that cater to the needs of millions of agents, brokers, home buyers, and sellers.

Design, Develop and test robust, scalable data platform components.

Collaborate with various teams and individuals to understand their data pipeline requirements and devising innovative solutions.

Work with a dedicated team of engineers, and multi-functionally with product managers and designers to define new data products and features.



Skills, accomplishments, interests:

BS/MS in Computer Science, Engineering, or related technical subject area and/or equivalent combination of training and experience.

5+ years core Scala/Java experience: building business logic layers and high-volume/low latency/big data pipelines.

3+ years of experience in large scale real-time stream processing using Apache Flink or Apache Spark with messaging infrastructure like Kafka/Pulsar.

5+ years of experience on Data Pipeline development, ETL and processing of structured and unstructured data.

3+ years of confirmed experience using NoSQL systems like MongoDB, DynamoDB and Relational SQL Database systems (PostgreSQL) and Athena.

Experience with technologies like Lambda, API Gateway, AWS Fargate, ECS, CloudWatch, S3, Datadog.

Experience owning and implementing technical/data solutions or pipelines

Excellent written and verbal communication skills in English.

Strong work ethic and entrepreneurial spirit.

#LI-JC1
#LI-Remote
#Dice
#AnywhereEngineers




Exciting News:

EEO Statement: EOE AA M/F/Vet/Disability

Compensation Range:

The base salary for this position is $130,000 to $160,000.",-1,Real Estate,Unknown / Non-Applicable,Real Estate,Unknown,Company - Public,False
Data Engineer - Snowflake,"the NBA
","Secaucus, NJ",$120K - $143K (Employer est.),4.2,"WORK OPTION: Remote


The NBA is committed to providing a safe and healthy workplace. To safeguard our employees and their families, our visitors, and the broader community from COVID-19, and in consideration of recommendations from health authorities and the NBA’s own advisors, any individual working onsite in our New York and New Jersey offices must be fully vaccinated against COVID-19. The NBA will discuss accommodations for individuals who cannot be vaccinated due to a medical reason or sincerely held religious belief, practice, or observance.


Position Summary:

You will be part of a growing Data Engineering team that handles NBA data for Internal and External Users. The IT department services over 10 internal groups and the Data Engineer will be a seasoned Technologist comfortable with a variety of data technologies. Data Engineering Group handles a data warehouse that sources data out of over 15 sources and services over 10 internal groups. The current data technology stack is a cloud-based solution utilizing Microsoft’s Azure platform. Data technologies deployed within the cloud platform include Azure Data Lake Storage (ADLS), Azure Databricks and Databricks Delta Lake, and Snowflake Data Warehousing. Related data tools and capabilities include AI/ML models using Databricks, Python, and R, and data cataloging using Alation and FiveTran for some data ingestion.




We're looking for someone who is laser-focused on operational excellence and customer satisfaction. You'll need to wear many hats, so flexibility and a can-do attitude are critical! We are looking for a dynamic, collaborative personality that can champion the cause of Agile within the organization. The individual should be a recent graduate with intern experience in a fast-paced environment where they utilize their technical skills and can-do attitude to add value to an established team with minimal supervision. A passionate engineer who strives for automation would be ideal for this position.




As a Data Engineer, you will lead NBA’s data efforts across all products and lines of business. You are a pioneer, building new capabilities that will help unlock new possibilities for our businesses. You will coordinate with external and internal resources to be a part of a Data Engineering practice. You will play a fundamental role in achieving our ambitious growth objectives. You must be comfortable switching between multiple projects, contributing as an individual, and working with both business teams and technology teams to translate business requirements into a finished product. You possess strategic vision and tactical mastery and combine it with an entrepreneurial spirit to get it done. You will collaborate closely with stakeholders across the company to design innovative solutions and balance challenging priorities and resource demands.


The right candidate is someone who is passionate about data technologies. We’re looking for someone who welcomes challenges and is hyper-focused on delivering exceptional results to internal business customers while creating a rewarding team environment.

This position reports to the Data Engineering Team Lead, IT


Major Responsibilities:

Understand business needs and develop solutions that delight consumers and customers
Understands Agile artifacts and develops applications based on business priority. Collaborate with project partners to ensure all requirements are met. Handles relationships with end-user communities. Interacts regularly with users to gather feedback, listen to their issues and concerns, and recommend solutions.
Build scalable, fault-tolerant batch and real-time data pipelines to power internal applications, operational workflows, and business intelligence platforms
Create and maintain data-driven APIs to support a wide range of integration with NBA partners
Recommend and implement best practices for data management and governance
Demonstrate your technical abilities and contribute to our overall architecture
Help implement the Enterprise Data Architecture for NBA and help implement it in multi-functional alignment with the Data teams that exist across functions like Marketing, Finance, HR, etc.
Provide insights during application design and development for highly complex or critical machine learning projects across numerous lines of business and shared technology.
Ensure alignment to enterprise architecture and usage of enterprise platforms when delivering projects
Continuously improve the quality of deliverables and SDLC processes


Required Skills/Knowledge:

Master’s Degree in Computer Science, Engineering, or Management of Info Systems/Technology preferred
Advanced Education in Statistics or Mathematics would be a plus
3+ years building data warehouses using Snowflake
Experience using Snowflake tools like Snowpipe and Snowpark
2+ years of experience using DBT to build data pipelines
3+ years of experience in developing BigData and/or machine learning solutions
3+ Years of experience defining and/or designing data architectures
Experience with the MS Cloud stack (Azure) or AWS
Experience with SQL, NoSQL, BigData, and Graph Technologies along with Programming languages like R, Python, Kafka, Storm, etc.
Background in agile SW development and Scaled Agile Frameworks
Someone who is a passionate coder and can spin up a snippet of code quickly
Strategic thinker with the ability to build and execute innovative digital products, combined with a tactical ability to execute simultaneously against multiple contending priorities
Someone with an iterative approach, the drive to move fast, and think big
Experience working with and/or managing internal and external teams at the same time, working with multiple brands and digital properties of varying maturities
Demonstrated ability to partner and communicate effectively with non-technical team members, resolving contending or contradictory objectives, and unifying disparate ideas into a homogenized solution
Ability to be versatile and handle multiple projects and reprioritization
Possess the ability to influence others, implement change, and standardize processes in a complex business environment
A passion for data and growing in your current role
Superb communication skills (both written and verbal)
Great teammate – should be ready to go beyond to help the immediate team and not be averse to not shy away from asking for help if needed.
Ability to translate ideas into solutions based on user and business needs
Open Eagerness to learn new technologies and bring new ideas to the table


Education:

Bachelor'see or equivalent. Masters would be a plus.


Salary Range: $120,000 - $142,500


The NBA does not accept unsolicited resumes from search firms or any other third parties. Any unsolicited resume sent to the NBA will be considered NBA property, and the NBA will not pay a fee should it hire the subject of any unsolicited resume.


The NBA considers applicants for all positions on the basis of merit, qualifications, and business needs, and without regard to race, color, national origin, religion, sex, age, disability, sexual orientation, gender identity, alienage or citizenship status, ancestry, marital status, genetic predisposition or carrier status, veteran status, familial status, status as a victim of domestic violence, or any other status or characteristic protected by applicable federal, state, or local law.


About the NBA
The National Basketball Association (NBA) is a global sports and media organization with the mission to inspire and connect people everywhere through the power of basketball. Built around five professional sports leagues: the NBA, WNBA, NBA G League, NBA 2K League and Basketball Africa League, the NBA has established a major international presence with games and programming available in 215 countries and territories in more than 50 languages, and merchandise for sale in more than 200 countries and territories on all seven continents. NBA rosters at the start of the 2021-22 season featured a record 121 international players from 40 countries. NBA Digital’s assets include NBA TV, NBA.com, the NBA App and NBA League Pass. The NBA has created one of the largest social media communities in the world, with 2.1 billion likes and followers globally across all league, team, and player platforms. Through NBA Cares, the league addresses important social issues by working with internationally recognized youth-serving organizations that support education, youth and family development, and health-related causes.",1946,Sports & Recreation,$5 to $10 billion (USD),"Arts, Entertainment & Recreation",1001 to 5000 Employees,Company - Private,False
Sr. Data Engineer,"Combined Insurance
","Whitehouse Station, NJ",$100K - $133K (Glassdoor est.),3.3,"We are looking for an experienced and motivated Senior ETL Developer to join our dynamic team. In this role, you will lead the delivery of key projects in support of North America financial reporting from the enterprise data warehouse and associated data marts, including the Business Analytics Repository (BAR). BAR is a strategic application within the business, feeding into multiple systems and applications both up and downstream with data that directly supports business decisions being made each and every day. You will be responsible for leading ETL development projects, coordinating with cross-functional teams to ensure project success, and creating and maintaining data integration solutions to meet business requirements. The ideal candidate will have experience with ETL development solutions such as AWS Glue, Google Dataflow, Azure Data Factory, Snowflake, Informatica/IICS and be able to identify and resolve data quality issues, performance bottlenecks, and other ETL-related problems.

Responsibilities:

Lead ETL development projects and coordinate with cross-functional teams to ensure project success
Create and maintain data integration solutions to meet business requirements
Identify and resolve data quality issues, performance bottlenecks, and other ETL-related problems
Design and develop scalable ETL workflows and data pipelines using ETL tools such as Informatica/IICS
Ensure compliance with data governance and security policies
Develop and maintain documentation such as technical design documents, data lineage, and ETL runbooks
Mentor junior ETL developers and provide technical guidance to the team
Evaluate modern technologies and tools, and recommend solutions to improve ETL processes and performance
Contribute to the architecture, design, and development of data warehousing and business intelligence solutions
Understands data mapping and data modeling methodologies including normal form, star, and snowflake to reduce data redundancy and improve data integrity.
Participate in analysis, design, and ETL development as part of Agile development methodologies and provide status updates to the management
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assesses the impact, and collaborates with Scrum Team and Leadership to incorporate current trends and developments in current and future solutions",1922,Insurance Carriers,$500 million to $1 billion (USD),Insurance,Unknown,Subsidiary or Business Segment,False
Sr. Big Data Engineer,"Ait
","Jersey City, NJ",$70.00 Per Hour (Employer est.),3.9,"Sr. BigData Engineer

Location: Jersey City, NJ [Hybrid Role] Look for Locals

Duration: FTE with Mphasis and C2C

Salary: $120-125K, Depend on Experience

Rate: $65-70/hr on C2C

Client-Mphasis/JPMC

Job Description:

Overall, 9+ Years of experience, with hands-on Bigdata development, production Exp.
Experience with AWS - CI/CD
Experience with Linux/Unix scripting
Experience troubleshooting long running Unix/Linux processes, Analyzing query plans, etc.
Exposure to Hadoop / Spark
Experience with Stored Procedures
Experience with RDBMS (Good to have)
Hands-on experience writing / supporting Java/Spring boot applications.
Good communication

Job Types: Full-time, Contract

Salary: Up to $70.00 per hour

Experience level:

10 years

Schedule:

8 hour shift

Application Question(s):

Looking for candidates local to NJ
Please do not apply if already been submitted to Mphasis/Jpmc

Education:

Bachelor's (Preferred)

Experience:

Big data development: 10 years (Required)
Aws: 5 years (Required)
CI/CD: 3 years (Required)
Hadoop: 5 years (Required)
Spark: 5 years (Required)
Java: 4 years (Required)
Stored procedure: 4 years (Required)

Willingness to travel:

75% (Required)

Work Location: On the road",1956,-1,$25 to $100 million (USD),-1,1001 to 5000 Employees,Self-employed,True
Software Engineer - Java / Big Data,"UBS
","Weehawken, NJ",$106K - $135K (Glassdoor est.),3.9,"United States - New Jersey
Information Technology (IT)
Group Functions

Job Reference #

280451BR

City

Weehawken

Job Type

Full Time

Your role

Are you looking to accelerate your cloud computing career? Do you want to be part of a team that designs and builds next generation data solutions using the latest technologies? Are you confident working with data professionals, collaborating across technology areas and engaging with key business stakeholders?

At UBS, we re-imagine the way we work, the way we connect with each other – our colleagues, clients, and partners – and the way we deliver value. Being agile will make us more responsive, more adaptable, and more innovative.

We are looking for a Software Engineer to:


implement and deliver high quality software solutions and components for the CDIO Group Functions Data Platform that conform to architectural standards
leverage expertise to mentor and lead developers
review code and designs, and ensure adherence to standards
deliver development tasks end-to-end and work closely with other development, testing, and implementation teams to roll out important regulatory and business improvement programs
leverage the latest tools and technologies to increase team productivity and collaboration across teams
play a vital role in designing, developing, and delivering solutions that deliver high quality increments to the product goal

Your team

You will be part of a global team based within CDIO GF Data Platform. Our team is building a strategic Azure cloud calculation and data platform, MEGDP (Multi-Tenant Enterprise Governed Data Platform), for Group Finance and Risk to replace existing legacy systems. The MEGDP serves many use cases including regulatory reporting, analytics, and data science.


Diversity helps us grow, together. That’s why we are committed to fostering and advancing diversity, equity, and inclusion. It strengthens our business and brings value to our clients.

Your expertise

Bachelor’s degree in engineering or science or foreign equivalent required from an accredited institution
data management and automation on Spark experience
hands-on technical experience with big data systems including experience in designing and implementing large distributed systems
experience with Data management, automation on Spark, performance optimization, automation and unit tests
experience with container management platforms like Kubernetes
excellent debugging, critical thinking, and communication skills
end to end Test of the integrated system (continuous integration can be a major help here)
solid knowledge of QA methodologies, test planning, system dependencies, and product integration phases
experience with build, test and maintaining a scalable test automation framework and test scripts to ensure repeatability, coverage, reliability and catching regressions
hands on experience in creating test plans for new features and improving existing test plans including identifying areas for automation
Technical Skills:

Programming Language: Scala, Java, Spark
Tools: Gitlab, Sonar, docker hub, container registry, nexus, Postman, Azure CLI
Build Scripting: Gradle, Maven, Shell
Packaging Tool/Technology: Shell
Cloud Technology: Azure
Hosting: Experience with container management platforms like Kubernetes and databricks
Data: Storage accounts, PostgreSQL, knowledge on Spark and Data Bricks API,
Security: Azure AD (SAML Token based, Single sign-on), Hashi corp Vault, Managed Identities (Service Principals)
Monitoring: Log Analytics, Azure Metrics, Azure Monitor,
Infrastructure as Code (IaC): ARM
Test Automation:

Test Frameworks: Cucumber, Junit, Mockito
Tools: Gitlab, Sonar, docker hub, container registry, nexus, Postman
Build Scripting: Maven, Shell

About us

UBS is the world’s largest and only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal & Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors.

With more than 70,000 employees, we have a presence in all major financial centers in more than 50 countries. Do you want to be one of us?

How we hire

This role requires an assessment on application. Learn more about how we hire: www.ubs.com/global/en/careers/experienced-professionals.html

Join us

At UBS, we embrace flexible ways of working when the role permits. We offer different working arrangements like part-time, job-sharing and hybrid (office and home) working. Our purpose-led culture and global infrastructure help us connect, collaborate, and work together in agile ways to meet all our business needs.

From gaining new experiences in different roles to acquiring fresh knowledge and skills, we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we’re more than ourselves. Ready to be part of #teamUBS and make an impact?

Disclaimer / Policy Statements

UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce.",1862,Investment & Asset Management,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
Sr Data Engineer,"HIGH BRIDGE CONSULTING LLC
","Paramus, NJ",$40.00 - $70.00 Per Hour (Employer est.),4.0,"THIS IS A W2 ONLY REQ - NO C2C - NO SUBS

Our client, is the global leader in optimized resource management. They have nearly 200,000 employees worldwide. The client designs and provides water, waste and energy management solutions which contribute to the sustainable development of communities and industries.
They are now looking to hire a Sr Data Engineer on a contract basis. This is onsite 2 days a week in the Paramus office. The ideal candidate must have:

More than 4 years of experience developing with Python.
4+ years performing with production environments in a DevOps culture managing code composed of multi-developer teams, following industry best practices.
4+ years SQL development experience.
Experience with data modeling
4+ years bash scripting experience.
Strong experience with Git, CI/CD (preferably GitLab) and Docker.
Experience deploying and running services in Cloud Big Data platforms such as BigQuery.
Strong experience with GCP services.
Experience designing and building data pipelines using tools Google Data Fusion (CDAP) or other ETLs.
Knowledge with CDC design patterns and their challenges.
Experience with DAG workflows orchestration such as Prefect.
Experience with NoSQL databases is a plus (i.e Firestore, MongoDB).
Experience designing and developing APIs is a plus (i.e using FastAPI, Flask).
Nice To Have: Google Cloud Data Engineer

Education / Experience / Background:

MS degree in Computer Science or computer related field from an accredited institution.
5+ years hands proven experience as a Data Engineer or similar role.
5+ years of strong experience building, running and maintaining datalake(s) and warehouse(s) in a cloud environment.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,True
Data Engineer II,"AmTrust Financial Services, Inc.
","Jersey City, NJ",$85K - $100K (Employer est.),3.3,"Overview:

Responsible for design, development, testing, and maintenance of data architectures including large scale databases, data pipeline processes, and data delivery solutions. Maintains a solid understanding of AmTrust’s mission, vision, and values. Upholds the standards of the AmTrust organization.

Responsibilities:
Assemble large, complex sets of data that meet the reporting and analytics needs of the enterprise.
Analyze raw data sources and develop, test, and implement optimized data pipeline solutions and controls.
Design, develop, test, and implement queries, reports, cubes, and dashboards in support of business analytic needs.
Continuous focus on improving data quality and efficiency.
Interface with business analysts to discuss timelines and clarify requirements as it pertains to new projects, enhancements and bug fixes.
Adherence to DevOps, SDLC, and Change Management practices
Keeps current with market trends and demands.
Performs other functionally related duties as assigned.
Qualifications:
Advanced knowledge of SQL, T-SQL and/or PL/SQL; Ability to write complex, highly optimized queries across large volumes of data.
A thorough understanding of data pipeline construction and ETL processes.
Proficiency with SSIS | SSAS | SSRS
Expertise in database design methodologies.
Excellent analytic skills.
5+ years of data focused technical experience


Preferred:

Excellent oral and written communication skills.
Ability to communicate complicated/ technical information to non-technical audiences in an efficient and simple method.
Curiosity and passion for data, visualization and solving problems
Highly creative in order to determine the best solutions for real-world problems with quantitative data.
Enjoy collaborating with others in a team atmosphere.
Eagerness to learn in a fast-paced environment.
B.S. degree in Computer Science, Math, Statistics, or related technical field, or equivalent professional experience.
Property & Casualty insurance experience a plus.

This job description is designed to provide a general overview of the requirements of the job and does not entail a comprehensive listing of all activities, duties, or responsibilities that will be required in this position. AmTrust has the right to revise this job description at any time.

The salary range for this role is $85,000-$100,000. This range is only applicable for jobs to be performed in Jersey City, New Jersey. Base pay offered may vary depending on, but not limited to education, experience, skills, geographic location, travel requirements, sales or revenue-based metrics. This range may be modified in the future. This job is also bonus eligible.

#LI-GD1
#LI-HYBRID
What We Offer:
AmTrust Financial Services offers a competitive compensation package and excellent career advancement opportunities. Our benefits include: Medical & Dental Plans, Life Insurance, including eligible spouses & children, Health Care Flexible Spending, Dependent Care, 401k Savings Plans, Paid Time Off.

AmTrust strives to create a diverse and inclusive culture where thoughts and ideas of all employees are appreciated and respected. This concept encompasses but is not limited to human differences with regard to race, ethnicity, gender, sexual orientation, culture, religion or disabilities.

AmTrust values excellence and recognizes that by embracing the diverse backgrounds, skills, and perspectives of its workforce, it will sustain a competitive advantage and remain an employer of choice. Diversity is a business imperative, enabling us to attract, retain and develop the best talent available. We see diversity as more than just policies and practices. It is an integral part of who we are as a company, how we operate and how we see our future.",1998,Insurance Carriers,$5 to $10 billion (USD),Insurance,5001 to 10000 Employees,Company - Private,False
"Senior Data Engineer, Public Company","Recruiting From Scratch
","Newark, NJ",$100K - $200K (Employer est.),4.0,"This is for a client of Recruiting from Scratch.
Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Our Client:

Our next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we’re blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.

With a track record of strong financial performance and plans for continued headcount growth, we’re looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us.

What’s so interesting about this role?

Our client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .

In this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.

What’s the job?

Design, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.
Moving implementation to ownership of real-time and batch processing and data governance and policies.
Maintain and enforce the business contracts on how data should be represented and stored.
Stay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users
Implementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.
Work closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.

What we’ll love about you

5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.
7+ years experience using Python,
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )
Significant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.
Experience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Experience with dimensional data modeling and schema design in Data Warehouses
Familiar with ETL (managing high-quality reliable ETL pipelines)
Be familiar with legal compliance (with data management tools) data classification, and retention.

Salary Range: $165,000-$210,000 USD base. Equity. Medical, Dental, Vision.
https://www.recruitingfromscratch.com/",2019,Staffing & Subcontracting,$1 to $5 million (USD),Human Resources & Staffing,1 to 50 Employees,Company - Private,True
Senior Data Engineer,"Audible
","Newark, NJ",$115K - $161K (Glassdoor est.),3.7,"Good storytelling starts with great listening. At Audible, that means each role and every project has our audience in mind. Because the same people who design, develop, and deploy our products also happen to use them. To us, that speaks volumes.

ABOUT THIS ROLE
This opportunity is within Audible’s Data Engineering group. The Data Engineering group owns technology platforms and datasets that enable systems and people to uncover new insights and fine-tune operations to meet business goals. We need your help designing and building these.

As a Senior Data Engineer, you will...

Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to build systems that meet business needs
Build systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices
Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications
Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines
Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts
Peer review work, actively mentor other members of the team, improving their skills, their knowledge of our systems and their ability to get things done

ABOUT AUDIBLE
At Audible, we innovate and inspire through the power of voice. We're changing the narrative on storytelling. As a leading creator and provider of premium audio storytelling, we've redefined the ways people access, discover, and share stories. The stories we tell have the ability to transport and transform everyday moments into meaningful experiences and it's our people who make Audible's service possible. We're listeners, storytellers, and problem-solvers. Our perspectives and experiences power our ideas and come together in our mission to unleash the power of the spoken word. Audible offers a Hub+Home hybrid workplace model that gives employees flexibility between gathering in an Audible workspace (work from hub) and remote work (work from home). For more information, please visit adbl.co/hybrid.

We are open to hiring candidates to work out of one of the following locations:

Newark, NJ, USA

Basic Qualifications


3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language

Preferred Qualifications


3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent

Audible is committed to a diverse and inclusive workplace. Audible is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",1995,Film Production,Unknown / Non-Applicable,Media & Communication,1001 to 5000 Employees,Subsidiary or Business Segment,False
Sr. Big Data Engineer,"PSRTEK
","Union, NJ",$43K - $156K (Employer est.),4.5,"Sr. BigData Engineer

Location: Jersey City, NJ [Hybrid Role]

Duration: FTE with Mphasis only and C2C

Job Description:

Overall, 8 + Years of experience, with hands-on Bigdata development, production Exp.
Experience with AWS - CI/CD
Experience with Linux/Unix scripting
Experience troubleshooting long running Unix/Linux processes, Analyzing query plans, etc.
Exposure to Hadoop / Spark
Experience with Stored Procedures
Experience with RDBMS (Good to have)
Hands-on experience writing / supporting Java/Spring boot applications.
Good communication skills

Job Types: Full-time, Contract

Salary: $42,581.90 - $156,325.72 per year

Ability to commute/relocate:

Union, NJ 07083: Reliably commute or planning to relocate before starting work (Required)

Experience:

Hadoop: 10 years (Preferred)
Kafka: 10 years (Preferred)

Work Location: In person",-1,Information Technology Support Services,Unknown / Non-Applicable,Information Technology,Unknown,Company - Private,True
Azure Data Engineer - Hybrid Model,Arjava Technologies Inc,"Mount Laurel, NJ",$60.00 - $75.00 Per Hour (Employer est.),-1.0,"This is a hybrid model with 2 days Onsite and 3 days remote.

```Duties:```

Azure Data Bricks Experience with PySpark & SQL.
Azure Data Factory Experience.
Ingestion Experience.
Python Experience.
Should have knowledge on Migration.
Should be proficient on Azure Data Lake.
Azure Synapse experience will be added advantage.
Good communication Skills and Problem-Solving Skills.
Customer facing experience.

```Qualifications:```
- Bachelor's degree in Computer Science, Engineering, or a related field
- Strong programming skills in Python , PySpark & SQL.
- Experience with Cloud Technologies
- Familiarity with data ETL concepts and technologies
- Proficiency in SQL for data manipulation and analysis
- Experience with Agile development methodologies
- Strong problem-solving and analytical skills
- Excellent communication and collaboration skills

Job Types: Full-time, Contract

Pay: $60.00 - $75.00 per hour

Expected hours: 40 – 50 per week

Compensation package:

1099 contract

Experience level:

8 years

Schedule:

8 hour shift

Experience:

Azure: 8 years (Preferred)

Ability to Commute:

Mount Laurel, NJ 08054 (Preferred)

Work Location: Hybrid remote in Mount Laurel, NJ 08054",-1,-1,-1,-1,-1,-1,True
Data Operations Engineer,"Daiichi Sankyo, Inc.
","Basking Ridge, NJ",$81K - $116K (Glassdoor est.),4.0,"Join a Legacy of Innovation 110 Years and Counting!

Daiichi Sankyo Group is dedicated to the creation and supply of innovative pharmaceutical therapies to improve standards of care and address diversified, unmet medical needs of people globally by leveraging our world-class science and technology. With more than 100 years of scientific expertise and a presence in more than 20 countries, Daiichi Sankyo and its 16,000 employees around the world draw upon a rich legacy of innovation and a robust pipeline of promising new medicines to help people. Under the Group’s 2025 Vision to become a “Global Pharma Innovator with Competitive Advantage in Oncology,” Daiichi Sankyo is primarily focused on providing novel therapies in oncology, as well as other research areas centered around rare diseases and immune disorders.
Summary
The candidate will work in R&D Data Integrations Operations team to deliver foundational data capabilities like Data Lakes, Master Data Management, NLP Integrations etc. for Clinical, Regulatory & Translational Research. The candidate will have direct accountability to evolving data lake platform for the R&D domain of Daiichi Sankyo globally. The candidate will be part of Dev Ops Team - responsible to build data platforms, test, deploy and support in accordance with DSI SDLC standards. This is a highly technical and hands on role.

Responsibilities


Defining database design, data flows and data integration techniques. Design and Build data solutions ensuring data quality, reliability, availability and data governance.
Evolve RD Master Data Management platform. Create Data processing routines for managing enterprise master data throughout the data lifecycle (capture, processing and consumption). Maximize business outcomes using MDM via improved data integrity, visibility, and accuracy.
Manage and Evolve global data lakes platforms – Develop Data Ingestion, Data Enrichment, Data DEIDENTIFICATION routines and RESTful API’s for consumption of data lakes data. Enable technologies, platforms and workflows to enable analysts and data scientists to focus on algorithms and analyses.
Serve as primary point of contact for implementation of complex data project. Provide technical expertise, risk analysis, business and technical assessment of change requests in relation to data platforms. Implement and document approved change requests.
Collaborates with domain experts in privacy, security, and compliance to ensure that the RD data platforms uphold privacy, security, and compliance requirements.
Qualifications: Successful candidates will be able to meet the qualifications below with or without a reasonable accommodation.
Education Qualifications (from an accredited college or university)


Bachelor's Degree or higher degree in Computer Science or a related discipline from an accredited college or university preferred
Experience Qualifications


4 or More Years experience in life sciences, pharma or informatics industry or commensurate experience preferred
4 or More Years 3 + years of experience with Clinical Trials Data, Genomics, Bio Marker & Regulatory Data preferred
4 or More Years 4 + years of experience with data integration tools using disparate data sources such as flat files, databases, xml files and/or unstructured data & web services preferred
4 or More Years 3 + years of experience with Master Data Management Technologies preferred
4 or More Years 3 + years of experience with RESTful API’s Development preferred
1 or More Years 2 + years of experience with NLP (Natural Language Processing) like Linguamatics etc. preferred
Extensive hands on experience with analyzing and designing data models for Data warehousing and Transactional applications with high availability/ scalability & performance. preferred
Strong in Unix shell/Perl scripting preferred
Proven ability to work in a global and highly matrix environment preferred
Familiarity with VALIDATED systems and understanding of regulatory and industry artifacts such as 21 CRF Part 11: Electronic Records, Electronic Signatures preferred
Daiichi Sankyo, Inc. is an equal opportunity/affirmative action employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",1899,Biotech & Pharmaceuticals,$5 to $10 billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Company - Public,False
Senior Data Engineer,"Everest Re Group, Ltd.
",United States,-1,3.5,"Title:
Senior Data Engineer
Company:
Everest Global Services, Inc.
Job Category:
Technology
Job Description:
It’s an exciting time for Everest! As we continue on our journey, we see significant opportunity ahead of us to expand our reach, build diversity, and enhance our capabilities in critical markets.
Everest is a leading global reinsurance and insurance provider, operating for nearly 50 years through subsidiaries in the Bermuda, Canada, Europe, Singapore, US, and other territories. Our strengths include extensive product and distribution capabilities, a strong balance sheet, and an innovative culture. Throughout our history, Everest has maintained its discipline and focuses on creating long-term value through underwriting excellence and strong risk and capital management. But the most critical asset in this organization is our people.
At Everest, we are committed to the development of our people. We offer dynamic training & professional development to our employees. You will benefit from career development and learning opportunities that will let you set career goals and fulfill them, including:
Generous tuition/continuing education reimbursement
Mentoring opportunities
Flexible work arrangements
Talent development initiatives
Networking groups
Everest is a growth company with $13 Billion of Gross Written Premium offering Property, Casualty and specialty products among others, through its various operating subsidiaries located in key markets around the world. Everest has been a global leader in reinsurance with a broad footprint, deep client relationships, underwriting excellence, responsive service and customized solutions. Our insurance arm draws upon impressive global resources and financial strength to tailor each policy to meet the individual needs of our customers.
Our financial strength is evident in Financial Agency Ratings of: A+ A. M. Best, A+ S&P Global and A1
Moody’s Investor Service. We are a market leader for our broad diversified income streams, strong underlying underwriting performance with reduced volatility and strong cash flow. We take pride in being known in the industry as nimble, entrepreneurial and responsive.
Everest Re Group, Ltd. (“Everest”) is seeking a Senior Data Engineer to drive the execution of our Reserving Transformation projects. In this highly visible position, you will apply strong technical acumen and leadership in partnership with business counterparts to effectively define, plan and deliver technical solutions that support business outcomes in service to Everest's strategy. This is a player/coach role that will lead a group of teams and be a strong engineering leader across the organization.
Responsibilities include but not limited to:
Partner and work collaboratively with internal customers to understand strategic analytics and business needs and the associated enabling technology requirements.
Lead the technology activities to enable the delivery of meaningful, actionable, data-driven capability in alignment with business strategies
Develop and lead the execution of the Reserving Transformation strategies and roadmaps to optimize rapid delivery of information management capabilities, while aligning to established technology and architecture standards
Define and deliver the data & analytics architecture, tooling and capabilities needed to enable a modern cloud-based data environment and the best practices, governance, and controls to support the broad adoption and use across the enterprise
Drive the delivery of an exceptional customer/partner experience through ready access to data and intuitive self-service capabilities that ensures the security, integrity and quality of data while enabling the agility and performance of a scaled ecosystem.
Deliver enabling capability to support the rapid ingestion of new data and the timely deployment of advanced analytic models into production
Support the development of engineering capabilities that promotes sharing, inner sourcing and reuse of code, capabilities and methods in a cloud-first environment that leverages highly automated DevOps tools and capabilities
Manage the engagement / coordination across assigned delivery teams to ensure high quality project delivery within scope, timeframe, and budgets
Qualifications, Education & Experience:
Bachelor’s degree in computer science, engineering, or business experience in insurance or financial services
5+years in the data and analytics space with deep experience delivering enhanced analytic and data access capabilities
Team Lead experience
Scaled agile experience a plus
Experience working in a large multinational company is preferred
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of business intelligence practices
Knowledge, Skills & Competencies:
SQL
PowerBI
Python
Azure Data Factory
Data Modeling
Azure Data Brick
Our Culture
At Everest, our purpose is to provide the world with protection. We help clients and businesses thrive, fuel global economies, and create sustainable value for our colleagues, shareholders and the communities that we serve. We also pride ourselves on having a unique and inclusive culture which is driven by a unified set of values and behaviors. Click
here
to learn more about our culture.

Our Values are the guiding principles that inform our decisions, actions and behaviors. They are an expression of our culture and an integral part of how we work: Talent. Thoughtful assumption of risk. Execution. Efficiency. Humility. Leadership. Collaboration. Diversity, Equity and Inclusion.
Our Colleague Behaviors define how we operate and interact with each other no matter our location, level or function: Respect everyone. Pursue better. Lead by example. Own our outcomes. Win together.

All colleagues are held accountable to upholding and supporting our values and behaviors across the company. This includes day to day interactions with fellow colleagues, and the global communities we serve.
#LI-HYBRID
#LI-AS1

Type:
Regular
Time Type:
Full time
Primary Location:
Warren, NJ
Additional Locations:
Everest is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion or creed, sex (including pregnancy), sexual orientation, gender identity or expression, national origin or ancestry, citizenship, genetics, physical or mental disability, age, marital status, civil union status, family or parental status, veteran status, or any other characteristic protected by law. As part of this commitment, Everest will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact Everest Benefits at everestbenefits@everestglobal.com.
Everest U.S. Privacy Notice | Everest (everestglobal.com)",1995,Insurance Carriers,$5 to $10 billion (USD),Insurance,1001 to 5000 Employees,Company - Public,False
Data Engineer/solution architect,"Matrix IFS
","Jersey City, NJ",$93K - $142K (Glassdoor est.),3.4,"Job Summary


Duties & Responsibilities

1. Service Delivery & Project Management: Led and managed the data engineering team to deliver projects on time and within budget. Collaborate with the Senior Data Solution Architect to translate client requirements into technical specifications. Oversee the development and implementation of data pipelines, workflows, and ETL processes.

2. Technical Expertise: Utilize expertise in DataBricks and Snowflake to design and implement scalable, reliable, and efficient data solutions. Conduct code reviews, ensuring adherence to best practices and coding standards. Troubleshoot and resolve technical issues, supporting the team as needed.

3. Team Leadership & Collaboration: Mentor and guide team members, fostering a culture of continuous learning and improvement. Facilitate cross-functional collaboration, ensuring smooth communication between engineering, sales, and other departments. Participate in recruitment, onboarding, and training of new team members.

4. Client Engagement: Serve as a technical liaison between clients and the engineering team, ensuring alignment and satisfaction. In collaboration with the senior data solution architect, assist with pre-sales support.

5. Continuous Improvement: Stay abreast of industry trends and emerging technologies, identifying opportunities for innovation and growth. Contribute to internal documentation, process improvement, and knowledge sharing.


Desired Qualifications

1. Bachelor’s or Master’s degree in Computer Science, Engineering, or related field.

2. Minimum of 4+ years of experience in data engineering, focusing on DataBricks and/or Snowflake.

3. Proven experience with any of the following related technologies:

4. Big Data Technologies - Apache Spark, Apache Kafka, Apache Flink

5. Cloud Platforms – AWS, GCP, Azure

6. DevOps and CI/CD Tools

7. Proven experience developing in one or more of the following programming languages: Scala, Java, Python, SQL

8. Proven experience leading and managing technical teams.

9. Strong knowledge of data warehousing, big data technologies, cloud platforms, and ETL processes.

10. Excellent communication, problem-solving, and organizational skills.


Preferred Qualifications

Relevant certifications in DataBricks, Snowflake, or related technologies.

Experience working in an agile development environment.


Why Matrix

Matrix is a global, dynamic, fast-growing technical consultancy leading technology services company with 13000 employees worldwide. Since its foundation in 2001, Matrix has made more travelers and acquisitions and has executed some of the largest, most significant. The company specializes in implementing and developing leading technologies, software solutions, and products. It provides its customers with infrastructure and consulting services, IT outsourcing, offshore, training and assimilation, and Ves as representatives for the world's leading software vendors. With vast experience in private and public sectors, ranging from Finance, Telecom, Health, Hi-Tech, Education, Defense, and Secu city, Matrix's customer base includes guest organizations in Israel and a steadily growing client base worldwide.

We are comprised of talented, creative, and dedicated individuals passionate about delivering innovative solutions to the market. We source and foster the best talent and recognize that all employee's contributions are integral to our company's future.

Matrix- success is based on a challenging work environment, competitive compensation and benefits, and rewarding career opportunities. We encourage a diverse work environment of sharing, learning, and ceding together. Come and join the winning team! You'll be challenged and have fun in a highly respected organization. To Learn More, Visit Matrix -ifs. Com,",2005,Financial Transaction Processing,$1 to $5 billion (USD),Financial Services,10000+ Employees,Subsidiary or Business Segment,True
"Senior Technical Lead, Data Engineer","Stryker
","Allendale, NJ",$101K - $139K (Glassdoor est.),4.1,"Why join Stryker?
We are proud to be named one of the World’s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting stryker.com


Position summary:

Lead Data Engineer is responsible for developing robust, scalable, high-performance data pipelines enabling the organization to extract valuable insights from large and complex datasets. This role will leverage Azure data services for data integration work, including developing a data model, maintaining a data lake and analytics environment, and writing scripts for data integration and analysis. This role will work closely and collaboratively with Data & Analytics team members to define requirements, mine and analyze data, integrate data from various sources, and deploy high-quality data pipelines to support the analytics needs of different Stryker business divisions and functions.

Essential duties & responsibilities: (detailed description)

Data Architecture:
Design, implement, and maintain scalable and efficient data architecture to support business intelligence and analytics needs primarily utilizing Azure, Databricks, and Snowflake technology stack.
Collaborate with cross-functional teams to understand data requirements and translate them into effective data models.
Data Pipeline Development:
Develop and maintain robust ETL/ELT processes to move and transform data from various sources into our data warehouse with key focus on Azure data factory pipelines.
Optimize and automate data pipelines to ensure high performance, reliability, and data integrity.
Database Management:
Manage and optimize database systems, ensuring they meet performance and security requirements.
Implement data retention policies and archival strategies.
Data Quality and Governance:
Establish and enforce data quality standards and best practices.
Work closely with data stewards to ensure data accuracy, completeness, and consistency.
Performance Tuning:
Monitor and tune database and query performance for optimal efficiency.
Troubleshoot and resolve issues related to data processing and storage.
Collaboration:
Collaborate with data scientists, analysts, and other stakeholders to understand their data needs and provide solutions.
Work closely with the IT team to integrate data engineering solutions into overall IT architecture.
Documentation:
Document data engineering processes, workflows, and solutions.
Create and maintain documentation for data dictionaries, data lineage, and metadata.

Education & special trainings:

Bachelor's Degree from an accredited university required, Bachelor’s degree in the areas of Computer science, Engineering, Information Systems, Business, or equivalent field of study is preferred.
Azure based data engineering certifications preferred.

Qualifications & experience:

Minimum 6 years of relevant experience required
Ability to analyze business situations
Proven experience as a Data Engineer with a strong focus on the Azure, Databricks, and Snowflake data analytics technology stack.
Proficient in SQL and extensive experience with Azure services, Databricks, and Snowflake.
Familiarity with big data and advanced data science technologies is a plus.
Excellent problem-solving and troubleshooting skills.
Strong communication and collaboration skills.

About Stryker

Our benefits:


12 paid holidays annually

Health benefits include: Medical and prescription drug insurance, dental insurance, vision insurance, critical illness insurance, accident insurance, hospital indemnity insurance, personalized healthcare support, wellbeing program and tobacco cessation program.

Financial benefits include Health Savings Account (HSA), Flexible Spending Accounts (FSAs), 401(k) plan, Employee Stock Purchase Plan (ESPP), basic life and AD&D insurance, and short-term disability insurance.

For a more detailed overview of our benefits or time off, please follow this link to learn more: US Stryker employee benefits

About Stryker
Stryker is one of the world’s leading medical technology companies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at stryker.com.

Know someone at Stryker?
Be sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program on our referral page

Stryker is driven to work together with our customers to make healthcare better. Employees and new hires in sales and field roles that require access to customer accounts as a function of the job may be required, depending on customer requirements, to obtain various vaccinations as an essential function of their role.",1941,Health Care Products Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Principal Data Engineer,"Bristol Myers Squibb
",New Jersey,-1,3.8,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.

Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.

Remote Opportunity

When you join BMS, you are joining a diverse, high-achieving team united by a common mission.

The Informatics and Predictive Sciences (IPS) mission is to Pioneer, Partner and Predict to drive transformative insights for patient benefit. IPS conducts applied computational research in areas that include genomic, structural and molecular informatics, computational and systems biology, patient selection and translational biomarker research, and broader fields including knowledge science, epidemiology and machine learning—across the full lifecycle of drug discovery and development and across all therapeutic areas at BMS. We do this in close partnership with scientific and clinical experts in the field, both inside and outside the company. We perform innovative science to empower key data-driven decisions across a rich pipeline of next-generation medicines. In doing so, our work transforms the lives of patients, as well as our own lives and careers.

Here, you’ll get the chance to grow and thrive through opportunities that are uncommon in scale and scope. You’ll pursue innovative ideas while advancing professionally alongside some of the brightest minds in biopharma.

Bristol Myers Squibb seeks a hardworking individual to contribute to groundbreaking informatics and data management initiatives within Research. This hands-on Principal Data Engineer role interfaces closely with scientists in the Chemistry, Biotherapeutics, and Informatics and Predictive Sciences groups working to identify novel therapies. We are seeking an individual with extensive experience integrating data and building data solutions to make data accessible and relevant for the research community.

Responsibilities include, but are not limited to, the following:

Work with multi-functional teams to lead design and implementation of cloud-based, integrated data platforms to facilitate the identification of novel therapeutic compounds.
Collaborate with colleagues across Informatics and Predictive Sciences to make a wide variety of data, from raw to scientific insights, readily available to researchers.
Collaborate with analysts to apply solutions for integration and delivery of complex biologic data to a wide variety of predictive modeling approaches.
Design and develop infrastructure and processes to load public and proprietary data from multiple source systems leveraging a mix of custom software and database development, open-source tools, and cloud-based services.
Collaborate with the project manager, solution architect, infrastructure team, and external vendors as needed to support successful delivery of technical solutions.
Innovate and advise on the latest technologies and standard methodologies in Data Engineering.
Basic qualifications
Bachelor's Degree in an engineering or biology field with 8+ years of academic / industry experience
or Master’s Degree in an engineering or biology field with 6+ years of academic / industry experience
or PhD in an engineering or biology field with 4+ years of academic / industry experience in an engineering or biology field.

Preferred Qualifications

Demonstrated proficiency in processing, analyzing, and constructing complex data capture, management, and dissemination solutions for public or proprietary biological patient and assay datasets including transcriptomic, proteomic, and/or small molecule datasets.
Demonstrated proficiency with predictive modeling approaches, and/or preparing data for predictive modeling.
Demonstrated proficiency with current software engineering methodologies, such as Agile SDLC approaches, distributed source code control, project management, issue tracking, and CI/CD tools and processes.
Excellent skills in an object-oriented programming language such as Python or Java, and proficiency in SQL and R.
High degree of proficiency in cloud computing. Preference will be given to candidates with AWS experience.
Solid understanding of container strategies such as Docker, Fargate, ECS, and ECR.
Excellent skills and deep knowledge of databases such as Postgres, Elasticsearch, Redshift, and Aurora, including distributed database design, SQL vs. NoSQL, and database optimizations.
Experience developing web applications in frameworks like Shiny, Vue, React, etc. is a plus.
Along with programming proficiency, must have a strong capacity for independent thinking and the ability to grasp underlying scientific questions.
Must have experience leading complex scientific data management and integration initiatives in a research environment.
Must be effective in a dynamic environment while adapting to changing priorities and have excellent written and verbal communication and presentation skills.
Must have excellent time management and interpersonal skills.

The starting compensation for this job is a range from $121,000 to $167,200 plus incentive cash and stock opportunities (based on eligibility).

The starting pay rate takes into account characteristics of the job, such as required skills and where the job is performed. Final, individual compensation will be decided based on demonstrated experience.

Eligibility for specific benefits listed on our careers site may vary based on the job and location. For more on benefits, please visit our BMS Career Site.

Benefit offerings are subject to the terms and conditions of the applicable plans then in effect and may include the following: Medical, pharmacy, dental and vision care. Wellbeing support such as the BMS Living Life Better program and employee assistance programs (EAP). Financial well-being resources and a 401(K). Financial protection benefits such as short- and long-term disability, life insurance, supplemental health insurance, business travel protection and survivor support. Work-life programs include paid national holidays and optional holidays, Global Shutdown days between Christmas and New Year’s holiday, up to 120 hours of paid vacation, up to two (2) paid days to volunteer, sick time off, and summer hours flexibility. Parental, caregiver, bereavement, and military leave. Family care services such as adoption and surrogacy reimbursement, fertility/infertility benefits, support for traveling mothers, and child, elder and pet care resources. Other perks like tuition reimbursement and a recognition program.

#LI Remote

#QLR

If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.

Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.

On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.

BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.

BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.

BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.

Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",1858,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Company - Public,False
Big data support engineer,Comprise IT Solutions,"Basking Ridge, NJ",$110K (Employer est.),-1.0,"Monitor production jobs for P1 system (Data Management and Reporting – DMR).
Debug and restart in the event of production failures.
Acknowledge, respond and resolve production issues.
Understand change requests / enhancements requests.
Design and developed data loading strategies.
Build, develop, testing shared components that will be used across modules.
Extract source data files, stage, transform and load into EERA system (PostGres SQL)
Ingest data from Mainframe system using Kafka and load into EERA.
Extract source data files, stage, transform and load into BDS system (Hive based)
Use Apache Spark for large data processing integrated with functional programming language Scala
Create programs to continuously listen in requests from consumption layer, generate data extracts and publish it via email.
Provide on-call support between 5 PM and 9 PM EST.
On call support during weekend
Handshake with offshore team on daily / need basis.

Mandatory Skills:

Scala, Spark, Hadoop, Kafka
Postgres SQL
Hive
Airflow (or Control M / Oozie)
Kubernetes (or equivalent containerization tool)
Agile
Strong architecture, design & coding skills
Experience in production operations and support
Experience in distributed databases

Share your resume at ashish@bslci.com

Job Type: Full-time

Salary: Up to $110,000.00 per year

Compensation package:

Yearly pay

Experience level:

9 years

Schedule:

8 hour shift

Experience:

Informatica: 5 years (Required)
SQL: 6 years (Required)
Data warehouse: 1 year (Preferred)

Work Location: On the road",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Self-employed,True
Data Center Design Engineer,"Digital Realty
","Clifton, NJ",-1,4.0,"Your role

Primary responsibilities include but are not limited to design engineering and record maintenance for all assigned facilities, assign customers’ space and power; issue Work Orders to instruct facility technician on task to be performed and for project tracking, create Project Bill of Materials (MOP) for customer installations, manage cable ties capacity and augment projects. Assist with colocation expansion projects. Assist sales with customer’s technical requests.




What you’ll do

Manage assignments of new customer racks, cabinets, cages, panels and conduits.
Create in ACAD Implementation Package and SOW documentation for installations of ladder rack, fiber raceway, cable ties, power and grounding.
Create Project Bill of Materials (BOM) for all installation projects.
Create Work Orders to instruct facility technicians on task to be performed and to track installation projects and sub-Contractor’s work.
Update facility floor plans using ACAD and DCIM software.
Update connectivity and cable tie records using DCIM software.
Update records of customers’ power circuits using company DCIM software.
Assist sales engineers with facility capacity inquiries regarding space, power and connectivity.
Perform audits as required at DLR sites.



What you’ll need

A.S./B.S. College degree related to technology, electrical or mechanical.
Minimum 2 years’ experience in telecommunications environment.
Minimum of 2 years of engineering and planning experience.
Must be detail oriented with excellent communications, interpersonal and oral/written presentation skills.
Advanced skills with ACAD.
Proficiency with Microsoft Office Suite (Visio, PowerPoint, Excel, Word, Outlook) and/or equivalents.
Proven organizational ability, attention to details and strong analytical skills.
Must be a self-starter, proactive, flexible, and able to work within deadlines.
Must be able to work on multiple tasks/projects.
Experience working in a Data Center or Colocation environment.
Work in central office environment with hands-on experience.



A bit about us

Digital Realty brings companies and data together by delivering the full spectrum of data center, colocation and interconnection solutions. PlatformDIGITAL®, the company’s global data center platform, provides customers with a secure data meeting place and a proven Pervasive Datacenter Architecture (PDx®) solution methodology for powering innovation and efficiently managing Data Gravity challenges. Digital Realty gives its customers access to the connected data communities that matter to them with a global data center footprint of 300+ facilities in 50+ metros across 28 countries on six continents.




A bit about our Digital team

Our Operations team keeps our customers’ infrastructure running safely and securely. We get plenty of opportunities to take on a variety of tasks and develop our technical skills. From overseeing electrical power to cooling and fire suppression systems, our team plays a vital role in making sure everything in our data centers operates as it should.




What we can offer you

Our rapidly evolving business sector offers the opportunity to be part of a courageous and passionate team who work together to understand and meet the changing needs of our global customers.




Join us and you’ll be part of a supportive and inclusive environment where you can bring your whole self to work. As part of our team, you’ll get to work with people from different business areas, challenge the way we do things and put your ideas into action. We’ll also give you plenty of development opportunities so you can build a rewarding and successful career with us.




Our Compensation Philosophy

Digital Realty offers its employees a highly competitive compensation package, excellent benefits, and an environment that recognizes and rewards your contributions. Central to our compensation philosophy is rewarding our employees for achieving the values and objectives aligned to the company's overall goals and values.

This is an exciting time to join our business so apply now and make your mark on our future.




Notes:

The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties, and skills required of personnel so classified.




Digital Realty is an equal opportunity employer, EOE/AA/M/F/Vets/Disabled. All applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability or protected veteran status, or other status protected by law or Company policy.




Digital Realty is a publicly traded company (NYSE: DLR) with investment grade ratings from all three major ratings agencies.




Please do not forward unsolicited resumes to any employee of Digital Realty and its subsidiaries. Digital Realty is not responsible for any fees related to unsolicited referrals.",2004,Information Technology Support Services,$1 to $5 billion (USD),Information Technology,1001 to 5000 Employees,Company - Public,False
"Union Asst Chief Engineer, Data Center","CBRE
","Rutherford, NJ",$85K - $134K (Glassdoor est.),4.0,"Posted
17-Nov-2023
Service line
GWS Segment
Role type
Full-time
Areas of Interest
Building Management, Data Centers
Location(s)
Rutherford - New Jersey - United States of America

Job summary

This role controls and implements results against all allocated customer specific service level agreements. Making a direct contribution to the development and successful operation of the Critical Environment function, work with colleagues to develop and implement departmental strategy, objectives and improvement processes. This role is responsible for the day to day operation of their team, carrying out planned preventative maintenance and reactive works to building services systems within a contracted site.

Essential duties and responsibilities

Ensure that planned preventative maintenance (PM) and reactive maintenance is performed on all equipment through the operation of planned preventative maintenance systems.

Ensure accurate and comprehensive records are kept pertaining to health and safety, building compliance and quality assurance. This includes overall responsibility for Configuration Management (CM) MS Work Orders, Preventative Maintenance (PM), Configuration Management (CM), or Repairs within the agreed Service Level Agreement (SLA) timeframe. Call out if issues cannot be resolved promptly.

Ensure that subcontractor performance meets all requirements per the Master Service Agreement (MSA.) Administer subcontractor work approvals and safe operation while repair or service is carried out on site.

Operate a permit-to-work system in accordance with CBRE's health and safety procedures and client requirements. Ensure that Method Statements and Risk Assessments are prepared and used for all tasks undertaken - completing safe working practices at all times.

Ensure that facility/plant faults and defects are swiftly remedied to maintain plant in serviceable order at all times. Ensure that suitable spares are available to carry out maintenance at the site.

Coordinate the site's environmental conditions, using the Building Management System and/or ignition system in order to maintain acceptable internal conditions. Finish the tasks to provide for a safe work environment.

Provide Mechanical and Electrical troubleshooting support (chiller, Computer Room Air Conditioning (CRAC), Computer Room Air Handler (CRAH), Uninterruptible Power Supply (UPS), Power Distribution Unit (PDU), Statis Transfer Switches (STS), etc.) Ensure that comprehensive maintenance records are completed, and conduct routine quality checks accordingly.

Partner with the Data Center Manager or other CBRE management to maintain and develop good relationships with account leadership.

Supervisory responsibilities

No formal supervisory responsibilities in this position. Provides informal assistance such as technical mentorship, and/or training to coworkers. Coordinates and assigns tasks to co-workers within a work unit and/or project.




QUALIFICATIONS
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

EDUCATION and EXPERIENCE
High School Diploma/GED required, Associates Degree preferred. 4-6 years of experience in mechanical or electrical engineering, preferred.

CERTIFICATES and/or LICENSES
Journeyman/Electrician/HVAC license, preferred. State and local licensures, where required.

COMMUNICATION SKILLS
Excellent written and verbal communication skills. Strong organizational and analytical skills. Ability to provide efficient, timely, reliable and courteous service to customers. Ability to effectively present information.

FINANCIAL KNOWLEDGE
Requires knowledge of financial terms and principles. Ability to calculate intermediate figures such as percentages, discounts, and/or commissions. Conducts basic financial analysis.

REASONING ABILITY
Ability to comprehend, analyze, and interpret documents. Ability to solve problems involving several options in situations. Requires intermediate analytical and quantitative skills.

OTHER SKILLS and/or ABILITIES
Experience in a financial setting working with billing and payables; prior experience using a financial system; and, the ability to use Microsoft Excel.
Ability to comprehend and interpret instructions, short correspondence, and memos and ask clarifying questions to ensure understanding.
Ability to write routine reports and correspondence.
Ability to respond to common inquiries or complaints from clients, co-workers, and/or supervisor.
Ability to effectively present information to an internal department and/or large groups of employees.

SCOPE OF RESPONSIBILITY
Decisions made with thorough knowledge of procedures and company policies to achieve set results and deadlines. Responsible for setting own project deadlines. Errors in judgment may cause short-term impact to co-workers and supervisor.

CBRE is an equal opportunity/affirmative action employer with a long-standing commitment to providing equal employment opportunity to all qualified applicants regardless of race, color, religion, national origin, sex, sexual orientation, gender identity, pregnancy, age, citizenship, marital status, disability, veteran status, political belief, or any other basis protected by applicable law.
CBRE is an equal opportunity employer that values diversity. We have a long-standing commitment to providing equal employment opportunity to all qualified applicants regardless of race, color, religion, national origin, sex, sexual orientation, gender identity, pregnancy, age, citizenship, marital status, disability, veteran status, political belief, or any other basis protected by applicable law. We also provide reasonable accommodations, as needed, throughout the job application process. If you have a disability that inhibits your ability to apply for a position through our online application process, you may contact us via email at recruitingaccommodations@cbre.com or via telephone at +1 866 225 3099 (U.S.) and +1 866 388 4346 (Canada).

NOTE: Some, but not all, of our positions may have an additional requirement to comply with COVID-19 health and safety protocols, including COVID-19 vaccination proof and/or rigorous testing. If you have questions about the requirement(s) for this position, please inform your Recruiter.",1906,Real Estate,Unknown / Non-Applicable,Real Estate,10000+ Employees,Company - Public,False
Senior Software Engineer - Data Strategy (NYC-Hybrid),Rad Hires,"Hoboken, NJ",$215K - $245K (Employer est.),-1.0,"Role
The Senior Software Engineer position in the Data Strategy team presents a chance to create and execute data products for the world's biggest and most reputable reinsurance brokerage. Data Strategy has a “start-up style” mandate (within a $2 billion company) to enhance the acquisition, storage, analysis, fidelity, and monetization of client, internal, and third-party data across the organization. This innovation spans our petabyte-scale insured assets, including property, business, marine, and aviation entities, and their associated risks, such as hurricanes, wildfires, cyber-attacks, and wars, in a financial and economic context.
As a member of the Data Strategy group, the Senior Software Engineer will work with fellow data and web engineers, data scientists, product managers, business analysts, and stakeholders from other internal groups to design and improve data-centric projects with the dual mandate of (1) increasing the efficiency of the data collection and analysis process across the company and (2) driving the monetization of data via newly designed and existing products for the company’s reinsurance clients. The Senior Software Engineer will be the head facilitator on multiple innovative initiatives and will have ownership over the design, development, and delivery of projects requiring direct reporting to senior-level management in both business and technical groups.
Leadership Responsibilities
Work with a product manager as technical lead of a team of ~5 engineers, data scientists, and analysts to design, scope, and oversee work in an Agile environment.
Manage junior data and web engineers, focusing on productivity, quality, and professional development.
Partner with the head of Data Strategy and other senior engineers to create and evangelize best-in-class engineering competency and tooling within the organization.
Enforce strong development standards across the team through code reviews, automated testing, and monitoring.
Establish strong relationships with internal clients as an engineering representative for data strategy.
Contribute to the overall Data Strategy vision and execution via quarterly planning and executive committee reporting.
Partner regularly improving engineering recruiting process for the required skillsets and resourcing demands.
Learn the complex business of reinsurance to coach data technologists and execute the team's initiatives more effectively.
Software Engineer Responsibilities
Develop, implement, and deploy custom data pipelines powering machine learning algorithms, insights generation, client benchmarking tools, business intelligence dashboards, reporting, and new data products.
Innovate new ways to leverage large and small datasets to drive revenue via the development of new products with the Data Strategy team, as well as the enhancement of existing products.
Architect engineering solutions using the latest cloud technologies in a process that spans hypothesis-validating prototypes to large-scale production data products, ensuring internal security and regulatory compliance.
Design solutions that account for unstructured data and document management system(s), including ingesting, tracking, parsing, analyzing, and summarizing documents at scale.
Perform exploratory and goal-oriented data analyses to understand and validate the requirements of data products and help create product roadmaps.
Develop, implement, and deploy front-ends and APIs, which may involve business intelligence dashboards, data pipelines, machine learning algorithms, and file ingestion mechanisms.
Work closely with data scientists, data engineers, web engineers, PMs, and other stakeholders to design & develop products.
Keep current on the latest trends and innovations in data technology and how these trends apply to the company's business and data strategy.
Required Qualifications
5-8+ years of relevant experience in data-focused software engineering
Master’s Degree or Ph.D. in data science, computer science, or related quantitative field such as applied mathematics, statistics, engineering or operations research, or equivalent experience
Experience in Python and familiarity with OOP and functional programming principles
Strong knowledge of SQL and familiarity with the high-level properties of modern data stores.
Strong understanding of the contemporary SDLC, including dev/QC/prod environments, unit/integration/UA testing, CI/CD, etc.
Experience building and maintaining CI/CD pipelines with tools such as Azure DevOps, GitLab, Travis, Jenkins, etc.
At least two and ideally all of the following sets of experience:
Data Engineering
2+ years’ experience with data engineering
Extensive experience with (py)Spark, Python, JSON, and SQL
Experience integrating data from semi-structured and unstructured sources
Knowledge of various industry-leading SQL and NoSQL database systems
Backend Web
2+ years of backend/full-stack web engineering
Experience working with Python-based server-side web frameworks like FastAPI or Django
Experience with complex backends involving multiple data stores, asynchronous worker queues, pub-sub messaging, and the like
Knowledge of cloud-based web deployments (AWS/Azure/GCP, Kubernetes, auto-scaling, etc.)
Experience with one or more major frontend frameworks (React strongly preferred)
Data Science/Analytics
2+ years of data analysis, AI, or data science work
Experience with data cleaning, enrichment, and reporting to business users
Experience selecting, training, validating, and deploying machine-learning models
Experience with or strong interest in learning about LLMs in a productized context
Experience working in an Agile environment to facilitate the quick and effective fulfillment of group goals
Good interpersonal and communication skills for establishing and maintaining sound internal relationships, working well as part of a team, and for presentations and discussions
Strong analytical skills and intellectual curiosity (interest in the meaning and usefulness of the data), as demonstrated through academic experience or work assignments
Excellent English verbal and writing skills for complex communications with company colleagues in all departments and levels of the organization, including communicating technical concepts to a non-technical audience
Good ability to prioritize workload according to volume, urgency, etc., and to deliver on required projects in a timely fashion
Preferred Qualifications
Strong understanding of entity resolution, streaming technologies, and ELT/ETL frameworks
Experience with web scraping and crowdsourcing technologies
Experience with Databricks and optimizing Spark clusters
Experience architecting web ecosystems from the ground up, including monolith vs. microservice decisions, caching technologies, security integrations, etc.
Experience working with data visualization dashboarding tools (PowerBI, Tableau)
Insurance domain knowledge or strong interest in developing it
Experience with the MS Azure cloud environment",2019,Staffing & Subcontracting,Unknown / Non-Applicable,Human Resources & Staffing,1 to 50 Employees,Company - Private,True
Sr. AWS Data Engineer,Sbase Technologies,"Princeton, NJ",$111K - $125K (Employer est.),-1.0,"Role – AWS Data Engineer

Only for W2 and Full-time candidates (No C2C)

Location – Boston, MA (or) Princeton, NJ or O'Fallon, MO

Yrs. of experience – 10+ Years

Hybrid

Mode of employment – Full-Time

Salary: $125K

Job Description:

We are seeking a skilled and experienced Databricks Architect with expertise in working with Databricks on the AWS cloud platform.
Comprehensive knowledge and hands on experience with Databricks pipelines, Unity Catalog and Medallion architecture
Proficiency in programming languages Python, Scala, or Java for data processing and application development
Experience in implementing data solutions on AWS cloud using cloud storage, compute and network resources.
Expertise in data engineering principles, ETL processes, data modeling and data integration techniques
Experience in end-end qualification and performance tuning of the data models and pipelines
Strong problem solving and analytic skills to handle data engineering challenges and troubleshoot issues.
Experience with agile development methodologies

Job Type: Full-time

Pay: $110,664.42 - $125,000.00 per year

Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance
Life insurance

Compensation package:

Monthly bonus
Quarterly bonus
Yearly bonus

Experience level:

10 years
11+ years
8 years
9 years

Schedule:

8 hour shift

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Senior Data Engineer Job at Apexon,"Apexon
","Berkeley Heights, NJ",$89K - $131K (Glassdoor est.),4.0,"About Apexon:

Apexon is a digital-first technology services firm specializing in accelerating business transformation and delivering human-centric digital experiences. We have been meeting customers wherever they are in the digital lifecycle and helping them outperform their competition through speed and innovation.




Apexon brings together distinct core competencies – in AI, analytics, app development, cloud, commerce, CX, data, DevOps, IoT, mobile, quality engineering and UX, and our deep expertise in BFSI, healthcare, and life sciences – to help businesses capitalize on the unlimited opportunities digital offers. Our reputation is built on a comprehensive suite of engineering services, a dedication to solving clients’ toughest technology problems, and a commitment to continuous improvement.




Backed by Goldman Sachs Asset Management and Everstone Capital, Apexon now has a global presence of 15 offices (and 10 delivery centers) across four continents.




We enable #HumanFirstDIGITAL




RESPONSIBILITIES:



5+ years of hands-on software engineering experience.
5+ years of experience integrating technical processes and business outcomes – specifically: data and process analysis, data quality metrics/monitoring, data architecture, developing policies/standards & supporting processes.
Designing and building data pipeline (batch & streaming), extensive experience in Spark with Java.
Strong database fundamentals including SQL, performance, and schema design.
Good experience on Java.
Good experience on Kafka
Excellent communications skills, both written and verbal.
Experience working in an offshore/onshore team model.
Design and implement Data security and privacy controls.
Experience with Git or equivalent source code control software.
Experience in designing solutions for large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS and/or knowledge on NoSQL platforms.

Qualifications



Bachelor's Degree or master’s degree in Computer Science, Mathematics, Statistics or equivalent.



Don’t worry if you don’t check all the boxes; we’d still love to hear from you.

Our Commitment to Diversity & Inclusion:

Did you know that Apexon has been Certified™ by Great Place To Work®, the global authority on workplace culture, in each of the three regions in which it operates: USA (for the fourth time in 2023), India (seven consecutive certifications as of 2023), and the UK.

Apexon is committed to being an equal opportunity employer and promoting diversity in the workplace. We take affirmative action to ensure equal employment opportunity for all qualified individuals. Apexon strictly prohibits discrimination and harassment of any kind and provides equal employment opportunities to employees and applicants without regard to gender, race, color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law.




You can read about our Job Applicant Privacy policy here Job Applicant Privacy Policy (apexon.com)

Our Perks and Benefits:

Our benefits and rewards program has been thoughtfully designed to recognize your skills and contributions, elevate your learning/upskilling experience and provide care and support for you and your loved ones.

As an Apexer, you get continuous skill-based development, opportunities for career advancement, and access to comprehensive health and well-being benefits and assistance.




We also offer:

Health Insurance with Dental & Vision
401K Plan
Life Insurance, STD & LTD
Paid Vacations & Holidays
Paid Parental Leave
FSA Dependent & Limited Purpose care
Learning & Development


Apply
Share

Job Code: RR6762

Category: Data

Job Type: Contractor

Location: Berkeley Heights, NJ, USA

Open Positions: 1",1996,Information Technology Support Services,Unknown / Non-Applicable,Information Technology,5001 to 10000 Employees,Company - Private,False
"Associate Specialist, Data Engineer Fellowship (Hiring Our Heroes) (Hybrid)","Merck Sharp & Dohme
","Rahway, NJ",$62K - $95K (Glassdoor est.),4.2,"Job Requirements





Fellowship Opportunity:

We are excited to be a sponsor of Hiring our Heroes and proud to offer transitioning service members a unique opportunity to gain valuable professional experience through our 12-week fellowship program.

During your fellowship with our company, you will have the chance to collaborate with our Veterans Leadership Network and receive support from various stakeholders within the organization. To ensure your success, each fellow is paired with a buddy who will provide guidance, mentorship, and different perspectives. Additionally, you will have access to a career development advisor who will offer support and guidance in managing your career.

As a fellow, you will be part of a Cohort consisting of other transitioning service members. This will enable you to engage in weekly touchpoints, attend educational sessions, and receive direction from our Veteran Talent Program Lead throughout the Fellowship. Our primary objective is to provide you with mentoring, networking opportunities, and exposure to help facilitate a successful transition into a full-time position within our company.

With our generous military-friendly policies, we've received accolades from several organizations such as GI Jobs, Military Times EDGE, and Employer Support of the Guard and Reserve (ESGR). Consider a future with us and discover an employer who will foster your best work as you continue to strive for the well-being of others.




Who we are …


We are known as Merck & Co., Inc., in the United States and Canada and MSD everywhere else. For more than a century, we have been inventing for life, bringing forward medicines and vaccines for many of the world's most challenging diseases. Today, our company continues to be at the forefront of research to deliver innovative health solutions and advance the prevention and treatment of diseases that threaten people and animals around the world.


What we look for …


Imagine getting up in the morning for a job as important as helping to save and improve lives around the world. Here, you have that opportunity. You can put your integrity, knowledge, imagination, skill, and teamwork to work in collaboration with a diverse group of colleagues who pursue and bring hope to countless people who are battling some of the most challenging diseases of our time. Our team is constantly evolving, so if you are among the intellectually curious, join us—and start making your impact today.


Overview:




Our ability to compete and win in an ever more competitive animal health industry is highly dependent upon effectively harnessing data to drive decision making across the enterprise whether bioinformatics in drug discovery, batch yield modeling in manufacturing, automation of forecasting and supply chain planning, personalization of eMarketing campaigns or the monetization of connected animal information. We are truly on the cusp of an amazing breakthrough... a chance to lead not only the animal health industry, but industry in general, in creating a true enterprise-wide data management and analytics platform as part AHIT JEDI initiative (Joint Enterprise Data and Infrastructure). You will be playing a critical role in these spaces today ingesting, managing and transforming business critical data and generating visualizations and insights, machine learning models and AI driven processes across the data domains powering our R&D, manufacturing, commercial and enterprise business processes.


Merck Animal Health IT focuses on leveraging information technology to enhance and optimize various aspects of the animal health industry. This includes developing and maintaining software applications, systems, and infrastructure to support research and development, manufacturing, sales and marketing, supply chain management, and regulatory compliance. AH JEDI is to address current data challenges and issues as we have forged forward building data-centric solutions. It is critical that we band together to Win as One Team to eliminate silos, engage the business, clarify strategy, select technologies and scale overall efforts.


Successful candidates will be able to work independently as well as proactively collaborate with colleagues.

Primary responsibilities will include :

Assisting in the design, implementation, and optimization of data systems, data lakes and workflows, to ensure efficient data extraction, loading and transformation (ELT) processes.
Ensuring that high quality of data, data pipelines, data ingestion, and data integration processes
Managing the infrastructure required to support and operate data pipelines in production.
Developing automated workflows, pipelines, and scripts for seamless and efficient deployment, monitoring, and maintenance of data solutions.
Implementing continuous integration and continuous deployment (CI/CD) practices for data and solutions.
Building monitoring systems to track the performance and health of deployed data and solutions. Setting up alerts and notifications to detect and respond to anomalies or issues in real-time. Collecting and analyzing relevant data to identify potential improvements or necessary data processes.
Utilizing a strong understanding of SQL and programming languages like Python, knowledge of cloud platforms, such as AWS, and problem-solving skills, attention to detail, and a willingness to learn and adapt to new technologies and data engineering best practices.

You will be part of a diverse, cross-functional team of individuals who execute our enterprise cloud platform. The Fellowship will include progressive on-the-job training and operational project assignments under the direction of Director of Data & Analytics Strategy.




Your Fellowship Project

You will partner with AH JEDI team members to develop and formalize data engineering processes.


The fellowship intends to:

Develop deeper understanding of the cloud computing
Develop an understanding of data engineering and DataOps
Develop an understanding of the systems and tools critical to cloud-based solution development
Participate/Lead in team meetings to develop an understanding of the different skills and expertise of the cross functional members




Benefits of Fellowship

Mentoring & networking opportunities within and beyond AHIT
Exposure to Senior level positions within AHIT
Hands-on experience in the modern cloud technology, AI/ML and product model
Development of critical analysis and project management skills


Work Experience





Experience/Skills We are Looking for:

Bachelor’s +1 year of experience in computer science / data science or STEM field, or Master’s Degree.
Strong communication abilities, including written, verbal, and interpersonal
Collaboration, project management, and organizational skills
Work experience in a results-driven environment
Strategic/critical thinking
Experience working on cross-functional teams
Experience with cloud preferred
Programming in Python is expected

Primary Work Site/Schedule

On-site work locations: Rahway, NJ; Hybrid schedule
Monday-Thursday (Core hours: 9:00 am – 4:40 pm, flexible start and stop)

Requirement: Transitioning Service Members who is participating in the Hiring Our Heroes Corporate Fellowship Program


Requisition ID:P-100752",1891,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Company - Public,False
Sr. Data Engineer,"Chubb
","Whitehouse Station, NJ",$85K - $117K (Glassdoor est.),3.7,"We are looking for an experienced and motivated Senior ETL Developer to join our dynamic team. In this role, you will lead the delivery of key projects in support of North America financial reporting from the enterprise data warehouse and associated data marts, including the Business Analytics Repository (BAR). BAR is a strategic application within the business, feeding into multiple systems and applications both up and downstream with data that directly supports business decisions being made each and every day. You will be responsible for leading ETL development projects, coordinating with cross-functional teams to ensure project success, and creating and maintaining data integration solutions to meet business requirements. The ideal candidate will have experience with ETL development solutions such as AWS Glue, Google Dataflow, Azure Data Factory, Snowflake, Informatica/IICS and be able to identify and resolve data quality issues, performance bottlenecks, and other ETL-related problems.

Responsibilities:

Lead ETL development projects and coordinate with cross-functional teams to ensure project success
Create and maintain data integration solutions to meet business requirements
Identify and resolve data quality issues, performance bottlenecks, and other ETL-related problems
Design and develop scalable ETL workflows and data pipelines using ETL tools such as Informatica/IICS
Ensure compliance with data governance and security policies
Develop and maintain documentation such as technical design documents, data lineage, and ETL runbooks
Mentor junior ETL developers and provide technical guidance to the team
Evaluate modern technologies and tools, and recommend solutions to improve ETL processes and performance
Contribute to the architecture, design, and development of data warehousing and business intelligence solutions
Understands data mapping and data modeling methodologies including normal form, star, and snowflake to reduce data redundancy and improve data integrity.
Participate in analysis, design, and ETL development as part of Agile development methodologies and provide status updates to the management
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assesses the impact, and collaborates with Scrum Team and Leadership to incorporate current trends and developments in current and future solutions


5 Year/bachelor’s degree or equivalent work experience (4 years of experience in lieu of Bachelors)_Minimum Required in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience
At least 5+ years of Strong understanding of ETL development concepts and tools such as ETL development solutions (e.g., AWS Glue, Google Dataflow, Azure Data Factory, Snowflake, Informatica/IICS)
Experience with Data Warehousing and Business Intelligence concepts and technologies
Strong knowledge of SQL and advanced programming languages such as Python and Java
Demonstrated critical thinking skills and the ability to identify and resolve data quality issues, performance bottlenecks, and other ETL-related problems
Experience with Agile methodologies and project-management skills
Excellent communication and interpersonal skills
Ability to mentor and provide technical guidance to junior ETL developers
Experience with cloud based environment required.
2+ years of experience in scheduling jobs using Autosys (or comparable distributed scheduler)
3+ years of experience writing Unix/Linux or Windows Scripts in tools such as PERL, Shell script, Python, etc.
3+ years of experience in creating complex technical specifications from business requirements/specifications



Chubb is the world’s largest publicly traded property and casualty insurer. With operations in 54 countries, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. The company is distinguished by its extensive product and service offerings, broad distribution capabilities, exceptional financial strength, underwriting excellence, superior claims handling expertise and local operations globally.



At Chubb, we are committed to equal employment opportunity and compliance with all laws and regulations pertaining to it. Our policy is to provide employment, training, compensation, promotion, and other conditions or opportunities of employment, without regard to race, color, religious creed, sex, gender, gender identity, gender expression, sexual orientation, marital status, national origin, ancestry, mental and physical disability, medical condition, genetic information, military and veteran status, age, and pregnancy or any other characteristic protected by law. Performance and qualifications are the only basis upon which we hire, assign, promote, compensate, develop and retain employees. Chubb prohibits all unlawful discrimination, harassment and retaliation against any individual who reports discrimination or harassment.",1792,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Public,False
Senior Data Platform Engineer - Agency Temp,"Adswizz
","Lawrenceville, NJ",$83K - $132K (Glassdoor est.),3.6,"Lawrenceville, New Jersey; Washington, Washington, DC
Engineering
Agency Temp Full-Time
R-2023-10-27



Who We Are:

SiriusXM and its brands (Pandora, SXM Media, AdsWizz, Simplecast, and SiriusXM Connected Vehicle Services) are leading a new era of audio entertainment and services by delivering the most compelling subscription and ad-supported audio entertainment experience for listeners - in the car, at home, and anywhere on the go with connected devices. Our vision is to shape the future of audio, where everyone can be effortlessly connected to the voices, stories and music they love wherever they are. This is the place where a diverse group of emerging talent and legends alike come to share authentic and purposeful songs, stories, sounds and insights through some of the best programming and technology in the world. Our critically-acclaimed, industry-leading audio entertainment encompasses music, sports, comedy, news, talk, live events, and podcasting. No matter their individual role, each of our employees plays a vital part in bringing SiriusXM’s vision to life every day.

SiriusXM is the leading audio entertainment company in North America, and the premier programmer and platform for subscription and digital advertising-supported audio products. SiriusXM’s platforms collectively reach approximately 150 million listeners, the largest digital audio audience across paid and free tiers in North America, and deliver music, sports, talk, news, comedy, entertainment and podcasts. Pandora, a subsidiary of SiriusXM, is the largest ad-supported audio entertainment streaming service in the U.S. SiriusXM's subsidiaries Simplecast and AdsWizz make it a leader in podcast hosting, production, distribution, analytics and monetization. The Company’s advertising sales organization, which operates as SXM Media, leverages its scale, cross-platform sales organization and ad tech capabilities to deliver results for audio creators and advertisers. SiriusXM, through Sirius XM Canada Holdings, Inc., also offers satellite radio and audio entertainment in Canada. In addition to its audio entertainment businesses, SiriusXM offers connected vehicle services to automakers.

How you’ll make an impact:

In this role you will be a member of a team responsible for designing, developing and supporting a data platform which will be used across data organization and other groups.

What you’ll do:

Build cloud-based data platform which supports Datalake, Job Orchestration, ETL template, ETL Compute, integration with third party tools like fivetran, Monte Carlo

Design, code and maintain infrastructure as a code (IaC) using CDK, typescript, CDKTF.

Build and improve workflow orchestration tooling to support efficient data pipelines E.g., airflow plugins, systems integration, deployments.

Strengthen best practices around data platform setup and configuration.

What you’ll need:

BS or MS in Computer Science or related technical field

7+ years’ experience developing infrastructure as Code such as AWS CDK, typescript/or Python.

3+ years of experience working on a cloud platform (ex. GCP, AWS, etc.)

AWS CDK with Typescript as language for CDK development

Working Experience for Job Orchestration tool – Airflow/MWAA

Working Experience/Expertise creating AWS infrastructure for AWS services including but not limited to: S3 Datalake, Kms keys, IAM Role/Policy, MWAA, RDS, Lambda function

Experience/Expertise on Databricks is a plus.

Experience architecting, designing and building infrastructure in AWS.

Experience using GitHub for code PR management.

Working Experience in Linux Operating System

Nice to Have - Knowledge/Expertise on tools viz (Fivetran, Monte-Carlo, Datadog, Tableau/Looker)

Excellent written and verbal communication skills.

Ability to work independently and in a team environment.

Ability to pay attention to details and be organized.

Ability to handle multiple tasks in a fast-paced environment.

Willingness to take initiative and to follow through on projects.

Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment.

Must have legal right to work in the U.S

Our goal at SiriusXM is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.

R-2023-10-27",2007,Advertising & Public Relations,Unknown / Non-Applicable,Media & Communication,51 to 200 Employees,Company - Private,False
Data Engineer,"Own Company
","Englewood Cliffs, NJ",-1,3.5,"Own is the leading data platform trusted by thousands of organizations to protect and activate SaaS data to transform their businesses. Own empowers customers to ensure the availability, security and compliance of mission-critical data, while unlocking new ways to gain deeper insights faster. By partnering with some of the world's largest SaaS ecosystems such as Salesforce, ServiceNow and Microsoft Dynamics 365, Own enables customers around the world to truly own the data that powers their business.

It's their platform. It's your data. Own it.

The Job

As a Data Engineer, you will collaborate closely with Analytics Engineering, Business Intelligence, and other cross-functional teams to craft business critical data assets and build strong relationships with key data consumers. In this role, you will report to the head of Data Engineering and play a critical part in maintaining and expanding Own's internal database.

Your Day-to-Day Role
Develop Data Engineering Pipelines and Assets with your Data Engineering peers.
Document and communicate the complexities of your work to the users and the team.
Identify areas of improvement within the database and code that powers it.
Troubleshoot data issues as they arise.
Define and promote DB management tools consolidation.
Your Work Experience
Generally 4 year Mathematics, Data Science, Statistics, CS or Finance degree with 1-2 years of professional experience.
Clear Verbal and Written Communicator.
Customer-centric focus for Internal Staff.
Able to write complex SQL; previous experience with dbt would be desirable.
Hands on experience working within Relational Databases (Snowflake, Amazon Redshift, Microsoft SQL) to deploy code and administer the platform.
Experience writing Python scripts to perform ELT/ETL and Reverse ETL.
Experience with Airflow, Dagster, or other orchestration tools.
Experience working with Scrum\Agile methodology is a plus.
Important Details

This is a full-time position. The ideal candidate will work out of our Englewood Cliffs, NJ office a minimum of 3 days per week to maximize collaboration and interaction with the business. Travel may be required.

Own is dedicated to creating an environment where employees thrive, which is why base pay is only one part of the total compensation package that is provided to compensate and recognize employees for their work. This role may also be eligible for unlimited PTO, generous medical benefits, a 401(k) savings plan with a 4% employer match, discretionary bonuses/incentives, and stock options. We also offer catered lunches in the office five days a week, a full fitness center, and free shuttle bus service to and from New York City.

Creating an environment where employees thrive also means making sure every employee feels accepted. As we scale to help all types of companies protect precious data, our team must reflect the diversity we serve. Own is an Equal Opportunity Employer and we believe that every employee in the company brings a unique perspective that they can and should contribute in order to make an impact every day. We strive to be one team and one culture that builds trust through transparency. We do not discriminate based on race, color, religion, sex, sexual orientation, gender identity, age, national origin, protected veteran status or disability status.

Learn more at owndata.com.

#LI-Onsite",2015,Enterprise Software & Network Solutions,$100 to $500 million (USD),Information Technology,501 to 1000 Employees,Company - Private,True
"Data Engineer, CRM Activations","ASK Consulting
","Ridgefield Park, Bergen, NJ",$94K - $142K (Glassdoor est.),3.6,"Job Type:Contract

Posted 24 days ago



Expiry Date: 01 December 2023
Referral: 233055@accuick.com

""All candidates must be directly contracted by ASK Consulting on their payroll and cannot be subcontracted. We are unable to provide sponsorship at this moment"".




job Description:

Position Summary: Are you a talented Data Engineer ready to make a significant impact in the world of data-driven marketing? Join our dynamic CRM Activations team as we develop and deploy cutting-edge data products and platforms to drive marketing efforts throughout the US. This is a contract position offering an exciting opportunity to work on innovative projects that redefine the marketing landscape.


Key Responsibilities:

Develop, monitor, and maintain critical data pipelines and platforms in a cloud-based Big Data environment.

Collaborate with product managers, data infrastructure teams, and project stakeholders to rapidly design and deploy solutions that meet business demands.

Qualifications:

5+ years of Data Engineering experience with cloud-based services and big data technologies, including Amazon EMR, GCP, Hive/Spark.

Advanced proficiency in Python and SQL (Presto, Postgres).

Experience in building and optimizing ""big data"" orchestration and workflows using tools like Airflow.

Solid understanding of security best practices, privacy regulations, and compliance.

A background in Martech, CRM, media agencies, or audience platforms is a plus.

Familiarity with Vertica is a plus.

Knowledge of Data Governance practices is a plus.

Strong analytical skills for working with structured and unstructured datasets.

Exceptional organization, communication, and interpersonal skills.

Excellent decision-making ability and the capability to thrive in an agile, fast-paced environment.

A self-driven passion for self-education and adopting new technologies and approaches.

A Bachelor's degree in Computer Science, Software Engineering, or a related discipline, or equivalent work experience.

Working with Us: This is a contract position, offering a unique opportunity to be part of our innovative CRM Activations team. We are committed to fostering an inclusive culture and a diverse workforce. Candidates should be prepared to join our company's payroll, as subcontracting is not allowed.

If you are a forward-thinking Data Engineer with a passion for technology and a desire to revolutionize data-driven marketing, we encourage you to apply. Your contributions will play a vital role in reshaping the marketing landscape for a leading organization in the industry.




About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With 5 nationwide offices, two global delivery centers, and employees in 42 states-ASK Consulting connects people with amazing opportunities

ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.",1995,HR Consulting,$25 to $100 million (USD),Human Resources & Staffing,501 to 1000 Employees,Company - Private,False
Senior Data Engineer - Vice President,"JPMorgan Chase & Co
","Jersey City, NJ",$157K - $200K (Employer est.),4.0,"JOB DESCRIPTION


Embrace this pivotal role as an essential member of a high performing team dedicated to reaching new heights in data engineering. Your contributions will be instrumental in shaping the future of one of the world’s largest and most influential companies.

As a Data Engineer- Vice President in the Community and Consumer Banking (CCB) Finance organization, you are an integral part of an agile team that works to enhance, build, and deliver data collection, storage, access, and analytics in a secure, stable, and scalable way. Leverage your deep technical expertise and problem solving capabilities to drive significant business impact and tackle a diverse array of challenges that span multiple data pipelines, data architectures, and other data consumers.

Job responsibilities

Provides recommendations and insight on data management, governance procedures, and intricacies applicable to the acquisition, maintenance, validation, and utilization of data
Designs and delivers trusted data collection, storage, access, and analytics data platform solutions in a secure, stable, and scalable way
Defines database back-up, recovery, and archiving strategy
Generates advanced data models for one or more teams using firm wide tooling, linear algebra, statistics, and geometrical algorithms
Approves data analysis tools and processes
Creates functional and technical documentation supporting best practices
Advises junior engineers and technologists
Evaluates and reports on access control processes to determine effectiveness of data asset security
Adds to team culture of diversity, equity, inclusion, and respect

Required qualifications, capabilities, and skills

6+ years of experience in engineering along with a Bachelor’s of Science in Computer Science
Minimum of 3 years professional experience with AWS
Working experience with both relational and NoSQL databases
Advanced understanding of database back-up, recovery, and archiving strategies
Advanced knowledge of linear algebra, statistics, and geometrical algorithms
Experience presenting and delivering visual data

Preferred qualifications, capabilities, and skills

Masters of Science in Computer Science preferred
Working experience with Databricks and/or Snowflake
Proficiency in data transformation using tools like Alteryx, PySpark etc.
Working knowledge of BI tools like Tableau , Thoughtspot

For this particular role, we are unable to sponsor any type of work visa including but not limited to H1B, H4 – EAD, OPT, TN, or L visas.

Candidates must be able to physically work in our Wilmington, DE or Jersey City, NJ offices 3 days a week and remotely from home 2 days per week. The specific schedule will be determined by direct management.

#LI-HYBRID

ABOUT US


Chase is a leading financial services firm, helping nearly half of America’s households and small businesses achieve their financial goals through a broad range of financial products. Our mission is to create engaged, lifelong relationships and put our customers at the heart of everything we do. We also help small businesses, nonprofits and cities grow, delivering solutions to solve all their financial needs.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.


We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.

Equal Opportunity Employer/Disability/Veterans




ABOUT THE TEAM

Our Consumer & Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We’re proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions – all while ranking first in customer satisfaction.",1799,Banking & Lending,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
Senior Web Engineer - Web Services - Data Technologies,"Bloomberg
","Princeton, NJ",$160K - $240K (Employer est.),4.1,"Bloomberg Data Technologies Engineering is seeking a strong Software Engineer that has a passion for full stack web application development, strong design/implementation skills, and experience integrating multiple external and internal systems.

Bloomberg Data Technologies is responsible for the acquisition, enrichment, and distribution of data and news throughout the firm and the Bloomberg Terminal. We have hundreds of thousands of internal and external users across the globe who are actively using our applications to analyze and process information that is critical to our clients in making key investment decisions. Key aspects of our business include developing web sites and web applications to facilitate our data pipeline.

Our team develops applications for both internal and external clients. Externally, our applications allow our clients and partners in the financial industry to help handle their needs for high-quality, real time data and services. Internally, our tools help support a wide variety of critically important data workflows. We also maintain a series of reusable front-end and back-end components for the entire Data Technologies group for building up their own web applications.

We'll trust you to:
Design, implement and own critical applications and components of our platform.
Participate in the full SDLC of various components and systems that are required to be robust and scalable.
Get to know engineering and data teams across Bloomberg, understand their application requirements and data access patterns.
Understand the needs of our clients, and come up with an efficient and innovative approach to translate them to features and enhancements to the platform.
Bring the latest and greatest innovation and technology stack features from the open source community to our products.
You'll need to have:
4+ years experience building comprehensive, scalable, and extensible client-side apps with JavaScript (ES2015+)/TypeScript, Front End Development frameworks/tools, such as React, Angular, Vue, Webpack, Babel, Twitter Bootstrap, etc.
4+ years experience working with Node.js, including server application, frameworks, CLI tools, and building microservices.
Prior contributions to system design and architecture and scaling fault-tolerant, distributed systems.
A Degree in Computer Science, Engineering, Mathematics, similar field of study or equivalent work experience.
We'd love to see:
Experience working with Microservice architectures and methodologies such as Twelve-factor.
Familiarity with Web standards and browser related technologies.
Knowledge of Big Data, SQL and NoSQL Databases, and Cloud-Based Object Stores.
Experience with optimizing performance for web applications and working with distributed systems.
Knowledge and experience with improving security and mitigating risks of web applications.

Bloomberg is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or maternity/parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law.

Bloomberg provides reasonable adjustment/accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable adjustment/accommodation to apply for a job or to perform your job. Examples of reasonable adjustment/accommodation include but are not limited to making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you would prefer to discuss this confidentially, please email AMER_recruit@bloomberg.net (Americas), EMEA_recruit@bloomberg.net (Europe, the Middle East and Africa), or APAC_recruit@bloomberg.net (Asia-Pacific), based on the region you are submitting an application for.

Salary Range: 160,000 - 240,000 USD Annually + Benefits + Bonus

The referenced salary range is based on the Company's good faith belief at the time of posting. Actual compensation may vary based on factors such as geographic location, work experience, market conditions, education/training and skill level.

We offer one of the most comprehensive and generous benefits plans available and offer a range of total rewards that may include merit increases, incentive compensation [Exempt roles only], paid holidays, paid time off, medical, dental, vision, short and long term disability benefits, 401(k) +match, life insurance, and various wellness programs, among others. The Company does not provide benefits directly to contingent workers/contractors and interns.",1981,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,10000+ Employees,Company - Private,False
Principal Data Engineer - U.S. Based Remote,"Anywhere Real Estate
","Madison, NJ",$154K - $200K (Employer est.),3.5,"It's an exciting time to be a part of Anywhere's team! We're working to build and improve a platform that will deliver modern, flexible solutions for our real estate professionals to work more efficiently while simultaneously crafting a one of a kind experience for home buyers and sellers. Combining great technology with phenomenal people drive our goals, and we are looking for a Principal Data Engineer to join our team to reach them.

We're looking for:
Dedicated and Creative: You thrive on developing powerful, stable, and intuitive applications. Working alongside a team of passionate individuals, you bring your creativity to the forefront.
Big Data and Java Mastery: Your validated experience has honed your skills in Big Data and Java2. Now, you’re eager to elevate your expertise to new heights.
Ambitious Projects: You relish in bold projects that involve large data sets. Even under pressure, you remain cool and focused.
Agile Environment: Fast-paced environments and agile development methodologies are your comfort zone. You embrace them wholeheartedly.
Analytical Skills: Your analytical prowess is unmatched, ensuring quality and precision in your work.
Collaborative Work Ethic: You thrive in collaborative settings, working closely with product managers, designers, and fellow engineers to achieve greatness at Anywhere Real Estate.

What you’ll do:

Design and build high-performance, scalable data solutions that cater to the needs of millions of agents, brokers, home buyers, and sellers.

Develop and test robust, scalable data platform components.

Collaborate with various teams and individuals to understand their data pipeline requirements and devising innovative solutions.

Work with a dedicated team of engineers, and multi-functionally with product managers and designers to define new data products and features.



Skills, accomplishments, interests:

BS/MS in Computer Science, Engineering, or related technical subject area or equivalent combination of training and experience.

8+ years core Scala/Java experience: building business logic layers and high-volume/low latency/big data pipelines.

5+ years of experience in large scale real-time stream processing using Apache Flink or Apache Spark with messaging infrastructure like Kafka/Pulsar.

5+ years of experience on Data Pipeline design, Data architecture, ETL and processing of structured and unstructured data.

3+ years of confirmed experience using NoSQL systems like MongoDB, DynamoDB and Relational SQL Database systems (PostgreSQL) and Athena.

Excellent understanding of Architecture, system Design including nonfunctional requirements and experience evaluating tech stack/product to decide build vs. buy.

Experience with technologies like Lambda, API Gateway, AWS Fargate, ECS, CloudWatch, S3, Datadog.

Experience defining and owning technical/data direction of the pipelines.

Excellent written and verbal communication skills in English.

#LI-JC1

#LI-Remote

#Dice

#AnywhereEngineers




Exciting News:

EEO Statement: EOE AA M/F/Vet/Disability

Compensation Range:

The base salary for this position is $154,300 to $199,600.",-1,Real Estate,Unknown / Non-Applicable,Real Estate,Unknown,Company - Public,False
Senior Data Platform Engineer - Agency Temp,"Sirius XM
","Lawrenceville, NJ",$87K - $126K (Glassdoor est.),3.5,"Responsibilities:

Who We Are:

SiriusXM and its brands (Pandora, SXM Media, AdsWizz, Simplecast, and SiriusXM Connected Vehicle Services) are leading a new era of audio entertainment and services by delivering the most compelling subscription and ad-supported audio entertainment experience for listeners - in the car, at home, and anywhere on the go with connected devices. Our vision is to shape the future of audio, where everyone can be effortlessly connected to the voices, stories and music they love wherever they are. This is the place where a diverse group of emerging talent and legends alike come to share authentic and purposeful songs, stories, sounds and insights through some of the best programming and technology in the world. Our critically-acclaimed, industry-leading audio entertainment encompasses music, sports, comedy, news, talk, live events, and podcasting. No matter their individual role, each of our employees plays a vital part in bringing SiriusXM’s vision to life every day.

SiriusXM is the leading audio entertainment company in North America, and the premier programmer and platform for subscription and digital advertising-supported audio products. SiriusXM’s platforms collectively reach approximately 150 million listeners, the largest digital audio audience across paid and free tiers in North America, and deliver music, sports, talk, news, comedy, entertainment and podcasts. Pandora, a subsidiary of SiriusXM, is the largest ad-supported audio entertainment streaming service in the U.S. SiriusXM's subsidiaries Simplecast and AdsWizz make it a leader in podcast hosting, production, distribution, analytics and monetization. The Company’s advertising sales organization, which operates as SXM Media, leverages its scale, cross-platform sales organization and ad tech capabilities to deliver results for audio creators and advertisers. SiriusXM, through Sirius XM Canada Holdings, Inc., also offers satellite radio and audio entertainment in Canada. In addition to its audio entertainment businesses, SiriusXM offers connected vehicle services to automakers.

How you’ll make an impact:

In this role you will be a member of a team responsible for designing, developing and supporting a data platform which will be used across data organization and other groups.

What you’ll do:

Build cloud-based data platform which supports Datalake, Job Orchestration, ETL template, ETL Compute, integration with third party tools like fivetran, Monte Carlo

Design, code and maintain infrastructure as a code (IaC) using CDK, typescript, CDKTF.

Build and improve workflow orchestration tooling to support efficient data pipelines E.g., airflow plugins, systems integration, deployments.

Strengthen best practices around data platform setup and configuration.

What you’ll need:

BS or MS in Computer Science or related technical field

7+ years’ experience developing infrastructure as Code such as AWS CDK, typescript/or Python.

3+ years of experience working on a cloud platform (ex. GCP, AWS, etc.)

AWS CDK with Typescript as language for CDK development

Working Experience for Job Orchestration tool – Airflow/MWAA

Working Experience/Expertise creating AWS infrastructure for AWS services including but not limited to: S3 Datalake, Kms keys, IAM Role/Policy, MWAA, RDS, Lambda function

Experience/Expertise on Databricks is a plus.

Experience architecting, designing and building infrastructure in AWS.

Experience using GitHub for code PR management.

Working Experience in Linux Operating System

Nice to Have - Knowledge/Expertise on tools viz (Fivetran, Monte-Carlo, Datadog, Tableau/Looker)

Excellent written and verbal communication skills.

Ability to work independently and in a team environment.

Ability to pay attention to details and be organized.

Ability to handle multiple tasks in a fast-paced environment.

Willingness to take initiative and to follow through on projects.

Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment.

Must have legal right to work in the U.S

Our goal at SiriusXM is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.

The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",1990,Broadcast Media,$1 to $5 billion (USD),Media & Communication,1001 to 5000 Employees,Company - Public,False
USA - Data Transport Infrastructure Operations Lead Engineer / MFT,Avestacs,New Jersey,-1,-1.0,"Job Title: Data Transport Infrastructure Operations Lead Engineer / MFT

Location: New Jersey, NJ

Type: Contract




Our customer is one of the largest custodian banks.




What you will be responsible for:

As Data Transport Infrastructure Operations Lead Engineer you will

Provide leadership and technical expertise for Managed File Transfer Application Services.
Manage and train Operational personnel.
Effectively participate and lead ITIL processes including Incident, Problem, Change, Capacity management
Serve as a client liaison and a point of escalation for internal and external customers.
Work with the engineering team on continuous service improvement focusing on automation and service standardization.
Initiate and manage vulnerability remediation, patching, upgrades, and hardware life cycle to ensure we remain current with technology solutions and meet client needs.



What we value:

These skills will help you succeed in this role

15+ years of relative IT experience
Experience with Managed File Transfer products. Self-developed platform or vendor MFT products from Axway- Secure Transport, Premier- Spazio/MFX, IBM-Connect Direct
Experience with Linux/Windows Operating systems
Experience with troubleshooting on file transfer tools/protocols.
Experience with scripting and orchestration - Puppet / Ansible / Python / Shell
Ability to multitask, manage high-priority initiatives and coordinate the activities with Service Delivery and Engineering teams to completion.
Ability to work in a team setting with a diverse group: operations support resources, SSC client services representatives, application and service delivery teams.



Education & Preferred Qualifications:

BS in Computer Science or equivalent",-1,-1,Unknown / Non-Applicable,-1,51 to 200 Employees,Company - Public,False
Data Engineer,"Contact Government Services, LLC
","Newark, NJ",$87K - $127K (Glassdoor est.),4.7,"Data Engineer
Employment Type: Full-Time, Mid-level
Department: Business Intelligence
CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.
Skills and attributes for success:
Complete development efforts across data pipeline to store, manage, store, and provision to data consumers.
Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices.
Write code to ensure the performance and reliability of data extraction and processing.
Support continuous process automation for data ingest.
Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing.
Work with program management and engineers to implement and document complex and evolving requirements.
Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork.
Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists.

Qualifications:
Must be a US Citizen.
Must be able to obtain a Public Trust Clearance.
7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.
Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats.
Proficiency in developing ETL processes, and performing test and validation steps.
Proficiency to manipulate data (Python, R, SQL, SAS).
Strong knowledge of big data analysis and storage tools and technologies.
Strong understanding of the agile principles and ability to apply them.
Strong understanding of the CI/CD pipelines and ability to apply them.
Experience with relational database, such as, PostgreSQL.
Work comfortably in version control systems, such as, Git Repositories.

Ideally, you will also have:
Experience creating and consuming APIs.
Experience with DHS and knowledge of DHS standards a plus.
Candidates will be given special consideration for extensive experience with Python.
Ability to develop visualizations utilizing Tableau or PowerBI.
Experience in developing Shell scripts on Linux.
Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions.
Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences.
Our Commitment:
Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:
Health, Dental, and Vision
Life Insurance
401k
Flexible Spending Account (Health, Dependent Care, and Commuter)
Paid Time Off and Observance of State/Federal Holidays

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:
https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:
Email: info@cgsfederal.com",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,True
Principal Data Engineer (Azure),"Tiger Analytics
","Jersey City, NJ",$108K - $152K (Glassdoor est.),4.0,"Tiger Analytics is a global AI and analytics consulting firm. With data and technology at the core of our solutions, we are solving problems that eventually impact the lives of millions globally. Our culture is modeled around expertise and respect with a team-first mindset. Headquartered in Silicon Valley, you’ll find our delivery centers across the globe and offices in multiple cities across India, the US, UK, Canada, and Singapore, including a
substantial remote global workforce.

We’re Great Place to Work-Certified™. Working at Tiger Analytics, you’ll be at the heart of an AI revolution. You’ll work with teams that push the boundaries of what is possible and build solutions that energize and inspire.


Requirements

Curious about the role? What your typical day would look like?


As a Principal Data Engineer (Azure), you would have hands on experience working on Azure as cloud, Databricks and some exposure/experience on Data Modelling. You will build and learn about a variety of analytics solutions & platforms, data lakes, modern data platforms, data fabric solutions, etc. using different Open Source, Big Data, and Cloud technologies on Microsoft Azure.

Design and build scalable & metadata-driven data ingestion pipelines (For Batch and Streaming Datasets)

Conceptualize and execute high-performance data processing for structured and unstructured data, and data
harmonization
Schedule, orchestrate, and validate pipelines
Design exception handling and log monitoring for debugging
Ideate with your peers to make tech stack and tools-related decisions
Interact and collaborate with multiple teams (Consulting/Data Science & App Dev) and various stakeholders to meet deadlines, to bring Analytical Solutions to life.

What do we expect?

Experience in implementing Data Lake with technologies like Azure Data Factory (ADF), PySpark, Databricks, ADLS,


Azure SQL Database

A comprehensive foundation with working knowledge of Azure Synapse Analytics, Event Hub & Streaming
Analytics, Cosmos DB, and Purview
A passion for writing high-quality code and the code should be modular, scalable, and free of bugs (debugging
skills in SQL, Python, or Scala/Java).
Enthuse to collaborate with various stakeholders across the organization and take complete ownership of
deliverables.
Experience in using big data technologies like Hadoop, Spark, Airflow, NiFi, Kafka, Hive, Neo4J, Elastic Search
Adept understanding of different file formats like Delta Lake, Avro, Parquet, JSON, and CSV
Good knowledge of building and designing REST APIs with real-time experience working on Data Lake or
Lakehouse projects.
Experience in supporting BI and Data Science teams in consuming the data in a secure and governed manner
Certifications like Data Engineering on Microsoft Azure (DP-203) or Databricks Certified Developer (DE) are
valuable addition.

Note: The designation will be commensurate with expertise and experience. Compensation packages are among the best in the industry.


Job Requirement

Mandatory: Azure Data Factory (ADF), PySpark, Databricks, ADLS, Azure SQL Database
Optional: Azure Synapse Analytics, Event Hub & Streaming Analytics, Cosmos DB and Purview.
Strong programming, unit testing & debugging skills in SQL, Python or Scala/Java.
Some experience of using big data technologies like Hadoop, Spark, Airflow, NiFi, Kafka, Hive, Neo4J, Elastic
Search.
Good Understanding of different file formats like Delta Lake, Avro, Parquet, JSON and CSV.
Experience of working in Agile projects and following DevOps processes with technologies like Git, Jenkins & Azure DevOps.
Good to have:
Experience of working on Data Lake & Lakehouse projects
Experience of building REST services and implementing service-oriented architectures.
Experience of supporting BI and Data Science teams in consuming the data in a secure and governed manner.
Certifications like Data Engineering on Microsoft Azure (DP-203) or Databricks Certified Developer (DE)

Benefits

This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.",2011,Business Consulting,$5 to $25 million (USD),Management & Consulting,1001 to 5000 Employees,Company - Private,True
Sr. Data Engineer- Customer Analytics (Hybrid),"Selective Insurance Company of America
","Branchville, NJ",$91K - $150K (Employer est.),3.3,"At Selective, we don't just insure uniquely, we employ uniqueness.

Our Business

Selective is a midsized U.S. domestic property and casualty insurance company with a history of strong, consistent financial performance for nearly 100 years. Selective's unique position as both a leading insurance group and an employer of choice is recognized in a wide variety of awards and honors, including listing in Forbes Best Midsize Employers in 2023 and certification as a Great Place to Work® in 2023.

Working at Selective

At Selective, we don't just insure uniquely – we employ uniqueness. Employees are empowered and encouraged to Be Uniquely You by being their true, unique selves and contributing their diverse talents, experiences, and perspectives to our shared success. Together, we are a high-performing team working to serve our customers responsibly by helping to mitigate loss, keep them safe, and restore their lives and businesses after an insured loss occurs. Employees receive comprehensive total rewards packages - including competitive compensation and performance awards, health benefits, and retirement savings - and professional development opportunities and flexible schedules to support their health, wealth, and well-being. Join our team and help make a difference.

Overview:

Selective Insurance is seeking an energetic and collaborative Sr. Data Engineer to work on data and analytics projects supporting the Customer Analytics team within the Information Management group. This group is responsible for technology support of all Data Engineering, Analytics and Reporting for the Marketing, Customer Experience and Contact Center business areas. This includes Data Engineering services, Enterprise reporting support and ML Ops Engineering operations for these groups. The candidate must be hands on with very good technical skills and a proven track record of project delivery.




Responsibilities:

Hands on development and support of new or existing data applications.
Work closely with business and analysts to understand data and business process and make recommendations to clients as requested on best practices or long-term solutions to resolve current issues and also for future system design
Works closely with Application and Enterprise Architects to create/review low level implementation designs, understand high level data flow designs developed by data architects.
Provide technical guidance to the team for implementing complex data solutions.
Provide support in the design, development, code reviews, test deploy and documentation of data engineering and data integration Applications.
Maintain detailed documentation to support downstream integrations
Provide support for production issues
Performs activities of a scrum master
Identify technology trends and explore opportunities for use within the organization



Qualifications:

Five to seven years of experience in Data Warehousing, Data integration or Data Engineering projects
Ability to effectively work well with people in other departments and/or outside of the enterprise.
Proficient in SQL.
Experience working within Azure ecosystem
Experience in Informatica Powercenter, IICS, Cognos, Netezza Performance servers
Experienced in any of these analytical platforms - PowerBI, AzureML, Databricks or Synapse
Experience using Python or Scala.
Experience in Azure DevOps and Github is preferred
P&C Insurance experience is preferred
Possesses excellent communication skills.
Bachelor’s degree in computer science or related engineering field preferred.



Salary range: $90,600 - $149,600. The actual base salary is based on geographic location, and the range is representative of salaries for this role throughout Selective's footprint. Additional considerations include the candidate's qualifications and experience.

Selective is an Equal Employment Opportunity employer. That means we respect and value every individual’s unique opinions, beliefs, abilities, and perspectives. We are committed to promoting a welcoming culture that celebrates diverse talent, individual identity, different points of view and experiences – and empowers employees to contribute new ideas that support our continued and growing success. Building a highly engaged team is one of our core strategic imperatives, which we believe is enhanced by diversity, equity, and inclusion. We expect and encourage all employees and all of our business partners to embrace, practice, and monitor the attitudes, values, and goals of acceptance; address biases; and foster diversity of viewpoints and opinions.

Selective maintains a drug-free workplace.",1926,Insurance Carriers,$1 to $5 billion (USD),Insurance,1001 to 5000 Employees,Company - Public,False
Senior Software Engineer/SRE- Data and Runtime Stability,"Bloomberg
","Princeton, NJ",$160K - $240K (Employer est.),4.1,"Our Team:
Bloomberg's Data and Runtime Stability SRE team is trusted to administer the end-to-end environment for Bloomberg's installation of numerous services which support the applications that constitute Bloomberg's line of products. On any given day we're inventing, engineering, developing, building, coding, trouble-shooting and maintaining a wide range of: tools, monitors, frameworks, interfaces, protocols, solutions and best-practices. These components stitch together a robust suite of automated and self-healing systems that manage the services that Data and Runtime provides to the rest of the firm. We improve uptime, provision and balance resources, architect and coordinate operational procedures, administer backup and recovery processes, coordinate maintenance windows, manage replication and oversee workflows.

The Role:
In addition to managing the overall Data and Runtime environment, you'll work directly on installations of technologies that use services such as RabbitMQ, Comdb2, Kafka, Redis and many more; getting to collaborate every day with the application developers that create these applications to integrate the services they provide into the Bloomberg operational environment as well as Bloomberg products. So, not only will you have high-level-ownership and ""the classic SRE responsibilities"" such as: system tuning, performance analysis and the management of patches, installations, and upgrades; you'll also have immediate access to the experts that are designing and coding the Bloomberg specific components, APIs and methods. This means insight and entry to the lowest levels of how Bloomberg applications interact with each other and the Runtime environment for the purposes of both in-depth troubleshooting and enhancing stability, reliability, performance and feature-set.
We're open to trying new ideas, processes, and technologies. The right applicant will be imaginative, creative, self-motivated, and highly curious as innovation and initiative are highly valued here. Problem-solving, programming, logical frameworks, and Unix systems should all be second nature. We are looking for someone that will continually strive to improve our environment; regularly asking ""why?"" and saying: ""we can make this better!""

You'll need to have:
4+ years of programming experience with Python
A degree in Computer Science, Engineering or similar field of study or equivalent work experience
5+ years experience with Unix, Unix tools and shell scripting
Deep understanding of TCP/IP networking and the OSI model
Experience designing and automating repeatable processes in a client/server modeled environment
Experience supporting a highly available production systems
Ability to build and maintain highly sophisticated, performant, and scalable, critically important systems
Experience building monitors and alarms for system performance, status and stability
Experience with CI/CD systems and writing robust unit and system tests
We'd love to see:
Experience in Rapid framework
Experience analyzing existing systems and identifying shortcomings with concrete ideas for improvement
C programming skills
Experience designing stable, long-lasting APIs
Experience with Splunk/Humio and Grafana
Experience with GitHub and JIRA.

Bloomberg is an equal opportunity employer, and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or maternity/parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law.

Bloomberg provides reasonable adjustment/accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable adjustment/accommodation to apply for a job or to perform your job. Examples of reasonable adjustment/accommodation include but are not limited to making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you would prefer to discuss this confidentially, please email AMER_recruit@bloomberg.net (Americas), EMEA_recruit@bloomberg.net (Europe, the Middle East and Africa), or APAC_recruit@bloomberg.net (Asia-Pacific), based on the region you are submitting an application for.

Salary Range: 160,000 - 240,000 USD Annually + Benefits + Bonus

The referenced salary range is based on the Company's good faith belief at the time of posting. Actual compensation may vary based on factors such as geographic location, work experience, market conditions, education/training and skill level.

We offer one of the most comprehensive and generous benefits plans available and offer a range of total rewards that may include merit increases, incentive compensation [Exempt roles only], paid holidays, paid time off, medical, dental, vision, short and long term disability benefits, 401(k) +match, life insurance, and various wellness programs, among others. The Company does not provide benefits directly to contingent workers/contractors and interns.",1981,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,10000+ Employees,Company - Private,False
Software Engineer III - Java/Data Engineering,"JPMorgan Chase & Co
","Jersey City, NJ",$128K - $180K (Employer est.),4.0,"JOB DESCRIPTION


We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.

As a Software Engineer III at JPMorgan Chase within the Corporate Sector Liquidity Team, you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.

Job responsibilities

Works in a fast-paced environment and helps build APIs, Calculators, on new cutting edge cloud and big data technologies such as AWS EMR, EC2, Scala Spark, Scala, Snowflake
Executes standard software solutions, design, development, and technical troubleshooting
Writes secure and high-quality code using the syntax of at least one programming language with limited guidance
Designs, develops, codes, and troubleshoots with consideration of upstream and downstream systems and technical implications
Applies knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation
Applies technical troubleshooting to break down solutions and solve technical problems of basic complexity
Gathers, analyzes, and draws conclusions from large, diverse data sets to identify problems and contribute to decision-making in service of secure, stable application development
Learns and applies system processes, methodologies, and skills for the development of secure, stable code and systems
Adds to team culture of diversity, equity, inclusion, and respect

Required qualifications, capabilities, and skills

Formal training or certification on software engineering concepts and 3 + years applied experience
Hands-on practical experience in system design, application development, testing, and operational stability using Java, Scala and/or Python.
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages
Experience across the whole Software Development Life Cycle
Exposure to agile methodologies such as CI/CD, Applicant Resiliency, and Security
Emerging knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.
Knowledge of Unix shell and SQL as well as NoSQL DBs is required.

Preferred qualifications, capabilities, and skills

Knowledge of Spark and Scala
Familiarity with modern front-end technologies
Exposure to cloud technologies (AWS EMR, EC2, Snowflake)ke)
ABOUT US

JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)

We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.

JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans







ABOUT THE TEAM

Our professionals in our Corporate Functions cover a diverse range of areas from finance and risk to human resources and marketing. Our corporate teams are an essential part of our company, ensuring that we’re setting our businesses, clients, customers and employees up for success.",1799,Banking & Lending,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
Senior Governance Data Engineer,"Mars
","Newark, NJ",$109K - $158K (Glassdoor est.),4.3,"Job Description:

Senior Governance Data Engineer, Supply Chain and Operations Analytics
Multiple locations: Slough/London-UK, Veghel-NL
Mars Inc is undergoing a significant Digital Transformation journey. Our ability to solve the most critical problems across Mars in a User Centric way through Data & Analytics is fundamental to our Digital Engine and transformation. The opportunities are significant for Mars, and the opportunities for those working in this space are both hugely exciting and rewarding. Connecting and deriving break-through insight from our Mars Snacking data ecosystems, leveraging the rapidly growing world of external data to get closer to our customers and consumers than ever before, and unlocking efficiencies and automation in our End-to-end Supply Chain operations are just some of our big focus areas.
Building on this momentum, we are recruiting an experienced Senior Governance Data Engineer to drive innovation, design and development for Data Mesh delivery and adoption within our organization in a transformational role. You are a part of the Data Engineering capability, working alongside teams of Data Scientists, and Delivery Managers, to design data frameworks and services which drive efficiency and quality across Mars Snacking’s end-to-end Supply Chain function.
This transformational role aims to support a 36-month transformative program and will be focused primarily on the reinvention and enhancement of the digital acceleration effort ongoing at Mars. This role has a strong potential to transition into a permanent Mars role prior to the conclusion of the transformation period, where appropriate.
The Role:
Lead the charge in establishing new ideas, governance, methodologies, and best practices in Data Engineering and analytics within Supply Chain Data & Analytics, with a focus on driving transformative change.
Engage and collaborate with our Chief Data Office and Data Stewards community across Mars to drive data quality, metadata.
Ensure data improvement plans are in place to support effective governance, by democratizing and maintaining coherent Data Models.
Own the design, build and execution of Data Frameworks for managing, governing, and improving the data quality of our Data Mesh assets, Data Catalogue and overall metadata management.
Evangelise the adoption of data driven decisions across Mars by leading the development of advanced analytical tools that utilize the vast amounts of data available to the company within the appropriate governance frameworks.
Establishes credibility with stakeholders at all levels of the organisation. Facilitates and influences complex or ambiguous business discussions, while flexing to communicate Data Engineering related possibilities and concepts in a relatable way.
Requirements:
You are a strong software engineer with deep expertise in cutting-edge technologies, robust design, development and testing of high quality and scalable data solutions.
Your deep expertise in data analytics, as well as strong practical experience with modern engineering technologies, standards and frameworks will enable you and the team to intelligently transform data into value, while creating robust and standardised capabilities.
You will work on Data Engineering projects in collaboration with other team members (including with offshore talent partners) to ensure rapid development of robust, scalable consistent and sustainable data solutions, with global best practices.
Own the design and technical roadmap for the evolution of our Data Mesh product to enable continuous adoption of Mesh assets into the organisation.
Day-to-day you will work in multidisciplinary teams & collaborate with Mars Chief Data organisation, Mars Global Analytics, Big Data Engineering, and Advanced ML teams.
Within this team, you will:
Create and implement Data Catalogue and underpinning Governance processes to allow users to access data in a standard approach as well as supporting discovery, prototyping and data science, which can subsequently be turned into enterprise solutions.
Implement the Data Quality Management standards and frameworks within the organisation through profiling, rules implementation, monitoring, alerting and resolution whilst being able to measure improvements in quality and identify the value that it delivers to the business teams.
Elevate overall data management maturity within the e2e supply chain organisation.
Understand complex business processes and combine your business acumen, problem solving skills, and curiosity to identify value-add opportunities for the applications of Data Engineering.
Present results in a cohesive, intuitive, and concise manner that can be understood by both technical and non-technical audiences.
QUALIFICATIONS & COMPETENCIES
Education:
Bachelor’s degree in Analytics or related quantitative fields (Statistics, Operations Research, Mathematics, Econometrics etc.) Advanced degree is preferred.
Preferred – Post-graduate qualifications in Computer Science, Data Engineering or professional qualifications in Advanced Data Design, Big Data.
Experience:
Minimum 8 years of experience in an Applied Data Engineering role or equivalent, ideally within the FMCG, Consumer Products, Insurance or Financial Services industries.
Technical expertise in Big Data Tech Stack and experience in database and data Engineering capabilities
Experience with Azure cloud-based computing platform.
Experience using Azure Data factory, Databricks, Azure Functions, Logic Apps , Power BI and Synapse technologies across traditional and contemporary databases (e.g. SQL Server, Hadoop, NoSQL DB), programming languages such as SQL, C#, Python and visualization tools
Experience using Azure DevOps for CI/CD, unit testing, and AGILE development.
Experienced with implementation and being the consumer of a Data Cataloguing capability, such as Alation, Collibra, MSFT Purview or other.
Understanding of design and development of data stores, digital solutions and data warehouses and associated toolsets.
Strong problem solving, communication, presentation, and stakeholder engagement skills.
Planning, project management and organizational orchestration skills and a strong attention to detail
What can you expect from Mars?
Work with over 130,000 diverse and talented Associates, all guided by the Five Principles.
Join a purpose driven company, where we’re striving to build the world we want tomorrow, today.
Best-in-class learning and development support from day one, including access to our in-house Mars University.
An industry competitive salary and benefits package, including company bonus.

Mars is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. If you need assistance or an accommodation during the application process because of a disability, it is available upon request. The company is pleased to provide such assistance, and no applicant will be penalized as a result of such a request.",1911,Food & Beverage Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Private,False
Lead Data Security Engineer,"ADP
","Roseland, NJ",-1,3.9,"ADP is hiring a Data Security Engineer

Are you ready to help us design the future-state to secure and govern our Data?

Well, this may be the role for you. Ready to make your mark?

As a Data Security Engineer, you will join a highly skilled and focused Global Security team, who provide excellent data protection services over the ADP Network platform and across ADP company assets. We protect sensitive ADP client and company data throughout the data life cycle.

You will need to leverage all your experience and be willing and eager to pick-up some new skills as well. Here are some skills that would be valuable to possess to be successful in role.

Programming Skills:
C#, Java, T-SQL, RegEx, PowerPlatform, PowerShell, C++/Rust, JavaScript & WebAPIs

Windows, Mac, & Linux application & development experience desired
Office Plug-In & SharePoint Framework (SPFx) experience desired

Technology Skills
FSRM, FCI, File System APIs & implementation (Windows, Linux, & MacOS wrt ADS and EFA)
Hashing, Tokenization, Digital Rights Management (DRM), MS Sensitivity Labels

Analysis Skills:
SQL, Graph API, and Reporting Tools

Data Security Knowledge
DLP (Storage, End Point, Network), File ACLs, Encryption & Key Management

Technology Platforms Knowledge
SharePoint Framework (SPFx), Splunk, Securiti.AI, ServiceNow, NetApp, Windows, Linux, MacOS

Leadership / Process Mindset
Advise, Develop, & Coordinate among multiple cross-discipline teams to establish sustainable processes to improve data security, while minimizing the impact to the average associate and reducing security incidents globally.

A little about ADP: We are a global leader in HR technology, offering the latest AI and machine learning-enhanced payroll, tax, HR, benefits, and much more. We believe our people make all the difference in cultivating an inclusive, down-to-earth culture that welcomes ideas, encourages innovation, and values belonging. A global Best Places to Work, Diversifying® Top 50 Company, Best CEO and company for women, LGBTQ+, multicultural talent, and more, ADP has a deep commitment to diversity, equity, and inclusion. Learn more about ADP's commitment on our YouTube channel: http://adp.careers/DEI_Videos

A little about the Data Security Team:

You will join a highly skilled and focused team providing excellent data security services, strategies, & processes. We protect sensitive ADP client and company data throughout the data life cycle. Responsibilities include protecting company and client data from exploitation or misuse, leading the design and implementation of data security and privacy policies, identifying weak control areas, and engineering relevant mitigating controls, and mitigating operational risks associated with data in motion and at rest. We help develop, enhance, and drive the vision & effectiveness of the data security program.

Like what you see? Apply now!

Learn more about ADP at tech.adp.com/careers

TO SUCCEED IN THIS ROLE:

Positive Professional. You have an upbeat, persistent style and the ability to produce creative solutions without fear of rejection. You can manage your time well, prioritize deliverables, and multi-task with the best of them. In addition, you can present your ideas in a clear, professional manner on paper, in-person, and over the phone. With your leadership skills, you are comfortable influencing, guiding and lending expertise to other teams & associates. You already possess a high degree of integrity, are trustworthy, and can work independently.
Subject Matter Expert. Solid programming experience will be key to being successful in this role... it will help you interface with the various product teams from an engineering perspective. Your experience with programming (in various language categories: scripting, procedural, functional, OO, etc.) for business applications & systems automation will help us deliver solutions to meet today's needs, and tomorrow's vision! Experience across Databases (SQL & Admin) and Business Intelligence (BI) reporting, as well as unstructured data technologies (NTFS, SMB, XFS, NFS, etc.) will help you jump right in.
Proven Experienced Winner. With your four to ten-plus years of experience in technology & cybersecurity roles, including: planning, implementing, and running security solutions. You have a track record of integrating both technological & people processes to ensure adoption success. You work well with key collaborators (security partners, technology teams, business units) to help improve or solution designs that adapt to ADP data platforms.
Technical Background You possess strong analytical skills and cross-functional knowledge of multiple technology and cybersecurity domains. You are superb at defining and documenting business processes and controls. Your background will lend strength based on your experience with Digital Rights Management (DRM), meta-data definitions, and encryption technologies & solutions. In addition, your knowledge and working experience with data loss prevention (DLP), and structured and unstructured data protection (UDP) technologies and approaches will help prevent unsafe and incorrect data disclosure, transmission, or exfiltration. You may possess a vast background (additional certificates help support your deep security knowledge (CISSP, GSEC, CISA, CISM, CRISC, MCSD), comprising of functional experience working in a global hybrid cloud environment, including AWS, Azure, O365, and GCP. Experience with Data Governance or Data Compliance Standards is valuable.
Fabulous Soft Skills. You recognize that with the pace that digital transformations drive, one must include the ability to communicate with various audiences that include executive leadership, business leaders, engineers, architects, clients, and associates. You know that it is important to possess great verbal communication skills to convey information to all levels. This includes exceptional written communication skills, documentation, and reporting. The sense-of-urgency, activator attitude you possess makes you a stellar candidate and highly sought after on project teams!
A college degree is great but not required. What is more important is having the attitude, skills, and experience to do the job.



WHAT YOU'LL DO:

Here is what you can expect on a typical day in the life of a at ADP.

Discover and analyze vulnerabilities in data repositories (databases, unstructured data: network/local storage, GitHub/Bitbucket, etc). Guide and contribute to efforts to gather and define requirements to develop prevention and detection capabilities that support ADP's data security policies. Interpret security and technical requirements from business requirements and communicate security risks to relevant stakeholders ranging from business leaders to engineers. Produce detailed solution designs for next generation data loss prevention and data protection capabilities and services. Continually improve program outcomes, address gaps, and reduce risk to ADP's infrastructure, processes, and sensitive data. Organize and coordinate supporting services for testing, deployment of new technical design specifications, and implementation and configuration of software suites.
Advise the business on data retention, security, & compliance concerns. Lead and influence multi-disciplinary teams in implementing and operating Cyber security controls. Work collaboratively with cross functional teams including strategic product managers, enterprise technology, privacy, and information security teams to create and drive a future vision for next generation data security in multiple cloud environments and data platforms. Provide input and feedback on security architectures, and influence others with your expertise. Your experience with data loss prevention platforms and collaborative approach will help shape ADP's security policies and standards for use in cloud and hybrid environments.
Maintain compliance with Internal Processes, Policies & Standards. Developing security guardrails, in alignment with business processes, to protect data collected and used at ADP. Analyze forensic information regarding security incidents to improve business processes & enhance security technologies. Lead efforts to gather/define requirements to develop prevention and detection capabilities that support ADP's data security policies, assess, and evaluate data security control effectiveness, enable comprehensive orchestration and automation to provide improved metrics and operational support, and identify and implement new security technologies and best practices into the company's critical applications.
Enable the comprehensive orchestration and automation of security processes to provide rapid incident response and gain efficiencies throughout the technical security services lifecycle.
Maintain an expert level understanding of emerging DLP security threats and the capabilities that provide relevant mitigating controls. Provide consulting services to the business units and IT organizations to educate and ensure adherence with ADP's data security standards and industry best practices. Develop and maintain vendor relationships that partner with cloud services. Ensure compliance, drive control coverage, and define technical policies for cloud security controls across multiple workloads and environments.
Drive the discovery and prioritize remediation of data controls to meet audit, compliance and ADP's data protection requirements, policies, and standards. Ensure global data security initiatives adhere to continually changing privacy and legal compliance requirements. Assess and evaluate end point and data security control effectiveness, and drive towards improved control effectiveness, consistency, and maturity across the organization.

YOU'LL LOVE WORKING HERE BECAUSE YOU CAN:

What we're doing here will surprise you. Whether we're leveraging one of the world's most comprehensive datasets that predicts the economic health of a nation, using the latest tech stacks to create adaptive, industry-changing platforms, or developing one of the Top 10 mobile applications for business, we're making a positive impact on the lives of millions of people around the world. Every day.
Deliver at epic scale. We deliver real user outcomes using strong judgment and good instincts. We are obsessed with the art of achieving simplicity with a focus on client happiness and productivity.
Join a company committed to equality and equity. Our goal is to affect lasting change through our actions.
Team collaboration. Courage comes from how associates are willing to have difficult conversations, speak up, be an owner, and challenge one another's ideas to net out the best solution.
Be surrounded by curious learners. We align ourselves with other smart people in an environment where we grow and elevate one another to the next level. We encourage our associates to listen, stay agile, and learn from mistakes.
Act like an owner & doer. Mission-driven and committed to navigating change, you will be encouraged to take on any challenge and solve complex problems. No tasks are beneath or too great for us. We are hands-on and willing to master our craft.
Give back to others. Always do the right thing for our clients and our community and humbly give back to the community where we live and work. Support our associates in times of need through ADP's Philanthropic Foundation.

Find out why people come to ADP and why they stay: https://youtu.be/ODb8lxBrxrY

(ADA version: https://youtu.be/IQjUCA8SOoA )

Actual salary may be above or below this range based on factors such as location, skills, and relevant experience.

In addition, this position may include additional compensation in the form of bonus, equity, or commissions.

If you are a full-time salaried or hourlyworker, we offer the following benefits:

Medical, Dental, Vision, Life Insurance, Matched 401(k), Student Loan Repayment
Program, Wellness Program, Short- and Long-TermDisability, Charitable
Contribution Match, Holidays, Personal Days & Vacation, Paid Volunteer Time Off,
and more.
Salary range for this role is: $75,600 - $202,590/year

Diversity, Equity, Inclusion & Equal Employment Opportunity at ADP: ADP affirms that inequality is detrimental to our associates, our clients, and the communities we serve. Our goal is to impact lasting change through our actions. Together, we unite for equality and equity. ADP is committed to equal employment opportunities regardless of any protected characteristic, including race, color, genetic information, creed, national origin, religion, sex, affectional or sexual orientation, gender identity or expression, lawful alien status, ancestry, age, marital status, or protected veteran status and will not discriminate against anyone on the basis of a disability. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.

Ethics at ADP: ADP has a long, proud history of conducting business with the highest ethical standards and full compliance with all applicable laws. We also expect our people to uphold our values with the highest level of integrity and behave in a manner that fosters an honest and respectful workplace. Click https://jobs.adp.com/life-at-adp/ to learn more about ADP's culture and our full set of values.",1949,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Analytics Engineer,TEKtalent Inc,"Trenton, NJ",$44.00 - $55.00 Per Hour (Employer est.),-1.0,"A dbt (data build tool) Developer is responsible for leveraging dbt to transform, model, and manage data within an organization's data analytics stack. dbt Developers play a crucial role in streamlining data workflows, ensuring data accuracy, and providing a structured foundation for data analysis and reporting.

Responsibilities:

1. Data Transformation and Modeling:

Design and implement data transformations and models using dbt to create structured, cleaned, and aggregated datasets.
Develop and maintain dbt models that accurately represent business logic and data requirements.

2. SQL Expertise:

Write and optimize SQL queries within dbt to extract, manipulate, and join data from various sources (e.g., databases, APIs, flat files).
Ensure SQL code follows best practices for readability, performance, and maintainability.

3. Version Control:

Use version control systems (e.g., Git) to manage dbt codebase, enabling collaborative development and tracking changes over time.
Collaborate with data engineers and analysts to coordinate code changes.

4. Testing and Documentation:

Implement unit tests within dbt to verify the accuracy and reliability of data transformations.
Document dbt models, data lineage, and transformations to facilitate understanding and collaboration.

5. Automation:

Schedule and automate dbt runs to keep data models up-to-date and synchronized with source systems.
Implement data orchestration and scheduling as needed.

6. Data Quality Assurance:

Develop and enforce data quality checks and validations within dbt to identify and rectify data issues.
Monitor data quality and integrity, responding to anomalies or discrepancies.

7. Performance Optimization:

Optimize dbt models and queries for performance, identifying and addressing bottlenecks.
Analyze and fine-tune data processing pipelines to meet performance requirements.

8. Collaboration:

Collaborate closely with data engineers, data analysts, and business stakeholders to understand data requirements and deliver data solutions.
Participate in cross-functional teams and contribute to data-related projects.

9. Security and Compliance:

Ensure data security and compliance with relevant data protection regulations (e.g., GDPR, HIPAA) through appropriate data handling practices.

10. Knowledge Sharing:

Share knowledge of dbt best practices and data modeling techniques with team members.
Provide training and support to data analysts and other users of dbt.

Qualifications:

Bachelor's or master's degree in computer science, data science, or a related field.
Strong proficiency in SQL and experience working with relational databases.
3+ years of experience using dbt for data transformation and modeling in a data warehouse environment (e.g., Snowflake, BigQuery, Redshift).
7+ years of experience building business rules using a business rules engine similar to dbt
Familiarity with version control systems (e.g., Git) and code collaboration workflows.
Excellent data analysis and problem-solving skills.
Strong attention to detail and a commitment to data quality.
Understanding of data warehousing concepts and best practices.
Knowledge of data governance and data security principles.
Effective communication and collaboration skills to work with diverse teams.
Experience with other data tools and languages (e.g., Python, R, Looker) is a plus.

Job Type: Full-time

Salary: $44.00 - $55.00 per hour

Expected hours: 40 per week

Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance

Experience level:

7 years

Schedule:

8 hour shift

Ability to commute/relocate:

Trenton, NJ 08609: Reliably commute or planning to relocate before starting work (Required)

Experience:

Data build tool: 7 years (Required)

Work Location: In person",-1,-1,-1,-1,-1,-1,True
