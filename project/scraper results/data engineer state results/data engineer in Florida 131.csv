Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply
Data Engineer,"Airlines Reporting Corporation
","Tampa, FL",$76K - $110K (Glassdoor est.),3.7,"About The Role::
It's a great time to join us at Airlines Reporting Corporation (ARC)! ARC accelerates the growth of global air travel by delivering forward-looking travel data, flexible distribution services and other innovative industry solutions. We are a leading travel intelligence company with the world’s largest, most comprehensive global airline ticket dataset, including more than 15 billion passenger flights. By working here, you can contribute to solutions and expertise that strengthen economies and enrich lives. We think big, embrace challenges and explore new ideas to lead the way for the travel industry.

ARC is looking for a Data Engineer to join our team! As a Data Engineer you will provide product teams’ software development and product delivery support for data products. Additionally, you will be responsible for product delivery data pipelines and product lifecycle with direction from the Product Owner, the Solution Owner and technical guidance from Solution Architects.
What You'll Get to Do::
Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.
Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and aheres to ARC’s Architectural Guiding Principals.
Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.
Develop datapipe lines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.
Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. Maybe required to present ideas to larger audience for review and buy-in.
You'll Bring These Qualifications::
Bachelor’s Degree in Computer Science or related field; or equivalent experience
3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),
3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery
3+ years of experience implementing modern applications using:
Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, Fargate
Implementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patterns
Open source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)
Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment tools
Data warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)
Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQL
BI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)
Understanding of Data Management and Data governance best practices
Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels
Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams
Ability to discover and define functional requirements and to transform them into technical requirements and solutions
Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture
Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences
A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market
A strong passion to support peers to help meet timelines on larger projects
What We Can Offer You::
Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.
Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.
ARC offers WorkFlex. WorkFlex is ARC’s new work model, allowing employees in eligible roles to work virtually without set days in the office. ARC employees can work from the office, at home, or any combination of the two. There will be times when it is important to gather in-person and WorkFlex employees will be expected to come into the office or another location, when needed.
We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.
By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.
EOE M/F/D/V Females and Minorities Encouraged to Apply",1984,Financial Transaction Processing,$100 to $500 million (USD),Financial Services,201 to 500 Employees,Company - Private,False
Data Engineer,"LTIMindtree
","Tampa, FL",$45K - $121K (Employer est.),3.5,"LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 750 clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit ;/p>

Since we are actively recruiting for multiple Data Engineering roles, would request to please circulate this note to among your groups for better reach and help referring to you colleagues.

Send your Resume to mandhagolla.chakradhar@ltimindtree.com

Position: Data Engineering roles

Position: Data Engineer with 9-10 years of experience

Location: Tampa,FL

Job Description:

We are seeking an experienced Data Engineer to join our team and help us build a secure and reliable data platform. The ideal candidate should have 9-10 years of experience in developing data pipelines, ETL processes, and data structures in Hadoop, Apache Spark, SQL, and Java.

The successful candidate will have a strong understanding of the data engineering pipeline, from ingestion to transformation, and be able to develop efficient and secure software solutions to support data-driven applications. The ideal candidate should have experience with design and implementation of data models, as well as performance tuning of data flows and services.

Responsibilities:

Design and develop data models and ETL processes in Hadoop, Apache Spark, SQL, and Java.
Design and implement data pipelines for data ingestion and transformation.
Develop and maintain data warehouses and data marts.
Develop data-driven applications to support data analysis and reporting.
Monitor and optimize data flows and services for maximum efficiency.
Troubleshoot data-related issues and provide technical support.
Ensure data quality and security standards are met.
Develop and document best practices for data engineering and data governance.
Work collaboratively with data scientists, analysts, and other stakeholders.

Requirements:

Bachelor's Degree in Computer Science, Mathematics, or a related field.
9-10 years of experience in developing data pipelines and ETL processes.
Strong understanding of data engineering pipeline (ingestion to transformation).
Experience with Hadoop, Apache Spark, SQL, and Java.
Experience with data modeling and data warehousing.
Experience with performance tuning of data flows and services.
Familiarity with data security and data governance best practices.
Ability to work independently and collaboratively with a team.
Excellent verbal and written communication skills.

Job Type: Full-time

Salary: $45,099.17 - $120,683.06 per year

Benefits:

Health insurance

Experience level:

8 years

Ability to commute/relocate:

Tampa, FL 33602: Reliably commute or planning to relocate before starting work (Required)

Experience:

Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)

Work Location: In person",1997,Information Technology Support Services,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Public,True
"SR Data Engineer (DBT, Data Modeling, ETL)","Rotech Healthcare Inc.
","Orlando, FL",,2.5,"About Rotech

Rotech Healthcare Inc. is a national leader in providing ventilators, oxygen, sleep apnea treatment, wound care solutions, diabetic solutions and home medical equipment. We help patients lead a more comfortable and productive life by keeping them engaged in their care and empowering them to manage their health and treatment at home. Rotech provides high quality medical products, services and outstanding customer care through hundreds of locations across 45 states. For additional information, visit our company homepage Rotech.com

Overview and Responsibilities

Job Summary
We are seeking a dedicated Senior Data Engineer to join our data engineering team to build and maintain scalable and reliable data engineering solutions that support our enterprise data warehouse and business analytics. In this position, you will be responsible for designing, developing and deploying data pipelines, workflows and data models. This position requires an in depth knowledge of dbt, Snowflake, Data Modeling, CI/CD, and DevOps. This position will also collaborate with other data engineers, architects, analysts, and stakeholders to ensure business requirements, data quality, security, and governance.

Essential Job Duties and Responsibilities
(Reasonable accommodations may be made to enable individuals with disabilities to perform these essential functions. Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.)

Design, develop and deploy data pipelines and workflows using dbt and Snowflake to ingest, transform, and deliver data from various sources to snowflake based enterprise data warehouse. This includes but not limited to writing SQL queries, macros, tests, source to target mappings, and documentation.
Expert level knowledge of optimizing performance of ETL/ELT, building & executing tests, maintaining versions/repository, and documenting the workflows
Apply data ops, CI/CD, DevOps principles and practices to automate and streamline data processes and ensure continuous delivery and integration of data solutions
Cross-collaborate with business stakeholders, reporting team and solution architects to lay out a robust design, data architecture and data models for data warehouse that support business intelligence solutions
Hands on experience delivering cloud data integration projects preferably with AWS
Document and communicate data solutions, standards, best practices, and guidelines to ensure consistency and alignment across the data engineering team and the organization
Deliver and manage projects using Agile/SCRUM/KANBAN methodologies
Mentor and coach junior data engineers and provide technical guidance and feedback
Monitor and troubleshoot data issues and incidents and provide root cause analysis and resolution
Research and evaluate new technologies and trends in the data domain and propose improvements and innovations
Performs other duties as assigned

Qualifications

Employment is contingent on

Background investigation (company-wide)
Drug screen ( when applicable for the position )
Valid driver's license in state of residence with a clean driving record (when applicable for the position)
Required Education and/or Experience

Bachelor's degree in computer science, engineering or related field is preferred
10+ years of experience in data engineering or related roles with experience with at least two data engineering and/or ETL/ELT tools
Proficient in dbt design, development and deployment, including writing SQL queries, macros, tests, sources, etc.
Knowledge of Snowflake cloud data platform, architecture, features and capabilities
Familiarity with modern modeling techniques like lake house, data vault as well as traditional concepts such as star schema, snowflake schema, dimensional modeling, facts and dimensions
Experience working in data engineering team in cloud environment preferable AWS
Skilled in data ops, CI/CD, DevOps tools and methodologies, such as Git, Azure DevOps, Jenkins etc.
Strong understanding of data quality, security, and governance principles and frameworks
Experience delivering and managing projects using Agile/SCRUM/KANBAN methodologies
Skills and Competencies

Effectively communicate in English; both oral and written
Interpret a variety of communications (verbal, non-verbal, written, listening and visual)
Maintain confidentiality, discretion and caution when handling sensitive information
Multi-task along with attention to detail
Self-motivation, organized, time-management and deductive problem solving skills
Work independently and as part of a team
Machines, Equipment and Technical Abilities

Email transmission and communication
Internet navigation and research
Microsoft applications; Outlook, Word and Excel
Office equipment; fax machine, copier, printer, phone and computer and/or tablet
Physical Demands

Lift and carry office equipment at times
Requires sitting, walking, standing, talking and listening
Requires close vision to small print on computer and/or tablet and paperwork

Rotech Information

Benefits

401k
Medical, Dental and Vision
Life Insurance and Disability
Generous Paid Time Off and Paid Holidays
Bonus and Incentive Opportunities
Mileage reimbursement (when applicable for the position)
Telephone reimbursement (when applicable for the position)
Make the Right Move and Submit your Resume Today! The hiring manager reviews resumes and contacts applicants that have related experience to the applied position. To view the status of a position that you submitted your profile to, Sign into your account . We appreciate your interest in Rotech Healthcare Inc.

Equal Opportunity Employer of Minorities, Females, Protected Veterans and Individuals with Disabilities. Rotech Healthcare Inc. recruits, employs, trains, promotes, transfers, separates from employment and compensates employees without regard to membership in, association with, or perception of race, color, age, gender, gender identity, religion, creed, national origin, ancestry, citizenship, marital status, veteran status, sexual orientation, physical or mental disability, pregnancy or any other personal characteristic protected by applicable federal, state and local laws governing nondiscrimination in employment in each locality where Rotech has employees.",2002,Health Care Services & Hospitals,$100 to $500 million (USD),Healthcare,1001 to 5000 Employees,Company - Private,False
Senior Data Engineer,PMSA Group,Florida,$130K - $140K (Employer est.),-1.0,"PMSA Group is currently searching for a qualified Data Programmers / Data Engineers for CONTINGENT POSITIONs in support of the USCENTCOM Director, Resources and Analysis, J8. The CCJ8 requires a Data Engineer to assist in identifiying, developing, and documenting new data requirements and management techniques in support of a newly formed team responsible to integrate data and artificial intelligence capabilities into USCENTCOM functions.

Responsibilities:

Data engineers assist analysts and decision makers in solving complex problems through the preparation of data for analytic applications to include, but not limited to inferential analysis, exploratory analysis, comparative analysis, and research. Design, develop, and manage data intake, storage, and processing through appropriate data pipelines and processes. Support and enable the design, development, and application of a variety of operations research and data science principles and techniques to include data analysis, decision support analytics, probability models, statistical inference, simulations, and optimization and economic models. Facilitate quantitative and qualitative analysis for a broad range of complex military problems. Support the development of information displays, data pipelines, data repositories, decision briefings, analytical papers, and facilitate senior leader discussions.

Major functions:

· Assist the Resources and Analysis Directorate in the development and documentation of detailed data requirements for application systems in a logical data model

· Develop the analysis, creation, acquisition, maintenance, and use characteristics of the data identified

· Ensure compliance with data management policies, guidance, and standards

· Evaluate data reuse, data integration, and data compliance and develop strategies based on stewardship and authorities

· Develop physical schemas that address functional and technical requirements for the database including data sharing as appropriate

· Develop, construct, test, and maintain data architectures

· Develop information displays, decision briefings, analytical papers, and facilitate senior leader discussions

· Some travel may be required

Required Qualifications and Experience

· Must have a DoD Top Secret (TS) clearance and Sensitive Compartmented Information (SCI); also, must have a current DoD approved Single Scope Background Investigation (SSBI/Tier 5) having at least one year of eligibility remaining before required renewal of their background investigation.

· B.S. Data Science, Data Engineering, or Applied Mathematics

· 10 years of experience supporting DoD at CCMD or similar level

· 5 years of experience in application development

· 5 years of experience designing, developing, operationalizing, and maintaining complex data applications at enterprise scale

· 3 years of experience creating software for retrieving, parsing, and processing structured and unstructured data

· 3 years of experience building scalable ETL/ELT workflows for reporting and analytics

· Experience with Python, SQL, Scala, or Java

· Experience creating solutions within a collaborative, cross-functional team environment

· Ability to develop scripts and programs for converting various types of data into usable formats and support project team to scale, monitor and operate data platforms

Additional Desired Qualifications and Experience

· M.A. or M.S. degree in OR, Data Science, Data Engineering, or Applied Mathematics preferred

· Experience with UNIX/Linux, including basic commands and Shell scripting

· Experience with a public cloud, including AWS, Microsoft Azure, or Google Cloud

· Experience with distributed data and computing tools including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka

· Experience working on real-time data and streaming applications

· Experience with NoSQL implementation, including MongoDB or Cassandra

· Experience with data warehousing using AWS Redshift, MySQL, or Snowflake

· Experience with Agile engineering practices

· Experience with preparing and presenting senior leadership briefings and papers a plus

· Excellent oral and written communication skills a plus

BuzzDoc LLC dba Performance Management Simulation and Analysis (PMSA) Group Overview:

PMSA Group is a small business focused on providing superior system and data analysis services to government and commercial clients. Join the growing PMSA Group family and let your career growth meet your expectations. We are a team of ORSAs, Data/Database Management, and Software Engineering professionals that reward employees through competitive salary, benefits, and profit sharing. BuzzDoc LLC was founded in 2011 by Bruce C. Shultes, PhD in Danville, CA. For additional information see our website at buzzdocllc.com

Job Type: Full-time

Pay: $130,000.00 - $140,000.00 per year

Benefits:

401(k)
Dental insurance
Flexible schedule
Health insurance
Paid time off
Vision insurance

Compensation package:

Bonus opportunities

Experience level:

9 years

Schedule:

8 hour shift

Experience:

Data Engineering: 5 years (Required)
Data warehouse: 3 years (Preferred)
Application Development: 5 years (Required)

Security clearance:

Top Secret (Required)

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Senior Principal Instrumentation & Data Network Engineer,"Northrop Grumman
","Melbourne, FL",$112K - $168K (Employer est.),4.0,"Requisition ID: R10135089
Category: Engineering
Location: Melbourne, Florida, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.

Northrop Grumman Aeronautics Systems has an opening for a Sr. Principal Instrumentation & Data Network Engineer to join our team of qualified, diverse individuals within our Test and Evaluation organization. This role is located in Melbourne, FL.

In this role, you will support the Instrumentation and Data Systems team in a lead role, you will be responsible for the development, design, and integration of a complex and secure test data acquisition network architecture for a next-generation development program. You will develop a local and cloud-based data processing and dissemination architecture using hardware and software solutions to support the recording of hardwire measurands, optical, and common bus protocols (Ethernet, 1553, 1394, ARINC 429, CAN, etc.) for laboratory, ground, and flight test activities across multiple sites.

Working in concert with a Network Architect and lab infrastructure leads to incorporate program integration requirements, you will develop network architecture diagrams, rack design drawings, and hardware selection for installation. You will support data collection configuration of the Flight Test Instrumentation system, coordinate test activity, and communicate instrumentation and system test data issues and status across IPTs. In addition, you will support test readiness reviews, test planning working groups, and pre- and post-test briefings.

Experience in network operating systems, network and computer hardware selection, design software, as well as database development for measurand and test data is important. Knowledge of telemetry, onboard recording, Data Acquisition System equipment by Safran/Heim, Zodiac, and TTC/Teletronics/Curtis-Wright and ground stations is preferred. You will prepare system specifications, Request for Quotes (RFQ’s), and Statement of Work (SOW’s) which satisfy test and system requirements plus support test activities, anomaly resolution, and process improvement initiatives. Strong leadership, communication and interpersonal skills are key.

Key Responsibilities:

Perform all aspects of network management from initial network design through test, implementation, and maintenance
Optimize data collection and dissemination to existing software tools and data reduction suites
Ensure network performance and data delivery capabilities meets System Test, vehicle subsystem Responsible Engineer, and customer requirements
Troubleshoot network, data collection, and system issues

We offer flexible work arrangements, 9/80 work schedule with every other Friday off, phenomenal learning opportunities, exposure to a wide variety of projects and customers, and a very friendly team environment. We are looking for self-motivated, proactive, and goal-oriented people to help us grow our services and become even better at what we do.

Basic Qualifications:

Must have a Bachelor’s of Science degree in a Science, technology, Engineering, or Math (STEM) discipline AND 9 years of related professional/military experience OR a Master of Science degree in a STEM discipline AND 7 years of related professional/military experience OR a STEM Ph.D. AND 4 years of related professional/military experience
Must have an active DoD Secret or higher clearance (with a background investigation completed within the last 6 years or currently enrolled into Continuous Evaluation)
Must have the ability to obtain and maintain Special Access Program (SAP) clearance prior to the commencement of employment

Preferred Qualifications:

Experience with network design and testing methodologies using routers, switches, firewalls, and encryption devices, and performing system validation and verification on complex networks
Possess a current DoD 8570 certification at IAT Level II or higher (Security+, GSEC, SCNP, SSCP, CISSP, CISA, GSE, SCNA, CCNP, or CCNA)
Ability to objectively assess architectural limitations or shortcoming in such areas as scaling, speed, and throughput
Familiarity with Model Based Systems Engineering (MBSE) using SysML
VMWare or other virtualization experience
Develop and document technical processes and procedures as needed
Interact, meet, discuss, and troubleshoot issues with vendors; evaluate vendor products, services, and suggestions
Maintain security audit and logging information and adhere to strict Information System security guidelines on all classified network hardware as directed by the Information Systems Security Manager (ISSM) and Communication Security (COMSEC) requirements
Work under minimal direction and independently determine and develop approach to solutions
Salary Range: $112,000 - $168,000
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.

Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",1939,Aerospace & Defense,$10+ billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
Cloud Data Platform Engineer,"Kforce
","Palm Beach Gardens, FL",$120K (Employer est.),3.9,"RESPONSIBILITIES:
Kforce has a client that is seeking a Cloud Data Platform Engineer in Palm Beach, FL.

Duties Include:

Cloud Data Platform Engineer will focus on proactive and reactive end to end FPLS data optimizations
Ingestion and pipeline technology expert (EMR, Glue, Step Functions, etc.)
Build scalable data monitoring, architecture, and governance
FinOps expert in cloud data -in motion- and -at rest- cost management
FPLS EDP liaison - Focus on databases, storage, and performance optimizations (S3, DynamoDB, RDS, Redshift) - this is most important
As a Cloud Data Platform Engineer, you will query performance tuning, optimizations, and code quality
Implementing database standards (Performance testing, SonarQube)
REQUIREMENTS:

To be considered for this position, candidates must have experience in a similar role, or they must possess significant knowledge, experience, and abilities to successfully perform the responsibilities listed
Relevant education and/or training will be considered a plus
The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",1962,Business Consulting,$1 to $5 billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Engineer,"Octagon Talent Solutions
","Fort Lauderdale, FL",$79K - $116K (Glassdoor est.),4.4,"Octagon Talent Solutions seeks an experienced and enthusiastic Data Engineer to join our client company team! Our ideal candidate will have a strong background in working with Azure Data Factory and experience in database design and development. Applicants should be able to demonstrate their knowledge of ETL (extract, transform, load) processes and data engineering concepts such as database architecture, coding using SQL, stored procedures, and developing schemas. An understanding of best practices related to data governance is also expected. This is an excellent opportunity for a self-motivated person who is excited about technology! The successful candidate must be a creative problem solver with excellent analytical skills. They must have the ability to stay organized while managing multiple tasks simultaneously. The person selected should also demonstrate exceptional communication skills, both written and verbal. If you have what it takes, we want you on our team!

RESPONSIBILITIES:


Design and develop databases, stored procedures, triggers, and functions following best practices.
Create ETL pipelines efficiently using Azure Data Factory to support data storage and processing.
Develop automated processes for loading, transforming, and integrating data from multiple sources.
Monitor the health of databases & ETL pipelines, troubleshoot issues, and recommend optimizations for performance.
Collaborate with stakeholders to ensure best practices are followed regarding data governance.
Execute data quality checks to identify problems and resolve accuracy issues.
Build dashboards, trackers, and reports as required by business needs.

REQUIREMENTS:

Proven experience working with Azure Data Factory.
Knowledge of database architecture, design, and development.
Proficient in Python, SQL coding, and developing stored procedures.
Experience with ETL processes, including data extraction, transformation, and loading.
Strong problem-solving skills combined with excellent analytical skills.
Exceptional communication skills, both written and verbal.
Highly organized with the ability to manage multiple tasks concurrently.",2010,HR Consulting,Unknown / Non-Applicable,Human Resources & Staffing,1 to 50 Employees,Company - Private,True
Data Engineer I - Data & Analytics (REMOTE),"CSX
","Jacksonville, FL",$76K - $110K (Glassdoor est.),2.9,"The Data Engineer is responsible for the maintenance, improvement, cleaning, and manipulation of data in the business’s operational and analytics databases. The Data Engineer works with the applications teams, business partners, and data scientists in order to understand and aid in the implementation of database requirements, analyze performance, and troubleshoot any existing issues. The data engineer maintains the optimal data pipeline architecture, assembles data sets that meet functional / non-functional business requirements and performs optimal extraction, transformation, and loading of data from a variety of data sources using SQL and/or other data technologies. They are responsible for delivering analytical tools, solutions, and reporting. They collaborate with other organizations both internal and external to the company.

Primary Activities and Responsibilities

Develop information solutions for data-related problems using a variety of technical and analytical skills.
Provide production support responsibilities for one or more reporting and analytical solutions.
Collaborate with team members, architects, data scientists and software developers to gather requirements and work towards delivering complete analytics/reporting solutions that help improve organizational decision making.
Provide ad-hoc analyses with large data sets.
Promote new initiatives, identify areas of critical need, and drive change through implementations.
Work directly with internal customers to enact change, identify business requirements and develop the best course of actions to meet their needs.
Partner with management to identify and research analytical solutions, and make recommendations.
Provide SQL query performance tuning capability to support development and data science teams.
Design and build technical solutions for advanced business problems based on standards and guidance from more experienced team members.
Partner with the architecture team to actively assist with developing and executing Data Engineering and Analytics Strategy.
Implement P.O.C.s for new Information technologies and to vet on-boarding into the organization.
Miscellaneous activities and responsibilities as assigned by manager.
Work hours may vary in length and schedule (may include a non-standard work week).

Minimum Qualifications

Bachelor’s degree from an accredited institution required
2+ years of experience required in Data and Analytics


Equivalent Minimum Qualifications

High School diploma/GED
5+ years of experience required in Data and Analytics


Preferred Qualifications

Bachelor degree from an accredited institution in Data Science, Computer Science, Computer Engineering, Information Systems, Statistics, Mathematics, Engineering, or a related major field of study.
Hands on experience developing cloud data solutions utilizing Azure, GCP, AWS, Snowflake
Experience in Transportation/Intermodal Operations, Information Systems, or Logistics
Hands on experience with Azure, ADF and Power BI strongly preferred.
Working knowledge of modern programming languages such as Python
Experience with streaming and processing big data
Demonstrated ability to think strategically about business, product, and technical challenges.
Strong communication and presentation skills, with both technical and business people.


Knowledge and Skills

Able to unravel complex data
Experienced building analytical tools that utilize the data pipeline to provide actionable insights, operational efficiency, and other key metrics.
A self-starter. Work independently to identify, design and implement internal process improvement, automating manual processes, optimizing data delivery, and re-designing for greater scalability.
Enable data driven decisions while disrupting data silos.
Be an advocate and set an example for CSX’s digital cultural.
Transform the way CSX operates with a proactive, informed risk-taking, and a winning attitude.
A strong enthusiasm to learn
Knowledge of cloud platforms such as Azure, Snowflake, GCP, and AWS
Experience using Microsoft cloud products is highly desirable
Results-oriented with a strong sense of ownership in delivering
Experience performing root cause analysis on internal and external data
Hands-on experience with end-to-end analytics (i.e., data extraction to presentation); able to build processes supporting data transformation
Experience supporting and working with cross-functional teams in a dynamic environment
Experience with SQL; a bility to write /tune advanced queries
Knowledge of analytical and visualization tools (e.g. Tableau, Power BI, Alteryx);
Knowledge of reporting technologies (e.g. SAP Analytics, Power BI, SAP Business Objects)
Experience working with data processing technologies including, Data Lakes, Data warehouse, NoSQL, SQL, PL/SQL
Strong time management and organizational skills.",1978,Rail Transportation,$10+ billion (USD),Transportation & Logistics,10000+ Employees,Company - Public,False
Azure Data Engineer,"Quirch Foods
","Coral Gables, FL",$82K - $124K (Glassdoor est.),3.2,"About Quirch Foods

In business for over 50 years, Quirch Foods is a global distributor and exporter of fresh and frozen food products with a unique focus on ethnic cultures. We service our customers from 5 distribution centers strategically located in the United States. We have consistently been ranked among the top 50 exporters in the US and are one of the largest importers of seafood. Our customers include independent grocers, chain supermarkets, foodservice distributors, cruise lines, restaurants and food processors/manufacturers. We have an extensive product list with over 8,000 SKU's and carry niche brands such as Panamei, Mambo and Chiquita along with national brands like Tyson, IBP, Excel, JBS, Iowa Premium, Smithfield, Dietz & Watson, along with many others. We are headquartered in Coral Gables, FL.
Quirch is a portfolio company of Palladium Equity Partners, a leading mid-market private equity fund based in New York City, which partnered with the Executive Team to capitalize on Quirch Foods’ record of excellence and to grow it decisively beyond its current business.

Position Summary
At Quirch Foods we believe in leveraging technology as a source of competitive advantage. This includes customized ERP Solutions, Business Intelligence, EDI, Web and Mobile Solutions. We are currently looking for a Data Engineer to join our development efforts.

Essential Duties and Responsibilities:

Develop, test and maintain custom business solutions by leveraging state of the art software development practices using an agile methodology
Evaluate business requirement and help define problems and develop solutions
Participate in design and architecture discussions with business leaders, end users and IT team members
Document business requirements and solution, document code and provide support for creation of end user documentation
Update business knowledge, technical skills and soft skills, leverage educational opportunities, participate in professional organizations

Experience:

MS SQL Programming
Visual Studio\C#\WPS Experience
Microsoft SSAS, SSIS, SSRS desired but not required
Biztalk experience desired but not required

Skills and Requirements:

Bachelor’s degree in Computer Science, Engineering, Math or equivalent and\or related experience and training preferred
Strong analytical and problem-solving skills
Strong collaborator and team player
Great organizational skills, attention to detail and follow thru
Effective oral and written communication skills
Extensive familiarity with data management principles

Benefits:

Professional growth and developmental opportunities to grow your skills using state of the art technology
Comprehensive benefits package that includes: Medical, Dental, Prescription Drug Plan, Disability Plan, Life insurance Plan
401K savings Plan
Paid Holidays
Personal Time off
Employee Discounts

Quirch Foods is an Equal Opportunity Employer (EOE). Qualified applicants are considered for employment without regard to age, race, color, religion, sex, national origin, sexual orientation, disability, or veteran status. All applicants must be eligible to work in the United States.

Job Type: Full-time

Benefits:

401(k)
Dental insurance
Health insurance
Life insurance
Paid time off
Vision insurance

Experience level:

3 years
4 years
5 years

Schedule:

8 hour shift
Monday to Friday

Ability to commute/relocate:

Coral Gables, FL 33134: Reliably commute or planning to relocate before starting work (Required)

Experience:

Power BI: 2 years (Required)
Azure Data Factory and Data Bricks: 2 years (Required)
Data Engineering: 2 years (Required)

Work Location: In person",1967,Wholesale,$500 million to $1 billion (USD),Retail & Wholesale,201 to 500 Employees,Company - Private,True
Data Engineer GCP,"Infocodec Solutions
","Sunrise, FL",$84K - $191K (Employer est.),4.9,"Hands-on experience with GCP, google composer, airflow, bigQuery and bigTable
3 to 7 years of experience within Data Engineering/ Data Warehousing using Big Data
Hands-on experience on writing and understanding complex SQL(Hive/PySpark-dataframes), optimizing joins while processing huge amount of data
Hands-on experience with programming using Python/Scala
Understanding of Cloud Native Principles and architectures and Experience in creating platform level cloud native system architecture with low latency, high throughput, and high availability.
Have experience in designing and building Cloud native applications. Experience in cloud platforms like Docker, Kubernetes, OpenShift are a plus.
Expert on Hadoop and Spark Architecture and its working principle
Experience in UNIX shell scripting
Experience with NoSQL i.e., HBase, Couchbase, MongoDB is good to have
Teamwork & ability to multi-task
Excellent communication skills

Job Type: Contract

Salary: $84,035.09 - $190,724.29 per year

Experience level:

5 years

Schedule:

Monday to Friday

Ability to commute/relocate:

Sunrise, FL 33313: Reliably commute or planning to relocate before starting work (Required)

Application Question(s):

Work on a W2 Role ? Must Answer??

Experience:

Python: 6 years (Preferred)
SQL: 5 years (Preferred)
Data warehouse: 6 years (Preferred)

Work Location: In person",2015,Information Technology Support Services,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,True
Data Engineer (On-Site),"PrismHR
","Sarasota, FL",$69K - $97K (Glassdoor est.),3.9,"Do you have a passion for building data architectures that enable smooth and seamless product experiences? Are you an all-around data enthusiast with a knack for ETL? We're hiring Data Engineers to help build and optimize the foundational architecture of our product's data.

We’ve built a strong data engineering team to date, but have a lot of work ahead of us, including:

Migrating from relational databases to a streaming and big data architecture, including a complete overhaul of our data feeds
Defining streaming event data feeds required for real-time analytics and reporting
Leveling up our platform, including enhancing our automation, test coverage, observability, alerting, and performance

As a Data Engineer, you will work with the development team to construct a data streaming platform and data warehouse that serves as the data foundations for our product.

Help us scale our business to meet the needs of our growing customer base and develop new products on our platform. You'll be a critical part of our growing company, working on a cross-functional team to implement best practices in technology, architecture, and process. You’ll have the chance to work in an open and collaborative environment, receive hands-on mentorship and have ample opportunities to grow and accelerate your career!

Responsibilities:

Build our next generation data warehouse
Build our event stream platform
Translate user requirements for reporting and analysis into actionable deliverables
Enhance automation, operation, and expansion of real-time and batch data environment
Manage numerous projects in an ever-changing work environment
Extract, transform, and load complex data into the data warehouse using cutting-edge technologies
Build processes for topnotch security, performance, reliability, and accuracy
Provide mentorship and collaborate with fellow team members

Qualifications:

Bachelor’s or Master’s degree in Computer Science, Information Systems, Operations Research, or related field required
3+ years of experience building data pipelines
3+ years of experience building data frameworks for unit testing, data lineage tracking, and automation
Fluency in Scala is required
Working knowledge of Apache Spark
Familiarity with streaming technologies (e.g., Kafka, Kinesis, Flink)

Nice-to-Haves:

Experience with Machine Learning
Familiarity with Looker a plus
Knowledge of additional server-side programming languages (e.g. Golang, C#, Ruby)

PrismHR is a fast-paced SaaS company which provides customers with a cloud-based payroll process software application. PrismHR also provides professional services including system implementation consulting, custom configurations, and training. Lastly, via the Company’s Marketplace platform customers and end users access other human resources and employee benefits applications from PrismHR’s Marketplace Partners.

Diversity, Equity and Inclusion Program/Affirmative Action Plan:
We have transformed our company into an inclusive environment where individuals are valued for their talents and empowered to reach their fullest potential. At PrismHR, we strive to continually lead with our values and beliefs that enable our employees to develop their potential, bring their full self to work, and engage in a world of inclusion.

Ensuring an inclusive environment for our employees is an integral part of the PrismHR culture. We aren't just checking a box, we are truly committed to creating a workplace that celebrates the diversity of our employees and fosters a sense of belonging for everyone. This is essential to our success. We are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about our roles but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for these open roles or other open roles. We particularly encourage applicants from traditionally under-represented groups as we seek to increase the diversity of our workforce and provide fair opportunities for all.

As a proud Equal Opportunity and Affirmative Action Employer, PrismHR encourages talent from all backgrounds to join our team. Employment decisions are based on an individual’s qualifications as they relate to the job under consideration. The Company’s policy prohibits unlawful discrimination based on sex (which includes pregnancy, childbirth, breastfeeding, or related medical conditions, the actual sex of the individual, or the gender identity or gender expression), race, color, religion, including religious dress practices and religious grooming practices, sexual orientation, national origin, ancestry, citizenship, marital status, familial status, age, physical disability, mental disability, medical condition, genetic information, protected veteran or military status, or any other consideration made unlawful by federal, state or local laws, ordinances, or regulations.

The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company and prohibits unlawful discrimination by any employee of the Company, including supervisors and co-workers.

Privacy Policy: For information about how we collect and use your personal information, please see our privacy statement available at https://www.prismhr.com/about/privacy-policy.

PrismHR provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need a reasonable accommodation due to a disability, you may use the following alternative email address to contact us about your interest in employment at PrismHR: taglobal@prismhr.com. Please indicate in the subject line of your email that you are requesting accommodation. Only candidates being considered for a position who require an accommodation will receive a follow-up response.

#LI-ML1

3DWT5dYxZ5",1985,Software Development,$500 million to $1 billion (USD),Information Technology,501 to 1000 Employees,Company - Private,True
Data Science Engineer,NUVIEW,"Orlando, FL",$90K - $138K (Glassdoor est.),-1.0,"NUVIEW is revolutionizing the Earth Observation industry by deploying the first commercial satellites designed to annually map the planet's entire land surface with LiDAR. NUVIEW's data will elevate global capabilities and transform what is possible for mankind to know about the Earth.

Role Summary:

As a Data Science Engineer specializing in Discriminative and Generative AI at NUVIEW, you will play a pivotal role in harnessing the power of LiDAR data and AI models to develop innovative solutions that have a significant impact on the fields of Earth observation and geospatial analysis.




Responsibilities:

Generative and Discriminative Model Development: Design, develop, and optimize both generative and discriminative AI models to process and analyze LiDAR data, extracting valuable information and insights.
Generative AI Tasks:
Semantic Segmentation: Using generative AI models to segment LiDAR data into different categories, helping to identify and understand objects, terrain, or features within a given area.
3D Point Cloud Generation: Generating 3D point cloud data from LiDAR scans, providing a richer representation of the environment for improved analysis and modeling.
Environmental Simulation: Creating synthetic environments for training LiDAR-based perception systems, enhancing the robustness of our Earth observation solutions.
Discriminative AI Tasks:
Object Detection: Implementing discriminative AI models to detect and classify specific objects in LiDAR data, such as vehicles, buildings, or trees, for various applications.
Change Detection: Using discriminative AI for identifying and quantifying changes in the Earth's surface over time, aiding in monitoring environmental shifts or construction progress.
Anomaly Detection: Employing discriminative AI to identify anomalies or irregularities in LiDAR data, which can be indicative of events like landslides, infrastructure damage, or other critical changes.
Model Training: Train, fine-tune, and extend generative and discriminative models for LiDAR data using large datasets, continuously monitoring and enhancing model performance.
Cross-Functional Collaboration: Collaborate closely with experts in LiDAR technology, remote sensing, and geospatial analysis to integrate generative AI solutions into our Earth observation products and services.
Documentation: Create comprehensive documentation for model architecture, data processing, and best practices, enabling knowledge sharing within the team.

Qualifications:

Bachelor's or Advanced Degree in Computer Science, Data Science, or a related field.
Minimum of 5 years of experience in Artificial Intelligence and Machine Learning.
Proven experience in developing both generative and discriminative AI models, with a strong portfolio of projects or research.
Proficiency in machine learning frameworks and libraries such as TensorFlow, PyTorch, or Keras.
Strong programming skills in languages such as Python.
Experience with cloud platforms and services, such as AWS, Azure, or GCP.
Strong problem-solving and analytical skills.
Excellent communication and teamwork abilities.

Preferred Skills:

Knowledge of LiDAR data processing and geospatial analysis.
Experience with deploying both generative and discriminative models in production environments specific to Earth Observation applications.
Familiarity with domain-specific applications, such as land cover classification, 3D modeling, and environmental monitoring.

NUVIEW is an Equal Opportunity Employer. We are committed to fostering a diverse and inclusive work environment that values and celebrates all employees' unique backgrounds, perspectives, and talents. We do not discriminate based on race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, disability, veteran status, or other protected characteristics. We strongly encourage individuals from all walks of life to apply and join our team in driving innovation and success for all.",-1,Construction,Unknown / Non-Applicable,"Construction, Repair & Maintenance Services",Unknown,Company - Public,True
Data Center Engineer,"Verizon
","Pompano Beach, FL",$60K - $87K (Glassdoor est.),3.8,"When you join Verizon

Verizon is one of the world’s leading providers of technology and communications services, transforming the way we connect around the world. We’re a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together—lifting up our communities and striving to make an impact to move the world forward. If you’re fueled by purpose, and powered by persistence, explore a career with us. Here, you’ll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife.

What you’ll be doing...

Continuous improvement efforts drive our business and you will work with customer technical teams to provide solutions for customers' internetworking communications requirements. You will be performing network design activity for our large enterprise customer data networks. As the main interface to customers in support of their WAN/LAN enterprise projects, you will make us better by building great enterprise customer data networks.

Investigating, crafting, planning, and implementing communications networks.

Partnering with customer teams to develop solutions that support their requirements.

Preparing rack elevation schematics to define and illustrate network design solutions.

Crafting hardware and software configuration upgrades.

Preparing detailed work requests for technicians.

Installing hardware and cabling into datacenters in coordiation with other engineering teams.

Perform smarthands activities on location for remote engineers.

Manage work orders that impact the datacenter as the on-site engineering lead.

Remotely assist other engineers with scheduled maintenance and other tasks

What we’re looking for...

Your technical skills are top notch, and you are known for digging into the details to find the best solutions. You know how to get to the bottom of your customers’ needs, and how to manage your partners’ expectations. Talking to people comes very naturally to you and you have an ability to communicate complex information in a way that people understand – whether verbal or written.

You’ll need to have:

Bachelor’s degree or four or more years of work experience.

Four or more years of relevant work experience.

Prior experience operating datacenters and overseeing implementation in support of customer buildouts.

Must be able to pass an extensive background investigation as a condition of employment.

Even better if you have one or more of the following:

A degree.

Cisco Certified Network Administrator (CCNA) certification.

Project management experience.

Experience with contemporary technologies including MPLS, TCP/IP, IPSec, BGP, QoS, IP Telephony, Multicast, and/or other similar tools.

Designed and implemented large scale datacenter operations.

Why Verizon?

Verizon is committed to maintaining a Total Rewards package which is competitive, valued by our employees, and differentiates us as an Employer of Choice.

We are a ‘pay for performance’ company and your contribution is rewarded through competitive salaries, performance-based incentives and an employee Stock Program. We create an opportunity for us all to share in the success of Verizon and the value we help to create through this broad-based discretionary equity award program.

Your benefits are market competitive and delivered by some of the best providers.

You are provided with a full spectrum of health and wellbeing resources, including a first in-class Employee Assistance Program, to empower you to make positive health decisions.

We offer generous paid time off benefits.

Verizon provides training and development for all levels, to help you enhance your skills and develop your career, from funding towards education assistance, award-winning training, online development tools and access to industry research.

You will be able to take part in volunteering opportunities as part of our environmental, community and sustainability commitment.

If Verizon and this role sound like a fit for you, we encourage you to apply even if you don’t meet every “even better” qualification listed above.

#STSERP22

Where you’ll be working
In this worksite-based role, you'll work onsite at a defined location(s).

Scheduled Weekly Hours
40

Equal Employment Opportunity

We’re proud to be an equal opportunity employer - and celebrate our employees’ differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.",2000,Telecommunications Services,$10+ billion (USD),Telecommunications,10000+ Employees,Company - Public,False
Data Analytics Engineer,"Abbott Laboratories
","Orlando, FL",$63K - $125K (Employer est.),3.8,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.

Job Description – Software Engineer II - Big Data

About Abbott

Abbott is a global healthcare leader, creating breakthrough science to improve people’s health. We’re always looking towards the future, anticipating changes in medical science and technology.


Working at Abbott

At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:

Career development with an international company where you can grow the career you dream of.
Free medical coverage for employees* via the Health Investment Plan (HIP) PPO
An excellent retirement savings plan with high employer contribution
Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.


The Opportunity

At Abbott, we believe people with diabetes should have the freedom to enjoy active lives. That’s why we’re focused on helping people with diabetes manage their health more effectively and comfortably, with life-changing products that provide accurate data to drive better-informed decisions. We’re revolutionizing the way people monitor their glucose levels with our new sensing technology.


Our location in Alameda, CA currently has an opportunity for a Data Analytics Engineer

Interested in applying your wealth of technical knowledge and experience towards an opportunity in the medical field and improving the lives of people with diabetes? The candidate will be responsible for big data engineering, data wrangling, and data analysis in the Cloud. The role will also contribute to defining and implementing Big Data Strategy for the organization along with driving implementation of IT solutions for the business. Candidate will be working with other data engineers and data scientists to focus on applying data engineering, data science and machine learning approaches to solve business problems.

Candidate should be able to work on a distributed project team along with data scientists to develop data pipelines capable of handling complex data sets quickly and securely as well as operationalize data science solutions. Candidate will be working in a technology driven environment utilizing the latest tools and techniques such as Redshift, S3, Lambda, DynamoDB, Sparc and Python.

#Software

Job locations: Alameda, CA, Bend, OR; Orlando, FL

What You’ll Work On

Collect and process raw data at scale for a variety of projects and initiatives.

Create and maintain optimal data pipeline architecture by designing and implementing data ingestion solutions on AWS using AWS native services.

Design and optimize data models on AWS Cloud using AWS data stores such as Redshift, RDS, S3.

Integrate and assemble large, complex data sets that meet a broad range of business requirements.

Design and develop data applications using selected tools and frameworks as required and requested for a variety of projects and initiatives.

Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.

Monitoring and optimizing data performance.

Customizing and managing integration tools, databases, warehouses, and analytical systems

Process unstructured data into a form suitable for analysis and assist in analysis of the processed data.

Working directly with the technology and engineering teams to integrate data processing and business objectives.

Ensure performance, uptime, and scale, maintaining high standards of code quality and thoughtful design.

Required Qualifications

Bachelors Degree in Computer Science, Information Technology or other relevant field.

At least 1 to 3 years of recent experience in Software Engineering, Data Engineering or Big Data.

Ability to work effectively within a team in a fast-paced changing environment.

Software development experience, ideally in Python, Spark, Kafka or Go, and a willingness to learn new software development languages to meet goals and objectives.

Knowledge of strategies for processing large amounts of structured and unstructured data, including integrating data from multiple sources.

Knowledge of data cleaning, wrangling, visualization and reporting.

Ability to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and experience.

Exposure to databases, BI applications, data quality and performance tuning.

Excellent written, verbal and listening communication skills.

Preferred Qualifications

Knowledge of or direct experience with the following AWS Services desired S3, RDS, Redshift, DynamoDB, EMR, Spark, and Lambda.

Knowledge of or direct experience with Hadoop, Snowflake or BigQuery.

Experience working in an agile environment.

Practical Knowledge of Linux.

Apply Now


Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.


Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com


Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.


Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.


The base pay for this position is $62,700.00 – $125,300.00. In specific locations, the pay range may vary from the range posted.",1888,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Company - Public,False
Operations and Data Analytics Engineer - NASA KSC,"Rothe Enterprises, Inc.","Cape Canaveral, FL",$67K - $106K (Glassdoor est.),-1.0,"Operations and Data Analytics Engineer


Rothe Enterprises, Inc. has an immediate opening for an Operations /Data Analytics Engineer. The potential candidate needs to have experience in developing analytical models, running simulations, performing quantitative and objective analyses, and using the latest Commercial Off-The Shelf (COTS) data science, analytics, and data visualization tools, (e.g., Tableau, Power BI) to collect, integrate, and report meaningful metrics from a variety of data sources.
The individual will work as part of the Exploration Ground Systems (EGS) Analytics Team responsible for providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, to EGS and NASA leadership in support of the Artemis Mission. This position is onsite at Kennedy Space Center.


Duties and Responsibilities
Provide quantitative analyses, data metrics and insights that will help drive design and operational efficiencies during Artemis flight hardware processing.
Analyze complex data structures and create advanced visualization.
Skills
Must have experience with developing analytical models and perform simulations.
Requires experience with data visualization software (Tableau, Power BI)
Must be proficient in MS Office.
Experience in applying Ops Research and data science principles.
Strong oral and written communication skills
Excellent interpersonal skills with the ability to work in a co-located team environment with multiple cross-program customers and technical experts.
Self-starter with outstanding organizational, analytical, and problem-solving skills.
Ability to perform work within specific timeframes and adhere to deadlines.
Ability to intuitively see and understand how things operate
Experience / Education
Requires BS degree in Industrial Engineering, or other physical science with demonstrated engineering, mathematical/computational analysis, or Operations Research experience
A combination of education, training, or certification that provides the requisite knowledge, skills, and abilities may be substituted for the degree.
Experience with KSC Launch Processing preferred
Experience in reliability analysis preferred
Work Conditions
This position is contingent on successful completion of security badging requirements which include but are not limited to background checks, and drug screening.
Travel requirements – occasional
Rothe Enterprises, Inc. is a HUBZone employer. HUBZone residents are encouraged to apply for preferential consideration without regards to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, or sexual orientation. You are being given the opportunity to provide EEOC information to help us comply with federal and state Equal Employment Opportunity/Affirmative Action record keeping, reporting, and other legal requirements and such information will not affect hire ability.
You may check your HUBZone status here: HUBZone Map (sba.gov). For more information on the HUBZone designation please visit the Small Business Administration.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Company - Public,True
Data Management Engineer/SAS Developer,"FCCI Services Inc.
","Sarasota, FL",$73K - $101K (Glassdoor est.),3.9,"As an FCCI Systems Developer/Data Engineer, you will have the opportunity to work with a great team providing data security, retention and governance across our IT platform. Produce secured, documented, high quality applications software in support of FCCI’s various business needs. Support the Data Warehouse ETL, BI reporting, data analytics and financial applications utilizing available & emerging technologies, (such as our current SAS & Cognos applications). This role will configure applications to meet NAIC model security regulations for data retention and anonymization, as well as supporting our migration to data lakes/lakehouse. Working in an Agile development environment, you will enjoy collaborating with our business & technical leaders using your leadership, business intelligence, data warehouse and system development skills.

A commitment to collaborative problem solving, sophisticated design, and delivering a quality product is essential. As part of our collaborative culture, the selected individual will provide on call support on a rotational basis to applications as necessary. This position will be located in one of the following: Sarasota, FL corporate office campus, Lake Mary, FL, Lawrenceville, GA, or our Richardson, TX office. FCCI provides the opportunity to work a hybrid work schedule of 3 days in the office and 2 days remote.

In exchange for your talents, FCCI offers competitive salaries and an excellent benefits package.

FCCI values the contributions of a diverse workforce.

We're committed to being fair and equitable to all employees and applicants for employment. FCCI prohibits discrimination on the basis of race, color, sex, age, marital status, religion, national origin, sexual orientation, handicap, disability and other legally protected classifications.

Please apply via our website at www.fcci-group.com.

Experience
Required
Bachelors or better in Computer Science or related field.
Two or more years of experience enhancing and supporting the Data Warehouse batch processing using SAS (as well as SAS EG, SAS Macros and SQL programming language.
Two or more years working on ETL & BI reporting
Advanced understanding of Data Warehousing concepts & governance, how data processes through systems from internal and external sources.
Experience working within an Agile methodologies environment
Preferred
Cognos experience and Solix Data Management is a plus",1959,Insurance Carriers,$500 million to $1 billion (USD),Insurance,501 to 1000 Employees,Company - Private,True
Data Engineer - 5050304,"Accenture
","Saint Petersburg, FL",-1,3.9,"Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.

As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.

You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.

Utilize strong SQL Python skills to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features.

Build reporting dashboards and visualizations to design, create and track campaign program KPIs.

Perform analyses on large data sets to understand drivers of operational efficiency.

Manage end to end process of analytic tooling feature development, including request intake, requirements evaluation, cross functional team alignment, feature execution, QA testing, and stakeholder communication.

Consult with business analysts, technical data SMEs, and cross functional partners to understand their reporting and data needs, serving as the point of contact for requests, inquiries, and actions.

Interface with other data engineering, product, and data science teams to implement client needs and initiatives.




Basic Qualifications:

Minimum 2 years experience with Python.

Minimum 3 years experience SQL.

Minimum 3 years experience Big Data Analytics.

High School Diploma or GED.

Preferred Qualifications:

Experience with large enterprise data sets.

Bachelors Degree

Compensation at Accenture varies depending on a wide array of factors, which may include but are not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York, or Washington as set forth below.

Information on benefits is here.

Role Location

California: $61.53 to $71.53/hour

Colorado: $61.53 to $71.53/hour

New York: $61.53 to $71.53/hour

Washington: $61.53 to $71.53/hour


What We Believe


We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.


Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here


Equal Employment Opportunity Statement


Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.


All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.


Accenture is committed to providing veteran employment opportunities to our service men and women.


For details, view a copy of the Accenture Equal Employment Opportunity and Affirmative Action Policy Statement.


Requesting An Accommodation


Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.


If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.


Other Employment Statements


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.


Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.


Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.


The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",1989,Business Consulting,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Engineer,"PHARMALOGIC
","Boca Raton, FL",$79K - $124K (Glassdoor est.),3.0,"Role Summary:
The Data Engineer will play an essential role in working closely with our operations and finance team to build a data warehouse and transform the way we read our data. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.


Responsibilities for data engineer

Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Help build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.


The ideal candidate must have:

A minimum of 5 years of relevant work experience
Advanced working SQL, and MySQL development experience
Experience with Domo, Snowflake, Tableu, or related product
Ability to work in Linux
Experience with BI / data visualization tools
Working experience with AWS and / or Azure
Experience in the fields of data warehousing, and business intelligence.
Experience with large-scale data processing solutions
Excellent computer science fundamentals and problem-solving skills
Experience in creating logical and physical data models
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with multiple programming languages.
Strong analytic skills related to working with unstructured datasets.
Data engineer certifications are a plus.",-1,Health Care Products Manufacturing,Unknown / Non-Applicable,Manufacturing,501 to 1000 Employees,Company - Public,True
Senior BI Data Engineer,"GenesisCare
","Fort Myers, FL",$92K - $120K (Glassdoor est.),2.7,"At GenesisCare we want to hear from people who are as passionate as we are about innovation and working together to drive better life outcomes for patients around the world.
GenesisCare USA Services, LLC, Senior BI Data Engineer, Fort Myers FL
Work closely with stakeholders and IT development teams to build modern and highly scalable cloud data platform that enables data ingestion, storage, transformations, and preparation of massive datasets for data analytics and machine learning models
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Design and develop optimal data pipeline architecture and infrastructure for data movement and data orchestration aligned with trending data pipeline design patterns in the industry and best practices
Assemble large, complex data sets that meet functional/non-functional business requirements
Perform proof of concepts for innovation and to continuously improve and enhance the capabilities of the business intelligence platform in cloud and scale them out for production use
Contribute ongoing monitoring including cloud resource capacity management, performance monitoring, troubleshooting, and resolving technical issues
Collaborate with the business and technical teams to ensure active support and resolution of risk and incidents.
JOB REQUIREMENTS:
Must have a Bachelor's degree or foreign equivalent in Computer Science, Computer Engineering, Information Technology, or a related field, and 5 years of post-bachelor’s, progressive related work experience;
OR a Master's degree or foreign equivalent in Computer Science, Computer Engineering, Information Technology, or a related field, and 3 years of related work experience.
Of the required experience, must have 3 years of experience with the following: Utilizing SQL Azure platform and Microsoft business intelligence suite; Designing and developing data movement and orchestration pipelines using Azure Data Factory, Azure Data Lake Storage, Azure Blob Storage, and Azure SQL; Managing CI/CD build, release, deploy process with Git and Docker containers; Automating Azure resources using Azure CLI, ARM templates and SQL Server PowerShell; and Writing scripts in Python.
Work Schedule: 40 hours per week, M - F (9:00am - 5:00pm)
Telecommuting permitted 5 days a week
Employer will accept any suitable combination of education, training, or experience.
Qualified Applicants: Apply online by clicking the ‘apply for this job’ button at the top of the page
#LI-CS1
GenesisCare is an Equal Opportunity Employer.",2005,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,5001 to 10000 Employees,Company - Private,False
Data Engineer,Global Triangles,"Orange Park, FL",$70K - $106K (Glassdoor est.),-1.0,"The Data Engineer will design and develop Tableau reports and dashboards that will yield
actionable insights that present the answer to business questions. Working alongside senior
executives to understand and solve complex BI needs.

About Global Triangles

At Global Triangles we are more than an external IT provider, we are a true ally. Our personalised services and reliable team allow us to be productive and reactive to the new challenges that arise in each project. We have a single mission; to offer solutions that, together, help us achieve our client goals.

What will you do


Design and develop Tableau reports and dashboards that will yield actionable insights that present the answers to business questions.
Run ad-hoc analysis for Product and Business Managers using standard query languages and operationalize for repeatable use via Tableau reporting suite.
Code and modify SQL/ETL based on dashboard requirements.
Work independently with the stake holder.

Who are we looking for?


Bachelors or Masters in Analytics or a related field.
Expert using Tableau, Alteryx or comparable data blending tools.
3 years' experience working with business analytics and data reporting.
Working knowledge of ETL (extract, transform, load)
Working knowledge with data streaming services (NoSQL and SQL based)
Working knowledge with SQL and NoSQL persistence stores (MySQL, MongoDB) (edited) -working knowledge of tiered Data Lake architectures and non-structured data sets (edited)
AWS Kinesis, Firehose, AWS Glue
Consultative experience working with large companies to achieve desired business outcomes.
Training end users for a clear and thorough understanding of the data and formatting.
Advanced English
Excellent communication skills
What we offer


Competitive salary
Remote work",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,False
Senior Data Engineer - Hybrid Remote,"Division of Rehabilitation and Liquidation
","Tallahassee, FL",$80K - $85K (Employer est.),3.0,"Senior Data Engineer - Hybrid Remote

Anticipated Salary Range: $80,000.00 – $85,000.00 per year

Closing Date: Until Filled

About Us

The Division of Rehabilitation and Liquidation (Division) is one of 13 divisions within the Florida Department of Financial Services. It serves as the Receiver of insurance companies that are placed in receivership, primarily for purposes of rehabilitation or liquidation. Under an order of rehabilitation, the Receiver seeks to remedy the problems that resulted in the company being placed into rehabilitation. In liquidation, the Receiver collects all assets of the company and ultimately distributes the available assets to claimants under a statutory prioritization. In both instances, the Receiver is responsible for conducting business on behalf of the company that has been placed in receivership. This process entails providing an array of services which include Accounting, Claims, Legal, Information Technology, Administrative Services, Asset Recovery and Estate Management functions.

Position Summary:

The Division is seeking a Senior Data Engineer. This hybrid-remote job, which is based in the Tallahassee office, allows employees to work one (1) day from home after six (6) months of employment. This position is responsible for performing complex analysis of database systems including planning, design, maintenance, and development. The duties and responsibilities of this position include the following:

Performs company data analysis and conversion into Division’s systems. Coordinates with receivership company IT staff to obtain necessary data.
Coordinates data transmissions from Division’s systems to external entities (e.g. Guaranty Associations).
Identifies data sources, constructs data decomposition diagrams, provides data flow diagrams and documents the process.
Develops reusable code and procedures to streamline data conversion and ensure data quality.
Develops integration between internal business applications at the database level.
Evaluates user's request for new data elements and systems against the existing shared data environment.
Coordinates use of the organization's data to ensure data integrity and control redundancy.
Establishes database design techniques using data modeling and prototyping software.
Analyzes and proposes changes to database structures.
Develops and maintains data dictionary ensuring uniformity of definitions and standards for use of data dictionary.
Works with infrastructure team to determine necessary database security.
Travels as required.
Support disaster recovery efforts.
Performs other related duties as required.

Salary Range:

The hiring salary range for this position is$80,000.00 – $85,000.00 per year.

Minimum Qualifications:

A bachelor’s degree from an accredited college or university in computer science, computer engineering, management information systems, information systems, engineering, or mathematics and three years of experience in database design and development, computer software development, management information systems, web design, information systems; or
Professional experience as described may substitute on a year-for-year basis for the required education.

Preferences:

Preference may be given to applicants with experience in one or more of the following areas:

Microsoft SQL Server and SQL scripting
Relational database design and development
Data analysis and conversion techniques
Extensive knowledge of data integration and processing including extraction, transformation, and loading.
Microsoft Visual Studio programming

Employment Requirements:

In compliance with federal law, individuals selected for hire will be required to confirm their identity and eligibility to work in the United States.
In accordance with Florida Statutes 110.1128, the Division must verify male applicants have registered with the Selective Service System or have proof of registration exemption to be eligible for employment or promotion with the Division. If registration or exemption cannot be verified, male applicants are not eligible for hire. If currently employed by the Division, this law prohibits the promotion of such person. This requirement also applies to any male who has legally or illegally entered the United States. To check the status of your registration, obtain proof of exemption, review requirements for transgender people, or for general information about the Selective Service System, please visit www.sss.gov.

Why Join Our Team?

The vision of the Receiver is to be a recognized and respected leader in the efficient administration of insurance receiverships. To accomplish this goal, the Receiver is comprised of a talented workforce that is dedicated to providing quality service that maximizes value for the public. Joining our team will provide the opportunity to experience the following benefits:

A welcoming and open environment that fosters a sense of belonging, purpose, and innovation.
Meaningful and challenging work that improves the quality of life for the citizens of Florida.
Shared values of service, teamwork, excellence, accountability, diversity, innovation, and integrity.
A comprehensive benefit package that includes medical, dental, vision, life and other supplemental insurances, retirement, and flexible spending accounts, front-loaded paid time off, and more.
A culture that supports flexible work schedules, community service and the recognition of employee contributions.
A commitment to training and development through continuous education and collaboration.

For more information, please visit our website at http://www.myfloridacfo.com/division/receiver/.

How to Apply:

Resumes can be submitted through one of the below methods. The information must be received by the position’s closing date and time.

Email: rehab.hr@myfloridacfo.com. Please include the position title in the email subject line.
Mail or Hand Delivery: 325 John Knox Road, Atrium Building Suite 101, Tallahassee, Florida 32303.
If you require an accommodation to participate in the application process due to a disability, please call (850) 413-4546 for assistance.

Equal Opportunity Employer

Job Type: Full-time

Pay: $80,000.00 - $85,000.00 per year

Benefits:

401(k)
Dental insurance
Flexible schedule
Health insurance
Life insurance
Paid time off
Tuition reimbursement
Vision insurance

Schedule:

8 hour shift

Work Location: In person",-1,Municipal Agencies,Unknown / Non-Applicable,Government & Public Administration,Unknown,Government,True
CyberSecurity Engineer (Data Stewardship),"Clarity Innovations, LLC
",Florida,-1,4.8,"Description

Clarity Innovations connects human creativity with emerging technology to design, develop, and deploy software that enhances mission success. Our focus is redefining the Department of Defense's relationship with technology by encouraging the use of DevSecOps and Agile methodologies, small-teams constructs, modern tech stacks, and automation. Our software improves the lives and work of our end users and enhances innovation. We fulfill our responsibility to our country by delivering mission-changing results that help shape a better and safer world.

Job Description:


Minimum of 1-year of Cyber Engineering experience is required

Experience with running red team/blue team security games and analysis

Understanding of live monitoring of cyber environment for potential attacks, vulnerabilities, and log analysis

Development of cybersecurity architecture with ability to adapt quickly to evolving requirements

CLEARANCE:

TS/SCI

Clarity Innovations provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, or any other protected class.",2013,Research & Development,Unknown / Non-Applicable,Management & Consulting,1 to 50 Employees,Company - Private,False
Senior Data Engineer,"Fortegra
","Jacksonville, FL",$102K - $135K (Glassdoor est.),4.0,"We are looking for a Data Engineer to join our technology organization. As a Data Engineer you will implement strategies for modernizing and remediating legacy platforms by leveraging existing tools as well as implementing new data platform capabilities. You will implement new technologies, design ETL processes, and administer databases. In addition, you will be part of the team developing critical insight for the company and supporting every function of the organization. You will take responsibility for identifying and solving issues concerning data management to improve data quality. As we grow our footprint in Azure, you will have the opportunity to lead transformation projects. You will be part of a high performing team working on mission critical projects with visibility across the organization.



Responsibilities:
Design, develop , build, and own robust and high-performance data pipelines and APIs.
Gain a thorough understanding of the business and the data strategy to support that business.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, dbt and Azure technologies.
Take ownership of the data quality and articulate opportunities for continuous improvement, think of data as a product!
Define and document cloud solution architecture(s) including technical designs and diagrams.
Create and document unit test scripts.
Develop a strong customer focus, ownership, urgency, and drive.
Be a team player that everyone wants to work with.
Be a critical stakeholder in architectural decisions and evaluating systems implementations.
Troubleshoot and assist in resolving all issues pertaining to data management.

The above cited duties and responsibilities describe the general nature and level of work performed by people assigned to the job. They are not intended to be an exhaustive list of all the duties and responsibilities that an incumbent may be expected or asked to perform.

Qualifications:
B.S. in Computer Science, Engineering or equivalent required.
Experience with deploying Azure Infrastructure as Code and building CI/CD pipelines using GitHub /Azure DevOps and such other source control environments is required.
Azure cloud certified engineers will be preferred.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Deep knowledge with Python.
Strong experience in SQL and strong knowledge of data warehousing and ETL best practices.
Excellent verbal, written, and interpersonal communication skills. Ability to articulate technical solutions to both technical and business audiences.
Ability to influence and build relationships with engineering and data science teams, technology leadership, external service providers, infrastructure, and enterprise architecture teams.



Additional information

Full benefit package including medical, dental, vision, life, company paid short/long term disability, 401(k), tuition assistance and more.",1978,Insurance Carriers,$1 to $5 billion (USD),Insurance,501 to 1000 Employees,Subsidiary or Business Segment,True
Data Engineer,"Quiet Professionals LLC
","Tampa, FL",$81K - $123K (Glassdoor est.),4.5,"Job Title: Data Engineer

Experience Level:   Senior

Location:   Tampa

Clearance: TS/SCI

Quiet Professionals, LLC is seeking a Data Engineer who will build and maintain data systems and construct datasets that are easy to analyze and support customer requirements. Implement methods to improve data reliability and quality. Combine raw information from different sources to create consistent and machine-readable formats. Develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling. Develop and deploy Application Programming Interfaces (API) to expose IDST maintained data to the enterprise.

This future opportunity is contingent upon award.

Duties & Responsibilities:

Acquire and assemble large, complex datasets that align with USSOCOM enterprise requirements
Building, testing, and maintaining data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using modern data technologies
Develop analytics tools and transformative algorithms for data to provide actionable insights into customer processes, operational efficiency and other key business performance metrics
Create new data validation methods for analytics and data scientist team members that assist them in building and optimizing products to fulfill customer objectives
Work with IDST stakeholders including USSOCOM leadership, customers, and design teams to assist with data-related technical issues and support their data infrastructure needs
Analyze procedures for USSOCOM data separation, access, and security across users and the enterprise data architecture
Work with IDST data and analytics experts to strive for greater functionality in our data systems and capability integration
Create and maintain optimal data pipeline architecture and support associated process improvements for automating manual processes, data delivery, and infrastructure re-design for scalability

Requirements:

Possess a minimum of a bachelor's degree in computer science, IT, or similar field.
8 years’ experience as a data engineer or in a similar role.
Demonstrated experience employing data models, data mining, and segmentation techniques.
Demonstrated experience developing, deploying and/or maintaining enterprise level data solutions
Experience with SQL database design • Data engineering certification is a plus Current DoD Top Secret clearance and eligible for SCI access and ACCM read-on
Python, SQL, noSQL, Cypher, POSTGRES

Preferred:

SQLAlchemy, Flask, Swagger, JavaScript, Spark, Hadoop, Kafka, Hive, R, storm, Matlab, Neo4J, MongoDB

Quiet Professionals, LLC, (QP) is an independently owned and operated CVE-Certified Service-Disabled Veteran Owned Small Business (SDVOSB) with headquarters located in Tampa, Florida. Our goal is to provide innovative and sustainable solutions that improve the operational effectiveness of our clients and partners. We have extensive knowledge and experience in a variety of areas involving Military Support, Intelligence, Information Technology and Security Operations. QP is committed to providing high quality services appropriate to the level of experience and expertise required in analyzing, planning, advising, and conducting operations on a global scale.

Fostering a diverse and inclusive culture is at the heart of what we do at Quiet Professionals, LLC. We want everyone to bring their true selves to work and be inspired to be innovative and results oriented. That is why we strive to always recruit, retain, and promote a diverse mix of people who can contribute to our culture rather than fit into it. We recognize that the work we do internally has a significant impact on the work we do externally, so we must constantly inspire great ideas and new paths forward from every member of our team in order to be successful. We can provide our clients with everything they require thanks to each person's superior skills and proven performance.

Job Type: Full-time

Benefits:

401(k)
Dental insurance
Health insurance
Life insurance
Paid time off
Vision insurance

Experience level:

8 years

Schedule:

8 hour shift

Ability to commute/relocate:

Tampa, FL: Reliably commute or planning to relocate before starting work (Required)

Application Question(s):

Please provide a reliable email address that we can contact you at.
Do you have previous experience with Python, SQL, noSQL, Cypher, POSTGRES?
Do you have previous experience with SQL database design?

Education:

Bachelor's (Preferred)

Experience:

data engineer: 8 years (Preferred)

Security clearance:

Top Secret (Required)

Work Location: In person",2013,Aerospace & Defense,$5 to $25 million (USD),Aerospace & Defense,201 to 500 Employees,Company - Private,True
Senior Data Analytics Engineer,"Sarasota County Government
",United States,$80K (Employer est.),3.9,"Department:
Enterprise Information Technology
Start Here. Grow Here. Stay Here.
Sarasota County Government has an excellent opportunity to be a Senior Data Analytics Engineer at the County’s Emergency Operations Center (EOC). The salary range for this role begins at $80,000, but with experience could start as high as $90,792. To thrive in this role, you must be detail-oriented, with excellent organizational skills, and exceptional technical knowledge of software development principles and scripting languages to support enterprise data initiatives. As the Senior Data Analytics Engineer, you will provide data operations services, including designing, developing, monitoring, and maintaining data pipelines, analyzing, and organizing raw data, interpreting trends and patterns, and preparing data models and consulting to meet department data needs and objectives. The senior data analytics engineer position is involved in on-call technical support 24/7/365 with mandatory personal cell phone required. Apply today!
Actively participate as project lead in software and hardware upgrades and keeps manager informed of progress, obstacles.
Advise management and provide recommendations on technical and project issues.
Proficient data cleansing, data integrity, data processing, ad-hoc analysis, and data mining methods.
Design, develop, and maintain data systems and interfaces to cloud and on-premises systems.
Support the development of automation efforts using platforms like: MS Power Platform or UiPath.
Implement new and modified data pipelines and data models following ITIL best practices.
Support data visualization and reporting efforts leveraging tools like MS Power BI or Tableau.
Design, develop, and maintain data structures and models for relational and non-relational data using platforms and tools: Python, .NET, MS SQL, PowerShell, Databricks, and Azure Data Platform in a Microsoft and Linux environment.
Develop and maintain documentation for customers, partners, and other IT professional staff using tools like: Azure DevOps and Azure Purview.
Identify opportunities for data acquisition, interpreting trends and patterns to enhance data quality and reliability.
Conduct complex data analysis and report on results to prepare data for descriptive, diagnostic, prescriptive and predictive modeling.
Provide 24/7 application support during on-call time.
Participate in technical designs to ensure compliance with business requirements and technical specifications.
E-Work/Hybrid Work: Currently this position is eligible to e-work up to 2 days per week! After you complete your first six months, contingent on work requirements and other factors, you’ll be eligible for this fantastic benefit.
CJIS Clearance: **The successful candidate will be subject to an extensive background check(s) as a part of the hiring process.
Hours: Monday – Friday, 8:00 a.m. – 5:00 p.m., and involvement with on-call technical support.
About You
To thrive in this role, you must have-
Bachelor’s degree in Computer Science, Information Systems, Business Administration and 4 – 5 years of related experience
– OR Master’s degree and 2 or more years of related experience
Experience may substitute for formal education at discretion of management.
Preferred Qualifications-
Ability to multi-task and prioritize workload.
Strong production design, development, and support for relational and non-relational data including data pipelines, system interfaces, and data stores.
Strong scripting skills in Python, .NET, PowerShell, and MS SQL Server T-SQL.
Ability to establish and maintain effective working relationships with others.
Strong customer service skills.
Ability to foresee and evaluate possible problems and to plan alternative solutions.
Excellent analytical and creative problem-solving skills; must be a self-starter, proactive and capable of taking direction and moving forward with minimal supervision.
Ability to assimilate user requirements and issues as well as the business rules governing the request.
About Everything Else
Starting Pay Range: $80,000 - $90,972/year, based on your experience.
Full Position Salary Range (future earning potential): $67,246.40 - $114,316.80/year
Benefits:
Enjoy great benefits including Health, Dental, Vision, and Life Insurance, Short-Term and Long-Term Disability, Flexible Spending Accounts, Employee Assistance Program (EAP), Florida Retirement System (FRS) and many, many more! Starting January 2024, choose one of three great medical plans, including one with a $0 premium option, with completed preventative visits!
Utilize our award-winning wellness program including free gyms and classes at multiple Sarasota County Government locations.
Enjoy 11 paid holidays, 3 personal days and 16 paid vacation days in the first year of full-time employment with increasing accrual rates with years of service. (That adds up to a possible 30 days off in your 1st year!)
A different blend of voices prompt better conversations, choices and results for everyone. Sarasota County – Many Voices, One Team.
We celebrate and value the experiences, backgrounds, perspectives, talents and strengths that make us different and are committed to creating a culture of understanding and respect where our employees realize that we are stronger together.
Our vision is to attract, develop, retain and engage a talented workforce broadly representative of the citizens and communities we serve. To further value creativity, innovation, collaboration and great customer service – internally and externally.
Sarasota County Government provides equal employment opportunities to all employees and applicants for employment without regard to race, color, creed, ancestry, national origin, citizenship, sex or gender (including pregnancy, childbirth, and pregnancy-related conditions), gender identity or expression (including transgender status), sexual orientation, marital status, religion, age, disability, genetic information, service in the military, or any other characteristic protected by applicable federal, state, or local laws and ordinances. Equal employment opportunity applies to all terms and conditions of employment, including hiring, placement, promotion, termination, layoff, recall, transfer, leave of absence, compensation, and training. A job applicant with a disability who requires reasonable accommodation to participate in the application/selection process is requested to make known the need for an accommodation to Human Resources or appropriate county staff members. For assistance with the application, please call 941-861-5353.
Government employers are drug-free and tobacco-free environments, EEO/AA/ADA employers, and they prohibit discrimination in all services, programs or activities.
Sarasota County Government is a Tobacco-Free/Drug-Free Workplace.",-1,Municipal Agencies,Unknown / Non-Applicable,Government & Public Administration,1001 to 5000 Employees,Government,False
Sr. Data Engineer,"Echelon Fitness
","Orlando, FL",$79K - $117K (Glassdoor est.),4.0,"Job Title: Sr. Data Engineer
Reports To: VP of Product and App Development
Classification: Exempt





About us:
We are an innovative fitness brand making at-home, connected fitness more accessible. We offer a line of connected products – bikes, rowers, treadmills, fitness mirrors – and an app experience that empowers members to participate in live and on-demand fitness classes.





We’re looking for a Sr. Data Engineer to maintain and improve upon our existing data pipeline. An excellent Sr. Data Engineer will extract and load data in a way that will ensure that our analysts have the resources to build and maintain clear reporting at the highest level of accuracy possible.





What you’ll do:


Own and manage extract/load tool responsible for data warehouse connections

Develop solutions for automated data extraction when a premade connector is not available

Work together with the data team, project management, and internal stakeholders to understand the purpose and context of the data being brought into the warehouse

Fulfill vetted requests to extract or transform data to meet reporting requirements as appropriate

Audit existing data as necessary, working with the greater team to make and document changes.

Maintain comprehensive technical documentation





Requirements:


GCP Experience preferred - AWS or Azure also acceptable cloud-based experience.

Expert knowledge of Python and familiarity with software libraries such as PANDAS.

Apache Airflow 2.x experience

Functional knowledge of various Extract/Load tools such as Fivetran

Working knowledge of DBT

Experience working in an agile environment and comfortable with project management tools such as JIRA

Capable of writing clear and concise technical documentation and organizing it for use within a shared repository such as Confluence

A clear vision for purposeful data warehouse design





Nice-to-haves:



CI/CD experience, such as with Github Actions

Strong experience extracting data from SaaS platforms directly, such as Shopify or Stripe

Subscription domain expertise

Working knowledge of javascript/typescript in the context of writing functions

Can implement and maintain webhook connections",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,True
Data QA Engineer,"Lennar Homes
","Miami, FL",$63K - $93K (Glassdoor est.),3.6,"Overview:

The primary mission of the Data Quality Engineer role is to help our business evolve into an AI-first, insights-driven organization. This position sits in our Enterprise Data and Analytics team, which aims to drive improved business outcomes using insights gleaned from data and analytics, infusing them into Lennar’s corporate fabric.

The Data Quality Engineer provides data quality testing and validation leadership to our data platform engineering team. This is done by performing quality testing and validation during the implementation of our next generation data and analytics platforms and products using DataOps and engineering best practices. In addition, the incumbent focuses on empowering and enabling our business users through self-service and automation. The Data Quality Engineer is a key role in operationalizing Lennar’s enterprise data fabric.

Responsibilities:
Performs quality assurance & testing on the platform team’s work products across all tiers (Development, QA, UAT, and Production) as applicable.
Test & validate data engineering solutions for Lennar’s data and analytics platforms and products before any release to the next tier.
Look for automation techniques to streamline data quality validation.
Instrument platforms with robust quality metrics and monitoring.
Support quality process improvements on the team to enable rapid development of data products.
Gain an understanding of core business processes and align quality data development with business strategy.
Qualifications:
Education and Experience Requirements:

Quality Engineering Requirements

2+ years of experience as Data Quality Engineer.
2+ years of experience performing data quality analysis & validation.
2+ years of experience writing test plans, test cases, and test scripts.
1+ years of experience validating solutions built on REST APIs.
1+ years of experience validating solutions with Snowflake.
1+ years of experience validating data pipelines.
Good conceptual understanding of data analytics architectural approaches and data models (Data Vault experience is a plus).
Strong adherence to core software testing principles (code modularization, versioning, git, testing, Agile etc.).
Nice to haves:
Experience performing validation on data ingestion solutions such as FiveTran and / or Qlik.
Experience performing validation on Prefect / workflow tool.
Experience performing validation on dbt.
Experience performing validation on Hasura & GraphQL.
Experience performing validation on database replication tools.

Other Requirements

Ability to work collaboratively and productively with others to accomplish Lennar’s objectives.
Thirst to help transform Lennar into an insights-driven organization.
Ability to work and partner with users and stakeholders to gather solution requirements and write test driven development cases.
Experience working with business users to understand how to optimally deliver insights within their operational workflows & decision-making processes.
Ability and willingness to quickly learn new technologies.
Strong adherence to core software testing principles (code modularization, versioning, git, testing, Agile etc.).
Ability and willingness to learn about the business, its strategy, objectives, and core business processes.
Physical Requirements:

This is primarily a sedentary office position which requires the incumbent to have the ability to operate computer equipment. Finger dexterity is necessary. Occasional travel (up to 10%) is required.



Additional Requirements:



Interact well with co-workers.
May be required to cross train for position(s) within the team organizational structure from time to time, as required by the Leadership
Comply with and implement company policies and procedures.
Accept constructive criticism.
Strong work ethic.
Team player.

This description outlines the basic responsibilities and requirements for the position noted. This is not a comprehensive listing of all job duties of the Associates. Duties, responsibilities and activities may change at any time with or without notice.
Type: Regular Full-Time",1954,Real Estate,$5 to $10 billion (USD),Real Estate,5001 to 10000 Employees,Company - Public,False
Data Engineer,"The Walt Disney Company (Corporate)
","Lake Buena Vista, FL",$73K - $114K (Glassdoor est.),3.9,"About the Role & Team

Join the Data Engineering team within the Disney Decision Science + Integration (DDSI) organization at The Walt Disney Company. We support clients within Disney Parks, Experiences and Products which include Parks & Resorts both domestic and international, Consumer Products and Disney Signature Experiences as well as the Disney Entertainment segment which include Studios Content (Disney Theatrical Group), General Entertainment Content, and ESPN and Sports Content.

We use technology, data analytics, optimization, statistical and econometric modeling to explore opportunities, shape business decisions and drive business value.

As a member of the Data Engineering team you will be responsible for partnering with Decision Science Products, Decision Science, Client and Technology team members on various development and sustainment projects, ad-hoc requests, prototyping and research initiatives by providing data pipeline and database engineering services.

As a Data Engineer you will work on projects such as Adventures by Disney (AbD), VIP Tours, Resort Inventory Optimization (RIO), and several upcoming initiatives. In this position, the candidate will have tasks to develop, implement, improve and support our solutions. The work will involve various data engineering activities throughout the project SDLC.

What You Will Do

Work assignments may cover activities such as participation in data requirements gathering, source-to-target mapping, develop and maintaining ELT data pipelines, data quality monitoring, producing input datasets for science models and visualizations and Batch/Orchestration job scheduling. In addition to technical abilities, the role is responsible for understanding the business domain and processes, then applying that knowledge to the assigned work. This role communicates data engineering progress to the project leadership team, and actively participates in meetings and discussions.

Required Qualifications & Skills

Minimum 3 years of related work experience

Experience with ELT/ETL data pipeline development and maintenance

Expertise using Python and SQL

Ability to showcase an understanding of one or more business domains

Prior experience gathering data requirements and producing data design solutions

Experience with developing in a multi environment (Dev, QA, Prod, etc.) and DevOps procedures for code deployment/promotion

Experience crafting and building relational databases (preferably in Postgres or Snowflake)

Experience leading and deploying code using a source control product such as GitLab/GitHub

Able to formulate solutions and communicate sophisticated technical concepts to non-technical team members

Preferred Qualifications

Knowledgeable with theme park attendance, reservations and/or products

Showed strength interacting with API’s

Experience with data orchestration tools such as Apache Airflow

Knowledgeable on cloud architecture and product offerings, preferably AWS

Experience using containerization technologies such as Docker or Kubernetes

Education

Bachelor’s degree in Computer Science, Mathematics, Engineering or related field preferred/or equivalent work experience

Master’s degree preferred Computer Science, Mathematics, Engineering or related field preferred",1923,Film Production,$10+ billion (USD),Media & Communication,10000+ Employees,Company - Public,False
Data Engineer,"PerfectLaw Software
","Miami, FL",$81K - $125K (Glassdoor est.),5.0,"Responsibilities

Demonstrated experience with relational & non-relational databases.
Demonstrated experience with ETL/API scripts and tools for data integration between applications and platforms.
Work with teams throughout the company to brainstorm ways to automate our systems
Design solutions for integrating services together through an API ecosystem
Create New APIs needed to integrate systems together, and update existing APIs to satisfy new business requirements as well as support additional features and functionality
Generate data schema layer and regular datasets for end-users using system tools and databases or data warehouse queries and scripts.
Platform administration and development
Demonstrate experience in cloud technology
Provide detailed approach and estimates for project solutions.
Acknowledge and continuously tackle issues identified for all deployed software solutions
Troubleshoot coding issues
May perform other responsibilities as assigned. Responsibilities and duties may change when circumstances dictate (e.g., emergencies change in workload, rush jobs or technical developments).



Qualifications

4+ years of experience as an Engineer
2+ years of proficiency in ETL or API Technology Concepts
Intermediate to Advanced knowledge of data management including: Extract, transform, load, API Concepts for relational databases, Data warehousing, data marts, data stores, data sets.
Experience with multiple successful API deployments used in production (on-prem, Azure Cloud or hybrid deployments)
Required hands-on experience and knowledge of implementing API using REST/web services
Strong analysis and design skills with a focus on system design, flow, and performance
Experience working in a fast-paced environment, ideally supporting a 24/7/365 organization
Attention to detail with the ability to produce reliable, effective solutions
Possess a positive attitude and ability to work in a collaborative and energetic team environment

If this sounds like you, we want to meet you! We are a fun, professional team of experts. Ambition, loyalty, and exceptional performance will be noticed and rewarded! Please apply to rdr@perfectlaw.com.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,False
Senior Data Engineer,"PT78 LLC
",United States,-1,3.3,"Who we are!

Platinum Technologies (PT78) is the growth opportunity you have been looking for! We are the next-generation leadership factory that equips you to use your talents for meaningful change. Our company is headquartered in Northern Virginia with offices in the Greater Washington D.C. and Tampa Bay areas.

We develop integrated Cybersecurity, Cloud and Digital solutions for our Mission Partners in the Defense, Intelligence and Federal Civilian sectors. Are you the dot-connecting, self-motivated individual that has a record for demonstrated learning agility and a passion for delivering high-quality work products? If so, we want you to join our team!

You.

Platinum Technologies is seeking a Senior Data Engineer to serve as the principal leader for the design, management, and operations for the data infrastructure across the Special Operations Forces (SOF) Intelligence Enterprise. Your ability to solve complex infrastructure challenges and design resilient platform architectures will enable the aggregation, processing, and translation of data into Intelligence products for our SOF mission partners. These partners count on you to provide the best technical advice and demonstrate fluency in multiple data(base) coding techniques and best practices.

This role requires an active Top-Secret clearance with the eligibility to obtain SCI access. The position is in Tampa, Florida at MacDill Air Force Base

What you get to do.

Researches, designs, develops, and/or modifies enterprise-wide systems and/or applications software
Performs software updates, refinement, testing, and debugging to meet business needs
Providesanalysis for reports on software project specifications, activities, or status
Analyzes user/business needs and functionality to plan and design software systems to meet those needs
Thoroughly documents the software or system for future maintenance and updates
Performs all phases of the software development lifecycle and additional duties as assigned
Works with stakeholders including the Executive, Product, Data and Design teams to assistwith data-related technical issues and support their data infrastructure needs
Models and evaluates the potential impact of data changes
Design SQL databases
Create process documentation
Provide written and verbal communication
Work independently and on teams
Code in python, java, Kafka, hive, R, or storm
Oversee real-time business metric aggregation, data warehousing and querying, schema and data management, and related duties.
Design, develop, and test state-of-the-artCloud-based database platforms
Implementation and maintaincomplex databases
Analyze procedures to control the access and allocation of data
Maintainsecurity controls in supported databases
Apply advanced principles, theories, and concepts to job assignments and contribute to the development of new ideas and principles
Solve complex problems, under consultative direction, and represent the SOF Data Science teams across the SOF Intelligence Enterprise working on long-range programs and objectives
Provide advice to the SOF Intelligence Data Team customer and assist in overall functional strategic data planning
Work directly with the SOF DST to ensure the data systems supporting the DST are functioning optimally and can integrate any needed capabilities to support the team

Requirements:

Bachelor's degree in Engineering, Computer Science, or other related analytical, scientific, or technical discipline Active Top Secret with eligibility to obtain an SCI.
Minimum eight (8) plus years’ experience in related position
Minimum 3 years in a lead role
Building Architecture, Data Engineering, Systems Design
Experience with Python, messages systems like Kafka, working experience with ETL processing.

Platinum Technologies is an Equal Opportunity/Affirmative Action employer. All qualified candidates will receive consideration for employment without regard to disability, protected veteran status, race, color, religious creed, national origin, citizenship, marital status, sex, sexual orientation/gender identity, age, or genetic information.

Job Type: Full-time

Benefits:

401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Relocation assistance
Tuition reimbursement
Vision insurance

Compensation package:

Signing bonus

Experience level:

8 years

Schedule:

8 hour shift

Ability to commute/relocate:

Macdill AFB, FL: Reliably commute or planning to relocate before starting work (Preferred)

Experience:

Data Engineer: 8 years (Preferred)

Security clearance:

Top Secret (Preferred)

Work Location: In person",-1,Education & Training Services,Unknown / Non-Applicable,Education,1 to 50 Employees,Company - Private,True
AWS Data Engineer,"Creative Financial Staffing
","Orlando, FL",$120K - $140K (Employer est.),4.5,"JOB DESCRIPTION
Role Overview:

An exciting opportunity awaits to be part of a dynamic team in the travel industry! We are a forward-thinking organization accelerating global air travel growth through innovative solutions and cutting-edge travel data. Seeking a skilled Data Engineer to contribute to software development and product delivery support for data products. In this role, you'll be accountable for managing data pipelines and the entire product lifecycle, collaborating with Product Owners, Solution Owners, and receiving technical guidance from Solution Architects.

Key Responsibilities:

Contribute to and leverage existing architectural patterns for optimal product-related data pipeline development.
Mentor fellow engineers, fostering cross-functional collaboration, and providing technical leadership to other teams as needed.
Collaborate with product owners and business SMEs to analyze business needs and engineer sustainable solutions aligned with architectural principles.
Drive the creation and modification of product portfolio components, ensuring consistency with architectural standards.
Develop data pipelines using industry best practices, adapting to new methodologies for increased business flexibility and agility.
Stay abreast of the latest cloud technologies, patterns, and methodologies, sharing knowledge and potentially presenting ideas to a larger audience for review and buy-in.

Qualifications:

Bachelor’s Degree in Computer Science or related field, or equivalent experience.
3+ years of experience in full-cycle application development, including design, development, and delivery.
3+ years of experience with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery.
3+ years of experience implementing modern applications using Cloud-Based Solutions/Technologies (AWS, Google, Azure), with expertise in AWS tech stack including Lambda, API Gateway, DynamoDB, S3, CloudWatch, SNS/SQS, Step Functions, and Fargate.
Implementation of modern application and infrastructure design patterns, including microservices and containers, disposable, reactive, stateless, and distributed patterns.
Familiarity with DevOps tools, data warehouse platforms, Data Lake concepts and design patterns, BI Technologies, and data management and governance best practices.
Proven ability to lead architectural development processes and mentor technical teams.
Strong communication skills (verbal and written) with the ability to communicate technical information to non-technical audiences.
Intellectual curiosity and passion to support peers in meeting project timelines.

What's in it for You:

Joining a motivated, diverse, creative, collaborative, and solutions-oriented team.
Hands-on learning and professional development opportunities to expand your skills and career.
WorkFlex model allowing virtual work with flexibility in office attendance.
Highly competitive, comprehensive benefits package.
Collaborate with top minds in the industry, using data and technology to innovate travel experiences.

#CFSNOV2023
#CBNOV2023
#INNOV2023",1994,HR Consulting,$100 to $500 million (USD),Human Resources & Staffing,1001 to 5000 Employees,Company - Private,False
Senior Data Engineer (Snowflake) - Contractor,"EY
",United States,$90.00 - $130.00 Per Hour (Employer est.),3.9,"The primary responsibility for the Sr. Data Engineer / Tech Lead is to ensure data accessibility, quality, and reliability within the client's data platform ecosystem.

RESPONSIBILITIES

Design and develop end-to-end data pipelines and ETL processes using Snowflake, Denodo, DBT Cloud, Fivetran, and AWS Glue, ensuring seamless data integration, transformation, and loading.
Collaborate with cross-functional teams to gather data requirements and implement scalable data models and schemas within Snowflake and Denodo, ensuring optimal performance and data consistency.
Implement and maintain data orchestration workflows using Stonebranch, ensuring efficient and reliable scheduling and automation of data processes.
Work with EnterpriseDataLake for ingestion and storage of data from various sources, ensuring the availability and accessibility of data for analytics and reporting purposes.
Utilize Azure DevOps and Teraform to implement and manage infrastructure as code, ensuring streamlined deployment and scalability of data engineering solutions.
Skills

snowflake

denodo

dbt cloud

fivetran

Qualifications

REQUIREMENTS

Proficiency in Snowflake and Denodo: Strong understanding and hands-on experience in working with Snowflake and Denodo for data integration, transformation, and analysis.
Knowledge of DBT Cloud: Familiarity with DBT Cloud, including experience in building and maintaining efficient data transformation workflows and deploying reliable data pipelines.
Experience with Fivetran: Demonstrated experience in utilizing Fivetran for data ingestion, source connectivity, and ensuring data accuracy and completeness.
Understanding of EnterpriseDataLake: Knowledge of EnterpriseDataLake principles and practices, including data ingestion, storage, and organization for analytics and reporting purposes.
Familiarity with Stonebranch: Proficiency in using Stonebranch for data orchestration and scheduling, ensuring efficient and reliable execution of data pipelines and workflows.
Proficiency in Azure DevOps and Teraform: Experience in leveraging Azure DevOps and Teraform for infrastructure as code, enabling streamlined deployment and scalability of data engineering solutions.

The expected pay rate range for this contract assignment is $90 to $130 per hour. The exact pay rate will vary based on skills, experience, and location. The position is approximately 65-70% remote and 30-35% travel to the client as needed.

#GigNowTechOpportunities

GigNowOpportunities

Equal Employment Opportunity Information
EY provides equal opportunities to applicants, employees, contractors, vendors, and stakeholders without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. If you are an individual with a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please email gignow.recruiting@ey.com.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,False
Lead Data Engineer,"Total Wine & More
","Boca Raton, FL",-1,3.1,"Lead Data Engineer


Total Wine & More is seeking a Lead Data Engineer with expertise in all aspects of data engineering, data management, and data analysis, to join our Data Services team in Bethesda, MD or Boca Raton, FL. We are embarking on a significant initiative to transform all aspects of data management services within Total Wine & More including enterprise data architecture, business intelligence, and data warehousing – leveraging the cloud to apply advanced analytics and data mining capabilities longer term. We are looking for an individual with experience in and who is passionate about data, data architecture, and data engineering to help execute the vision for data services at Total Wine & More. You will leverage advanced data engineering, cloud architecture, and programming skills to drive business value across all departments. You will work closely with the business, software development and support teams, infrastructure, and security staff and will enjoy learning and problem-solving in a fast-paced environment. You will report to the Principal Data Engineer.

You will:



In partnership with the Data Services leadership team, develop the vision for the next evolution of our Enterprise Data & Analytics Platform
Partner with Data Services product owners, data warehouse engineers, data scientists, and BI developers to support and deliver best-in-class reports, predictive models, datasets, and solutions
Create and manage batch and real time data pipelines
Manage and enhance our Kafka and Kubernetes implementations
Stay informed of new technologies and trends to guide the optimization of and continuous advancement of our platforms
Conduct exploratory data analysis to understand the patterns and potential business insights exhibited in the data
Be proactive and take ownership of the projects and tasks assigned
Coach junior team members and share knowledge with the broader team
Engage in implementing good security practices to handle sensitive information

You will have:



Bachelor's degree from four-year College or university in Computer Science, Technology, Business, or related field. Master’s or PhD preferred.
5+ years of experience in data engineering, data architecture, data warehousing or related fields
Proven track record in building impactful platforms and solutions using cloud-native tools
Experience using ETL/ELT tools – Airflow, Data Fusion, Dataprep, Informatica, Fivetran
Experience using Apache Kafka or Confluent Kafka or Google Pub/Sub
Experienced with general programing languages, such as Python, SQL, and SQL-like query languages for NoSQL databases
Experience using MapReduce or distributed computing technologies like PySpark, Apache Beam
Experience in leveraging the cloud in the development of data & analytics platforms
Familiarity with Dev-ops, Kubernetes, Docker
Experience with CI/CD including GitHub, Cloud Build, Jenkins
Passionate about data, data engineering, and platform development
Strong analytic skills, attention to detail, ability to multi-task, troubleshoot and problem solve along with the ability to make recommendations based on analysis are extremely important
Must possess excellent verbal, written, and presentation communication skills

We offer

Paid Time Off (PTO)
Generous store discounts
Health care plans (medical, prescription, dental, and vision)
401(k), HSA, FSA, Pretax commuter benefits
Disability & life insurance coverage
Paid parental leave
Pet insurance
Critical illness and accident insurance
Discounted home and auto insurance
College tuition assistance
Career development & product training
Consumer classes
& More!

Grow with us

Total Wine & More is the country's largest independent retailer of fine wine, beer and spirits, and we continue to grow our footprint year over year. Total Wine offers exciting and unique career opportunities across the country and in our corporate office. Our strength is our people. We have a commitment to training and career growth, all in an environment that values new ideas and teamwork. If you share our entrepreneurial spirit and a passion for providing best-in-class customer experience, take a moment to apply or learn more at www.TotalWine.com/About-Us/Careers!

Total Wine & More considers several factors when establishing compensation. Estimated salaries determined by third parties have not been validated by Total Wine & More. Total Wine & More is an equal opportunity employer and all qualified applicants will receive consideration for employment without discrimination based on race, color, religion, national origin, sex, sexual orientation, age, marital status, veteran status, disability, or any other characteristic protected by applicable law. Total Wine & More makes reasonable accommodations during all aspects of the employment process, including during the interview process. Total Wine & More is a Drug Free Workplace.

The information provided above indicates the general nature and level of work required of the position and is not a comprehensive list of all responsibilities or qualifications. Benefits list is only a highlight of some of the benefits offered to team members; eligibility for certain benefits apply.

About Total Wine & More

Total Wine & More is America‘s Wine Superstore®—the country‘s largest independent retailer of fine wine. We started in 1991 when brothers David and Robert Trone opened two wine stores in Delaware. Today, our typical store carries more than 8,000 wines from every wine-producing region in the world. In addition, Total Wine & More carries more than 2,500 beers, from America‘s most popular beers to hard-to-find microbrews and imports, and more than 3,000 different spirits from every price range and category.

Our strength is our people. We are always looking for motivated, talented team members who are interested in working for a company with entrepreneurial spirit and a passion for providing best-in-class service. Our retail stores and corporate office (called the Store Support Center) provide opportunities for career growth and advancement. Offering competitive compensation and comprehensive benefits for qualifying positions, we strive to ensure that all Team Members feel that they are a part of the business, as they are valuable resources to our customers, co-workers, and communities.",1991,Food & Beverage Stores,$5 to $10 billion (USD),Retail & Wholesale,5001 to 10000 Employees,Company - Private,False
Data Platform Engineer,"Availity, LLC.
","Jacksonville, FL",$79K - $109K (Glassdoor est.),4.4,"Availity delivers revenue cycle and related business solutions for health care professionals who want to build healthy, thriving organizations. Availity has the powerful tools, actionable insights and expansive network reach that medical businesses need to get an edge in an industry constantly redefined by change.
Availity is a Healthcare IT company headquartered in Jacksonville, FL. Availity is the nation’s largest health information network, connecting 2 million providers nationwide and processing more than 12 billion transactions a year, and growing! We work collaboratively with health plans and providers to disrupt an antiquated healthcare system by solving core issues in the way stakeholders communicate. Fixing the broken provider data management process and creating real time communication of risk and quality information are just two of the ways Availity is streamlining this process. Availity also offers providers, hospitals, and health systems revenue cycle and patient financial management solutions. We help prepare our providers for the rise in consumerism and value-based care, so that they can get paid accurately, and timely, for their services.
What you will be doing:
Writing Spark pipelines to ETL data within our data platform running on AWS.
Working closely with Data Analysts, Data Scientists, and business and technical teams to deliver secure, reliable, fault-tolerant, scalable, quality, and efficient outcomes.
Developing a scalable and resilient cloud data platform and scalable data pipelines.
Ensuring industry best practices around data pipelines, metadata management, data quality, data governance, and data privacy.
Building highly scalable AWS Infrastructure (from scratch or through 3rd party products) to enable Big Data Processing in the platform.
Requirements for this position:
Bachelor’s degree in Computer Engineering, Information Systems, Systems Engineering or a directly related field
3 years of experience as a data analyst or related occupation
3 years of experience must include 3 years of experience with each of the following: (1) development experience with big data technologies; (2) Spark and Scala; (3) Unit Testing; (4) AWS Services, including AWS EMR for big data processing; (5) SQL and relational database systems, including Oracle and SQL Server; and (6) Linux.
This is a 100% remote position and is subject to Availity LLC's employee referral program.
Why work at Availity:
Availity has recently been named a certified “Great Place to Work”! Culture is important to us and there are many ways for you to make your mark here!
We have several Diversity & Inclusion teams, a Young Professionals Group, a She Can Code IT group for women in tech, and various ways to engage with fellow Availity associates.
Availity is a culture of continuous learning. We have many resources and experts in our tech stack and in our industry that can help get you there too!
Want to work for an organization that gives back to the community? You’re at the right place! Availity partners with various organizations, both locally and nationally, to raise awareness, funds and morale as our staff members volunteer their time and funds to engage the organizations campaign.
Why you want to work on this team:
This is a highly intelligent and highly collaborative and dedicated team that works to ensure our companies most valuable data is being handled and transmitted properly.
This team has high visibility within the organization and works with various teams to ensure proper system function.
Next steps in process:
After you apply, you will receive text/email messages thanking you for applying and then you will continue to receive more text/email messages alerting you as to where you are in the recruitment process.
Availity is an equal opportunity employer and makes decisions in employment matters without regard to race, religious creed, color, age, sex, sexual orientation, gender identity, gender expression, genetic information, national origin, religion, marital status, medical condition, disability, military service, pregnancy, childbirth and related medical conditions, or any other classification protected by federal, state, and local laws and ordinances.

Availity is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.

NOTICE: Federal law requires all employers to verify the identity and employment eligibility of all persons hired to work in the United States. When required by state law or federal regulation, Availity uses I-9, Employment Eligibility Verification in conjunction with E-Verify to determine employment eligibility. Learn more about E-Verify at
http://www.dhs.gov/e-verify
.",2001,Information Technology Support Services,$100 to $500 million (USD),Information Technology,1001 to 5000 Employees,Company - Private,False
Operations and Data Analytics Engineer,"ARES Corporation
","Merritt Island, FL",$59K - $80K (Glassdoor est.),3.9,"Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.

If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.


Expectations

Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.


Minimum Requirements

Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.


Education and Relevant Work Experience

Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.


ARES offers a competitive compensation and benefit package. Full time employees may participate in:

Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays

ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.

ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.",1992,Aerospace & Defense,$100 to $500 million (USD),Aerospace & Defense,501 to 1000 Employees,Company - Private,True
Sr Data Engineer,"Voloridge Investment Management
","Jupiter, FL",$100K - $144K (Glassdoor est.),4.6,"At Voloridge Investment Management our quantitative systems are deeply dependent on vast quantities of data. The Senior Data Engineer must understand the many different and evolving use cases for data at Voloridge and design systems that supply high-performance datasets for advanced analytics. In this role the Sr. Data Engineer / Architect will provide mentorship and impart experience to the data engineering team.

Summary of Job Functions

Collaborate effectively with Stakeholders, Project Managers, Software Engineers, Data Analysts, QA Analysts, DBAs, and Data Engineers
Build and maintain data pipelines based on functional and non-functional requirements
Proactively seek out information and overcome obstacles to deliver projects efficiently
Ensure that data pipelines incorporate best practices related to performance, scaling, extensibility, fault tolerance, instrumentation, and maintainability
Ensure that data pipelines are kept simple and not overly engineered
Produce and maintain design and operational documentation
Analyze complex data problems and engineer elegant solutions
Stay abreast of emerging technologies and make relevant recommendations
Upgrade existing data models and pipelines leveraging newer features and techniques
Work in a Kanban environment
Mentor less experienced data engineers
Participate in engineering standards and best practices evolution
Participate in an on-call rotation
Lead investigations to troubleshoot pipeline issues

Minimum Requirements

10+ years with hands-on data engineering and deep knowledge of data architecture fundamentals including:
Extensive experience building ETL/ELT pipelines from a variety of data sources
Broad experience with SQL Server 2019+, including advanced SQL Server features such as Table Partitioning, Columnstore
Deep knowledge and measurable experience in performance tuning TSQL, execution plan analysis blocking/deadlock analysis and index optimization
Extensive experience using SSMS to create and maintain SQL Server tables, views, functions, stored procedures, and user-defined table types
Comprehensive experience with data modeling indexes, Temporal tables, CLR, and Service Broker
Deep understanding of the development of data pipelines with either SSIS or Python and building data pipelines using multiple external data sources and transport mechanisms
Strong initiative, collaboration, accountability, impartiality, and communication
Strong analytical skills, a real passion for working with data and strong interest in solving data problems
Strong track record for judging core requirements and meeting deadlines
Experience managing master data
Experience writing C#, PowerShell, and Python
Experience with Git source control integration with SSMS
Experience working in a Kanban SDLC and a strong understanding of traditional Kanban SDLC workflows
Experience with deploying changes through segregated Development, QA, UAT and Production SDLC stages
Experience owning mission-critical processes
Bachelor’s degree in Computer Science, Information Systems, or related disciplines
Ability to work onsite in our Jupiter, FL office

Preferred Skills and Previous Experience

Python programming using libraries such as Pandas, Numpy, csv, Traceback, JSON, PyODBC, Math
Experience with source code branching and pull requests / code reviews
Experience with AWS
Experience working with trading / financial / investment / accounting data
Experience with tools such as Red Gate, Grafana, OpsGenie and JAMS
Experience with MPP databases such as Greenplum
MS/PhD in Computer Science, Information Systems, or related disciplines

Compensation and Benefits

Highly competitive base salary
Profit sharing bonus
Health, dental, vision, life, and disability insurance
401K

Additional Information

Voloridge Investment Management is an SEC registered investment advisor. A private investment company founded in 2009, our mission is to deliver superior risk-adjusted returns for qualified investors, using advanced proprietary modeling technology, conservative investment tactics and sophisticated risk management.

Voloridge Investment Management is an Equal Opportunity Employer. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other legally protected characteristic or status.",2009,Investment & Asset Management,Unknown / Non-Applicable,Financial Services,51 to 200 Employees,Company - Private,False
Data Engineer II,"Boar's Head
","Sarasota, FL",$89K - $130K (Glassdoor est.),3.8,"Hiring Company:
Delicatessen Services Co., LLC
Overview:
A Boar’s Head Data Engineer II is a key analytical resource that is part of the Enterprise Applications team and is driven to identify, define, develop, and deliver innovative solutions that are in alignment with the organization's goals. As a Data Engineer II, you will enhance operations for analytics, reporting, applications, and data science by gathering and processing raw data at scale. Your focus will be on maintaining scalable, reliable, consistent, and repeatable systems that efficiently provide data for company-wide analytics and operations. A Data Engineer II must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.

The primary focus of the Data Engineer II role is centered on the development and support of the Boar’s Head Analytics Data Warehouse and associated technologies. Areas of focus and responsibilities include:

Create and maintain optimal data pipelines using current Boar’s Head streaming technologies (Kafka, Flink and Clickhouse)
Assisting with the designing, building, and maintaining of the infrastructure to support data storage, processing, and retrieval.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Assist business analytics teams with analytics tools (Tableau) that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders (Business and IT teams) to assist with data-related technical issues and support the data quality and infrastructure needs of the organization.
Support Business analytics teams by ensuring the availability of data and tools necessary to support organizational data analytics projects.
Work with data and analytics experts to strive for greater functionality in our data systems.
Job Description:
Essential Duties and Responsibilities
General Duties
Understands how to use technology to competitive advantage and to solve business issues – focusing on data streaming and analytics concepts and business-level functionality.
Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Develops and maintains a thorough understanding of business operations, identifying opportunities for operational efficiency through automation and effective utilization of reporting & and analytics tools critical for all business areas (e.g., Marketing, Sales, Distribution, Manufacturing, Finance, Human Resources).
Assists in technical delivery management and relationship management in identifying options for potential solutions and assessing them for both technical and business suitability.
Partners with knowledge management leads within Boar’s Head to ensure and maintain consistency on Standard Operating Procedures and formal Work Instructions that outline use of Data Governance and Analytics applications.
Work with data and analytics experts to strive for greater functionality in our data systems.
Supports roll outs of new and expanding applications/processes/projects.
Specific Duties
Create and maintain optimal data pipelines using current Boar’s Head streaming technologies (Kafka, Flink and Clickhouse)
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Adept at outlining the current state and designing conceptual/future state visual process level diagramming and documentation (in Visio and other more advanced visual modeling tools) that help articulate options to reduce costs, improve efficiencies, and effectiveness, and streamline execution while keeping quality norms in alignment.
Identifies, documents, and communicates current state of business process, partnering with Technical Delivery Managers, Data Engineers, and Developers to recommend future state options.
Provides process documentation (to include interaction points with other systems and/or applications).
Fosters understanding of software functions and limitations, usage scenarios, outlines error handling (system/human interaction points) and expected /necessary quantitative measures for success (e.g., expected performance targets, specific percentages for quality improvements)
Develops and executes thorough data validation unit and functional test plans to ensure data accuracy and integrity throughout data streams to the data warehouse.
Partners with QA teams in end-to-end systems testing and coordination of user acceptance testing strategy development and validation.
Project Management Support
Assists Technical Delivery Manager(s) in business strategy analysis and enhancement demand management and assists Project Manager (PM) in refining project plans/objectives for items responsible for delivering and executing according to best practice methodologies and IT process standards.
Assesses project requirements and works with PMs, resource managers, and others delegated as PMs to assess level of effort estimates.
Partners with the project manager to define change requests for missed requirements and scope change, helping maintain the right focus on defined project constraints (schedule, resources, and scope/quality).
Experience with Atlassian project management tools (JIRA, Confluence) is a significant plus
Communication
Demonstrates strong oral communication skills, including the ability to effectively interact with business partners and internal team members.
Demonstrates strong written communication skills, including the ability to produce clear and concise technical documentation.
Communicates technical concepts and issues to non-technical people.
Interacts with all levels of the company with patience, courtesy, diplomacy, and professionalism
Education and Experience
A Bachelor's degree in computer science, software engineering, information technology, or a related field.
A minimum of 4 years of experience in a Data Engineer (or equivalent) role to be considered; to include experience with data streaming, data wrangling, data modeling, and/or data analytics.
Technology and Desired Skills –
Experience and/or knowledge of Data Streaming technologies
Apache Kafka (or equivalent)
Apache Flink (or equivalent)
Clickhouse Columnar Databases (plus)
Experience with a variety of coding languages such as SQL, Python and/or R. Java Programming and SQL experience is necessary.
Experience with data integrity and validation techniques
Experience with Oracle EBS is a plus
Knowledge of Tableau (or equivalent) analytics tool is a plus
Ability to articulate business and technology needs/constraints to IT members and end users alike.
Self-starter, motivated, and having a proactive and strategic mindset are a must.
Strong written and verbal communication skills
Strong collaboration and coalition-building skills
Hands-on experience and proficiency with the full Microsoft Office Suite, Microsoft Visio, and SmartDraw is a plus.
Physical Demands & Work Environment
This position requires working in an office environment.
Occasional travel may be required.
This is primarily a first shift position but adjustments to shift start/end times may be required depending on future production support schedules.
Availability for on-call during non-business hours is required.
After-hours and weekend work is intermittently required for system troubleshooting, maintenance, and upgrades.
Location:
Sarasota, FL
Time Type:
Full time
Department:
Management Information Systems",1905,Food & Beverage Manufacturing,$500 million to $1 billion (USD),Manufacturing,1001 to 5000 Employees,Company - Private,False
DATA PLATFORM ENGINEER,"Swisher International
","Miami, FL",-1,3.8,"Swisher is a leading lifestyle brand for adult consumers headquartered in Jacksonville, Florida. Our superior customer relationships, innovative thinking, and action have driven the company to grow and adapt for 160 years. The legendary company we are today is a result of our unrelenting drive to shape the experiences of tomorrow.

As we shape the future, we are looking for people to continue to build on our history of pushing boundaries, shattering expectations, and evolving to solidify connections with adult consumers. In pursuing our mission, we require a passionate team of diverse backgrounds, viewpoints, and ideas. Our strong brand heritage provides our employees with challenging and rewarding careers, along with real growth opportunities.

Position Overview
As the Data Platform Engineer, you will be responsible for designing, building, testing, and maintaining cloud-native data pipelines to support various analytics algorithms. You will optimize systems for data collection, storage, access, and analytics. You will create data pipelines that convert raw data into formats that are available and accessible to stakeholders.

The Role



Develop and maintain databases by acquiring data from primary and secondary sources and build scripts that will make our data evaluation process more flexible or scalable across data sets.
Design, build, and manage data pipelines to support data and analytics needs in the organization.
Implement data warehousing solutions using a range of methodologies including – but not limited to – Inmon, Kimball, and Medallion methodologies.
Utilize Azure Databricks and Azure Synapse to manage and transform data
Utilize SQL databases, understanding the best cases for their use and how to optimize performance.
Facilitate the inclusion of multiple disparate data sources located in the data platform/data warehouse into the overall reporting framework.
Collaborate with Principal Solutions Architects to ensure the data platform design/process is optimally aligned with overall architecture to enhance the ‘end-user experience.’
Collaborate on project teams, systems and data analysis, design, development, integration, and enhancement activities, as well as related maintenance and more complex production support
Assist in the development of project scopes for multiple complex projects in collaboration with the project team and serves as a project point of contact when necessary
Provide architectural ownership, governance control, and solution management across all reporting initiatives.

The Experience Needed



5 Years experience as a Data Engineer or similar role.
Experience designing, building, and maintaining efficient, reusable, and reliable data marts using Microsoft SQL Server and Azure.
Experience with data and analytics experts to strive for greater functionality in our data systems.
Experience developing and implementing data standards, protocols, and procedures for effective data management and quality.
Experience monitoring data performance and modifying infrastructure requirements
Experience with data pipeline and workflow management tools
Ability to build effective partnerships with coworkers and coordinate overall efforts to contribute to the team, department, and organizational objectives
Knowledge of understanding and implementing security and data privacy settings and standards
Ability to optimize data delivery and re-design infrastructure for greater scalability
Ability to with data scientists and architects on multiple, concurrent projects
Strong analytical skills and problem-solving aptitude
High School diploma or equivalent
Must be located in the US and able to travel to corporate office quarterly

The Preferred Experience

Bachelor's Degree required in Computer Science, Information Systems, or related field
Working industry experience with Big Data systems and projects
Experience in building large-scale distributed systems in a product environment
Experience in writing, analyzing, and debugging SQL queries
Experience in data privacy and security-related projects
Certification in one or more of the following:
Generative AI,
Project Leadership &
IT Strategy
Data Engineering Foundations
Statistics Foundations

What we offer

Great benefits package, including a full suite of health benefits, a generous 401(k) Plan, paid parental leave, a strong rewards and recognition program, and a focus on mental health and well-being.
An inclusive environment with Employee Resource Groups to join and volunteer opportunities.
A Hybrid work schedule.
Professional growth and development programs to help advance your career.
Challenging environment with big goals and the opportunity to make a significant impact.



#MON",1861,Consumer Product Manufacturing,$1 to $5 billion (USD),Manufacturing,501 to 1000 Employees,Company - Private,False
Data Management Engineer/SAS Developer,"FCCI Insurance
","Sarasota, FL",$73K - $101K (Glassdoor est.),3.9,"As an FCCI Systems Developer/Data Engineer, you will have the opportunity to work with a great team providing data security, retention and governance across our IT platform. Produce secured, documented, high quality applications software in support of FCCI’s various business needs. Support the Data Warehouse ETL, BI reporting, data analytics and financial applications utilizing available & emerging technologies, (such as our current SAS & Cognos applications). This role will configure applications to meet NAIC model security regulations for data retention and anonymization, as well as supporting our migration to data lakes/lakehouse. Working in an Agile development environment, you will enjoy collaborating with our business & technical leaders using your leadership, business intelligence, data warehouse and system development skills.

A commitment to collaborative problem solving, sophisticated design, and delivering a quality product is essential. As part of our collaborative culture, the selected individual will provide on call support on a rotational basis to applications as necessary. This position will be located in one of the following: Sarasota, FL corporate office campus, Lake Mary, FL, Lawrenceville, GA, or our Richardson, TX office. FCCI provides the opportunity to work a hybrid work schedule of 3 days in the office and 2 days remote.

In exchange for your talents, FCCI offers competitive salaries and an excellent benefits package.

FCCI values the contributions of a diverse workforce.

We're committed to being fair and equitable to all employees and applicants for employment. FCCI prohibits discrimination on the basis of race, color, sex, age, marital status, religion, national origin, sexual orientation, handicap, disability and other legally protected classifications.

Please apply via our website at www.fcci-group.com.




Qualifications

Experience

Required

* Bachelors or better in Computer Science or related field.
* Two or more years of experience enhancing and supporting the Data Warehouse batch processing using SAS (as well as SAS EG, SAS Macros and SQL programming language.
* Two or more years working on ETL & BI reporting
* Advanced understanding of Data Warehousing concepts & governance, how data processes through systems from internal and external sources.
* Experience working within an Agile methodologies environment

Preferred

* Cognos experience and Solix Data Management is a plus",1959,Insurance Carriers,$500 million to $1 billion (USD),Insurance,501 to 1000 Employees,Company - Private,False
Data Engineer,"Noggin
","Fort Lauderdale, FL",$86K - $120K (Employer est.),3.9,"We are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.
Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data.
Able to break down and communicate highly complex data problems into simple, feasible solutions.
Extract patterns from large datasets and transform data into an informational advantage.
Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations.
Partner with the internal product and business intelligence teams to determine the best approaches around data ingestion, structure, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately.
Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes.
Ongoing development of technical solutions while developing and maintaining documentation, at times training impacted teams.
Early on, collaborate with the team on internal initiatives to create strategies that improve company processes.

BASIC QUALIFICATIONS:
STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations.
Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)
Proficient in Python and SQL.
Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis
Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc.
Strong problem-solving and creative-thinking skills.
Ability to break down and communicate highly complex data problems as simple, feasible solutions
Demonstrated development of ongoing technical solutions while developing and maintaining documentation, at times training impacted teams.
Experience developing solutions to business requirements via hands-on discovery and exploration of data.
Robust written and verbal communication skills, including the ability to communicate technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions
Experience building and deploying applications on a cloud platform (Google Cloud Platform preferred)

ADDITIONAL QUALIFICATIONS:
Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus.
Experience with Apache Airflow is a plus.
Familiarity with Data Modeling.
Familiar with GIT.
Can perform statistical analyses using tools such as R, Numpy/SciPy with Python
Experience with Adobe Analytics (Omniture) or Google Analytics.
Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising.
Familiarity with ELT/ETL concepts.
#LI-FV 38443

Join the Paramount Streaming Talent Community ! Get the inside scoop on life at Paramount Streaming and about career opportunities.

Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.

ADDITIONAL INFORMATION

Hiring Salary Range: $85,600-$120,000.

The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.

https://www.paramount.com/careers/benefits

Paramount is an equal opportunity employer (EOE) including disability/vet.

At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.

If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",2019,Film Production,$10+ billion (USD),Media & Communication,10000+ Employees,Company - Public,False
ETL Data Engineer IV,"Southeastern Grocers
","Jacksonville, FL",$99K - $131K (Glassdoor est.),3.7,"Overview:
Southeastern Grocers is committed to a culture of belonging and fostering an inclusive environment where we celebrate differences. As a great place to work, we empower everyone to be their full, authentic selves. Read our Belonging, Inclusion and Diversity Statement here.

Data Engineer IV

Job Purpose

The Senior ETL Data Engineer will assist in being a BI Evangelist, business leaders often ask what can we do to help them share information, Analysis or KPI’s to a team or business unit. Reviewing the benefits of Enterprise BI and the data we gather have been able to focus on Single Source of Truth. The Senior ETL Data Engineer will also be the primary contact for PM updates on Capital Projects, ensure the Project BRD and Architecture are followed and assist in on time project delivery. Strong knowledge of Analytic tools and ETL, ELT tools. Knowledge of SaaS, PaaS and Cloud DB’s like Snowflake or Azure.

Essential Responsibilities

Responsibility

% Of Time

Works with business partners to represent the BI/EDW team on projects that my require Analytics and Data Integration. Validates the data sources and rules and ensures the Architecture is appropriate and doable. Collaborates with the PM or PMO to agree on deliverables and dates, and keeps the communications flowing between BI/EDW Shared Service partners, Business Partners and Directors. Must have a deep understanding of Data Standardization, Data Warehousing and Analytics.

35%

Once resources are assigned to a Cap project, ensure they are fully utilized and engaged in decisions which can impact delivery precision.

15%

Partners with ETL Architect to build and maintain a 5 yr ETL/ELT Road Map for Analytics/Data Integration.

10%

Participates in problem solving that may impact performance. Includes the Servers and the Applications being used in Data Integration suite. Escalates issues with vendors and follows through with root cause analysis and problem resolution.

15%

Participate in the 24x7 Support tasks to ensure problem closure. Ensure testing has been done. Model data/analytics using SQL and appropriate tools to ensure data integrity. Ensure BI data sources are available to Compass and liaison with them to prevent duplication of efforts. Work with business partners to ensure Data is defined properly from source to target. Guide the team in best practices with training efforts and testing efforts for BI/EDW team.

20%

Disclaimer

Performs other job-related duties as assigned.

Qualifications

Required Education

Required Education

Course of Study

Bachelor’s Degree

Information Technology or related field

Preferred Education

Preferred Education

Course of Study

Master’s Degree

Information Technology or related field

Relevant Experience

Relevant Experience

Supervisory Experience

8+ years

1-5

Language Requirements

Language(s) Required

Language(s) Preferred

English

English & Spanish

Knowledge, Skills & Abilities Required


Leadership skills, technical skills and a wide vision of what may be needed to solve a problem from the business.
Data doesn’t yield answers, so applying the correct tools to accomplish business requests.
A strong knowledge of ETL products to effectively guide the company solution.
Strong knowledge of SDLC, PMI and Scrum.
Master of BI Technology products like Datastage and Data Factory. Strong Data Warehousing experience.

Knowledge, Skills & Abilities Preferred


Leadership skills, technical skills and a wide vision of what may be needed to solve a problem from the business.
Must have a strong knowledge of Data Integration products to effectively implement and apply the company solutions.
Work to evangelize data governance standards and best practices.
Help with the administration of the Datastage or ETL environments.

Environmental Factors

Department

Information Technology

Environmental Factors

SSC Light: Physical Demands: While performing the essential functions of this position, the associate is regularly required to sit, use hands or fingers to handle, hold or feel objects, tools or controls, talk, see, hear and perform repetitive movements with both hands. The employee is occasionally required to stand or walk on carpet, tile or concrete Working Conditions: Majority of the time will be spent indoors in a traditional office environment. Safety Risk Factors: The employee is rarely required to twist back and/or neck and walk on a slippery or cluttered floor surface. Overall Required Equipment a personal computer, telephone, printer, copy machine, fax machine and other general office supplies and equipment. Pulling Requirement 20 lbs. Lifting Requirement 20 lbs.

Location and Travel Requirements

Location

SEG Technology Center-Hybrid

Travel Percent, Overnight & Motus

Travel Percent

Overnight

Motus Eligible

20%

No

No

Addendum

May participate in the 24x7 Support tasks to ensure problem closure and ensure testing has been done.",2015,Grocery Stores,Unknown / Non-Applicable,Retail & Wholesale,10000+ Employees,Company - Private,False
Data Engineer,"Lennar Homes
","Miami, FL",$84K - $126K (Glassdoor est.),3.6,"Overview:
Lennar is seeking a Data Engineer to support our marketing and digital analytics initiatives. Lennar is poised to revolutionize home buying by bringing it online, improving customer experience, and driving business growth. The ideal candidate is an experienced, strategic data engineer with deep experience in data ingestion, data modeling, and monitoring/alerting. They’re excited about the opportunity to build a world-class data infrastructure and enabling analysts.
Responsibilities:

Principal Duties and Responsibilities:

Ingest, analyze, and organize raw data into easy-to-use data sets for analysts, data scientists, and machine learners
Build data systems and pipelines leveraging dbt, Snowflake, and Prefect
Conduct complex data analysis and report on results
Prepare data for prescriptive and predictive modeling
Build algorithms and prototypes
Combine raw information from different sources
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition
Collaborate with data scientists and architects on several projects
Qualifications:

Education and Experience Requirements:

Bachelor’s degree or higher in Statistics, Economics, Math, Computer Science, or a related analytical field with equivalent experience.
5+ years in Data Engineering
Excellent problem-solving and analytical skills
Proactive, not reactive, with the ability to work independently in a fast-paced environment
Ability to take in loose requirements and produce scalable and reliable data infrastructure
Confident in learning new tools, technologies, and methodologies
Expertise with DBT, Snowflake, Funnel, and Prefect
Designs, builds, and monitors key data pipelines from end to end

Physical Requirements:


This is primarily a sedentary office position which requires the incumbent to have the ability to operate computer equipment, speak, hear, bend, stoop, reach, lift, and move and carry up to 25 lbs. Finger dexterity is necessary.




This description outlines the basic responsibilities and requirements for the position noted. This is not a comprehensive listing of all job duties of the Associates. Duties, responsibilities and activities may change at any time with or without notice.

Type: Regular Full-Time",1954,Real Estate,$5 to $10 billion (USD),Real Estate,5001 to 10000 Employees,Company - Public,False
Data Science Engineer,"AI Cyber Solutions
","Tampa, FL",$89K - $128K (Glassdoor est.),4.5,"Job Description

AI Cyber Solutions is looking for an enthusiastic data science engineer to take and-to-end responsibility for processing systems and large-scale databases. The candidate would be involved in developing and designing architectures and AI or ML services. Besides, you’d also test and maintain the databases and systems. As a part of your role, you may have to clean and wrangle raw data to keep it readily available for analysis.

Skills Required
Python, Linux OS, Pandas, Scikit-learn, and other machine learning libraries
Experience in deep learning on NLP/NLU is a big plus
Solid understanding of mathematical underpinnings behind Machine Learning algorithms such as Probability, Statistics, Linear Algebra.
Strong Understanding of ML concepts – Probabilistic Models, Supervised and Unsupervised Learning, Neural Networks, Support Vector Machines
Has hands-on knowledge on setting up Docker containerization and running application on ECS,EKS
Very good exposure in setting up Analytical tools such as RStudio, MLFLOW, Databricks, Jupyter etc.
Bachelors/Masters in Computer Science, Engineering, Statistic/Mathematics or relevant field; graduate degree in Data Science or another quantitative field is preferred
Tasks to be Performed

Work with deep data and analytics skills with strong business acumen to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results.


Experience using statistical computer languages R, Python, SLQ, NoSQL databases etc. to manipulate data and draw insights from large data sets


Build topic analysis, text classification, named entity recognition methods for unstructured and semi-structured data


Experience with Python ML libraries; Apache Spark and Kafka.


Proficiency in machine learning techniques and data mining algorithms such as Regression, Clustering, Classification, Decision trees, KNN and SVM


Ability to design algorithmic implementation for performing real-time and scalable learning machines


Knowledge of open source machine learning libraries like scikit-learn, TensorFlow, NLP tool as NLTK


Demonstrate and Document working prototype on test datasets and real-world scenarios.

Demonstrate and Document working prototypes on test datasets and real-world scenarios.


You’ll utilize the latest techniques in AI, ML (including Deep Learning approaches) and NLU


Build topic analysis, text classification, named entity recognition methods for unstructured and semi-structured data


Develop and perform text classification using methods such as logistic regression, decision trees, SVM and maximum entropy classifiers


Perform text mining, generate and test working hypotheses, prepare and analyze historical data and identify patterns


Generate creative solutions (patents) and publish research results in top conferences (papers)


Design and develop AI/ML services on the platform


Design and Develop customer use cases and applications


Innovate to come up with new solutions and improve existing solutions.


Be an enthusiastic and motivated member of the team.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,False
Data Engineer,"Quiet Professionals LLC
","Tampa, FL",$81K - $123K (Glassdoor est.),4.5,"Job Title: Data Engineer

Experience Level: Senior

Location: Tampa

Clearance: TS/SCI


Quiet Professionals, LLC is seeking a Data Engineer who will build and maintain data systems and construct datasets that are easy to analyze and support customer requirements. Implement methods to improve data reliability and quality. Combine raw information from different sources to create consistent and machine-readable formats. Develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling. Develop and deploy Application Programming Interfaces (API) to expose IDST maintained data to the enterprise.

Upon contract award.


Duties & Responsibilities:

Acquire and assemble large, complex datasets that align with USSOCOM enterprise requirements
Building, testing, and maintaining data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using modern data technologies
Develop analytics tools and transformative algorithms for data to provide actionable insights into customer processes, operational efficiency and other key business performance metrics
Create new data validation methods for analytics and data scientist team members that assist them in building and optimizing products to fulfill customer objectives
Work with IDST stakeholders including USSOCOM leadership, customers, and design teams to assist with data-related technical issues and support their data infrastructure needs
Analyze procedures for USSOCOM data separation, access, and security across users and the enterprise data architecture
Work with IDST data and analytics experts to strive for greater functionality in our data systems and capability integration
Create and maintain optimal data pipeline architecture and support associated process improvements for automating manual processes, data delivery, and infrastructure re-design for scalability

Requirements:

Possess a minimum of a bachelor's degree in computer science, IT, or similar field.
8 years’ experience as a data engineer or in a similar role.
Demonstrated experience employing data models, data mining, and segmentation techniques.
Demonstrated experience developing, deploying and/or maintaining enterprise level data solutions
Experience with SQL database design • Data engineering certification is a plus Current DoD Top Secret clearance and eligible for SCI access and ACCM read-on
Python, SQL, noSQL, Cypher, POSTGRES


Preferred:

SQLAlchemy, Flask, Swagger, JavaScript, Spark, Hadoop, Kafka, Hive, R, storm, Matlab, Neo4J, MongoDB


Quiet Professionals, LLC, (QP) is an independently owned and operated CVE-Certified Service-Disabled Veteran Owned Small Business (SDVOSB) with headquarters located in Tampa, Florida. Our goal is to provide innovative and sustainable solutions that improve the operational effectiveness of our clients and partners. We have extensive knowledge and experience in a variety of areas involving Military Support, Intelligence, Information Technology and Security Operations. QP is committed to providing high quality services appropriate to the level of experience and expertise required in analyzing, planning, advising, and conducting operations on a global scale.

Fostering a diverse and inclusive culture is at the heart of what we do at Quiet Professionals, LLC. We want everyone to bring their true selves to work and be inspired to be innovative and results oriented. That is why we strive to always recruit, retain, and promote a diverse mix of people who can contribute to our culture rather than fit into it. We recognize that the work we do internally has a significant impact on the work we do externally, so we must constantly inspire great ideas and new paths forward from every member of our team in order to be successful. We can provide our clients with everything they require thanks to each person's superior skills and proven performance.",2013,Aerospace & Defense,$5 to $25 million (USD),Aerospace & Defense,201 to 500 Employees,Company - Private,True
Data Engineer- AVP - Tampa - Hybrid (HM),"Citi
","Tampa, FL",$97K - $145K (Employer est.),3.9,"The Role

The Data Engineer is accountable for developing high quality data products to support the Bank’s regulatory requirements and data driven decision making. A Data Engineer will serve as an example to other team members, work closely with customers, and remove or escalate roadblocks. By applying their knowledge of data architecture standards, data warehousing, data structures, and business intelligence they will contribute to business outcomes on an agile team.

Responsibilities

Designing, developing and supporting scalable, extensible, and highly available data solutions
Deliver on critical business priorities while ensuring alignment with the wider architectural vision
Identify and help address potential risks in the data supply chain
Follow and contribute to technical standards
Design and develop analytical data models

Required Qualifications

3+ years’ experience of implementing data-intensive solutions using agile methodologies
Proficient in one or more programming languages commonly used in data engineering such as Python, Java or Scala
Proficiency in working with relational databases and of using SQL for data querying, transformation and manipulation
Experience of modelling data for analytical consumers
Ability to automate and streamline the build, test and deployment of data pipelines
Excellent communication and problem-solving skills

Preferred Qualifications

Prior experience of Ab Initio is a strong plus and will be given special consideration. Appreciation of data parallelism, associated partitioning strategies and an understanding of key components in the GDE is particularly relevant
Familiarity with open-source data engineering tools and frameworks (e.g. Spark, Kafka, Beam, Flink, Trino, Airflow, DBT) is a valuable asset
Experience in cloud native technologies and patterns (AWS, Google Cloud)
Experience with Hadoop for data storage and processing is valuable, as is exposure to modern data platforms such as Snowflake and Databricks

Education:

Bachelor’s degree/University degree or equivalent experience


This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

-

Job Family Group:

Technology

-

Job Family:

Applications Development

-

Time Type:

Full time

-

Primary Location:

Tampa Florida United States

-

Primary Location Salary Range:

$96,960.00 - $145,440.00

-

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting",1812,Investment & Asset Management,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
Data Center Network Engineer,"Parrish Medical Center
","Titusville, FL",$66K - $94K (Glassdoor est.),2.7,"Department:
Information Systems/IT

Schedule/Status:
Varies; 8:00am-4:30pm

Standard Hours/Week:
40

Location:
Titusville

General Description:
The Network Engineer – Data Center is responsible for demonstrating Parrish Healthcare’s Culture of Choice®, designing, implementing, and managing the network infrastructure of the data centers. The Network Engineer – Data Center will ensure the data center's design structure and network is secure, reliable, and efficient, and they work closely with other IT professionals to meet the organization's networking needs. The position shall exemplify the desired Culture of Choice® and philosophies of Parrish Healthcare.

Key Responsibilities:

Specify, configure, maintain, monitor, and troubleshoot local area network hardware and software, such as routers, switches, cabling, firewalls, security appliances, wireless access points, circuits, and Internet service.
Maintain excellent network performance by performing regular network monitoring and performance tuning; escalate problems to vendors as needed.
Provide proactive network support, including daily review of device and security logs, assisting with traffic monitoring, intrusion protection systems, and support for data center environment monitoring.
Establish and maintain network user accounts, user environments, directories, security, and connectivity.
Maintain a secure network by developing access standards, structure and develop processes to monitor usage.
Investigate, test, and perform software upgrades, install patches, hot-fixes, versioning, and virus definitions updates.
Prepare staff for network related changes using a variety of tools including references, training programs, and in-person support.
Provide technical support and advice as necessary for all departments and outside agencies, including researching, evaluating, and recommending new technologies.
Provide project management support for network/infrastructure projects.
Create documentation of procedures in a format that will assist other staff in carrying out those procedures.
Communicate with vendors and external support resources to research products, new technologies, and deployment of new technologies.
Maintain up-to-date skills and awareness of new and emerging network-based technologies and how they may apply to our infrastructure to support our long-term goals.
Knows fire, disaster and safety procedures and regulations as it pertains to the work area.
Performs similar or related duties as assigned.
Requirements:

Formal Education:

Bachelor’s degree in computer science, information technology, computer engineering or a related field is required (A combination of experience and certifications may be considered).
Work Experience:

5 to 7 years of systems or network engineering experience
Required Licenses, Certifications, Registrations:

1 of the following are required within one (1) year of employment:
Cisco Certified Network Associate (CCNA),
Cisco Certified Network Professional - Collaboration (CCNP – Datacenter) certification required.
Cisco Certified Internetwork Expert – Data Center (CCIE – Data Center),
Training or Certification in Dell, EMC,
Fortinet highly preferred.",1958,Health Care Services & Hospitals,Less than $1 million (USD),Healthcare,1001 to 5000 Employees,Hospital,False
Senior Data Integration Engineer - Remote,"Healthe systems
","Tampa, FL",$98K - $135K (Employer est.),4.2,"Healthesystems offers workplace flexibility with our Work-From-Home model, and a competitive compensation and benefits package including healthcare coverage, PTO, paid holidays, 401(k), company-provided life insurance/disability coverage, wellness options, and more.

Note: we are unable to hire in every state

Summary: Responsible for the analysis, design, documentation, development, unit testing, and support of Data Integration and database objects development for software applications. Provides support and guidance regarding Data Integration and T-SQL best practices and development standards. Promotes approved agile methodologies, leading the design and development efforts for the agile team. Actively coaches, guides, and mentors team members in providing valuable solutions to our customer.

Key Responsibilities: “To simplify complexities for each customer.”

Collaborates with stakeholders and development team members to achieve business results.
Work closely with other engineers to integrate databases with other applications.
Leads the design, development, and implementation of database applications and solutions for managing and integrating data between operational systems, data repositories, and reporting and analytical applications. This includes but is not limited to ETL, stored procedures, views, and functions.
Recommends and provide guidance regarding Data Integration and database development, T-SQL best practices, and standards to the development team members as needed.
Create and propose technical design documentation which includes current and future functionality, database objects affected, specifications, and flows/diagrams to detail the proposed database and/or Data Integration implementation.
Has a deep understanding of the business processes and the technology platform that enables it.
Translates stakeholder’s requirements into common language that can be adopted for the use with Behavior Driven Development (BDD) or Test Driven Development (TDD).
Participates in industry and other professional networks to ensure awareness of industry standards, trends and best practices in order to strengthen organizational and technical knowledge.
Provides support for investigating and troubleshooting production issues.
Promotes the establishment of group standards and processes. Participates in the Communities of Practice.
Works continually on improving performance of source code using industry standard methodologies.
Helps drive technology direction and choices of technologies by making recommendations based on experience and research.



Qualifications/Education/Certifications:

Bachelor's degree from four-year college or university (in Information Technology or Computer Science preferred), plus five to eight years related experience and/or training; or equivalent combination of education and experience.

Knowledge, Skills and Abilities:

Prefer experience in Healthcare, PBM and/or ABM, workers’ compensation and/or insurance industry.

Required experience:
5+ years SQL Server 2008/2014
5+ years Data Integration technologies and principles
Advanced knowledge of T-SQL including complex SQL queries (ex: using various joins and sub-queries) and best practices
Advanced knowledge of index design and T-SQL performance tuning techniques
Advanced experience integrating data from structured and unstructured formats: flat files, XML, EDI, JSON, EXCEL
Advanced knowledge and experience in online transactional (OLTP) processing and analytical processing (OLAP) databases and schemas
Advanced knowledge of Data Warehousing methodologies and concepts
Experience with TDD / BDD
The following knowledge is not required, but is preferred:
Experience with BI Tools is a plus
Basic understanding of object oriented programming
Experience in distributed architectures such as Microservices, SOA, and RESTful APIs
Continuous Integration
Cucumber, Gherkin
Jira
Agile Competency Requirements:
Requires an understanding of the application of Agile development methodology.
Must be comfortable with change, close collaboration, and have conflict resolution skills.
Knowledge of or willingness to learn Agile / DevOps values.
Takes initiative and are passionate about what they do.
Adaption, Ability & Desire to Learn, Team Oriented - tolerance & helpful, and Quality Focus

Physical Demands/Working Conditions:

Duties are performed primarily in a home office setting utilizing computer equipment. Travel to attend meetings and visit locations throughout the country may be required. While performing the duties of this job, the employee is regularly required to sit and talk or hear. The employee is frequently required to use hands. The employee is occasionally required to stand and walk.*** Job descriptions will be reviewed and are subject to changes of business necessity. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Pay is based on several factors including but not limited to education, work experience, certifications, geographical cost of labor, etc. In addition to base pay, Healthesystems offers a comprehensive benefits package including, health, dental, vision, disability and life insurance, wellness resources, recognition programs, 401k contribution, and PTO & Holiday pay (all subject to eligibility requirements). Applicable statutory benefits also provided. https://healthesystems.com/careers/

Anticipated Starting Pay Range
$98,100—$135,000 USD

To facilitate working from home, and as a requirement for this role, candidates must provide their own reliable, high speed internet access with sufficient bandwidth to execute all job functions. Company laptop will be provided.",2002,Information Technology Support Services,$100 to $500 million (USD),Information Technology,201 to 500 Employees,Company - Private,False
Lead Data Engineer - USA,Pelico,"Miami, FL",$112K - $168K (Glassdoor est.),-1.0,"After becoming a leader in the European market with logos like Cartier, Safran and Arcelor Mittal, Pelico is now expanding its operations on the US market. This is an opportunity to join the company at a critical moment of its growth.

As a Lead Data Engineer, you will play a pivotal role in overseeing and developing our team dedicated to data integration of our clients for US territory.

You will be responsible for leading but also contributing in the structure of data integration activities of our clients, by defining data pipelines architectures, automatisation process and make our Software & Data Engineering team grow.

As a Lead Data Engineer, you will play a pivotal role in overseeing and developing our team dedicated to data integration of our clients for US territory.

You will be responsible for leading but also contributing in the structure of data integration activities of our clients, by defining data pipelines architectures, automatisation process and make our Software & Data Engineering team grow.

What you’ll do & learn

Plan, coordinate, and manage software and data integration projects, ensuring adherence to timelines and budgets agreed with the clients
Work closely with other departments to understand business needs and translate them into technical solutions.
Oversee the development, maintenance, and updating of practice, ensuring compliance with quality and security standards.
Establish rigorous testing processes to ensure application stability.
Supervise data collection, storage, quality, and security.
Collaborate with the Customer Operations team to extract valuable insights from data.
Efficiency through Standardization: Standardize processes across the organization. Reduces the risk of errors, improves consistency, and streamlines operations.
Optimization: Regularly assess processes, gather feedback from team members, and implement improvements to respond to changing needs.
Data-Driven Decision-Making: Utilize data and analytics to provide objective guidance to obtain the most significant impact
Alignment with customers to embrace a perfect data integration: Tailor your interactions and services to each customer's preferences and needs using data and insights to personalized experiences.
Embrace multiple channels to communicate with customers effectively.
Implement systems and processes to proactively identify and resolve issues before they impact the data integration experience.
Stay updated with relevant technological trends and advancements for the team.
Design, develop, maintain and evolve the data stack to answer both business and product needs (especially back end features within the platform)
Build data pipelines and configure the platform (incl. algorithms) to on-board new customers


What you embody

At least 7 years of Data engineering experience, ideally in a SAAS environment
You are mastering on Python Javascript, C++, Kotlin, You-name-it… but note that we hire based on engineering fundamentals rather than familiarity with specific technologies
Experience in building data-rich products or complex data pipelines (professional or personal projects) or working with data (data transformation & event driven pipeline)
SQL expert
Bilingual English mandatory (verbal & written), other language is a plus
Proactive, Autonomous, results oriented and you excel in stimulating environments
Willingness to create impact for customers and see the product in the hand of happy users
Team player and comfortable working with others
Comfortable in client facing if needed
Miami based or willingness to relocate

Technical Stack

Services :

GraphQL
PostgreSQL
Redis
RabbitMQ
ElasticSearch
InfluxDB

Processes Management :

Airflow (ETLs, managment batchs)
Gitlab CI / CD

Security :

Yubikeys
Keeper passwords
Gsuite SSO

Pelico promotes inclusion and non-discrimination, and acts daily in favour of social mix, gender equality, senior citizens & disability


What we offer

Join an exciting adventure with a lot of challenges at all levels!

Work on a highly impactful product that users love!
Office location in Miami - Florida
Stock Options
20 annual paid leaves + 10 bank holidays
Remote flexibility
Healthcare Insurance with dental & vision
401 K
Team events every quarter",2019,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,1 to 50 Employees,Company - Private,False
AWS Data Engineer(USC/GC Only),"Apolis
","Juno Beach, FL",$60.00 - $72.00 Per Hour (Employer est.),4.0,"AWS Glue Engineer

Hybrid in Juno Beach - FL (2 weeks onsite in given month)

Contract

Role and Responsibilities

3+ years of experience on AWS Glue development.
Experience in building ETL ingestion frameworks using AWS Glue.
Strong hands-on experience in native AWS Glue ETLengineering, operationalization, automation build-out, integration with other native AWS services like S3, RDS, RedShift & Lambda
Design, build and launch new data extraction, transformation and loading processes.
Estimate and optimize the AWS Glue jobs based on cost.
Strong SQL, ETL/ELT knowledge.
Experience in complex database objects to move the changed data across multiple environments.
Deploy Glue jobs using CFT templates.
Work with data scheduling team (Control M) to schedule the Glue jobs.
Focus on reliability, performance, and adherence to best practices.

Skillset:

Required Skills: AWS Glue, Postgres, RDS, RedShift, Lambda and Python/ Pyspark

Job Type: Contract

Salary: $60.00 - $72.00 per hour

Ability to commute/relocate:

Juno Beach, FL 33408: Reliably commute or planning to relocate before starting work (Required)

Experience:

ETL: 1 year (Preferred)
SQL: 1 year (Preferred)
AWS GLUE: 2 years (Required)
Redshift: 1 year (Preferred)
Python/Pyspark: 1 year (Preferred)

Work Location: In person",1996,Information Technology Support Services,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,True
"Jr. Engineer, Data Scientist","Advanced Technology and Research Corporation
","Fort Lauderdale, FL",$95K - $110K (Employer est.),3.5,"Salary Range: $95,000-$110,000 USD per year

Advanced Technology & Research Corporation (www.atrcorp.com) is seeking to fill the following full-time permanent position. Based in Maryland and incorporated in 1973, ATR is an equal-opportunity engineering company with a solid reputation in various engineering disciplines for the government and Fortune 500 commercial customers.

Salary for the position is competitive according to qualifications. ATR offers an attractive comprehensive benefits package, including Medical/Dental insurances, free basic life/ADD, and long-term and short-term disability insurances, 401(k) plan, educational assistance program, and paid time off.

All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, age, disability or veteran status.

PRINCIPAL DUTIES & RESPONSIBILITIES:

The successful applicant will join ATR's Engineering Services Division, working as a Junior Engineer/Data Scientist at the Naval Surface Warfare Center South Florida Ocean Measurement Facility, (SFOMF) located near Ft. Lauderdale, FL. Applicant will work as part of a research, design, test, and evaluation team, who will develop systems to acquire surface & sub-surface ocean sensor data and fused into a coherent picture for monitoring the underwater ocean environment. Applicant will collect, organize, store, process and archive ocean data. As part of the team, the applicant will simultaneously get to work alongside scientists and experts in these fields to help develop complex signal processing algorithms that will include adaptive noise cancellation techniques and signal extraction using machine learning (ML) and artificial intelligence (AI). Applicant is expected to produce technical reports, standard operating procedures and presentations. Some off-site work from home will be available on a weekly basis.

The applicant will participate and contribute to team in developing project plans, test and analysis plans, and for writing and briefing research progress and results to upper management and sponsors.

EDUCATION & EXPERIENCE REQUIREMENTS:

Advanced degree in Engineering, Physics, or Applied Physics
2+ years of experience with database management, digital signal processing, probability theory, stochastic signal processing, design of digital filters, statistical/analytical signal processing and machine learning techniques
Job experience with the Navy or other DoD laboratories is a plus

SKILLS & ABILITIES REQUIREMENTS:

Knowledge of programming languages such as LabVIEW, Simulink, C/C++, MATLAB, and Python
Knowledge of database management software such as SQL
Working knowledge of scientific programming and algorithm development
Experience with electromagnetic data is a plus
Familiar with sensors, measurements and design of experiments in an underwater ocean environment
Familiar with noise reduction and signal extraction algorithms
Ability to work in a multi-disciplinary group environment
Strong technical writing and presentation skills with the ability to effectively communicate
Some minimal travel required

OTHER REQUIREMENTS:

Candidate must be a US citizen with the ability to obtain and maintain a security clearance or favorable adjudication of a national security background investigation. Current successful background investigation completion is a plus.

HMK1bLWlNY",1973,Aerospace & Defense,$5 to $25 million (USD),Aerospace & Defense,51 to 200 Employees,Company - Private,True
Operations and Data Analytics Engineer,"ManTech International Corporation
","Orlando, FL",$73K - $110K (Glassdoor est.),4.3,"Secure our Nation, Ignite your Future

Become an integral part of a diverse team while working at an Industry Leading Organization, where our employees come first. At ManTech International Corporation, you’ll help protect our national security while working on innovative projects that offer opportunities for advancement.



Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis. If you are an entry to mid-level career professional with data analysis skills

ManTech is actively seeking a motivated, customer-oriented Operations and Data Analytics Engineer to join our team at Kennedy Space Center - Orlando, FL.

The ideal candidate must have the following:

Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Basic Qualifications:

Bachelor of Science in Industrial Engineering, Operations Research, coupled with a strong background in Mathematics, Statistics, or other physical sciences preferred.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.

Physical Requirements:

Must be able to remain in a stationary position 50%.
Needs to occasionally move about inside the office to access file cabinets, office machinery, etc.
Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.
Frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations.




For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone.

ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.

If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.

If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access",1968,Aerospace & Defense,$1 to $5 billion (USD),Aerospace & Defense,5001 to 10000 Employees,Company - Public,False
Senior Data Engineer,"GeniusRx
","Boca Raton, FL",$94K - $144K (Glassdoor est.),2.9,"Job Summary

GeniusRx is looking for an experienced data engineer to help bring the next evolution of pharmacy to life. As part of the data science team under product and technology, you will be working together with the data science, engineering, and product teams to ensure the right data gets to the right people. We are building a data platform that will allow us to bring a new level of intelligence to the pharmacy experience.

Our analytics stack comprises of:

Python, Spark, and Singer for ETL pipelines.
Snowflake, Azure Blob Storage, and PostgreSQL for data storage.
Databricks for additional transformations and machine learning.
Looker for BI and reporting.

You will design and implement data pipelines while factoring for scalability, availability, and quality and be instrumental in setting standards and best practices for the rest of the data science team.

Roles & Responsibilities

Work within the existing data ecosystem to move and integrate data pipelines across warehouses, legacy platforms, and external partners.
Create actionable reports and dashboards that allow business stakeholders to self-service data requests while encouraging a culture of data discovery.
Work together with stakeholders from marketing, pharmacy ops, engineering, and product to understand how the data works, where it comes from, and where it needs to go.
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and Azure big data technologies.
Transform raw data into actionable data layers for use across the organization powering not only our business intelligence capabilities but also helping to establish a base for machine learning applications.
Establish a data platform that can be used as a sole source of truth across the organization.
Develop metrics and leading indicators that not only give answers to data questions but also provide context and understanding of trends.
Monitor and review our drug pricing and give recommendations on ways to get customers the best possible price for their medications while achieving margin targets for the company.
Work in a supportive, passionate team as we drive to bring a new level of medication savings and insight to our customers.

Skills and Attributes for Success

Bachelor’s degree in computer science, engineering, mathematics, economics, or related discipline.
3+ years of experience in data engineering or business intelligence with a track record of manipulating, processing, and extracting valuable information from large datasets.
Strong SQL skills.
Experience working with business intelligence tools such as Looker, and Tableau.
Experience working with executive stakeholders to not only develop reporting that meets their needs but be able to explain the importance/impact of our measures.
Experience using Python, or other language equivalents, and its related data packages (Pandas, Numpy, SQLalchemy), and experience using Spark-based platforms like Databricks is a plus.
Knowledge of best practices related to data transformations and reporting – healthcare experience is a plus.
Knowledge of software engineering best practices including git, agile methods, coding standards and reviews, testing, and operations.
Experience working in the Azure ecosystem is a plus.

Preferred

Experience with healthcare and pharmacy (preferred)

Working at GeniusRx (Headquarters in Boca Raton, FL) means you are working with a diverse, passionate, collaborative team who are dedicated to making pharmacy personal again and are on a mission to disrupt the virtual pharmacy industry. We believe in cultivating a culture of bravery, kindness, and honesty.

We encourage a healthy work-life balance and encourage our employees to take care of themselves by utilizing our comprehensive medical benefits, generous paid time off benefits, wellness programs, social events, and much more!

GeniusRx provides equal opportunity to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristics protected by federal, state, or local laws.",2020,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,51 to 200 Employees,Company - Private,True
Geospatial Data Engineer 2,"University of Miami
","Miami, FL",$74K - $109K (Glassdoor est.),4.0,"Current Employees:

If you are a current Staff, Faculty or Temporary employee at the University of Miami, please click here to log in to Workday to use the internal application process. To learn how to apply for a faculty or staff position using the Career worklet, please review this tip sheet .

The Center for Southeastern Tropical Advanced Remote Sensing (CSTARS) at the University of Miami Rosenstiel School of Marine, Atmospheric and Earth Science has an exciting full-time opportunity for a Geospatial Data Engineer 2. We seek a candidate whose technical skills and interests are focused on data management, documentation, and data curation approaches applied to remote sensing and Earth science data systems. Applicants should have experience in data management, particularly in evaluation and integration of heterogeneous data. Applicants should have experience in metadata standards, scientific data formats such as HDF and netCDF, remote sensing, GIS, and data documentation experience. Position is non-remote .

Essential Requirement:

Due to the nature of our work and existing contractual requirements, qualified candidates must be a U.S. citizen and be able to obtain and maintain a DoD security clearance.

The candidate will:

Lead the CSTARS data team for curation for all datasets acquired

Be responsible for continuous optimization of the dataset lifecycle policy, curation workflow and product preservation/retirement

Be responsible for the execution of day-to-day data curation activities

Be responsible for planning and execution of key milestones and deliverables

Be responsible for generating, tracking, validating, and closing out data quality issues

Work with the CSTARS staff and data providers to track and move datasets through reception and curation.

Support the Development of processes for efficient effective QA/QC of datasets received

Provide feedback to team members to enhance the usability of all datasets, including documentation

Develop and support the preparation of programs, processes, scripts, tutorials to provide seamless access to commercial and public domain data

Provide scientific and technical support for remote sensing data processing tools and services and usability

This lead Geospatial Data Engineer 2 will primarily involve commercial synthetic aperture radar data, but will also be responsible for acquiring publicly available data from national and international agencies such as NASA, NOAA and ESA.

This position will lead CSTARS data management for oceanographic, atmospheric and hydrological data. Primarily, this will be data derived from space-based remote sensing platforms. The data managed will include airborne (e.g., drones) and in situ platforms (e.g., ships, buoys, HF radar.

This candidate be able to implement open-source methods for data format translation and product generation, subsetting and reprojecting data.

In this primary role, this candidate will be the lead developer and maintainer of software that will be used to import various data sets from a variety of sources to more standardized and interoperable data formats.

Required Skills:

M.S. in Geography or Oceanography, Information Science, or Earth Sciences, with 4-5 years of experience in a related field

Demonstrated ability to manage a data from variety of sources and track updates and modification

Strong experience in building and coordinating the development of dataset documentation for Earth science datasets

Knowledge and Experience with Geographic Information Systems (GIS)

technologies and software packages and tools

Proficiency with interpreted data languages for Earth science data, including one or more of the following: Python, MATLAB, R, and/or IDL (Python required)

Experience with reading, subsetting, interpreting, and utilizing geospatially referenced and structured data for research and applications.

Proficient with scientific software tools (e.g., R, NCO, HDF library, ArcGIS, and Python)

Familiarity and experience in metadata standards and conventions

Excellent data documentation skills, strong interpersonal skills, and working effectively as a team member

Experience with version control (i.e. GitHub) and agile development practices

Proficiency working in a UNIX/Linux command-line environment and shell scripting

Demonstrated ability to work both independently and in a dynamic team environment while dealing with multiple issues, tasks, and priorities concurrently

The University of Miami offers competitive salaries and a comprehensive benefits package including medical, dental, tuition remission and more.

UHealth-University of Miami Health System, South Florida's only university-based health system, provides leading-edge patient care powered by the ground breaking research and medical education at the Miller School of Medicine. As an academic medical center, we are proud to serve South Florida, Latin America and the Caribbean. Our physicians represent more than 100 specialties and sub-specialties, and have more than one million patient encounters each year. Our tradition of excellence has earned worldwide recognition for outstanding teaching, research and patient care. We're the challenge you've been looking for.

Patient safety is a top priority. As a result, during the Influenza (""the flu"") season (September through April), the University Of Miami Miller School Of Medicine requires all employees who provide ongoing services to patients, work in a location (all Hospitals and clinics) where patient care is provided, or work in patient care or clinical care areas, to have an annual influenza vaccination. Failure to meet this requirement will result in rescinding or termination of employment.

The University of Miami is an Equal Opportunity Employer - Females/Minorities/Protected Veterans/Individuals with Disabilities are encouraged to apply. Applicants and employees are protected from discrimination based on certain categories protected by Federal law. Click here for additional information.

Job Status:

Full time

Employee Type:

Staff

Pay Grade:

i107",-1,Colleges & Universities,Unknown / Non-Applicable,Education,10000+ Employees,College / University,False
"Data Engineer III, IT","Pediatric Associates
","Plantation, FL",$71K - $100K (Glassdoor est.),3.3,"Remote Position

PRIMARY FUNCTION

The Data Engineer III is a senior level data engineer role and is responsible for designing & building a leading-edge Data & Analytics platform for enabling value-based healthcare, population health management, and enterprise analytics. Designs, develops, maintains, and supports the cloud-based (Microsoft Azure) big data platform and uses modern data engineering design patterns and tools.

ESSENTIAL DUTIES AND RESPONSIBILITIES

This list may not include all of the duties that may be assigned.

Owns solution design blueprints and architecture of the enterprise data platform features and functionality, including data ingestions, data integrations, data pipelines, data models, data quality, data governance.
Plays technical leadership role and leads other team members and guides them on solution design blueprints, data solutions development, and best practices for our enterprise data platform.
Designs, builds and maintains scalable, automated data pipelines to enable Reporting, Data Visualization, Advanced Analytics, Data Science, and Machine Learning solutions.
Supports critical data pipelines with a scalable distributed architecture, including data ingestion (streaming, events, and batch), data integration (ETL, ELT, Azure Data Factory), and distributed data processing using Databricks Data & Analytics and Azure Cloud Technology Stacks.
Builds cloud data solutions using multiple technologies, such as SQL, Python, Data Lake (Databricks Delta Lake), Cloud Data Warehouse (Azure Synapse), RDBMS, NoSQL databases.
Understands and implements best practices in managing data, including master data, reference data, metadata, data quality, and lineage.
Deploys, automates, maintains, and manages cloud-based production systems to ensure the availability, performance, scalability, and security of production systems.
Engages with cross-functional stakeholders to identify pain points, business and technical requirements, and to design data solutions using best-practice patterns and modern architecture.
Owns end-to-end design and development, testing, the release of critical components using Databricks technology stack and Microsoft Azure cloud platforms and services.
Performs other duties as assigned.

QUALIFICATIONS

EDUCATION: Minimum BA or BS degree in Computer Science, Information Systems, or related field required. MS in Business Analytics or related discipline preferred.

EXPERIENCE

Minimum 6 years of experience required in creating robust enterprise-grade data engineering pipelines using SQL, Python, Apache Spark, ETL, ELT, Databricks Technology Stack, Azure Cloud Services, Cloud-based Data and Analytics platforms required. 8-10 years preferred.
Minimum 3 years of experience required in solution design blueprinting and leading technical team members towards delivery of robust enterprise-grade data platform solutions.
Strong proficiency in SQL and data analysis required.
Experience in distributed data (structured, semi-structured, unstructured, streaming) processing techniques using Apache Spark, Hadoop, Hive, Kafka, and big data ecosystem technologies preferred.
Experience in data modeling and design for data warehouse, relational databases, and NoSQL data stores preferred.

KNOWLEDGE, SKILLS AND ABILITIES

Familiarity with Data Science and Machine Learning technologies, development process, and common Machine Learning libraries (e.g., Scikit-Learn, Tensorflow).
Strong problem-solving, critical thinking, verbal, and written communication skills.
Ability to influence decisions related to advanced analytics strategy & roadmaps, business use cases, and data platform capabilities.
Effective communication and collaboration with internal cross functional teams, leadership team, technology partners & vendors, and end users.
Excellent analytical, organizational skills and ability to work in a startup environment and to deliver on tight deadlines using Agile practices.
Healthcare industry experience highly desired.

TYPICAL WORKING CONDITIONS

Non-patient facing
May be either full time remote/telework or rotate working in the office and remote/telework
If remote, this job must be U.S. based
Indoor work; professional office environment
Operating computer
Reach outward

OTHER PHYSICAL REQUIREMENTS

Vision
Sense of sound
Sense of touch
Enter all here

PERFORMANCE REQUIREMENTS

Adhere to all organizational information security policies and protect all sensitive information including but not limited to ePHI and PHI (Protected Health Information) in accordance with organizational policy, Federal, State, and local regulations.




Location: Pediatric Associates · Data & Analytics
Schedule: Full Time, Days",1955,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,1001 to 5000 Employees,Company - Private,False
Data Scientist/Engineer,"Castalia Systems, LLC
","Cocoa, FL",$101K - $142K (Glassdoor est.),4.3,"Overview:

Are you ready to take the next step in your career with Castalia Systems?


We’re looking for growth-oriented stars looking to thrive as part of our growing Castalia team! Diversity is what makes our company great, and we’re looking for top talent to be a part of the difference.




When founded in 2011, the vision of Castalia Systems was to create a company that focused on its people - the Castalia family - while providing advanced solutions to clients with honesty and integrity. Castalia Systems is a Woman Owned Small Business (WOSB) and Small Disadvantage Business (SDB) providing top-tier solutions in the Defense and Intelligence space.




Castalia employees love working here because we put them first.




We know benefits are important, and our package includes medical, dental and vision coverage, 401k matching with day one vesting, generous PTO and paid holidays, paid life insurance, AD&D, long/short-term disability, professional training, tuition reimbursement, and many more!


The Role:




Castalia Systems is hiring a Data Scientist/Engineer (RF MASINT Sensor Program).

Title: Data Scientist/Engineer
Location: Cape Canaveral, FL

On-site Only

Responsibilities:

How You’ll Impact:

Regularly process and analyze sensor-produced radio frequency (RF) data to extract meaningful assessments.
Use existing or create data processing tools that efficiently process sensor data to produce relevant products in various formats.
Develop a wide range of products from sensor data that assist a wide range of consumers ascertain related findings quickly and easily.
Develop and maintain databases that catalog and track sensor performance, to include but not limited to data quality/integrity, sensitivity, and other metrics.
Identify, recommend, or create methods to improve sensor data handling, transport, and analysis.
Maintain awareness of innovations in data processing methods and technology within government, academia, and industry circles
Provide recommendations to program manager for future investments in sensor data handling, transport, and analysis.
Willing to help craft and participate in briefings on sensor capabilities and employment of a wide range of DoD and IC customers.
Willing to work in a small team environment with occasional flexible shifts to support program objectives.
Qualifications:

What You Bring:


Required Skills:




Active TS/SCI with current CI Poly or eligibility
SIGINT or MASINT experience
Strong understanding of the RF / Electro Magnetic (EM) spectrum and associated theory
Experienced as a Data Engineering or Data Scientist working with large volume data.
Experience working with RF Data - data formats, standards, protocols, and applications with RF data.
Experience in processing and analyzing data to formulate assessments – preferably with RF type data.
Expert understanding of data handling, transport, storage, optimization, and visualization techniques
Moderate familiarity with development tools and coding to support RF and systems analysis (e.g., ImageJ, Python, Matlab)

Desired:
Ability to develop ad-hoc scripts quickly to test and evaluate systems / data.
Familiarity with Sensors and collection techniques
Understanding of how to Collect, exploit or process Telemetry data.
Familiar with Cryo-cool systems
Basic familiarity with DoD or IC data transport systems or communications networks and their protocols
Willing to travel in support of program participation in exercises, demonstrations, and other events.
Assist team members with sensor set up, breakdown, and travel preparation; be able to lift items rated at 40 pounds or less




Required Education:
Bachelor’s degree in data analytics, engineering, or computer science

Castalia Systems is an equal employment opportunity and affirmative action employer and strives to comply with all applicable laws prohibiting discrimination based on race, color, creed, sex, sexual orientation, age, national origin, or ancestry, physical or mental disability, veteran status, marital status, HIV-positive status, as well as any other category protected by federal, state, or local laws. All such discrimination is unlawful, and all persons involved in the operations of the company are prohibited from engaging in this type of conduct.",2007,National Agencies,Unknown / Non-Applicable,Government & Public Administration,51 to 200 Employees,Company - Private,False
Data Engineer,"Echo Analytics
","Tampa, FL",$84K - $124K (Glassdoor est.),4.5,"Job Title : Data Engineer

Experience Level: Senior

Location: Tampa

Clearance: TS/SCI


Quiet Professionals , LLC is seeking a Data Engineer who will build and maintain data systems and construct datasets that are easy to analyze and support customer requirements. Implement methods to improve data reliability and quality. Combine raw information from different sources to create consistent and machine-readable formats. Develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling. Develop and deploy Application Programming Interfaces (API) to expose IDST maintained data to the enterprise.

Upon contract award.


Duties & Responsibilities :

Acquire and assemble large, complex datasets that align with USSOCOM enterprise requirements
Building, testing, and maintaining data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using modern data technologies
Develop analytics tools and transformative algorithms for data to provide actionable insights into customer processes, operational efficiency and other key business performance metrics
Create new data validation methods for analytics and data scientist team members that assist them in building and optimizing products to fulfill customer objectives
Work with IDST stakeholders including USSOCOM leadership, customers, and design teams to assist with data-related technical issues and support their data infrastructure needs
Analyze procedures for USSOCOM data separation, access, and security across users and the enterprise data architecture
Work with IDST data and analytics experts to strive for greater functionality in our data systems and capability integration
Create and maintain optimal data pipeline architecture and support associated process improvements for automating manual processes, data delivery, and infrastructure re-design for scalability

Requirements:

Possess a minimum of a bachelor's degree in computer science, IT, or similar field.
8 years’ experience as a data engineer or in a similar role.
Demonstrated experience employing data models, data mining, and segmentation techniques.
Demonstrated experience developing, deploying and/or maintaining enterprise level data solutions
Experience with SQL database design • Data engineering certification is a plus Current DoD Top Secret clearance and eligible for SCI access and ACCM read-on
Python, SQL, noSQL, Cypher, POSTGRES


Preferred:

SQLAlchemy, Flask, Swagger, JavaScript, Spark, Hadoop, Kafka, Hive, R, storm, Matlab, Neo4J, MongoDB


Quiet Professionals, LLC, (QP) is an independently owned and operated CVE-Certified Service-Disabled Veteran Owned Small Business (SDVOSB) with headquarters located in Tampa, Florida. Our goal is to provide innovative and sustainable solutions that improve the operational effectiveness of our clients and partners. We have extensive knowledge and experience in a variety of areas involving Military Support, Intelligence, Information Technology and Security Operations. QP is committed to providing high quality services appropriate to the level of experience and expertise required in analyzing, planning, advising, and conducting operations on a global scale.

Fostering a diverse and inclusive culture is at the heart of what we do at Quiet Professionals, LLC. We want everyone to bring their true selves to work and be inspired to be innovative and results oriented . That is why we strive to always recruit, retain , and promote a diverse mix of people who can contribute to our culture rather than fit into it. We recognize that the work we do internally has a significant impact on the work we do externally, so we must constantly inspire great ideas and new paths forward from every member of our team in order to be successful. We can provide our clients with everything they require thanks to each person's superior skills and proven performance.",2013,Business Consulting,Unknown / Non-Applicable,Management & Consulting,1 to 50 Employees,Company - Private,False
Senior Data Engineer,"Vertical Bridge Management Llc
","Boca Raton, FL",$102K - $139K (Glassdoor est.),3.6,"Summary:

The Lead Business Intelligence developer is responsible for designing and implementing enterprise Business Intelligence (BI) solutions. This individual is responsible for understanding business data, aggregating data, analyzing data, the data architecture, generating reports and dashboards, data governance, and performing quality assurance testing to ensure the data presented is correct. This position will be an advocate as well as a tester of data quality for the organization, working with the rest of the BI Team to better integrate 3rd party applications into our data platform.




This role will support application development and data applications by developing reusable and precise reports and dashboards based on defined processes and standards. You will contribute to the effective data governance of Vertical Bridge’s business data, including but not limited to data quality, data management, data policies, business process management, and risk management surrounding the handling of business data at Vertical Bridge.

Job Functions:

Partner and work closely with Product Owners, Business SMEs, and application development teams to understand the reporting requirements
Gather and analyze data to develop insightful conclusions and generate solutions to address user needs
Develop Business Intelligence reports, data models and dashboards, analytical models, etc. using data from our major business systems
Ability to develop and support data integration frameworks
Ability to write manual and automated test plans; following and develop a formal test plan process, working closely with the business partners and Business Analyst to ensure the data meets expectations
Provide work estimates based on the scope of new and current features, and work iteratively in an Agile environment
Simultaneously manage multiple projects. Effectively communicate project status to stakeholders.
Demonstrate attention to detail, work well in a team environment, be highly motivated, and willing to learn new skills
Backup BI Director in functions such as database backups and restore, grant user permissions, performance tuning, and maintain schema and data integrity throughout all environments
Train and mentor BI developers on SDLC best practices
Stay current on the latest BI technologies
Minimum Qualifications:
A four-year degree (BA or BS), preferably in Computer Science or Engineering is required
Minimum of 7 years of experience in data analytics implementation, from requirements gathering with business partners, through development, testing, training, and implementation
Minimum 5+ years hands-on experience with implementing enterprise-level data platforms and functions:
Experience with Apache Spark, Spark SQL, Azure Databricks, Azure Data Lake Store, Event Hubs, ADF, Synapse, Azure SQL and NoSQL databases
Experience with Continuous Development/ Integration (CI/CD) / DevOps skills (Git, Azure DevOps/ Git Actions).
Experience in big data processing for batch and/or streaming data; data includes file systems, data structures/databases, automation, security, messaging, movement, etc.
Data Modeling, Azure Synapse Analytics, Python, PySpark/Spark, Databricks
Design and develop enterprise data marts, information and architecture
Implementation of Data Lake House architecture
Integrate, monitor, optimize, maintain and troubleshoot Azure Cosmos DB databases with other Azure services
Boomi Integration platform
GIS Spatial data analysis and implementation
Minimum Qualifications:
A four-year degree (BA or BS), preferably in Computer Science or Engineering is required
Minimum of 7 years of experience in data analytics implementation, from requirements gathering with business partners, through development, testing, training, and implementation
Minimum 5+ years hands-on experience with implementing enterprise-level data platforms and functions:
Experience with Apache Spark, Spark SQL, Azure Databricks, Azure Data Lake Store, Event Hubs, ADF, Synapse, Azure SQL and NoSQL databases
Experience with Continuous Development/ Integration (CI/CD) / DevOps skills (Git, Azure DevOps/ Git Actions).
Experience in big data processing for batch and/or streaming data; data includes file systems, data structures/databases, automation, security, messaging, movement, etc.
Data Modeling, Azure Synapse Analytics, Python, PySpark/Spark, Databricks
Design and develop enterprise data marts, information and architecture
Implementation of Data Lake House architecture
Integrate, monitor, optimize, maintain and troubleshoot Azure Cosmos DB databases with other Azure services
Boomi Integration platform
GIS Spatial data analysis and implementation
Minimum 5+ years of extensive Microsoft Power BI implementation and development
Comfortable working in Agile development manner with multiple priorities occurring simultaneously; working with shorter release cycle/continuous delivery environment
Work in a small team environment that takes on multiple priorities and responsibilities throughout the week with little to no daily management oversight
Need the ability to follow established company protocol and communication guidelines and be able to prioritize tasks in a fast-paced environment and work well within a team-oriented environment as well as being able to work independently
Strong analytical skills with a problem-solving aptitude

Supervisory Responsibilities:

None

Working Conditions and Physical Demands:

Position will work directly in the corporate office, with minimal travel. Candidate must have the flexibility to occasionally work overtime.


Vertical Bridge is committed to a policy of equal employment and will not discriminate against an applicant or employee. Vertical Bridge is an Equal Employment Opportunity Employer M/F/D/V



Minimum Qualifications:
A four-year degree (BA or BS), preferably in Computer Science or Engineering is required
Minimum of 7 years of experience in data analytics implementation, from requirements gathering with business partners, through development, testing, training, and implementation
Minimum 5+ years hands-on experience with implementing enterprise-level data platforms and functions:
Experience with Apache Spark, Spark SQL, Azure Databricks, Azure Data Lake Store, Event Hubs, ADF, Synapse, Azure SQL and NoSQL databases
Experience with Continuous Development/ Integration (CI/CD) / DevOps skills (Git, Azure DevOps/ Git Actions).
Experience in big data processing for batch and/or streaming data; data includes file systems, data structures/databases, automation, security, messaging, movement, etc.
Data Modeling, Azure Synapse Analytics, Python, PySpark/Spark, Databricks
Design and develop enterprise data marts, information and architecture
Implementation of Data Lake House architecture
Integrate, monitor, optimize, maintain and troubleshoot Azure Cosmos DB databases with other Azure services
Boomi Integration platform
GIS Spatial data analysis and implementation
Minimum 5+ years of extensive Microsoft Power BI implementation and development
Comfortable working in Agile development manner with multiple priorities occurring simultaneously; working with shorter release cycle/continuous delivery environment
Work in a small team environment that takes on multiple priorities and responsibilities throughout the week with little to no daily management oversight
Need the ability to follow established company protocol and communication guidelines and be able to prioritize tasks in a fast-paced environment and work well within a team-oriented environment as well as being able to work independently
Strong analytical skills with a problem-solving aptitude

Vertical Bridge is committed to a policy of equal employment and will not discriminate against an applicant or employee. Vertical Bridge is an Equal Employment Opportunity Employer M/F/D/V",2014,Telecommunications Services,$100 to $500 million (USD),Telecommunications,201 to 500 Employees,Company - Private,True
Finxact - Senior Data Engineer,"Fiserv, Inc.
","Jacksonville, FL",$86K - $119K (Glassdoor est.),3.0,"Calling all innovators – find your future at Fiserv.

We’re Fiserv, a global leader in Fintech and payments, and we move money and information in a way that moves the world. We connect financial institutions, corporations, merchants, and consumers to one another millions of times a day – quickly, reliably, and securely. Any time you swipe your credit card, pay through a mobile app, or withdraw money from the bank, we’re involved. If you want to make an impact on a global scale, come make a difference at Fiserv.

Job Title

Finxact - Senior Data Engineer

Finxact, a Fiserv Company, brings innovation at the core of banking and provides a next generation core platform. Our mission is to redefine core processing and our commitment is to be the best at what we do.

What does a Senior Data Engineer do?

The Senior Data Engineer will manage architecture of data pipelines from operational systems to reporting/analytical systems. The Senior Data Engineer will also provide oversight and mentoring of junior data engineers.

What you will do:

Manage architecture of data pipelines from operational systems to reporting/analytical systems.

Collect requirements to create and maintain optimal data pipelines.

Document and present data pipeline architecture and design.

Model staging/intermediate to presentation layer data structures to meet functional and performance requirements.

Develop, design, test, and deploy data pipelines.

Manage version control data pipeline code.

Validate quality of data sets for each data layer and transformation logic.

Design and implement data pipeline observability and operational processes.

Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

Collaborate with Product and Business Teams to create new data product offerings.

Collaborate with Data Analysts and Data Visualization team members on analytical and reporting data products.

Debug and troubleshoot operational issues.

Oversight and mentoring of junior data engineers.

What you will need to have:

Bachelor’s degree or combination of education, and equivalent work experience is preferred in the field of computer science, management information systems or Information Technology.

5 to 7 years of professional experience in data engineering.

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Postgres preferred.

Experience with structured data (Relational) and semi-structured data (JSON, XML).

Proficient at defining and building processes supporting data transformation, data structures, metadata, dependency, and workload management.

Experience building and optimizing data pipelines, pipeline architecture, and data sets.

Experience working with both batch and streaming data for ingestion into cloud-based data storage and analytical platforms.

Ability to resolve complex ingestion issues due to evolving data layouts and formats.

Proficiency with an object-oriented/object function scripting language such as Python, Java, Scala.

Experience with Snowflake.

Experience with Cloud storage and compute in AWS, Azure, or GCP. Specifically, data ingestion and analytical solutions such as Databricks, Hadoop, or EMR.

Experience with Jira, Confluence, Git, and DevOps technologies.

What would be nice to have:

Experience in Banking or Fintech preferred.

Experience with Kubernetes and containerized applications preferred.

This role is not eligible to be performed in Colorado, California, New York or Washington.

Please note that salary ranges provided for this role on external job boards are salary estimates made by outside parties and may not be accurate.

Thank you for considering employment with Fiserv. Please:

Apply using your legal name
Complete the step-by-step profile and attach your resume (either is acceptable, both are preferable).

What you should know about us:

Fiserv is a global fintech leader with 40,000-plus (and growing) associates proudly serving clients in more than 100 countries. As a FORTUNE™ 500 company, one of Fast Company’s Most Innovative Companies, and a top scorer on Bloomberg’s Gender-Equality Index, we are committed to excellence and purposeful innovation.

Our commitment to Diversity and Inclusion:

Fiserv is an Equal Opportunity Employer, and we welcome and encourage diversity in our workforce that reflects our world. All qualified applicants will receive consideration for employment without regard to race, color, religion, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by law.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Warning about fake job posts:

Please be aware of fraudulent job postings that are not affiliated with Fiserv. Fraudulent job postings may be used by cyber criminals to target your personally identifiable information and/or to steal money or financial information.

Any communications from a Fiserv representative will come from a legitimate business email address. We will not hire through text message, social media, or email alone, and any interviews will be conducted in person or through a secure video call. We won’t ask you for sensitive information nor will we ask you to pay anything during the hiring process. We also won’t send you a check to cash on Fiserv’s behalf.

If you see suspicious activity or believe that you have been the victim of a job posting scam, you should report it to your local FBI field office or to the FBI’s Internet Crime Complaint Center.",1984,Financial Transaction Processing,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
Senior Data Engineer,"AIR HAMBURG Luftverkehrsgesellschaft mbH
","Fort Lauderdale, FL",$101K - $141K (Glassdoor est.),3.6,"Requisition ID
2023-3757
City
Fort Lauderdale
Position Type
Permanent Full-Time
Work Base
Remote
Category
Engineering
Brand
Vista Global
Job Profile
About Team
The Data Foundation Team is highly critical for the organization to provide timely, accurate and most up to date data so that the business can take decisions accordingly. The team works with several application teams, data analytics, data science team etc. We are looking for a highly skilled and experienced Senior Data Engineer to design, implement, and maintain robust and scalable data pipelines.

About Company
Vista Tech plays a vital role in the Vista group operations by delivering and accelerating comprehensive technology solutions across all brands. Vista’s end-to-end and click-to-flight solutions offer the industry's only comprehensive flight booking platform, seamlessly integrating global operations, and leveraging AI and machine learning to optimize pricing and fleet movement. Comprised of the Product Management, Engineering, and IT teams, Vista Tech’s mission is to enhance transparency and accessibility in private aviation through the development of the world's largest digital private aviation marketplace. In achieving this, Vista Tech always ensures the utmost safety and efficiency for FLIGHT CREW, EMPLOYEES and Members, while fostering a culture of innovation and excellence.

You will report to Engineering Manager and play a crucial role in driving the technical direction of our projects and guiding the team in adopting best practices and cutting-edge technologies. This position is a 100% remote role with regular shif timings (9 AM to 6 PM EST). You will collaborate with cross-functional teams, provide technical leadership, and contribute to the entire software development lifecycle.
Your Responsibilities
Scalable Data Infrastructure: Lead the development and maintenance of highly scalable data pipelines, playing a crucial role in fortifying our data foundation.
Technical Excellence: Demonstrate hands-on technical expertise in designing, building, and documenting complex data pipelines while adhering to data engineering best practices.
Cross-Functional Collaboration: Collaborate closely with data engineering, analytics, and data science leadership to continuously enhance the functionality and capabilities of our data systems.
Process Optimization: Identify opportunities for internal process improvements, spearheading automation of manual tasks, optimizing data delivery mechanisms, and redesigning infrastructure to ensure greater scalability and efficiency.
Data Integration Mastery: Define and construct the infrastructure necessary to facilitate efficient extraction, transformation, and loading (ETL) of data from a diverse array of sources.
Required Skills, Qualifications, and Experience
Strong Analytical Foundation: A robust background in mathematics, statistics, computer science, data science, or a related discipline, showcasing your analytical prowess.
Programming Proficiency: Advanced expertise in programming languages, particularly Python and SQL, to tackle complex data challenges.
Production Experience: Proven experience in the production environment with a range of essential tools and platforms, including Snowflake, DBT, Airflow, Amazon Web Services (AWS), Docker/Kubernetes, and PostgreSQL.
Database Mastery: Proficiency in database technologies, including Snowflake, PostgreSQL, Redshift, and others, enabling efficient data management.
Exceptional Organizational Skills: Strong organizational capabilities, allowing you to manage multiple projects and priorities concurrently while consistently meeting deadlines.
Additional Assets: Familiarity and experience with additional tools and technologies, such as AWS certification, Kafka Streaming/Kafka Connect, MongoDB, and CI/CD tools like GitLab, Jira, and Confluence, are highly advantageous.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Company - Private,False
Data Engineer,"MDVIP LLC
","Boca Raton, FL",$84K - $120K (Glassdoor est.),3.5,"Overview:

Are you looking to join an innovative IT team supporting the healthcare industry? MDVIP, based in Boca Raton, FL is seeking a Data Engineer who will work with business stakeholders and analysts to understand business drivers and goals to develop requirement and user stories while developing critical business intelligence solutions. Requires performance of complex technical, analytical and professional services to evaluate database-driven business applications the future support of these solutions.

MDVIP has consistently been recognized as a Great Place to Work® employer since 2018, (Greatplacetowork.com/certified-company/MDVIP) and was named by Fortune and Great Place to Work® as one of the 2023 Best Workplaces in Healthcare™ . This is a corporate based role, however a hybrid corporate office and work from home schedule may be available based on position and departmental needs.

Responsibilities:

Essential Duties and Responsibilities:

Responsible for data modeling, data mart, data warehouse design, and development, writing relational and multidimensional database queries to design custom-fit analysis and reporting solutions.
Manages and optimizes SQL databases for storage, compute, performance, and cost optimization for growing analytical needs.
Performs hands on work in designing, developing, testing, optimizing, and documenting existing and new systems for reporting, including merging data from various sources, and embed reports for use in other systems. Manages reporting environments including report data sources, security, subscriptions, metadata, and documentation of operating procedures.
Works closely with IT members, especially DBAs, Systems Analysts, and Systems Engineers to assess impact of changes and updates to source productions systems. Plans and implements resulting changes to report.

This job profile is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee. Other duties, responsibilities and activities may change or be assigned at any time with or without notice.

Qualifications:

Education / Experience / Knowledge:

Bachelor's degree preferably in the disciplines of STEM such as Computer Science, Management Information Systems, or in a quantitative technical field and at least 3 years of experience in business intelligence, data warehousing, data modeling, and/or data analysis.

Required Skills and Experience:

Technical experience to include Python, SQL and OLAP, various Azure services, Databricks, Database Architecture and design for OLAP/Data Warehouse (star and snowflake design). Reporting tools – SSRS, PowerBI
Knowledge of github and its features, including fork, pull request and merge.
Experience working with end users, managers, customer and other stakeholders to analyze user requirements, sourcing data, and building front-end BI Applications for end users.
Ability to articulate complex technical topics in business terms to non-technical audiences
Troubleshoot and use of performance-tuning BI tools, systems, software. Able to resolve data quality/integrity problems.
Experience designing and delivering end-use training, materials, and technical support.

Preferred Skills, Experience and Certifications:

Experience with MS SQL Server, Microsoft Azure, Amazon Web Services, or Google Cloud Platform a plus (data pipelines, database/data warehouse, etc.)
Experience working using AGILE project management methodology
Background in Software Development Life Cycle (SDLC) with ability to manage or perform development duties
Project Management/Business Analysis, Salesforce and healthcare industry experience
Certified Business Intelligence Professional and Azure Fundamentals


Additional information:

At no time may work be performed, or computer systems accessed, from outside of the U.S.

Individuals hired must be able to perform essential duties satisfactorily. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

MDVIP provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.

Consistent with our mission, purpose, and core values, MDVIP takes the health and safety of its employees very seriously. With the concern over the spread of the coronavirus or “COVID-19,”and its variants, MDVIP has, and will continue to take reasonable measures to mitigate the potential spread of COVID-19. Your recruiter will provide more information during the interview process.",2000,Health Care Services & Hospitals,$100 to $500 million (USD),Healthcare,201 to 500 Employees,Company - Private,False
Distinguished Data Engineer,"Verizon
","Temple Terrace, FL",$94K - $157K (Glassdoor est.),3.8,"When you join Verizon

Verizon is one of the world’s leading providers of technology and communications services, transforming the way we connect around the world. We’re a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together—lifting up our communities and striving to make an impact to move the world forward. If you’re fueled by purpose, and powered by persistence, explore a career with us. Here, you’ll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife.

What you’ll be doing...

We are seeking an experienced strategic technical leader with telecom and wireless expertise to join our team in a role as Distinguished Staff Engineer. You will leverage your deep hands-on expertise in cloud solution, data and ML to build solutions that support key functions like marketing, service assurance, and sales. This is a high-impact role shaping the future of our cloud data and AI platforms. The Ideal candidate is a driven technical leader who will spearhead data engineering research initiatives that will shape the future of our data infrastructure. As our Data Engineering Lead, you will explore cutting-edge technologies and techniques to build next-generation data platforms that power our products, operations, and strategic growth. Responcibilites inlcude...

Architecting data pipelines, warehouses, and machine learning solutions to power marketing, network operations, customer insights, and other telecom use cases.

Leading projects to productionize promising technologies like distributed computing, streaming analytics, and cloud-native data patterns in our environment

Building, and producing petabyte-scale data pipelines, lakehouses, and machine learning infrastructure on Google Cloud Platform leveraging tools like BigQuery, Dataflow, Dataproc, and Vertex AI.

Researching, prototype, and evaluating emerging data engineering tools, architectures, and methodologies to solve complex challenges for telco workloads

Handling massive datasets related to call records, network traffic, customer usage, and other telecom data sources

Building a strategy and execution plan for migration to the cloud

Data Engineering Cloud Cost/Operation Optimization

Analyzing cloud spending across data platforms and identify optimization opportunities

Right-size data infrastructure resources based on usage analytics and workload profiling

Implementing automation and policies to eliminate waste, stop unused resources, increase efficiency

Promoting architectural and workload best practices for cost-efficient data systems.

Creating and managing processes for cloud budgeting, allocation, monitoring, and reporting

Negotiating contracts with cloud providers to improve spending effectiveness

Developing cost awareness initiatives such as chargebacks, show backs, and financial training

Driving major technical initiatives and architectural decisions for the data platform, analytics, and AI

Continuously improve engineering best practices related to data security, testing, CI/CD, and reliability of large-scale distributed systems on the cloud.

Sharing knowledge across the organization by publishing papers, giving tech talks, and maintaining reference architectures

Developing and promoting standards for high-quality, well-tested, maintainable code. Foster a culture of technical excellence.

Architecting highly automated solutions for data observability platform for validation, and data drift detection to maintain quality and reliability of company core data.

Collaborating cross-functionally with product managers, data scientists, and business stakeholders to understand needs and deliver impactful data solutions.

Mentoring and developing junior engineers through code reviews, architectural guidance, design frameworks, and coaching sessions.

Acting as a trusted advisor to executives on strategic technology and data solution directions.

Where you will be working…

In this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager

What we’re looking for...

You’ll need to have:

Bachelor's degree or four or more years of work experience.

Six or more years of relevant work experience.

Even better if you have one or more of the following:

15+ years of industry experience in data engineering, analytics, and production machine learning systems.

Deep hands-on experience with Google Cloud data services: BigQuery, Dataflow, Dataproc, PubSub, Storage, CloudFunctions, Cloud Run.

Deep knowledge of large-scale distributed data architecture patterns and performance optimization techniques.

Deep expertise in strategizing, planning, program management, and technical architecture for large-scale cloud data modernization.

Deep expertise in building data pipelines, warehouses, and machine learning solutions to power marketing, network operations, customer insights, and other telecom use cases.

Proficiency in developing complex data pipelines, ETLs, and workflows on cloud platforms optimized for high volumes of telecom data.

Expertise in designing modern data architecture using Fivetran or Matillion, dbtlabs or dataform, BigQuery, DatabrickSQL, Snowflake

Knowledge of tools like Composer, Spark, Kafka, BigQuery, Dataform, Azure Data Fabric, Databricks, Snowflake

Expertise in Open source Data Technologies in processing, storage, data quality - Cloudera Hadoop, Presto HUDI, Iceberg, Delta Lake, Apache Flink, GreatExpectations, Airflow, Kubernetes, Kafka

Proficiency using cloud platforms like GCP, AWS, or Azure.

Proficiency with CI/CD tooling like Jenkins, Airflow, Kubernetes, and Git/GitHub to enable robust development pipelines for data and ML

Strategic thinker able to solve complex technical challenges and mentor junior engineers working with telecom data

Knowledge of data data observability solutions Elementary.io, MonteCarlo, HoneyComb

If Verizon and this role sound like a fit for you, we encourage you to apply even if you don’t meet every “even better” qualification listed above.

This role is eligible to be considered for the Department of Defense SkillBridge Program.

Where you’ll be working
In this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.

Scheduled Weekly Hours
40

Equal Employment Opportunity

We’re proud to be an equal opportunity employer - and celebrate our employees’ differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.",2000,Telecommunications Services,$10+ billion (USD),Telecommunications,10000+ Employees,Company - Public,False
Data Engineer,"Brooksource
","Jacksonville, FL",$37.00 - $42.00 Per Hour (Employer est.),3.9,"Data Engineer

Contract

Jacksonville (Hybrid Preferred)

Brooksource is looking for an Associate Data Engineer to join one of our leading global pharmaceutical clients. This person willcreate prototype data engineering solutions for use cases across critical business priorities. They will also manage new data sources and drive business impact across the US for the Americas Region. This is an exciting and meaningful position as an integral part of the overall Business Intelligence Team!

Types of Responsibilities

· Identify and resolve quality issues during complex data migration & transformation.
· Support BI analysts in basic data engineering capabilities enabling throughput, complex analytics support.
Accountable for data engineering use cases that may have “limited time” life cycles.
· Writing queries / coding real-time, fast deployment within sandbox environment
· Data Engineering to support acceleration of E2E Reporting and Analytics
· Manage data catalog for the business.
· Pull disparate data sources together in the sandbox.
· Manage new data sources (conform w/ HIPAA, HCC) and access protocols.
· Problem solving for data issues in the lake in partnership with IT team.
· Analytics to answer urgent business priority questions to drive action.

Qualifications

A bachelor’s or advanced degree is required (Computer Science, Data Science, Business Administration, Engineering, with an Information Technology focus or related field)
A minimum of two years of progressive, broad-based information systems and technology experience in data warehousing, and decision support/reporting environments
Minimum of two years of software development experience, specifically in the area of data transformation scripting languages – proprietary (INFORMATICA, SQL) or open source (TALEND, Python) – required; open source transformation scripting strongly preferred.
Demonstrable data lifecycle capability required around data ingestion (ingest data from disparate systems into cloud computing environment), data contextualization (merging large data sets, developing algorithms to merge and clean data); data insights and analytics is required.
Demonstrated familiarity with large datasets and understanding of data analysis workflows is required – experience with data visualization tools like Tableau preferred.
· Superior attention to detail, organization skills, and the ability to balance multiple tasks.
· Ability to talk with business partners and help determine problem statement.
· Strong oral and written communication skills.

Eight Eleven Group provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state, and local laws.

Job Type: Full-time

Pay: $37.00 - $42.00 per hour

Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance
Paid time off
Vision insurance

Schedule:

Monday to Friday

Ability to commute/relocate:

Jacksonville, FL 32256: Reliably commute or planning to relocate before starting work (Required)

Experience:

SQL: 3 years (Preferred)
Data warehouse: 1 year (Preferred)
Python: 4 years (Preferred)

Work Location: Hybrid remote in Jacksonville, FL 32256",2000,HR Consulting,$100 to $500 million (USD),Human Resources & Staffing,201 to 500 Employees,Company - Private,True
Data Engineer IV,"Navy Federal Credit Union
","Pensacola, FL",$112K - $145K (Glassdoor est.),4.1,"Overview

Develop strategies for data acquisition, archive recovery, and database implementation. Responsible for designing, building, integrating data from various resources, and managing big data. Develop data consumption patterns to share data with internal/external channels, while ensuring they are easily accessible, work smoothly, with the goal of optimizing the performance of Navy Federal’s big data ecosystem. Recognized as an expert with a specialized depth and/or breadth of expertise in discipline. Solves highly complex problems; takes a broad perspective to identify solutions. Leads functional teams or projects. Works independently.

Responsibilities

Define and build data integration processes to be used across the organization
Build channel contracts and data consumption patterns for customer facing (On-line/Mobile) channels
Analyze and validate data sharing requirements within and outside data partners
Recognize potential issues and risks during the project implementation and suggest mitigation strategies
Communicate and own the processes related to contracts and data consumption patterns
Expert and key point of contact between the operational data hubs and the channel contracts for On-line/Mobile
Apply engineering principles into the design and enhancement of new and existing data management systems
Coach and mentor project team members in carrying out project implementation activities
Work directly with business leadership to understand data requirements; propose and develop solutions that enable effective decision-making and drives business objectives
Prepare advanced project implementation plans which highlight major milestones and deliverables, leveraging standard methods and work planning tools
Lead the preparation of high-quality project deliverables that are valued by the business and present them in such a manner that they are easily understood by project stakeholders
Ensure the security and integrity of system and product solutions including compliance with Navy Federal, industry engineering and Information Security principles and practices
Present clear, organized and concise information to all audiences through a variety of media to enable effective business decisions
Perform other duties as assigned

Qualifications

Master’s degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience
Advanced skills in systems and application integration in a large, distributed architecture environments
Proficient skill level in .Net/C#, Python, Agile Frameworks (SAFE), Microsoft Databricks, Azure Data Factory
Proficient skills in developing and operationalizing various data distribution patterns like, APIs, event based, pub/sub models
Proficient in Data Architecture, Web Services, REST APIs, Event and Pub/Sub messaging architecture
Proficient in Mobile and Web application technologies
Ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner
Proficient skills in understanding SQL and NoSQL and JSON structure
Ability to understand other projects or functional areas to consolidate analytical and operational needs and processes
Demonstrates change management and/or excellent communication skills
Working knowledge of various data structures and the ability to extract data from various data sources
Understands the concepts and application of data mapping and building requirements
Understands data models, large datasets, business/technical requirements
Skilled in managing the process between updating and maintaining data source systems and implementing data related requirements

Desired Qualifications

Knowledge of Navy Federal Credit Union instructions, standards, and procedures

Hours: Monday - Friday, 8:00AM - 4:30PM
Location: 820 Follin Lane, Vienna, VA 22180 | 5550 Heritage Oaks Dr. Pensacola, FL 32526 | 141 Security Dr. Winchester, VA 22602

About Us

You have goals, dreams, hobbies, and things you're passionate about—what's important to you is important to us. We're looking for people who not only want to do meaningful, challenging work, keep their skills sharp and move ahead, but who also take time for the things that matter to them—friends, family, and passions. And we're looking for team members who are passionate about our mission—making a difference in military members' and their families' lives. Together, we can make it happen. Don't take our word for it:


Military Times 2022 Best for Vets Employers


WayUp Top 100 Internship Programs


Forbes® 2022 The Best Employers for New Grads


Fortune Best Workplaces for Women


Fortune 100 Best Companies to Work For®


Computerworld® Best Places to Work in IT


Ripplematch Campus Forward Award - Excellence in Early Career Hiring


Fortune Best Place to Work for Financial and Insurance Services



Equal Employment Opportunity: Navy Federal values, celebrates, and enacts diversity in the workplace. Navy Federal takes affirmative action to employ and advance in employment qualified individuals with disabilities, disabled veterans, Armed Forces service medal veterans, recently separated veterans, and other protected veterans. EOE/AA/M/F/Veteran/Disability EOE/AA/M/F/Veteran/Disability


Disclaimers: Navy Federal reserves the right to fill this role at a higher/lower grade level based on business need. An assessment may be required to compete for this position. Job postings are subject to close early or extend out longer than the anticipated closing date at the hiring team’s discretion based on qualified applicant volume. Navy Federal Credit Union assesses market data to establish salary ranges that enable us to remain competitive. You are paid within the salary range, based on your experience, location and market position


Bank Secrecy Act: Remains cognizant of and adheres to Navy Federal policies and procedures, and regulations pertaining to the Bank Secrecy Act.",1933,Banking & Lending,Unknown / Non-Applicable,Financial Services,10000+ Employees,Self-employed,False
Principal Engineer Electromechanical - Instrumentation and Data Systems,"Northrop Grumman
","Melbourne, FL",$90K - $136K (Employer est.),4.0,"Requisition ID: R10139574
Category: Engineering
Location: Melbourne, Florida, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.

Northrop Grumman Aeronautics Systems has an opening for a Principal Engineer Electromechanical to join our team of qualified, diverse individuals within our Test and Evaluation organization. This role is located in Melbourne, FL.

As an Instrumentation and Data Systems engineer, you will be responsible for the development, design and maintenance of complex instrumentation and data system solutions for laboratory, ground and flight test activities on the program. You will maintain Flight Test Instrumentation system configurations and coordinate test activity, maintenance and communicate instrumentation issues and status across teams. In addition, support planning and flight test readiness reviews; flight test planning working groups and coordination meetings; pre and posttest briefings. Also, define data system configurations, sensor selection, installation, checkout requirements and operational procedures and define air vehicle interface, integration and logistic requirements. Knowledge of telemetry, onboard recording, Data Acquisition Systems (Teletronics) and ground stations is key. You will also provide test crews, manufacturing and/or suppliers the guidance and direction required for operation, fabrication, modifications, assembly and checkout of Instrumentation systems and associated equipment. Experience in computer operating systems and application software (AutoCAD), as well as database development for measurand and test data is important. You will prepare system specifications, Request for Quotes (RFQ’s) and Statement of Work (SOW’s) that satisfy test and system requirements plus support test activities, anomaly resolution and process improvement initiatives. Strong leadership, communication and interpersonal skills are key.

Key Responsibilities:

Applies electrical, electronic and mechanical principles to components and systems, including assembly, analysis, and documentation of results
Construction of developmental assemblies, sub-assemblies and components
Quality testing
Supports and participates in the design, test, modification, fabrication and assembly of prototype electromechanical systems.

We offer flexible work arrangements, 9/80 work schedule with every other Friday off, phenomenal learning opportunities, exposure to a wide variety of projects and customers, and a very friendly team environment. We are looking for self-motivated, proactive, and goal-oriented people to help us grow our services and become even better at what we do.

Basic Qualifications (Principal Engineer Electromechanical):

Must have a Bachelor of Science degree in a Science, Technology, Engineering, or Math (STEM) discipline AND 5 years of related professional/military experience OR a Master of Science degree in a STEM discipline AND 3 years of related professional/military experience OR a STEM Ph.D. AND 0 years of related professional/military experience
Must have the ability to obtain and maintain a DoD Secret clearance prior to the commencement of employment
Must have the ability to obtain and maintain Special Access Program (SAP) clearance prior to the commencement of employment

Preferred Qualifications:

Current SAP/PAR Clearance
Top Secret clearance
Master’s degree in a STEM discipline
Salary Range: $90,400 - $135,600
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.

Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",1939,Aerospace & Defense,$10+ billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
Full Stack Software Engineer (Data Stewardship),"Clarity Innovations
","Tampa, FL",$74K - $104K (Glassdoor est.),4.8,"Responsible for developing applications designed to enhance user interface, enable operators, and increase effectiveness and efficiency of operating tasks. Identify areas in which technology can be used to improve current processes through automation and data management. Participate in the software development life cycle of an application, including the architecture, development, testing, and deployment of software solutions. Applications are designed to be user-friendly and easily accessible by the end-user while emphasizing security.

The Full stack software engineer shall perform the following tasks:

Design, prototype, develop, and implement applications using Web programming technologies to
include but not limited to: JavaScript, HTML, HTMLS, and CSS.

Proficiency using the Python programming language, along with experience with web frameworks
such as Django.

Database knowledge (such as My Sequel) to query databases and facilitate database
design.

Work with Data Analysts, Data Integrators, Data Scientists, and Database Engineers to create,
troubleshoot, and recommend appropriate user interface capabilities.

Work with customers to enhance user experience and implementation requirements.",2013,Research & Development,Unknown / Non-Applicable,Management & Consulting,1 to 50 Employees,Company - Private,False
Data Engineer - 5050304,"Accenture
","Miami, FL",-1,3.9,"Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.

As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.

You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.

Utilize strong SQL Python skills to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features.

Build reporting dashboards and visualizations to design, create and track campaign program KPIs.

Perform analyses on large data sets to understand drivers of operational efficiency.

Manage end to end process of analytic tooling feature development, including request intake, requirements evaluation, cross functional team alignment, feature execution, QA testing, and stakeholder communication.

Consult with business analysts, technical data SMEs, and cross functional partners to understand their reporting and data needs, serving as the point of contact for requests, inquiries, and actions.

Interface with other data engineering, product, and data science teams to implement client needs and initiatives.




Basic Qualifications:

Minimum 2 years experience with Python.

Minimum 3 years experience SQL.

Minimum 3 years experience Big Data Analytics.

High School Diploma or GED.

Preferred Qualifications:

Experience with large enterprise data sets.

Bachelors Degree

Compensation at Accenture varies depending on a wide array of factors, which may include but are not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York, or Washington as set forth below.

Information on benefits is here.

Role Location

California: $61.53 to $71.53/hour

Colorado: $61.53 to $71.53/hour

New York: $61.53 to $71.53/hour

Washington: $61.53 to $71.53/hour


What We Believe


We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.


Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here


Equal Employment Opportunity Statement


Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.


All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.


Accenture is committed to providing veteran employment opportunities to our service men and women.


For details, view a copy of the Accenture Equal Employment Opportunity and Affirmative Action Policy Statement.


Requesting An Accommodation


Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.


If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.


Other Employment Statements


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.


Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.


Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.


The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",1989,Business Consulting,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
"Sr. Cloud Data Engineer, Data Operations","CardWorks
","Orlando, FL",$76K - $123K (Glassdoor est.),3.1,"CardWorks Servicing (""CWS"") is one of the largest privately-held provider of outsourcing services for bankcard-related products to banks and non-bank lenders in North America. CWS offers management expertise across the credit spectrum and supports both MasterCard and Visa accounts as well as a variety of private label debit, credit, stored value, and customer bankcards.

Position Summary:
As a Senior Cloud Data Engineer, you will support data engineering related initiatives within Data Operations department with a focus on building data & analytics platform and data stores for consumption by data operations, reporting, business intelligence and analytics user community. This role is responsible for developing data ingestion patterns, data pipelines, data extraction, load, and transformation (ETL) programs, ETL test plans, and automating the ETL process through scheduling and exception-handling routines.

Essential Functions:

Works with business teams to understand business use cases, requirements and translate business requirements into data requirements.
Works with applications specialists (SMEs) to understand data sources and perform data discovery and document the learnings
Creates ETL system design specifications and data flow diagrams etc.
Prepares technical and system specifications documents including Source to Target Mapping covering data sources integration patterns, controls, data transformation and load rules.
Design, develop, test, and deploy ELT programs to extract, stage, cleanse, transform and load the data needed.
Troubleshoots, maintains, and supports the warehouse and the downstream data feeds sent to consuming applications.
Supports system, integration and UAT testing.
Assists with performing source data quality assessments
Performs root cause analysis, resolves production issues and supports production teams.
Performs other job duties as assigned and fulfill report and data extraction requests as needed
Adherence to legal and company standards
Education and Experience:

Bachelor’s degree in software engineering/computer science/information technology or related field is required.
Five (5) years’ experience in ETL/ELT development including building data ingestion & integration pipelines.
Minimum three (3) years’ experience in AWS Cloud technologies and data integration tools such as Amazon S3, Amazon Athena, AWS Glue, AWS Glue Catalog, AWS Lake Formation etc.
Experience in scripting languages: Python, SQL
Experience working with Analytics Databases like Snowflake, Redshift
Experience in Big Data technologies like Data Lakes, Delta Lake, Data Factory, relational data stores in AWS Cloud Platform
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ stores
Experience building and implementing data ingest and egress patterns and pipelines.
Ability to troubleshoot and solve complex technical problems.
Strong project management skills
Clear communication skills
Consumer Financial Services background, preferably credit card business knowledge
Summary of Qualifications:

Ability to gather requirements, apply strong analysis and design skills to build ELT and system specifications
Proficient in designing and developing SQL Queries & ETL Programs using cloud technologies and tools.
Strong project management & analytical skills
Ability to work with data warehouse users, IT Business Analysts
Strong problem solving, written and verbal communication skills
Hands on experience with SQL-Based databases (e.g., Snowflake)
Proficiency in Python
Experience in Informatica ETL Tools will be an added advantage
We are an equal opportunity employer, and we evaluate qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status or any other legally protected characteristic. We will conduct a thorough background check for all hires in compliance with applicable law which includes (but may not be limited to) a review of factors including the applicant’s personal credit history, drug testing, and employment/personal references.",1987,Banking & Lending,$25 to $100 million (USD),Financial Services,501 to 1000 Employees,Company - Private,True
Azure Data Engineer,"Wipro Limited
","Orlando, FL",$85K - $114K (Glassdoor est.),3.1,"Overview:
About Wipro:
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.
A PROUD HISTORY OF OVER 75 YEARS
FY22 REVENUE 10.4 BN USD
WE’RE PRESENT IN 66 COUNTRIES
OVER 1,400 ACTIVE GLOBAL CLIENTS

Role - Azure Data Engineer

Location - Remote (Anywhere in USA)

JD for this requirement
Strong proficiency in designing and implementing data integration solutions using Azure Data Factory
Good experience in data load from different data sources like DBs, APIs, Flat files and cloud based data sources like ADLS, Amazon S3
Design, develop, and deploy data integration and transformation solutions using Azure Data Factory
Develop and maintain data pipelines to extract, transform, and load (ETL) data from various sources into target data repositories
Solid understanding of data modeling, data warehousing concepts, and ETL principles.
Familiarity with Azure services and tools, including Azure Blob Storage, Azure SQL Database, Azure Data Lake
Strong knowledge in SQL language
Implement data validation and quality to ensure accuracy and consistency of data
Optimize data pipelines for performance and scalability
Have worked with high data volume and continuous data flow
Very good communication and presentation skill

Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.",1945,Information Technology Support Services,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer,"Elder Research Inc
","Tampa, FL",$87K - $124K (Glassdoor est.),4.4,"DATA ENGINEER

Work Locations: Tampa, Florida

Clearance: Top Secret with SCI Eligibility

Elder Research Inc. is a recognized leader in predictive analytics and machine learning. We pride ourselves in our ability to find creative, cutting edge solutions to real-world problems. We are looking for innovative and inquisitive self-starters who enjoy translating complex models into actionable solutions that deliver real value for our clients.

As a member of the Elder Research team, you will join a functional team of accomplished Data Scientists and Software Engineers that deliver custom analytic solutions. Some of your responsibilities will include: wrangling and fusing large and disparate data sets, assisting in the deployment of models and algorithms, automating the entire data pipeline, and communicating model results through user-focused data visualizations.

We are looking for an experienced Data Engineer to join our team! In this role, you will support robust and repeatable data manipulation, large scale infrastructure for data ingestion, and stunning data visualization for custom client applications.

Required Qualifications:

5+ years of Data Engineering or Data Management experience.
Strong SQL skills, and ability to identify issues with data.
Understanding of database and database design
Demonstrated experience with cleaning, processing, managing, and optimizing performance of large volumes of data.
Demonstrated experience within an AWS environment (AWS certifications preferred)
Familiarity with industry best-practices for software-hardware optimization when processing large sets of data.
Experience with machine learning, with statistical modeling, time-series forecasting and/or geospatial analytics is preferred.
Experience with Hadoop, Spark or other parallel storage/computing processes is a plus.
Ability to travel to and work on site at clients as needed.
Excellent communication skills both verbal and written
Hands on experience with cloud native data warehousing and data lake solutions with Azure ADF, Redshift, Snowflake, etc
Engineering experience and seasoned coder in one or more relevant language: Python, Java, Scala, SQL, etc


About Elder Research, Inc.

Elder Research is a fast growing consulting firm specializing in predictive analytics and machine learning. Elder Research has been in the data science business for over 20 years providing analytic solutions to hundreds of companies and organizations across numerous industries. At Elder Research, you’ll be part of a fun, friendly community. In keeping with our entrepreneurial spirit, we want candidates that are self-motivated with an innate curiosity and strong team work ethic. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately.

Achieving success on defense, intelligence and security projects requires a data science team with broad experience, critical thinking, a proven ability to solve complex problems, and the ability to effectively communicate results. Our scientists conduct analysis in a collaborative environment that frequently brings together the expertise of decision-makers, analysts, agents, investigators, and even behavioral scientists. Our team relies on well-trained technical personnel who have experience with tools, algorithms, best practices, and custom software development to navigate the frontier of unsolved problems we typically encounter. Our team enjoys great variety in the type of work they do and exposure to a wide range of analytic techniques and tools.

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.",1995,Business Consulting,$5 to $25 million (USD),Management & Consulting,51 to 200 Employees,Company - Private,True
Data Engineer,Sparibis,"Orlando, FL",$67K - $117K (Glassdoor est.),-1.0,"Location: 100% Remote

Years' Experience: 5+ years

Education: bachelor's degree in computer science, Engineering, Mathematics, Statistics, Business, or similar field

Work Authorization: Must show that applicant is legally permitted to work in the United States.

Clearance: Applicants must be able to meet the requirements to obtain a Secret security clearance. NOTE: United States Citizenship is required

Key Skills:

Experience in Databricks is required.
Experience with data engineering, mapping, and modeling tools
Current certifications in Network+, Security+, or higher
Responsibilities


Implement and validate predictive and prescriptive models, create, and maintain statistical models with a focus on big data.
Oversee Databricks clusters and document parameters.
Support development of data sets, data processes and data acquisition to support the data hub activities.
Incorporate a variety of statistical and machine learning techniques in your projects.
Write programs to cleanse and integrate data in an efficient and reusable manner.
Participate end to end in the product life cycle: requirements gathering, solution design, development, testing, and implementation.
Work in an Agile, collaborative environment to bring analytical rigor and statistical methods.
Communicate with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.
Evaluate modelling results and communicate the results to technical and non-technical audiences.
Build reusable code and libraries for future use.
Create work estimates and meet project deadlines.
Translate application storyboards, requirements docs and use cases into functional applications.
Work both independently and collaboratively with business and development teams to create great user experiences for our customers.
Troubleshoot and resolve any bugs assigned.
Qualifications


3+ years of experience in data using architecture, data engineering, data hub / data warehouse development and design.
Bachelor's degree
Must be able to obtain a Secret Security Clearance. United States Citizenship is required to be able to obtain a Secret clearance.
Must have experience with data architecture concepts and tools such as data warehouse and physical, enterprise, and cloud services
Experience in utilizing data management, enterprise repository, data modeling, data quality and data mapping tools.
Current Network+, Security+, or higher as defined by DoD CIO Information Assurance (IA) certification requirements.
Experience with Databricks is required.
About Sparibis

Sparibis LLC is a professional solution firm that Clients rely on to access the best talent to drive their business success.

Sparibis is an equal opportunity employer that values diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,True
Data Platform Engineer (Data Stewardship),"Clarity Innovations, LLC
","Tampa, FL",$83K - $118K (Glassdoor est.),4.8,"Description

Clarity Innovations connects human creativity with emerging technology to design, develop, and deploy software that enhances mission success. Our focus is redefining the Department of Defense's relationship with technology by encouraging the use of DevSecOps and Agile methodologies, small-teams constructs, modern tech stacks, and automation. Our software improves the lives and work of our end users and enhances innovation. We fulfill our responsibility to our country by delivering mission-changing results that help shape a better and safer world.

Job Description:


A platform engineer (production) is responsible for developing and maintaining the production environment (k8s, Openshift, VMWare PKS Essentials, etc.) They ensure a modern and secure foundation upon which all product teams can deploy containerized applications.

Minimum of 1-year experience is required
Experienced in providing DevSecOps implementation using Jenkins, Gitlab, or similar tools.
Experienced in developing, testing, and maintaining containerized applications utilizing docker, K8s, Openshift, etc.
Working knowledge of Source Version Control and Build/Release tools and methodologies
Strong understanding of Software Build process and how it connects to CI/CD
Must be able to do some coding
Must be 8570 Compliant
Must have some exposure to Data Science
CLEARANCE:

At least “Interim Secret” w/in 30 days of hire is required, while Top Secret clearance eligible for SCI is preferred

Clarity Innovations provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, or any other protected class.",2013,Research & Development,Unknown / Non-Applicable,Management & Consulting,1 to 50 Employees,Company - Private,False
Data Quality Assurance Engineer,"Wabtec
","West Melbourne, FL",$61K - $86K (Glassdoor est.),3.7,"Wabtec Corporation is a leading global provider of equipment, systems, digital solutions and value-added services for freight and transit rail. Drawing on nearly four centuries of collective experience across Wabtec, GE Transportation and Faiveley Transport, the company has unmatched digital expertise, technological innovation, and world-class manufacturing and services, enabling the digital-rail-and-transit ecosystems. Wabtec is focused on performance that drives progress, creating transportation solutions that move and improve the world. Wabtec has approximately 27,000 employees in facilities throughout the world. Visit the company’s new website at:
http://www.WabtecCorp.com
.

It’s not just about your career… or your job title…it’s about who you are and the impact you are going to make on the world. Do you want to go into uncharted waters…do things that haven’t been done to make yours and someone else's life better? Wabtec has been doing that for decades and we will continue to do so! Through our people, leadership development, services, technology and scale, Wabtec delivers better outcomes for global customers by speaking the language of industry.
Who will you be working with?
Our best-in-class Data Services team combines knowledge of customers’ data and processes with deep domain expertise and tenured experience to deliver unparalleled data support services for our Digital Intelligence platform products. You will engage with customers daily to facilitate the triage and resolution of data-related issues. You will also collaborate with essential stakeholders to provide robust support for our customers and operations. This role will report to Director , Customer Support & Services
How will you make a difference?
As a member of the Customer Support and Services Database team, you will be responsible for examining and interpreting complex data from large-scale railroads, monitoring performance and quality control to identify any issues or ways to improve movement planning and dispatch systems and their related algorithms. Some manual testing will be required with an aim to move towards test automation. This role requires collaborating with database developers, data analysts, data quality engineers, senior management, and other external stakeholders to implement effective analysis, quality, and automation processes by developing queries in a SQL platform so that data can be mined for better quality control, accuracy, performance, and system stability.
What do we want to know about you?
You must have:
Bachelor’s degree in computer science, STEM (Science, Technology, Engineering, and Math), or a closely related field
Minimum of 3 years of professional experience in a data analysis, data science, or data validation position
Minimum of 1 year of Manual testing experience
Experience working with virtual machines (VMs) as part of a test/integration infrastructure
Experience working in Linux/Unix and Windows environments
Experience with R, python, or similar
Strong SQL querying abilities
Exposure to tools like Jenkins, Rally, Azure Dev-Ops etc.
Ability to work well in a team environment and display strong interpersonal skills
Ability to break down problems, document problem statements and estimate efforts
Strong technical aptitude, including, applicable engineering tools and systems
Experienced in Agile methodology (Kanban, Scrum, SAFe)
We would love it if you had:
Rail experience is a major plus!
Test automation experience
What will your typical day look like?
Interpret and analyze data using statistical techniques and provide ongoing reports on the effects of different strategies, observing any trends or issues that may arise.
Perform manual testing with an aim towards test automation.
Interpret test results and troubleshoot testing issues.
Work with mixed discipline team of database developers, data analysts, and data quality engineers alongside external customers to implement tools and strategies for more effective data collection, storage, configuration, quality, and implementation.
Perform data analytics and other strategies to optimize the efficiency and quality of data being collected.
Work with management to prioritize business and information needs and identify new processes that will improve the systems in place to define new opportunities.
What about the physical demands of the job?
Employee will be performing work that primarily involves sitting/standing.
Employee will spend a lot of time looking at a computer monitor.
Employee is regularly required to talk and hear.
Employee able to travel if needed less than 10%
Employee able to use a computer for programming and interacting with his team.
Employee will be repeating motions that may include the wrists, hands and/or fingers.
Employee will be communicating with others to exchange information.
You may also be asked to perform other duties outside of your function or trade, for which adequate training will be provided if necessary.
Relocation assistance may be provided if eligibility requirements are met.
Wabtec will only employ those who are legally authorized to work in the U.S. for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable) and fitness for duty test (as applicable).
Wabtec Corporation is committed to taking on the world’s toughest challenges. In order to fulfill that commitment we rely on a culture of leadership, diversity and inclusiveness. We aim to employ the world’s brightest minds to help us create a limitless source of ideas and opportunities. We believe in hiring talented people of varied backgrounds, experiences and styles…people like you! Wabtec Corporation is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, or protected Veteran status. If you have a disability or special need that requires accommodation, please let us know.",1869,Transportation Equipment Manufacturing,$5 to $10 billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Data and Control Systems Engineer II,"Relativity Space
","Cape Canaveral, FL",$108K - $138K (Employer est.),3.8,"Company Overview:

A rocket company at the core, Relativity Space is on a mission to become the next great commercial launch company. Meeting the needs of a growing demand for space infrastructure, our rockets will revolutionize how we connect and communicate on Earth by getting satellites to space. We have developed a vertically integrated technology platform in which we leverage additive manufacturing, artificial intelligence, and autonomous robotics to 3D print rockets. Our unique approach enables rapid product iteration, allowing us to push the boundaries of what's possible today and unlock the full potential of 3D printing for tomorrow. Join us on this extraordinary journey, as we work together to transform our vision into reality.

Team:

Relativity is seeking a highly talented Launch Instrumentation Specialist to join a rapidly growing space startup. As a Data and Controls Systems Engineer, your responsibilities will include the design, installation, and operations of data and control systems for the Terran R Launch pad. This includes instrumentation, pad construction, system build-up, activation, and launch operations to support the Terran R and the launch program. You will work closely with the launch engineering team, supporting activities required to get the launch pad built, activated, and operated through launch.

What you’ll do:

At Relativity, we are redefining the way rockets are designed, built and flown. Starting with our proprietary and cutting-edge 3D printing technology, we aim to simplify and automate the manufacturing of rockets. This revolutionary approach enables us to make launch vehicles faster and more cost efficiently, allowing us to offer cost-efficient and short lead-time launch services to our customers. You will support the Design, installation, and operations of Data and Control System hardware and various instrumentation required to create an operational launch site. Once the launch site is functional, you will provide system level troubleshooting and procedural support while conducting launches of Terran R.

As a Data and Controls Systems Engineer, you will be at the forefront of creating a world class orbital launch site. In order to be successful in this role, you should be someone who is able to create, design, and lead projects to completion; ideally, you are someone who has come from a fast paced, aerospace environment, having completed difficult projects while collaborating effectively across various groups. The ability to perform work at the highest quality with minimal direction across all major technical disciplines is key. You should have extensive experience in designing, installing, verifying, and troubleshooting sensors that measure temperature, pressure, flow, displacement, and vibration. Oscilloscopes, signal generators, and multi-meters are just a few of the tools that you should already know how to operate. You will also be responsible for providing feedback and communication with the launch engineering team to prevent issues and help improve the launch pad build/activation process.

What you need to know:

Bachelor’s degree in Mechatronics Engineering, Electrical Engineering, Computer Engineering, or related field
Hands on experience with Data Acquisition (DAQ) systems including sensors and actuators
Understanding of proper signal shielding and grounding for low noise systems
2+ years of experience designing, building, and testing electrical and software systems
Demonstrated experience with retrofit and clean sheet design of complex DAC systems
Experience identifying and implementing new project opportunities based on long term company goals
Track record of developing top engineering talent through mentorship and training

Nice to haves but not required:

Design and operation of spacecraft and launch vehicle ground infrastructure
Integration of communication interfaces such as Ethernet, RS422, RS232, RS485, Modbus, CANbus, etc
Programming experience in C/C++, Python, Java or similar languages
Experience in implementing industrial control systems derived from a P&IDs
Experience with general facility maintenance
Experience operating pressurized systems
Design of lightning protection systems for large metallic structures and mounted systems
Specification of sensing technologies for low and high data acquisition rates (100 Hz to 100 kHz and beyond) to measure values of interest directly and indirectly
Architecture of highly distributed data and control systems
Design of hardware and software systems that demand high-availability, high-reliability, and time-critical operation

Relativity Space offers competitive salary and equity, a generous vacation policy, an annual L&D stipend and more!

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

The below-range represents Relativity Space’s current good-faith pay scale for this role. Relativity Space reserves the right to modify or update this range at any time.

Compensation is only one part of our entire total rewards package. To see some of the benefits & perks we offer, please visit here: https://px.sequoia.com/relativityspace
Hiring Range:
$108,000—$138,000 USD",2016,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,501 to 1000 Employees,Company - Private,False
Data Quality Engineer,"RiseIT Solutions
","Orlando, FL",$120K (Employer est.),3.7,"Title: Data Quality Engineer
Location: Orlando, FL (100% onsite)
Type: Direct Hire Position
Rate: $120K per year + 8% annual bonus + full benefits + full relocation
Education: Bachelor's degree in IT related discipline or equivalent experience (BS / BA in MIS, Computer Science, Business, Mathematics or Engineering)
The responsibilities of the IT Engineer will provide technical expertise in developing and maintaining a data quality framework. This role will participate in the full data quality lifecycle from requirement elicitation through ongoing support. The candidate selected for this role will create technical design specifications from business/functional requirements or from logged data incidents. The position plays a pivotal role in the definition of our data quality program, which includes policy, process, standards, and tools. The role demands an ability to understand the data semantics, business use and relationships.
REQUIRED TECHNICAL SKILLS:
Strong understanding of data structures, data types, and data transformation.
Familiarity with industry data patterns, normalizations rules and data performance tuning.
Ability to perform complex data mappings, workflows and sessions.
Strong relational database skills and an understanding of columnar data structure.
Extensive experience with SQL, and other data transformation/analytics tools such as Informatica, Talend, or Alteryx.
Advanced expertise in reading, analyzing and debugging SQL.
Ability to troubleshoot data processing performance issue.
Experience or willingness to learn data profiling/quality tools such as Collibra, Ataccama, Informatica or OEDQ.
Experience or willingness to learn SparkSQL and Databricks.
Highly developed analytical, problem solving and debugging skills, with strong ability to quickly learn and comprehend business processes and problems in order to effectively analyze result set and triage quality issues.
Work with all levels of development from analysis through implementation and support.
Expertise in working with spreadsheets, strong understanding of financial concepts and data.
Ability to work independently, take ownership of tasks and follow through to implementation/resolution.
Resolve end user data problems through collaboration with both technical and functional personnel in a team environment.
Demonstrated competency in designing, developing and testing complex rule sets.
Demonstrated competency in accurately identifying the scope of work and preparing thorough, accurate and estimates.
Exceptional verbal and written communications skills, with an ability to express complex technical concepts in business terms.
Solid teamwork and interpersonal skills.
Strong analytical, problemsolving and conceptual skills.
REQUIRED EDUCATION:
Bachelor's degree in IT related discipline or equivalent experience (BS / BA in MIS, Computer Science, Business, Mathematics or Engineering)
OTHER KEY QUALIFICATIONS:
Data modeling Experience
Exposure to Cloud Infrastructure
Experience with Cloud Data Warehouse products such as Snowflake or Azure Synapse
Experience with data integration patterns, data pipelines and tools such as Azure Data Factory
Experience using reporting tools like Power BI for Data quality visualizations
Knowledge of Data and Delta Lake Structures
Experience with Python, Scala or Java
Knowledge of restaurant or retail business
SKILLS AND EXPERIENCE:
7+ years’ experience across Business Intelligence/Data Warehouse/Data Lake projects
2+ years’ experience on Data Quality and Governance initiatives, with at least one successful implementation
Experience programming in SQL with ability to develop complex queries against large disparate data sets",-1,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,201 to 500 Employees,Company - Private,False
Data Analytics Engineer - SOCOM,"Barbaricum
","Tampa, FL",$84K - $122K (Glassdoor est.),4.0,"Barbaricum is a rapidly growing government contractor providing leading-edge support to federal customers, with a particular focus on Defense and National Security mission sets. We leverage more than 15 years of support to stakeholders across the federal government, with established and growing capabilities across Intelligence, Analytics, Engineering, Mission Support, and Communications disciplines. Founded in 2008, our mission is to transform the way our customers approach constantly changing and complex problem sets by bringing to bear the latest in technology and the highest caliber of talent.


Headquartered in Washington, DC's historic Dupont Circle neighborhood, Barbaricum also has a corporate presence in Tampa, FL and Dayton, OH, with team members across the United States and around the world. As a leader in our space, we partner with firms in the private sector, academic institutions, and industry associations with a goal of continually building our expertise and capabilities for the benefit of our employees and the customers we support. Through all of this, we have built a vibrant corporate culture diverse in expertise and perspectives with a focus on collaboration and innovation. Our teams are at the frontier of the Nation's most complex and rewarding challenges. Join us.




Barbaricum is seeking a Data Analytics professional to provide support to a US Special Operations Command (USSOCOM) customer to integrate as part of a team that provides advanced analytical knowledge of data, with a focus on conducting big data analysis, data conditioning, programming, advanced computing, developing algorithms, developing software and data models, executing predictive analytics, and utilizing visualization tools in support of SOF Intelligence functions.
Responsibilities
Use technology to mine complex, voluminous, and different varieties of data from various sources and platforms in order to collect, analyze, and compile data to meet customer needs
Identify new sources of data and methods to improve data collection, analysis, and reporting
Collect customer requirements
Determine technical issues
Design algorithms and data manipulation capabilities using R, Python, C++, JavaScript, and other known programming languages
Build data solutions, tools, and capabilities to enable self-service frameworks for data consumers to monitor and report on data
Improve the quality of data use and usability by driving an understanding and adherence to the principles of data quality management including metadata, lineage, and business definitions
Work collaboratively with Intelligence and Data analysis teams to produce qualitative and quantitative data that support Intelligence products
Qualifications
Active DoD TS/SCI clearance
Possess a minimum of a bachelor's degree in a computer science OR a bachelor's degree in a non-related field and four years of relevant experience in Python, C++, JavaScript, or other programming languages
Professional experience on the command line in Python
Experience providing services similar in required tasks, scope, and complexity

Additional Information

For more information about Barbaricum, please visit our website at www.barbaricum.com. We will contact candidates directly to schedule interviews. No phone calls please.",2008,Business Consulting,$5 to $25 million (USD),Management & Consulting,51 to 200 Employees,Company - Private,True
Data Solutions Engineer,"Brown & Brown Insurance
","Daytona Beach, FL",$75K - $108K (Glassdoor est.),3.8,"Built on meritocracy, our unique company culture rewards self-starters and those who are committed to doing what is best for our customers.
It's an exciting time to join Brown & Brown! Our business is growing both in North America and internationally which emphasizes the need to build an unparalleled team that promotes future growth. We're excited to continue solidifying that foundation as we are looking for a Data Solutions Engineer to join our growing team in Daytona Beach, Florida, Atlanta, Georgia, or Dallas, Texas.
The Data Solutions Engineer is a member of the Enterprise Data Enablement team reporting to the Sr. Director, Enterprise Data Enablement. This experienced individual will support one or more divisions of Brown & Brown in defining their data strategy and in the design and delivery of the data solutions necessary to support the data strategy. They will serve as a mentor and subject matter expert for the embedded delivery, analytics and data science teams within the division(s).
Who We Are: Brown & Brown, Inc. is a growing global insurance brokerage firm delivering risk management solutions and services since 1939. Our unique culture is built on honestly, integrity, innovation and discipline and defines who we are and how we treat our customers, teammates and the communities we serve. We think of ourselves as a team, so we have teammates-not employees. We prioritize health, family, and business-in that order. We embrace and celebrate diversity, always striving to be an inclusive place where you have the power to be yourself. Traded on the New York Stock Exchange as BRO, Brown & Brown is a big company that doesn’t act like one.
Who We Are Looking For: We are looking for passionate team players who believe in working hard and having fun in a collaborative environment. Our team is customer-focused and values the importance of strong relationships, professionalism, and trust. We embrace solutions-oriented big thinkers who are committed to results and aren’t afraid to take risks. We are driven to set goals high and aim even higher.
General Responsibilities:
Partner with embedded delivery, analytics and data science teams to understand their business objectives and strategic initiatives.
Serve as a consultant to embedded delivery, analytics and data science teams in the development of their data strategy and the ideation, design and implementation of data solutions including data assets and insights.
Ensure data solutions adhere to relevant policies, standards, procedures and patterns.
Partner with the Enterprise Data Architecture and Enterprise Data Platform teams to align Modern Data Platform capabilities and roadmap in support of the data strategies and data solutions.
Promote re-use of data assets and insights across the organization.
Mentor and provide guidance to Data Engineers with respect to Modern Data Platform capabilities and technologies.
Provide leadership and oversight of third-party resources and services in the design and delivery of data solutions as needed.
Work well with co-located and distributed team members and partners.
Demonstrate a high degree of creativity and problem-solving skills.
Up to 50% travel
Other duties as assigned.
Required Qualifications:
Bachelor’s Degree in Computer Science or related field or equivalent work experience.
Experience designing and delivering solutions for data pipelines, data integration, data transformation, analytics, reporting and modeling (e.g. AI/ML).
Strong understanding of designing and delivering solutions in a cloud environment.
Deep understanding of data modeling, data management and data governance principles.
Passion for learning new technologies and enhancing existing skills.
Experience in end-to-end Software Development Life Cycle (SDLC) projects.
Experience working with key stakeholders and business leaders.
Excellent verbal and written communication skills.
Ability to build strong relationships and work collaboratively on teams.
Self-starter that works well and is able to be a leader in a matrixed team environment.
Ability to adapt and respond in a rapidly evolving business environment.
5+ years of related work experience.
Preferred Qualifications:
Experience designing and delivering solutions in an Azure cloud environment.
Experience with Azure Data Factory, Azure Synapse Analytics, Azure Databricks, Snowflake and/or equivalent cloud data technologies and platforms.
Experience defining and delivering solutions leveraging Data as a Product, Data as a Service, Data Mesh, Data Virtualization, Delta Lake, Lakehouse and/or Data Fabric.
Familiarity with SQL, Java and Python.
Experience working with Agile/Scrum methodologies.
Experience leading matrixed teams to architect and design platforms and solutions.
10+ years of related work experience.
Microsoft Azure Solutions Architect Expert, Azure Data Engineer Associate or equivalent certification(s).
Experience in the insurance industry and/or basic knowledge of insurance.
What we offer:
Excellent growth and advancement opportunities
Competitive pay based on experience
Discretionary Time Off (DTO)
Tuition Reimbursements and Student Loan Repayment Assistance Program
Mental Health Resources
We are an Equal Opportunity Employer. We take pride in the diversity of our team and seek diversity in our applicants.",1939,Insurance Agencies & Brokerages,$1 to $5 billion (USD),Insurance,5001 to 10000 Employees,Company - Public,False
Data Engineer III,"CAE
","Orlando, FL",$96K - $131K (Glassdoor est.),3.8,"Role and Responsibilities


Who We Are:

CAE Vision: Our vision is to be the worldwide partner of choice in defense and security, civil aviation, and healthcare by revolutionizing our customers’ training and critical operations with digitally immersive solutions to elevate safety, efficiency and readiness.
CAE Defense & Security Mission: CAE's Defense and Security business unit focuses on helping prepare military customers to develop and maintain the highest levels of mission readiness.
CAE Values: Empowerment, Innovation, Excellence, Integrity and OneCAE make us who we are and we strive to make a difference in the world while helping each other succeed.

What We Have to Offer:

Comprehensive and competitive benefits package and flexibility that promotes work-life balance
A work environment where all employees are valued, respected and safe
Freedom to succeed by enabling team members to deliver, take initiatives and make decisions
Recognition, professional development, advancement and having fun!

Summary

The Data Engineer III will support software developers, data analysts, and data scientists deliver robust data solutions from the ground up in support of applications and advanced analytics pipelines.

Essential Duties and Responsibilities

Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Identify, design, and implement internal process improvements for the automation of data flow, optimizing data delivery, re-designing infrastructure for greater scalability, etc
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and ‘big data’ technologies
Build processes supporting data transformation, data structures, metadata, dependency and workload management
Perform engineering tasks including writing and testing software, creating software tools, updating drawings and documentation
Develop documentation to support objectives of operationally-focused team members
Effectively Interface with customer personnel at varying organizational levels
Effectively report status on tasks and assignments and to support business development team in the production of winning proposals

Qualifications and Education Requirements

BS degree in Engineering discipline, Computer Science, Mathematics, or related field required
Experience manipulating, processing and extracting value from large disconnected datasets
Experience integrating data from diverse sources to a structured data repository ensuring the quality and consistency of data is maintained at all times
Advanced working knowledge of SQL language and experience with RDBMS, NoSQL DBs, Data Warehouses, big data repositories, and unstructured datasets
Strong analytic skills related to working with unstructured datasets
Advanced working knowledge of Python with the ability to write high performance code
Minimum 5 years’ experience implementing high performant data ingestion pipelines using one or more ETL/ELT tools (Talend, Informatica, etc) or workflow tools (Argo, AirFLow, etc)
You will be expected to support a diverse set of projects and teams. The skillsets required for this role will vary based on what systems you are working on. To be considered, you should have strong skills in 1 or more of the following categories
Programming language (Rust, C#, C++, C, Julia)
Database systems (PostgreSQL, MongoDB, Oracle, MSSql, etc)
Devops (Docker, Kubernetes, Jenkins, etc)
Cloud Systems (Azure, GCP, AWS)
Ability to effectively prepare and present information and respond to questions from peers, and customers
Must be able to perform effectively as part of a project ""team""
Must be self-motivated and expected to work independently with minimal supervision

Desired Skills

Experience with Agile Development
Experience using Git or other source code management system
Security clearance

Security Responsibilities

Must comply with all company security and data protection / usage policies and procedures. Personally responsible for proper marking and handling of all information and materials, in any form. Shall not divulge any information, or afford access, to other employees not having a need-to-know. Shall not divulge information outside company without management approval. All government and proprietary information will be accessed and stored electronically on company provided resources.

Due to U.S. Government contract requirements, only U.S. citizens are eligible for this role.

Work Environment and Physical Demands

May be required to sit down for long lengths of time.
May be required to climb stairs.

This job operates in a professional office environment. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines.

Other Duties

Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for their job. Duties, responsibilities, and activities may change at any time with or without notice.

CAE USA Inc. is an EOE/AA employer and gives consideration for employment to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. If you’d like more information about your EEO rights as an applicant under the law, please click here EEO is the Law poster.

PAY TRANSPARENCY NONDISCRIMINATION PROVISION The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information.

Position Type




Regular

CAE thanks all applicants for their interest. However, only those whose background and experience match the requirements of the role will be contacted.

Equal Employment Opportunity

At CAE, everyone is welcome to contribute to our success. With no exception.

As captured in our overarching value ""One CAE"", we’re proud to work as one passionate, boundaryless and inclusive team.

At CAE, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability, neurodiversity or age.

The masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.",1947,Aerospace & Defense,$1 to $5 billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
Traffic Management Center Data Engineer,"HNTB Corporation
","Bradenton, FL",$53K - $74K (Glassdoor est.),4.0,"What We're Looking For

At HNTB, you can create a career that is meaningful to you while building communities that matter to all of us. For more than a century, we have been delivering solutions for some of the largest, most complex infrastructure projects across the country. With our historic growth, it is an exciting time to join our team of employee-owners.

Data Engineer will build and maintain data pipelines and systems that support our data analysis and machine learning projects. You will be responsible for extracting, transforming, and loading data from various sources using SQL and AWS technologies, as well as creating and testing data models and schemas. You will also work closely with data scientists and analysts to provide them with the data they need to perform their tasks.

What You’ll Do:

On a task basis, is responsible for preparation and completion of basic tasks that are responsive to project needs.
Assists in developing using programming tools and languages, based upon the project’s Requirements Document and strong, direct supervision from the Senior Developer or Team Leader.
Provides basic user support for legacy applications for medium-complexity issues. Analyzes and solves simple technical problems with legacy applications.
Assists in developing enhancements for existing applications according to direction.
Submits code fixes for senior review/approvals.
Develops and maintains application documentation as appropriate. Codes, tests, debugs and refines programs under direct supervision.
Performs other duties as assigned.

What You’ll Need:

Bachelor's degree in Programming, Computer Science or related field
1 year related experience

What You'll Bring:

Design, develop, and deploy data pipelines and systems using SQL, AWS, Python, and other technologies
Implement best practices for data engineering, such as data modeling, data quality, data governance, data security, etc.
Perform data analysis, validation, and troubleshooting to ensure data accuracy and integrity
Monitor, optimize, and maintain existing data pipelines and systems for performance and scalability
Research and evaluate new data technologies and tools to improve data engineering processes and capabilities
Collaborate with cross-functional teams to understand business requirements and deliver data solutions that meet or exceed expectation

What We Prefer:

Master’s degree in Computer Science or Engineering
Proficiency in SQL queries and database management
Experience with AWS services such as S3, EC2, EMR, Lambda, etc.
with ETL tools and frameworks such as Airflow, Spark, Kafka, etc.
Basic knowledge of Python or other programming languages for data manipulation and automation
Ability to work in a team and communicate effectively

Additional Information

Click here for benefits information: HNTB Total Rewards

Click here to learn more about EOE including disability and vet

Visa sponsorship is not available for this position.

\#MD #Traffic

.

Locations:

Bradenton, FL

.

.

.

.

.

.

.

.

.

NOTICE TO THIRD-PARTY AGENCIES:

HNTB does not accept unsolicited resumes from recruiters or agencies. Any staffing/employment agency, person or entity that submits an unsolicited resume to this site does so with the understanding that the applicant's resume will become the property of HNTB. HNTB will have the right to hire that applicant at its discretion and without any fee owed to the submitting staffing/employment agency, person or entity. Staffing/employment agencies who have fee agreements with HNTB must submit applicants to the designated HNTB recruiter to be eligible for placement fees.

Job Type: Regular

Full/Part Time: Part time

Job Category: Technical Group

ReqID: R-17820",1914,Architectural & Engineering Services,$100 to $500 million (USD),"Construction, Repair & Maintenance Services",1001 to 5000 Employees,Company - Private,False
Big Data Software Engineer IV,"Availity, LLC.
",Florida,-1,4.4,"Availity delivers revenue cycle and related business solutions for health care professionals who want to build healthy, thriving organizations. Availity has the powerful tools, actionable insights and expansive network reach that medical businesses need to get an edge in an industry constantly redefined by change.
At Availity, we're not just another Healthcare Technology company; we're pioneers reshaping the future of healthcare! With our headquarters in vibrant Jacksonville, FL, and an exciting office in Bangalore, India, along with an exceptional remote workforce across the United States, we're a global team united by a powerful mission.

We're on a mission to bring the focus back to what truly matters – patient care. As the leading healthcare engagement platform, we're the heartbeat of an industry that impacts millions. With over 2 million providers connected to health plans, and processing over 13 billion transactions annually, our influence is continually expanding.

Join our energetic, dynamic, and forward-thinking team where your ideas are celebrated, innovation is encouraged, and every contribution counts. We're transforming the healthcare landscape, solving communication challenges, and creating connections that empower the nation's premier healthcare ecosystem.
Reporting to the Manager, Applications Development the Big Data Software Engineer IV will work on a dedicated team of engineers developing, enhancing, and maintaining Availity’s high transactional Provider Data Management platform. This team directly supports one of our largest clients, Elevance.
Sponsorship, in any form, is not available for this position.
Location: Remote US – Eastern Time Zone Preferred
Why work on this team:
This team supports a high transactional platform that directly impacts patient experience
This team is working to continually improve process and enhance platform capabilities
What you will be doing:
Participating in daily stand ups at 10:00am ET
Participating in weekly planning and refinement meetings
Working on a team dedicated to our Elevance client
Working on ETL transformation which includes gathering raw data and files from the client, transforming it into Availity’s format and sending down the ETL pipeline for further processing
Working with a team of 3 engineers
Utilizing JIRA for project planning and tracking
Collaborating with the Product Owner on a regular basis
Interacting with the end client on a daily basis via email, call or virtual meeting
Solving healthcare problems and improving processes
Implementing a backlog of items to fulfill a focused roadmap
Working on a team following Agile Scrum principles
Incorporating development best practices
Ensuring your code is efficient, optimized, and performant
Collaborating on programming or development standards
Maintaining technical debt and applying security principles
Reviewing the code of others while receiving feedback to ensure code quality
Innovating with ideas and products to the organization
Performing unit testing and complex debugging to ensure quality
Learning new things & sharing your knowledge with others
Requirements:
Bachelor’s degree preferably Computer Science, Engineering, or other quantitative fields
7+ years of related experience in designing and implementing enterprise applications using big data
3+ years of experience in a senior level engineering role mentoring other engineers, which includes engineering best practices, unblocking, code reviews, unit testing, managing deployments, technical guidance, system design, etc.
5+ years of experience working with Java EE
5+ years of experience working with large-scale data and developing SQL queries
3+ years of hands-on experience with AWS cloud services, such as Apache Spark, with Scala, AWS EMR, Airflow, RedShift
3+ years of experience with RESTFul APIs and web services
Excellent communication skills including discussions of technical concepts, soft skills, conducting peer-programming sessions, and explaining development concepts
Experience with RedShift is a plus
Experience with Airflow is a plus
Experience with AWS is a plus
Experience in the healthcare industry or another highly regulated field is a plus
Availity culture and benefits:
Availity is a certified “Great Place to Work”, a “Best Workplaces for Technology Companies”, a “Best Workplaces for Women” and a “Best Workplaces for Millennials”!
Culture is important to us and there are many ways for you to make your mark here!
We have several Diversity & Inclusion teams and various ways to engage with fellow Availity associates. “Availadies”, “Beyond Black”, “HOLA”, “Availity Pride”, “VetAvaility” a Young Professionals Group and “She Can Code IT” a group for women in tech are some of the groups you can get involved in.
Availity is a culture of continuous learning. We have many resources and experts in our tech stack and in our industry that can help get you there too!
We offer a competitive salary, bonus structure, generous HSA company contribution, healthcare, vision, dental benefits and a 401k match program that you can take advantage of on day one!
We offer unlimited PTO for salaried associates + 9 paid holidays. Hourly associates start at 19 days of PTO and go up from there with all the same holiday benefits.
Interested in wellness? We allow our associates to reimburse up to $250/year for gym memberships, participation in racing events, weight management programs, etc.
Interested in furthering your education? We offer education reimbursement!
Availity offers Paid Parental Leave for both moms and dads, both birth parents and adoptive parents.
Want to work for an organization that gives back to the community? You’re at the right place! Availity partners with various organizations, both locally and nationally, to raise awareness, funds and morale as our staff members volunteer their time and funds to engage the organizations campaign.
Next steps in process:
After you apply, you will receive text/email messages thanking you for applying and then you will continue to receive more text/email messages alerting you as to where you are in the recruitment process.
Interview process:
Recruiter resume review
Manager resume review
Recruiter video interview
Manager video interview
Technical assessment
Panel video interview
Availity is an equal opportunity employer and makes decisions in employment matters without regard to race, religious creed, color, age, sex, sexual orientation, gender identity, gender expression, genetic information, national origin, religion, marital status, medical condition, disability, military service, pregnancy, childbirth and related medical conditions, or any other classification protected by federal, state, and local laws and ordinances.

Availity is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.

NOTICE: Federal law requires all employers to verify the identity and employment eligibility of all persons hired to work in the United States. When required by state law or federal regulation, Availity uses I-9, Employment Eligibility Verification in conjunction with E-Verify to determine employment eligibility. Learn more about E-Verify at
http://www.dhs.gov/e-verify
.",2001,Information Technology Support Services,$100 to $500 million (USD),Information Technology,1001 to 5000 Employees,Company - Private,False
Senior Data Ops Engineer (R-15257),"Dun & Bradstreet
","Jacksonville, FL",$86K - $120K (Glassdoor est.),3.9,"Why We Work at Dun & Bradstreet
Dun & Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!

This Role:
Develop, maintain, and analyze datasets from diverse sources, including mobile and web, government agencies, web crawls, social media, and proprietary datasets, to create insights for our clients, power our platform, and create an innovative market understanding. Create designs and share ideas for creating and improving data pipelines and tools.

This position is a hybrid role and will need to be in Jacksonville office 3 days a week - NO REMOTE
Key Requirements:
Collaborate with the data, platform, QA, and DevOps teams to design and construct advanced systems for processing, analyzing, searching, and visualizing vast datasets.
Architect resilient systems and write highly fault-tolerant software to consistently deliver high-quality results.
Take initiative to become familiar with existing application code and achieve a complete understanding of how the applications function.
Pioneering novel methods for extracting intelligence from a wide array of unique data sources.
Generate fresh insights for our clients, provide novel perspectives on their markets.
Co-create and document data processing systems that are easy to maintain, fostering collaborative and supportive team environment.
Help maintain existing systems, including troubleshooting and resolving alerts.
Be a good collaborator with your peers. Be easy to get ahold of and attend all required meetings.
Share ideas across teams to spread awareness and use of frameworks and tooling.
Share a friendly, supportive, and reliable attitude with a great team that hold each other accountable.

This position is a hybrid role and will need to be in office 3 days a week - NO REMOTE
Key Requirements:
Extensive experience working with GCP services, including Big Query, Dataflow, Pub/Sub, Cloud Storage, Cloud Run, Cloud Functions and related technologies is required.
Extensive experience with SQL and relational databases, including optimization and design.
Expertise in containerized infrastructure and CI/CD systems, including CloudBuild, Docker, Kubernetes, and GitHub Actions.
Testable and efficient Python coding for data processing and analysis.
Experience with Amazon Web Services (EC2, RDS, S3, Redshift, EMR, and more).
Experience with OS level scripting (bash, sed, awk, grep, etc.).
Experience in AdTech, web cookies, and online advertising technologies.
Familiarity with parallelization of applications on a single machine and across a network of machines.
Experience with version control (GIT/Github/BitBucket) and Agile Project Management tools (Clickup/Jira/Confluence).
Experience with object-oriented programming, functional programming a plus
Analytic tools and ETL/ELT/data pipeline frameworks a plus.

This position is a hybrid role and will need to be in office 3 days a week - NO REMOTE
Benefits We Offer
Generous paid time off in your first year, increasing with tenure.
Up to 16 weeks 100% paid parental leave after one year of employment.
Paid sick time to care for yourself or family members.
Education assistance and extensive training resources.
Do Good Program: Paid volunteer days & donation matching.
Competitive 401k & Employee Stock Purchase Plan with company matching.
Health & wellness benefits, including discounted Gympass membership rates.
Medical, dental & vision insurance for you, spouse/partner & dependents.
Learn more about our benefits: http://bit.ly/41Yyc3d.

All Dun & Bradstreet job postings can be found at https://www.dnb.com/about-us/careers-and-people/joblistings.html. Official communication from Dun & Bradstreet will come from an email address ending in @dnb.com.

Notice to Applicants: Please be advised that this job posting page is hosted and powered by Lever. Your use of this page is subject to Lever's Privacy Notice and Cookie Policy, which governs the processing of visitor data on this platform.

Equal Employment Opportunity (EEO): Dun & Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law. View the EEO is the Law poster here and its supplement here. View the pay transparency policy here.",1841,Information Technology Support Services,$1 to $5 million (USD),Information Technology,5001 to 10000 Employees,Company - Public,True
Python Data Engineer,"INTELETECH GLOBAL INC
","Altamonte Springs, FL",$60.00 - $70.00 Per Hour (Employer est.),3.7,"Job Role: Python Data Engineer - 4 openings
Location: Wilmington, DE
Duration: 6+ months contract to hire
Visa: (H4, L2, TN, USC, GC, GCEAD)
Pay rate: $60-70/hr on w2

Preferred Skills:


Expert level SQL knowledge with strong complex query writing skills
4-5 years of experience with big data – preferably in a large complex organization
4-5 years of Data Engineering/Data Analytics/Business Intelligence
4-5 years of legacy ETL experience
4-5 years of hands on Pipeline Development Experience with Apache Spark
4-5 years Years experience with RDBMS such as Oracle,DB2 MySQL, Teradata Hive
4-5 years Years experience with No SQL database such as Hbase, DynamoDB, MongoDB, Cassandra Experience with Cloud/Virtual warehouse systems such as Snowflake/Redshift.
Distributed computational framework experience required AWS solutions and data experience preferred - Glue Any related experience in the distributed event streaming platforms such as Kafka, Kinesis etc",-1,Accounting & Tax,Unknown / Non-Applicable,Financial Services,1 to 50 Employees,Company - Private,True
Senior Data Engineer (AWS),"Raymond James Financial
","Saint Petersburg, FL",$100K - $140K (Employer est.),4.1,"The Senior Data Engineer works as part of the Enterprise Data Team and will be responsible for developing Data Integration solutions in support of a critical data platform. The Senior Data Engineer plays a key role in the journey of Raymond James to develop a leading Wealth Management Platform. This position will have extensive contact with multiple application development teams and other shared services teams. This role will follow a hybrid workstyle in one of the following locations: Saint Petersburg, FL or Denver, CO.

Essential Duties and Responsibilities:

Responsible for developing highly optimized low latency Data Integration solutions.
Responsible for writing code which conforms to standards and best practices and is highly efficient.
Responsible for understanding deeply the end-to-end data requirements, application and service requirements and designing end to end data solutions.
Work with other Data Engineers and Architecture as part of database design and development.
Performs other duties and responsibilities as assigned.

Qualifications


Knowledge, Skills, and Abilities:

Knowledge of:

Previous experience with Oracle, SQL Server, SSIS, Oracle Data Integrator or Informatica is a plus.
Experience with AWS is preferred.
Experience with Data Warehouse and Big Data concepts across both batch and streaming patterns.
Understanding of Master Data Management (MDM) and data modeling concepts.
Creating patterns for adoption from scratch and being able to document and articulate coding and architecture standards for others to follow.
Performance tuning and optimization of code and infrastructure.
Creating a culture of continuous improvement, performs code reviews and makes recommendations for improvement or streamlining patterns.
Financial Services industry knowledge is a plus.

Skill in:

Must have relevant experience in various database platforms, ETL solutions/products, ETL architecture.
Experience with Oracle or RedShift (or similar DB platforms), ETL architecture and development.
Experience using Python, Glue, Spark and Kafka technologies with knowledge of migrating from existing legacy to modern cloud environments – including implementing SRE and CI/CD concepts.
Experience in Performance Optimization of ETL and Database (Oracle – SQL, PLSQL or similar)
Expert level experience with efficient Data Integration patterns/technologies.
Experience in building low latency Data Integration solutions.

Ability to:

Identify and understand issues, problems and opportunities; compare data from different sources to draw conclusions.
Clearly convey information and ideas through a variety of media to individuals or groups in a manner that engages the audience and helps them understand and retain the message.
Use effective approaches for choosing a course of action or developing appropriate solutions; recommend or take action that is consistent with available facts, constraints and probable consequences.
Demonstrate a satisfactory level of technical and professional skill or knowledge in position-related areas; remains current with developments and trends in areas of expertise.
Develop and use collaborative relationships to facilitate the accomplishment of work goals.
Make internal and external clients and their needs a primary focus of actions; develop and sustain productive client relationships.
Occasionally work a non-standard shift including nights and/or weekends and/or have on-call responsibilities.

Education/Previous Experience:

Minimum of a Bachelor’s degree in Computer Science, MIS or related degree and three (3) to five (5) years of relevant development or engineering experience or combination of education, training and experience.

Licenses/Certifications:

None required.

Raymond James Guiding Behaviors

At Raymond James our associates use five guiding behaviors (Develop, Collaborate, Decide, Deliver, Improve) to deliver on the firm's core values of client-first, integrity, independence and a conservative, long-term view.
We expect our associates at all levels to:

Grow professionally and inspire others to do the same
Work with and through others to achieve desired outcomes
Make prompt, pragmatic choices and act with the client in mind
Take ownership and hold themselves and others accountable for delivering results that matter
Contribute to the continuous evolution of the firm


At Raymond James – as part of our people-first culture, we honor, value, and respect the uniqueness, experiences, and backgrounds of all of our Associates. When associates bring their best authentic selves, our organization, clients, and communities thrive. The Company is an equal opportunity employer and makes all employment decisions on the basis of merit and business needs.
Job Technology
Primary Location US-FL-St. Petersburg-Saint Petersburg
Other Locations US-FL-St. Petersburg-Saint Petersburg, US-CO-Denver-Denver
Organization Technology
Schedule Full-time
Shift Day Job
Travel Yes, 5 % of the Time

Salary Range: CO, NY, CA, WA (based on Education, Work Experience, and Geographic Location) $100,000 - $140,000
Eligible for Discretionary Bonus Yes
#LI-NM1",1962,Investment & Asset Management,$5 to $10 billion (USD),Financial Services,10000+ Employees,Company - Public,False
Lead Data Engineer,"DICK'S Sporting Goods
","Pembroke Pines, FL",$95K - $159K (Employer est.),3.7,"At DICK’S Sporting Goods, we believe in how positively sports can change lives. On our team, everyone plays a critical role in creating confidence and excitement by personally equipping all athletes to achieve their dreams. We are committed to creating an inclusive and diverse workforce, reflecting the communities we serve.

If you are ready to make a difference as part of the world’s greatest sports team, apply to join our team today!

OVERVIEW:

At Dicks Sporting Goods we are creating the future of sports, driven by powerful data products and platforms that serve our Athletes and Teammates.

We are looking for a Lead Data Engineer to join our passionate team, adding your background and experience making us even stronger. In this role, you will build dataset and make them accessible to our partner teams by writing great code to simplify the complexity and ensure quality. Your work will enable product teams, data science, and decision-makers across the company to bring together insights and inform our business.

At Dick’s Sporting Goods are constantly seeking to improve ourselves. We believe that trusted, easy to consume data is the critical and as a Lead Data Engineer your work will help to build that foundation.

What you will do:

Own Data Domains and Data Solutions across entire life cycle while utilizing strong problem-solving ability.

Participate in design sessions and code reviews to elevate the quality of data engineering across the organization.

Participate in an on-call rotation for support during and after business hours.

Lead design sessions and code reviews to elevate the quality of data engineering across the organization.

You’ll be working with a variety of internal teams — Engineering, Business — to help them solve their data needs

Your work will provide teams with visibility into how DICKs products are being used and how we can better serve our customers

Identify data needs for business and product teams, understand their specific requirements for metrics and analysis, and build efficient and scalable data pipelines to enable data-driven decisions across DICKs.

Experience in one or more of the following: Python (Preferred), Scala, C++, or Java.

Design, develop, reliable data models and extremely efficient pipelines to build quality data and provide intuitive analytics to our partner teams.

Help the Data Analytics & Data Science team apply and generalize statistical and econometric models on large datasets

Mentor and Lead engineering teams and team members in software delivery within Data in an Agile Environment

Drive the collection of new data and the refinement of existing data sources, develop relationships with production engineering teams to manage our data structures as the Stripe product evolves

Develop strong subject matter expertise and manage the SLAs for those data pipelines

Participate in design sessions and code reviews to elevate the quality of data engineering across the organization.

Participate in an on-call rotation for support during and after business hours.

Lead design sessions and code reviews to elevate the quality of data engineering across the organization.

QUALIFICATIONS:

10+ years of experience in Data Warehousing and development using data technologies such as Relational & NoSQL databases, open data formats, building data pipelines (ETL and ELT) with batch or streaming ingestion, loading and transforming data.

BS or MS or PhD in Computer Science or a related technical field, or equivalent work experience

Expert in SQL and/or SQL based languages and performance tuning of SQL queries

Strong understanding of Normalized/Dimensional model disciplines and similar data warehousing techniques.

Experience in one or more of the programming languages are required: Python (Preferred), Scala, C++, or Java, Go, Kotlin.

Strong experience working with ETL/ELT concepts of data integration, consolidation, enrichment, and aggregation in petabyte scale data sets.

Experience with at least one of the following cloud platforms: Microsoft Azure (Preferred), Amazon Web Services (AWS), or Google Cloud Platform (GCP)

Strong Experience with cloud-based data warehouses – e.g., Snowflake, Big Query, Synapse, RedShift, etc.

#LI-HC1

Targeted Pay Range: $95,200 – $158,800. This is part of a competitive total rewards package that could include other components such as: incentive, equity and benefits. Individual pay is determined by a number of factors including experience, location, internal pay equity, and other relevant business considerations. We review all teammate pay regularly to ensure competitive and equitable pay.",1948,Sporting Goods Stores,$5 to $10 billion (USD),Retail & Wholesale,10000+ Employees,Company - Public,False
Cloud Data Platform Engineer,"Accenture Federal Services
","Tampa, FL",$81K - $117K (Glassdoor est.),4.1,"At Accenture Federal Services, nothing matters more than helping the US federal government make the nation stronger and safer and life better for people. Our 13,000+ people are united in a shared purpose to pursue the limitless potential of technology and ingenuity for clients across defense, national security, public safety, civilian, and military health organizations.
Join Accenture Federal Services to do the work you love in an inclusive, collaborative, and caring community, where you can be empowered to grow, learn and thrive through hands-on experience, certifications, industry training and more.
Join us to drive positive, lasting change that moves missions and the government forward!


You are:

A Data Engineering pro—someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You're passionate about digital technology, and you take pride in making a tangible difference. Complex issues don't faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy. As part of our AI & Technology group, you will lead cloud technology innovation for our clients through robust delivery of world-class data platforms. There will never be a typical day and that's why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing cloud data landscape.

The work:

You help build the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, and recent advances in distributed systems. You develop and drive automated solutions and solve challenging data integration problems utilizing optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources.

Qualifications:

Experience with SQL, data modeling, and building ETL pipelines
Knowledge of data management fundamentals and data storage principles
Experience in coding and automating processes
Cloud Data Services experience through certification, education, or hands-on experience

Bonus Points:

Data Warehousing
Object-oriented languages
Schema design

Eligibility Requirements:

US Citizenship required




ALL EXPERIENCED HIRE

Compensation for roles at Accenture Federal Services varies depending on a wide array of factors including but not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture Federal Services provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York, or Washington State as set forth below and information on benefits offered is here.

Role Location: Range of Starting Pay for role:

California: $67,200-$120,000

Colorado: $67,200-$103,600

New York: $62,100-$120,000

Washington State: $71,500-$110,400



What We Believe
We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture Federal Services has the responsibility to create and sustain an inclusive environment.
Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here
Equal Employment Opportunity Statement
Accenture Federal Services is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.
All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.
Accenture is committed to providing veteran employment opportunities to our service men and women.
For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.
Requesting An Accommodation
Accenture Federal Services is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture Federal Services and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.
If you are being considered for employment opportunities with Accenture Federal Services and need an accommodation for a disability or religious observance during the interview process or for the job you are interviewing for, please speak with your recruiter.
Other Employment Statements
Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.
Candidates who are currently employed by a client of Accenture Federal Services or an affiliated Accenture business may not be eligible for consideration.
Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.
The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",1989,Business Consulting,Unknown / Non-Applicable,Management & Consulting,10000+ Employees,Subsidiary or Business Segment,False
Principal Analytical Data Engineer - Healthcare,"ADP
","Miami, FL",-1,3.9,"ADP is hiring a Principal Analytical Data Engineer for our newly formed HR Outsourcing (HRO) Data and Analytics organization. The Principal Analytical Data Engineer will play a key role in growing our newest chapter of analytics engineering professionals while interacting with cross-functional teams to address complex business requirements. We're seeking a value seeking, self-motivated, and analytical profession who act as a player and coach to multiple workstreams at the same time. The role demands the individual to possess technical skills required to perform the job in an effective manner. The right candidate will be a technical expert, should have the passion for data & analytics and works along with the team they manage.

What are we looking for?

An analytics and data engineering professional with a passion and track record for designing analytics and delivery methods to increase accuracy of reporting and advanced analytics in an agile environment to unlock transformational growth. Someone with intellectual curiosity who wakes up excited to work with a team towards excellence and partner with leaders to drive business outcomes and deliver analytical solutions. The ideal candidate is business-minded, customer-centric, team-oriented, self-motivated, a strategic thinker and results-driven.

Like what you see? Apply now!
Learn more about ADP at tech.adp.com/careers
Learn more about Client Services at ADP: https://adp.careers/Client_Services_Videos

A little about ADP: We are a global leader in HR technology, offering the latest AI and machine learning-enhanced payroll, tax, HR, benefits, and much more. We believe our people make all the difference in cultivating an inclusive, down-to-earth culture that welcomes ideas, encourages innovation, and values belonging. ADP has a deep commitment to diversity, equity, and inclusion as a global Best Places to Work, DiversityInc® Top 50 Company, Best CEO and company for women, LGBTQ+, multicultural talent, and more. Learn more about ADP's commitment on our YouTube channel: http://adp.careers/DEI_Videos

WHAT YOU'LL DO:

Behaviors:

Lead workstreams that thrive.As an experienced leader, you want everyone to shine. You are constantly looking for ways to share your knowledge, motivate others, and keep everyone engaged and productive.
Customer focused.You marry data strategy to business strategy. A trusted partner to key stakeholders across business and analytics functions who understands how data can be activated to deliver value. Your teams are responsible for democratizing data for data science and advanced applications.
Clear Communicator. Ability to tell data stories to senior leaders and communicate working plans to the team. Excellent communication skills, both verbal and written; able to communicate effectively with multiple leadership layers and across a broad base of team members. Effective at increasingly complex stakeholder alignment, where priorities often compete, drives transparency on priorities and expected return
Create Results.You're proactive and hands-on when needed. When you see a potential issue, you never leave things hanging and unfinished. When you and your team deliver a finished product, it's as polished as you could make it.
Variety of work.There is no typical day. You could be checking in with the CDO one minute, meeting with leadership to review initiatives for the coming quarter later and tomorrow helping your team overcome blockers.
Influence and inspire confidence. You are comfortable presenting to senior leaders, analytics and program management leads, and peers with a compelling voice that you demonstrate through executive presence, leading change, and creating clear executive-level communications on milestone achievements.
Continuous improvement. Document current analytics and automation processes and recommend and implement best practices to improve and optimize.
Inevitable challenges will arise, and we'll rely on you to look for a solution.

Responsibilities:

Strategic Data Solution Development: Be the primary contributor to the development of data solutions with a strategic outlook, focusing on the broader scope of building and enhancing domains within the semantic layer of HRO.
Documentation and Best Practices: Catalog existing analytics and automation processes, and provide recommendations for best practice methods to optimize and improve these processes.
Collaborative Stakeholder Engagement: Collaborate closely with Strategic Pod Operations, Data Science, Business Intelligence, and Senior Leadership to create comprehensive roadmaps and execute project plans within a fast-paced agile development environment.
Data Engineering Expertise: Lead and create the development of data tables tailored to specific use-cases by skilfully engineering critical elements from multiple data domains. Ensure the ingestion of HRO-specific data is well-structured, compliant with data quality standards, and traceable from the consumption layer back to the raw data layer.
Strategic Integration and Security: Partner with the Data Operations, Data Governance and Strategic Pod Operations teams to streamline data integration, maintain data security, and access best practices. Contribute to the creation of end-to-end data analytics solutions.
Technological Advancement: Conduct thorough research to identify and recommend cutting-edge technologies and processes that support rapid scaling and future growth initiatives.
Prioritization and Delivery: Spearhead the prioritization of Business Needs, Leadership Questions, and Ad Hoc Requests to ensure on-time delivery and alignment with organizational goals.
Quality Assurance: Drive the quality assurance and data quality efforts to enhance development timelines, reduce bugs, and maintain the reliability of our analytics products.
Iterative Development: Bring your experience in developing v0.5 solutions, incorporating real-world feedback, and iterating to v1.0+ with a continuous improvement mindset.
Exceptional Delivery: Leverage your successful track record of superior delivery and change management within an enterprise organization to drive positive change and growth.

To succeed in this role:

Educational Background: Possess a bachelor's degree in computer science, engineering, business, statistics, or related fields; advanced degrees are preferred but not mandatory.
Experience: Demonstrate a strong foundation in data analytics, engineering, and project management with a minimum of 12 years of hands-on experience in the implementation, development, improvement, and support of data-related projects.
Matrix Organization Experience: Showcase 3+ year of experience working in a matrix organization, where you directed the development team to achieve use case goals.
Data Expertise: Exhibit deep experience with ETL (Extract, Transform, Load), Data Modeling, and Data Architecture, highlighting your ability to design and maintain data solutions.
Industry Knowledge: Preference will be given to candidates with a background in PEO, Service, or Risk analytics, data engineering, data analytics and visualization, business intelligence, or analytical consulting.
Healthcare Expertise: 5+ years of experience in the Health Insurance industry is preferred.
Problem-Solving Aptitude: Prove your ability to lead a team in leveraging data, analytics, and business acumen to address intricate business challenges.
Data Warehouse and Big Data Experience: Possess hands-on experience in designing and maintaining data warehouses and/or data lakes using big data technologies such as Hadoop, Spark, and specially DataBricks. Demonstrate expertise in managing data housed in various relational databases.
Data Pipeline Proficiency: Showcase your expert competence in building data pipelines and deploying/maintaining them using tools like Git and Jenkins.
MLOps and Containerization Knowledge: Familiarity with MLOps infrastructure (e.g., Databricks, MLflow) and containerization, including experience in managing production pipelines and microservices using technologies like Docker and Kubernetes.
Data Analytics Skills: Demonstrate experience and expertise in data mining methods, data modeling, and working with data warehouses, showcasing your ability to extract valuable insights.




Technical Skills: Exhibit mastery in Pyspark and SQL, as well as an understanding of agile methodologies and the key factors that contribute to a team's success Preferred Qualifications

Proficiency in DataBricks: Hands-on experience and strong technical knowledge with DataBricks, particularly focusing on Apache Spark fundamentals, including Spark Architecture, its API's, and how to leverage it for data processing and analysis. Proficiency in Pyspark/Python/SQL is essential for data manipulation, analysis, and transformation.
AWS Certification: AWS certification is highly desirable, reflecting your expertise in cloud technologies and services.
Framework Development: Experience in developing frameworks and utility services, including logging/monitoring, is a valuable asset, demonstrating your ability to create efficient and scalable solutions.
Programming Skills: Proficiency in UNIX and the Python programming language is essential, as it is fundamental for data engineering tasks.
Software Development Best Practices: Proven experience in delivering high-quality software following continuous delivery practices and using code quality tools such as JIRA, GitHub, and Jenkins is a strong advantage.
Data Storage Solutions: Comfort with a variety of data storage solutions, including RDBMS (e.g., Oracle), Hive, HBase, Impala, and other options, showcases your versatility in handling different data storage needs.
NoSQL Databases: Knowledge of NoSQL databases like MongoDB, HBase, Cassandra, etc., is a plus, highlighting your familiarity with a range of data storage technologies.
Project Management Tools: Familiarity with Jira and Confluence is preferred, as it facilitates effective project management and documentation.
Data Solutions Architecture: While not mandatory, experience as a data solutions architect is considered a significant advantage, demonstrating your ability to design comprehensive data solutions.
Cloud Database Technologies: Experience with cloud database technologies, especially in the AWS environment, and the ability to develop solutions on cloud computing services and infrastructure in the data and analytics space is a valuable skill set.
PySpark Expertise: Comfort with using PySpark APIs to perform advanced data transformations is a key technical requirement.

YOU'LL LOVE WORKING HERE BECAUSE YOU CAN:

Have courageous team collaboration. Courage comes from how associates are willing to have difficult conversations, speak up, be an owner, and challenge one another's ideas to net out the best solution.
Deliver at epic scale. We deliver real user outcomes using strong judgment and good instincts. We're obsessed with the art of achieving simplicity with a focus on client happiness and productivity.
Be surrounded by curious learners. We align ourselves with other smart people in an environment where we grow and elevate one another to the next level. We encourage our associates to listen, stay agile, and learn from mistakes.
Act like an owner & doer. Mission-driven and committed to leading change, you will be encouraged to take on any challenge and solve complex problems. No tasks are beneath or too great for us. We are hands-on and willing to master our craft.
Give back to others. Always do the right thing for our clients and our community and humbly give back to the community where we live and work. Support our associates in times of need through ADP's Philanthropic Foundation.
Join a company committed to equality and equity. Our goal is to impact lasting change through our actions.

What are you waiting for? Apply today!
Find out why people come to ADP and why they stay: https://youtu.be/ODb8lxBrxrY
(ADA version: https://youtu.be/IQjUCA8SOoA )

#LI-PP1
#LITECH

Diversity, Equity, Inclusion & Equal Employment Opportunity at ADP: ADP affirms that inequality is detrimental to our associates, our clients, and the communities we serve. Our goal is to impact lasting change through our actions. Together, we unite for equality and equity. ADP is committed to equal employment opportunities regardless of any protected characteristic, including race, color, genetic information, creed, national origin, religion, sex, affectional or sexual orientation, gender identity or expression, lawful alien status, ancestry, age, marital status, or protected veteran status and will not discriminate against anyone on the basis of a disability. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.

Ethics at ADP: ADP has a long, proud history of conducting business with the highest ethical standards and full compliance with all applicable laws. We also expect our people to uphold our values with the highest level of integrity and behave in a manner that fosters an honest and respectful workplace. Click https://jobs.adp.com/life-at-adp/ to learn more about ADP's culture and our full set of values.",1949,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Principal Engineer - Data Integration,"Cendyn
","Boca Raton, FL",$96K - $142K (Glassdoor est.),3.8,"Job Overview:

We are seeking a highly skilled and experienced Principal Engineer to lead our Data Integration team. As a Principal Engineer, you will be responsible for architecting, designing, and delivering complex data integration projects. You will collaborate with cross-functional teams, leveraging your expertise in C# .NET technology, Rest API, SQL, Azure technologies, and data integration services to create seamless solutions tailored to our industry requirements.

Key Responsibilities:

Collaborate with cross-functional teams to design, develop, and maintain industry-specific data integration applications using C# .NET, Rest API, SQL, Azure technologies, and data integration services.
Evaluate operational feasibility by conducting detailed analysis, defining problems, and proposing effective solutions tailored to industry-specific challenges.
Provide strategic architectural blueprints and technical leadership across the technology team, ensuring alignment with industry best practices and standards.
Lead new technology research, concept specification, and design of software components to address unique industry demands.
Supervise and oversee the technical aspects of integration projects, ensuring compliance with industry-specific regulations and optimal software performance.
Mentor and support development staff, fostering a culture of innovation, collaboration, and continuous learning within the team.
Lead the hiring and training initiatives for the Data Integration team, ensuring the recruitment of top-tier talent and providing comprehensive training programs for skill enhancement and professional growth.
Collaborate closely with the Product team to collect industry-specific requirements, providing expert technical guidance on business solutions.
Enforce and evolve software development standards and best practices relevant to our industry sector.

Qualifications:

Bachelor’s degree in Computer Science or related field; Master’s degree preferred.
8-12 years of professional experience in developing and deploying industry-specific web-based software solutions.
Proficiency in C# .NET, Rest API, SQL Server, .Net core, message queueing, and familiarity with industry-specific design patterns and architectural concepts (e.g., MVC, DI, Restful API, Microservice).
Strong understanding of cloud-based infrastructure development, such as Azure or AWS, tailored to industry requirements.
Experience with Agile (Scrum) Software Development Process and methodologies, emphasizing industry-specific workflows.
In-depth knowledge of industry-specific database management and security standards, ensuring data integrity and confidentiality.
Proven track record in developing and maintaining enterprise multi-tenant SaaS systems within the industry.
Excellent analytical and communication skills, with the ability to convey complex technical concepts to non-technical stakeholders.

Performance Metrics:

Roadmap delivery: On-schedule, on-scope, and high-quality industry-specific integration projects.
Integration project scalability and security, ensuring compliance with industry regulations.
Team performance metrics: Sprint completion, defect quality, and best practice adherence specific to our sector.

Company Culture:

We foster a culture of Accountability, Excellence, Innovation, Collaboration, and Humanity. These values are at the core of our organization, guiding our interactions and shaping our industry-leading solutions.

Preferred Education and Experience:

Master’s degree or higher

Expected Competencies:

Detailed oriented with strong organizational skills
Strong English communication skills, both written and verbal
Software architecture and application design experience
Expertise with SQL and data analysis concepts
Strong software development experience in multiple languages
Able to implement scrum and agile processes into an organization
Ability to troubleshoot code level problems quickly and efficiently

Work Environment:

This job operates in an office environment. Working in an office environment requires a high degree of discipline and the ability to work with others in a moderately noisy open office environment with centrally controlled head/AC setting.

Physical Demands:

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.

While performing the duties of this job, the employee is regularly required to talk or hear. Specific vision abilities required by this job include close vision, color vision, and ability to adjust focus. This position requires the ability to occasionally lift office products and supplies, up to 20 pounds.

Position Type/Expected Hours of Work:

This is a full-time position. Days and hours of work are Monday through Friday, 9:00 a.m. to 5:30 p.m.

Occasional evening and weekend work may be expected in case of job related emergencies or client needs.

Travel:

Travel up to 20% of the time – may be required

EEO Statement

Cendyn provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Cendyn complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Cendyn expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Cendyn’s employees to perform their job duties may result in discipline up to and including discharge.

Other Duties

Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.



This is a remote position.",1996,Enterprise Software & Network Solutions,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,True
Software/Data Engineer,"Syniverse
","Tampa, FL",$73K - $126K (Glassdoor est.),3.2,"Syniverse is the world’s most connected company. Whether we’re developing the technology that enables intelligent cars to safely react to traffic changes or freeing travelers to explore by keeping their devices online wherever they go, we believe in leading the world forward. Which is why we work with some of the world’s most recognized brands. Eight of the top 10 banks. Four of the top 5 global technology companies. Over 900 communications providers. And how we’re able to provide our incredible talent with an innovative culture and great benefits.
Who We're Looking For
A Software/Data Engineer has the responsibilities to develop new applications and perform lifecycle support for existing applications. The company uses a variety of programming languages, including Scala, C++, Python, and Java. The ideal candidate will have a strong understanding Scala and C++ and should have strong foundation of object-oriented programming, functional programming, and software design principles. They will also have experience working in a collaborative environment and be able to work with different teams as the need arises. Finally, the candidate is required to adhere to all the company’s software development procedures and processes while fulfilling the leadership role.
Some of What You'll Do
Principal Duties and Responsibilities:
Design, develop, and maintain software applications using Scala and C++.
Assist in the requirements phase for projects; apply current telecommunications knowledge and research current standards documents to keep up with the continuing changes in the industry.
Create high-level design documents from requirements utilizing Object Oriented or Structured Methods that contain such items as use cases, flow diagrams, structure definitions and architecture diagrams.
Work on detailed design documents, coding, unit test and integration testing across interfacing functional groups that may be involved.
Document thorough release notes and release planning walk-throughs.
Assist operations with the actual implementation and monitor to ensure the release is functioning as expected.
Review design documents, code, and test results to ensure accuracy and completeness and adherence to the requirements.
Work with operations to provide the highest quality of service possible.
Research and recommend new technology, methodologies to help increase overall efficiencies.
Leadership role:
Learning our existing applications and be the expert; “GO TO” resource for all aspects of the internal/external assigned subsystems.
Capable of leading an application enhancement or project from requirements through implementation working with a team of engineers.
Work closely with manager to create project plans for medium to large-scale efforts and host weekly meetings to track progress.
Work with Product Managers and Business Development personnel on new initiatives leveraging telecommunications expertise.
Capable of problem solving & keeping a group on task to complete projects in a timely manner.
Capable to stand alone in meetings and represent group with internal/external customers.
Provide guidance to peers on appropriate technical methodologies and implementations.
Support internal procedures used to support existing/new applications:
Create a Rough Order of Magnitude (ROM) of hours for projects.
Create a Level of Effort (LOE) of hours for projects.
Job Requirements:
Bachelor’s degree in computer science or related field or equivalent work experience.
5+ Years of Software Development experience using Scala or functional programing is a must
Experience working with advanced level programming in C/C++ including data structures, thread synchronization multithreading, multi-processing, concurrency, and TCP/IP Socket Programming.
Experience using Java is optional/nice to have.
Expert Knowledge in:
Development environment – OS, editor, utilities, database,
Compiler, Debugger (role dependent),
Production runtime environment (role dependent),
Object Oriented and Structured development methodologies,
Unix commands.
CI/CD Experience with Ansible is preferred.
Experience with relational Database like Oracle / postgreSQL.
Experience with git source control
Ownership/Accountability for tasks/projects.
Work well within a team environment and be independent.
Excellent oral and written communication skills.
Why You Should Join Us
Join us as we write a new chapter, guided by world-class leadership. Come be a part of an exciting and growing organization where we offer a competitive total compensation, flexible/remote work and with a leadership team committed to fostering an inclusive, collaborative, and transparent organizational culture.
At Syniverse connectedness is at the core of our business. We believe diversity, equity, and inclusion among our employees is crucial to our success as a global company as we seek to recruit, develop, and retain the most talented people who want to help us connect the world.
Know someone at Syniverse?
Be sure to have them submit you as a referral prior to applying for this position.",1987,Enterprise Software & Network Solutions,$500 million to $1 billion (USD),Information Technology,1001 to 5000 Employees,Company - Private,False
Lead Data Engineer,"Iron EagleX
","Tampa, FL",$92K - $133K (Glassdoor est.),4.9,"Overview:
Iron EagleX is a veteran owned defense contracting company based in Tampa, FL.

It is our mission to provide solutions to the most challenging technical problems facing the Department of Defense while simultaneously making a positive impact on our employees and community.

Job Description:

USSOCOM has a requirement for Data Technical Support services under the Intelligence Program of Record within the SOF Acquisition Technology and Logistics (AT&L) Program Executive Officer (PEO) SOF Digital Applications (SDA).United States Special Operation Command (USSOCOM) DTS will be based on a hub and spoke concept of operations with analysts permanently positioned or on Temporary Duty (TDY) status at the USSOCOM HQ, TSOC, Component Commands, Special Operations Joint Task Forces (SOJTF), Combined Joint Special Operations Task Forces (CJSOTF), Special Operations Task Forces (SOTF), and Special Operations Command Forward Elements (SOCFWD). The DTS contractors/analysts will vary in skill sets ranging from Data Scientists to Data Integrators and will provide support to IDST leadership during recurring planning events, customer requirement discussions, and capability development in line with their respective positional technical requirements. DTS contractors will operate and conduct analysis on SOFNET-U, SOFNET-S, JIANT, SOIS, SOCRATES, NSAnet, and in some cases on the commercial internet. The team, at a minimum will be comprised of Data Integrators, Data Engineers, Data Analysts, Data Scientists, System Architects, Data Engineers, and Front-End Developers.

This position is contingent upon the award of a SOCOM contract. Work is expected to begin as early as January 2024.
Responsibilities:

Job Duties Include (but not limited to):

Design SQL databases
Create process documentation.
Provide written and verbal communication.
Work independently and on teams
Code in python, java, Kafka, hive, R, or storm
Oversee real-time business metric aggregation, data warehousing and querying, schema and data management, and related duties.
Design, develop, and test state-of-the-art Cloud-based database platforms.
Implementation and maintain complex databases.
Analyze procedures to control the access and allocation of data.
Maintain security controls in supported databases.
Apply advanced principles, theories, and concepts to job assignments and contribute to the development of new ideas and principles.
Solve complex problems, under consultative direction, and represent the SOF Data Science teams across the SOF Intelligence Enterprise working on long-range programs and objectives.
Provide advice to the SOF Intelligence Data Team customer and assist in overall functional strategic data planning.
Work directly with the SOF DTS to ensure the data systems supporting the DTS are functioning optimally and can integrate any needed capabilities to support the team.
Qualifications:

Security Clearance:

Top Secret Clearance with the ability to obtain a SCI is required.

Benefits:

National Health, vision, and dental plans
20 days of PTO and 11 paid holidays
Life Insurance
Short – and long-term disability plans
401(K) retirement plans
Incentive and recognition programs
Relocation opportunities

Iron EagleX is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, among other things, or status as a qualified individual with disability.",-1,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,1 to 50 Employees,Company - Private,False
"Asset Management Engineer (Data Analytics), Progression","Tampa Electric Company
","Tampa, FL",$68K - $95K (Glassdoor est.),4.2,"POWER UP A CAREER WITH US
Our people are our greatest investments.

Be the light to help us keep our customers connected. If you are interested in a career and not just a position, Tampa Electric is the place to be! Tampa Electric offers competitive pay, a comprehensive benefits package and opportunities for growth and development in a friendly and professional work environment. We embrace diversity and the inclusion of all. We believe our differences, unique perspectives and talents are our strengths and integral to the success of our company.

We’re honored to serve approximately 780,000 customers across West Central Florida and safely provide them with clean, affordable and reliable electricity. We’ve been doing it for more than 100 years, and there’s so much more ahead.

Join our team of energy experts as we build on that legacy through innovation, continued solar investments, cost-effective and sustainable energy solutions all while keeping top-notch customer service at the center of all we do.




Title: Asset Management Engineer (Data Analytics), Progression
Company: Tampa Electric Company
State and City: Florida - Tampa
Shift: 8 Hr. X 5 Days




TITLE: Asset Management Engineer (Data Analytics)
PERFORMANCE COACH: Manager, Analytics and Systems
COMPANY: Tampa Electric
DEPARTMENT: ES/ED Asset Management




Engineer Classification is multi-level based on the qualifications guidelines outlined in the Company’s Engineer Career Path, Administrative Policy 2.13. A minimum classification of an Engineer I is required in this position.




Concept: The Asset Management (AM) Engineer can perform various functions within the Analytics and Systems Solutions Team. In a data analytics capacity, this position develops the requirements, design, development, implementation, maintenance, and governance for Analytics (Business Intelligence, Data Science, Artificial Intelligence, Machine Learning) and Information and Operational Technology (IT/OT) system solutions for ED/ES Asset Management and configures Analytics and IT/OT systems supporting ES/ED business objectives.




Primary Job Duties and Responsibilities:
1) Works with ED/ES and Asset Management to develop requirements for business solutions and maintaining solution throughout full lifecycle





2) Develop and implement Analytics and Systems (Engineering models, GIS, etc.) considering corporate and company direction, the objectives of the ED/ES system portfolio roadmap and overall solution efficiency and effectiveness.





3) Works with TEC business units and IT to establish the optimum design and architecture of Analytics and OT/IT system solutions which follow best practices and most effectively meets current and future business needs.





4) This position will develop and maintain Master Data Management for ED/ES Asset Management and integration design for associated systems, particularly focused on Asset Hierarchy, Analytics, and IT/OT system solution data integration effectiveness.





5) Continuously educates and leads TEC business units when it comes to the importance of data governance. Develops and provides documentation for this process.





6) Work closely with the IT Business Relationship manager and system leads/managers to develop a prioritized system portfolio roadmap, associated projects including scoping, business analysis, project justification and approval, procurement, project development, execution, management and ongoing maintenance and governance.





7) Develops knowledge and experience pertaining to Solar and DER SCADA Controls (5%)




Supervision
Direct Supervision: None
Indirect Supervision: Supervision of project and System governance teams.




RELATIONSHIPS
Key Internal: ES and ED team members (VP, directors, managers and program leads) to understand functional requirements for systems and to validate their translation into system requirements. Works with IT business relationship manager to prioritize a system portfolio roadmap and coordinate execution of the projects. IT and ES technical leads to develop and implement an effective technology plan.
Key External: Consultants (Solution implementers, etc.), Contractors, Industry Associations, Vendors




Qualifications




Education
Required: Bachelor’s degree in Engineering from an ABET accredited program
Preferred: Electrical/Electronics engineering degree




Licenses/Certifications
Preferred: Florida Professional Engineer’s License




Experience
Related Experience
Required: Minimum of 1.5 years of Engineering Experience at an Electric Utility
Preferred: Experience with the application of operational and information technologies in the fields of engineering, maintenance, and/or electric generation, e.g. OSI PI and computer simulation and optimization of engineered systems, etc. use of Scrum framework and data analytics, data science and business intelligence.




Knowledge/Skills/Abilities (KSA)
Required: Ability to lead the company’s direction in how ED/ES Analytics and System are implemented and applied.
Preferred: Broad knowledge and skills in management and innovation in Analytics and IT/OT system solutions and the ability to apply this knowledge to develop and implement effective programs and roadmaps to meet business objectives.




WORKING CONDITIONS
This position primarily works in an office environment. Occasionally required to work in an industrial environment. Some travel within the Tampa Electric Service Area is required.




LEADERSHIP COMPETENCIES

Champions Safety, Health and the Environment
Takes Ownership and Acts with Integrity
Drives Business Excellence for Customers
Builds Collaborative Relationships",1899,Energy & Utilities,$1 to $5 billion (USD),"Energy, Mining & Utilities",1001 to 5000 Employees,Subsidiary or Business Segment,False
Data Scientist/Data Engineer,"Northrop Grumman
","Melbourne, FL",$61K - $91K (Employer est.),4.0,"Requisition ID: R10132401
Category: Information Technology
Location: Melbourne, Florida, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.

Northrop Grumman's Chief Information Office is seeking a Software Development and Data Scientist/Engineer. This position will be located in Melbourne, Fl.

What you’ll get to do:

Research, design, develop, and/or modify enterprise-wide systems and/or applications software.

Involved in planning of system and development deployment as well as responsible for meeting software compliance standards.

Evaluates interface between hardware and software, operational requirements, and characteristics of overall system.

Document testing and maintenance of system corrections.

Specify, collect, process and present information from potentially several disparate data sets.

Generate actionable knowledge from data.

Utilize possesses analytical and problem solving skills for quickly developing recommendations based on quantitative and qualitative data from many different types of sources.

Identify patterns and higher level information from all the data sources through use of tools and application programming.

Interpret the general problem space and explain the different insights generated from the data.

Translate business questions, identify and implement appropriate visualization or analysis techniques

Taking projects from initial concept through deployment

Collaborating with stakeholders, teammates, and business leaders

Level 1 Basic Qualifications:

Bachelor's degree in Computer Science, Statistics, Mathematics, Finance, Chemistry, Physics, Engineering, with zero (0) years of experience.

U.S. Citizenship and the ability to obtain a security clearance

Must possess a DoD 8570 certification at IAT Level II or higher, or obtain in 90 day from hire.

Proven experience using and/or application of technical principles, theories, and concepts. Demonstrates the skill and ability to perform professional tasks.

Experience developing recommended solutions to technical problems as assigned.

Level 2 Basic Qualifications:

Bachelor's degree in Computer Science, Statistics, Mathematics, Finance, Chemistry, Physics, Engineering, with two (2) years of experience.

U.S. Citizenship and the ability to obtain a security clearance

Must possess a DoD 8570 certification at IAT Level II or higher or obtain in 90 day from hire.

1 year experience in analytics

Experience with Tableau development

General understanding and experience with IT systems (Windows and/or Linux)

Experience with Graphic Design/Data Visualization

General frequent use and application of technical standards, principles, theories, concepts and techniques.

Demonstrates the skill and ability to perform moderately complex professional tasks.

Provides solutions to a variety of technical problems of increasing scope and complexity as assigned.

Preferred Qualifications:

Active Secret Security Clearance

Experience Generating Valuable Metrics from Disparate Systems

Experience building Tableau Dashboards

Experience building Power BI Dashboards

Experience writing Python ETLs and general Data Engineering knowledge

Excellent communication skills and customer facing experience.

Proven ability to learn and master new technologies and techniques

Experience managing databases, data structures, data governance

CIOSoftDev

Salary Range: $60,600 - $91,000
Salary Range 2: $74,300 - $110,000
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.

Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",1939,Aerospace & Defense,$10+ billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
Data Engineer,"Kforce
","Jacksonville, FL",$50.00 - $55.00 Per Hour (Employer est.),3.9,"RESPONSIBILITIES:
Kforce's client located in Jacksonville, Florida (FL) is looking for a Data Engineer.

Summary:
The Data Engineer III aims to provide data in a ready-to-use form to enable a diverse set of business processes. They will be responsible for design, build, maintenance, and production support of data processing pipelines and systems. The Data Engineer III will work closely with Data Analysts, Data Scientists, business, and technical teams to deliver outcomes that are secure, reliable, fault-tolerant, scalable, quality, and efficient. They will be applying analytics (e.g., machine learning) and statistical models, as needed. The Data Engineer III can also provide data analysis and extracts on large and complex data sets.

REQUIREMENTS:

Bachelor's degree in Information Systems or Computer science
5+ years of work experience in a Data Engineer
Experience designing, building, and operating in-production big data/stream processing and/or enterprise data warehouse
Experience with large scale, concurrent applications
Experience building backend RESTful web services
Experience with SQL and relational database systems (e.g., Oracle, SQL Server)
Experience with Linux
Experience using Informatica PowerCenter or similar ETL tools
Experience using data transformation tool in Informatica or similar ETL tool
Experience with flat file to XML conversion a big plus
Must have experience working in a DevOps culture or concepts
Strong problem-solving capabilities and exhibits strong Computer Science Fundamentals
Experience working with Agile and Lean Practices
Excellent communication skills
The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",1962,Business Consulting,$1 to $5 billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Engineer,"Vaco
","Orlando, FL",$140K (Employer est.),3.6,"Job Summary and Responsibilities:

We are seeking a dedicated Senior Data Engineer to join our data engineering team to build and maintain scalable and reliable data engineering solutions that support our enterprise data warehouse and business analytics. In this position, you will be responsible for designing, developing and deploying data pipelines, workflows and data models. This position requires an in depth knowledge of dbt, Snowflake, Data Modeling, CI/CD, and DevOps. This position will also collaborate with other data engineers, architects, analysts, and stakeholders to ensure business requirements, data quality, security, and governance.

Essential Job Duties and Responsibilities
(Reasonable accommodations may be made to enable individuals with disabilities to perform these essential functions. Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.)

Design, develop and deploy data pipelines and workflows using dbt and Snowflake to ingest, transform, and deliver data from various sources to snowflake based enterprise data warehouse. This includes but not limited to writing SQL queries, macros, tests, source to target mappings, and documentation.
Expert level knowledge of optimizing performance of ETL/ELT, building & executing tests, maintaining versions/repository, and documenting the workflows
Apply data ops, CI/CD, DevOps principles and practices to automate and streamline data processes and ensure continuous delivery and integration of data solutions
Cross-collaborate with business stakeholders, reporting team and solution architects to lay out a robust design, data architecture and data models for data warehouse that support business intelligence solutions
Hands on experience delivering cloud data integration projects preferably with AWS
Document and communicate data solutions, standards, best practices, and guidelines to ensure consistency and alignment across the data engineering team and the organization
Deliver and manage projects using Agile/SCRUM/KANBAN methodologies
Mentor and coach junior data engineers and provide technical guidance and feedback
Monitor and troubleshoot data issues and incidents and provide root cause analysis and resolution
Research and evaluate new technologies and trends in the data domain and propose improvements and innovations
Performs other duties as assigned
Preferred Education and/or Experience
Bachelor's degree in computer science, engineering or related field is preferred
10+ years of experience in data engineering or related roles with experience with at least two data engineering and/or ETL/ELT tools
Proficient in dbt design, development and deployment, including writing SQL queries, macros, tests, sources, etc.
Knowledge of Snowflake cloud data platform, architecture, features and capabilities
Familiarity with modern modeling techniques like lake house, data vault as well as traditional concepts such as star schema, snowflake schema, dimensional modeling, facts and dimensions
Experience working in data engineering team in cloud environment preferable AWS
Skilled in data ops, CI/CD, DevOps tools and methodologies, such as Git, Azure DevOps, Jenkins etc.
Strong understanding of data quality, security, and governance principles and frameworks
Experience delivering and managing projects using Agile/SCRUM/KANBAN methodologies
Skills and Competencies
Effectively communicate in English; both oral and written
Interpret a variety of communications (verbal, non-verbal, written, listening and visual)
Maintain confidentiality, discretion and caution when handling sensitive information
Multi-task along with attention to detail
Self-motivation, organized, time-management and deductive problem solving skills
Work independently and as part of a team
Qualifications:
Required Education and/or Experience
High school diploma or GED equivalent, required
Employment is contingent on
Background investigation (company-wide)
Drug screen (when applicable for the position)
Valid driver's license in state of residence with a clean driving record (when applicable for the position)",2002,Staffing & Subcontracting,$500 million to $1 billion (USD),Human Resources & Staffing,501 to 1000 Employees,Company - Private,True
Senior Data Engineer (Snowflake) - Contractor,"EY
",United States,$90.00 - $130.00 Per Hour (Employer est.),3.9,"The primary responsibility for the Sr. Data Engineer / Tech Lead is to ensure data accessibility, quality, and reliability within the client's data platform ecosystem.

RESPONSIBILITIES

Design and develop end-to-end data pipelines and ETL processes using Snowflake, Denodo, DBT Cloud, Fivetran, and AWS Glue, ensuring seamless data integration, transformation, and loading.
Collaborate with cross-functional teams to gather data requirements and implement scalable data models and schemas within Snowflake and Denodo, ensuring optimal performance and data consistency.
Implement and maintain data orchestration workflows using Stonebranch, ensuring efficient and reliable scheduling and automation of data processes.
Work with EnterpriseDataLake for ingestion and storage of data from various sources, ensuring the availability and accessibility of data for analytics and reporting purposes.
Utilize Azure DevOps and Teraform to implement and manage infrastructure as code, ensuring streamlined deployment and scalability of data engineering solutions.
Skills

snowflake

denodo

dbt cloud

fivetran

Qualifications

REQUIREMENTS

Proficiency in Snowflake and Denodo: Strong understanding and hands-on experience in working with Snowflake and Denodo for data integration, transformation, and analysis.
Knowledge of DBT Cloud: Familiarity with DBT Cloud, including experience in building and maintaining efficient data transformation workflows and deploying reliable data pipelines.
Experience with Fivetran: Demonstrated experience in utilizing Fivetran for data ingestion, source connectivity, and ensuring data accuracy and completeness.
Understanding of EnterpriseDataLake: Knowledge of EnterpriseDataLake principles and practices, including data ingestion, storage, and organization for analytics and reporting purposes.
Familiarity with Stonebranch: Proficiency in using Stonebranch for data orchestration and scheduling, ensuring efficient and reliable execution of data pipelines and workflows.
Proficiency in Azure DevOps and Teraform: Experience in leveraging Azure DevOps and Teraform for infrastructure as code, enabling streamlined deployment and scalability of data engineering solutions.

The expected pay rate range for this contract assignment is $90 to $130 per hour. The exact pay rate will vary based on skills, experience, and location. The position is approximately 65-70% remote and 30-35% travel to the client as needed.

#GigNowTechOpportunities

GigNowOpportunities

Equal Employment Opportunity Information
EY provides equal opportunities to applicants, employees, contractors, vendors, and stakeholders without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. If you are an individual with a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please email gignow.recruiting@ey.com.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,False
Azure Data Engineer/Architect,"SNI Technology
","Tampa, FL",$86K - $128K (Glassdoor est.),3.4,"JOB DESCRIPTION

Fulltime remote allowed if candidate resides in (FL, GA, TN, CO, TX, HI,VA,NC)
Position can be Contract to Hire or Direct Hire
-Candidate needs to be able to work as a direct hire with no sponsorship after 6 months-
Job Title: Azure Data Architect
Department: Software Engineering
Location: Remote
Summary of Duties & Responsibilities
We have an opening for an Azure Data Architect on the Artificial Intelligence and Analytics team (AI+A). This is a greenfield opportunity to develop an AI and Analytics application in the ERP and Work Management space. The Azure Data Architect is responsible for designing and implementing Big Data and BI solutions using the Microsoft Azure platform. This role is 80% hands-on development and 20% architecting Big Data and BI solutions.
The Azure Data Architect is expected to evangelize and educate others on engineering design and development standards. Azure Data Architect is expected to function as a productive member of a team, working and communicating proactively with engineering peers, technical leads, project managers, product owners, and resource managers.
The ideal candidate will have10 years of hands-on experience in designing, implementing, and delivering into production, large-scale near real-time data warehouses.
Essential Functions
Design and develop data warehouses and data pipelines within Azure
Design and develop Azure ML model execution pipelines
Evangelize engineering design and development standards
Act as a key contributor to the design and development lifecycle of analytic applications utilizing Microsoft Azure and BI technology platforms
Participate in Agile ceremonies including daily stand-ups, sprint planning, retrospectives, and product demonstrations
Produce efficient and elegant code that meets business requirements
Author unit tests that adhere to code coverage guidelines
Proactively communicate progress, issues, and risks to stakeholders
Accurately estimate assignments
Create and maintain technical documentation
Mentor less experienced engineers
Contribute to the growth and maturity of the Software Engineering Group
Performs other related duties as directed
SKILLS & COMPETENCIES
10 years of hands-on experience designing and implementing large-scale distributed data architecture for BI and OLTP systems
10 years of hands-on experience designing and implementing large-scale data pipelines
5 years of hands-on experience in Azure data services
5 years of hands-on experience with data integration using ETL / ELT tools
5 years of hands-on experience with Python including object-oriented programming and unit testing
Advanced experience with one or more Python parallel processing libraries
Advanced experience with one or more Python data analysis libraries
Advanced data modeling experience
Broad experience in Microsoft SQL technologies
Broad multi-tenant data architecture and implementation experience across different data stores, messaging systems and data processing engines
Experience with data integration through APIs, Web Services, SOAP, and/or REST services
Experience using Azure DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira, and Confluence
Knowledge of SOA and Micros Services Application Architecture
Ability to work in a fast-paced, collaborative team environment
Excellent written and verbal communication skills and ability to express ideas clearly and concisely
DESIRED ATTRIBUTES
Strong team player with ability to collaborate with all levels of the organization
Possess a drive towards forward progress and delivering results while taking responsibility
Multi-tasker with ability to set and manage priorities
Proactively and transparently communicate challenges and successes to product leadership
Exhibit attention to detail
Flexibility and willingness to help in other areas as priorities shift
Ability to effectively operate with minimal supervision, but knowing how to keep leadership in the loop
EDUCATION OR PRIOR WORK EXPERIENCE
Bachelor’s degree in CS or related field, master’s degree preferred
10+ years of experience with designing and developing complex data architecture solutions
5+ years of design and development experience with Microsoft Azure data architecture and related solutions
5 years of hands-on experience with Python
Reports to
Manager, Software Engineering",1998,HR Consulting,Unknown / Non-Applicable,Human Resources & Staffing,201 to 500 Employees,Company - Public,False
Mission Data Engineer - SE-4,"ERC
","Shalimar, FL",$51K - $84K (Glassdoor est.),3.6,"Overview:
Oasis Systems has an exciting opportunity for SE-4 Mission Data Engineer in support of the 36th Electronic Warfare Squadron (EWS) 350th Spectrum Warfare Wing (SWW), located at Eglin AFB, FL. The 350 SWW is the technical focal point for all electronic warfare (EW) support of warfighter systems for the Combat Air Forces (CAF) fighter, bomber, airborne surveillance, and helicopter platforms.

LOCATION: Eglin AFB
JOB STATUS: Full-time
TRAVEL: 10%

REQUIRED QUALIFICATIONS A Bachelor’s or Master’s degree and 3-10 years of experience or equivalent work experience

SECURITY CLEARANCE: Active Secret Security Clearance Required & Fully Completed Application (US Citizenship Required)

EDUCATION: Master’s Degree in technical/engineering discipline
CERTIFICATIONS: N/A
EXPERIENCE LEVEL: 10+ years of experience or equivalent work experience


OTHER QUALIFICATIONS/SKILLS:

This position requires an active secret government security clearance for consideration
Candidates must have at least a Master’s degree in a technical/engineering discipline with at least 10 years of experience in an engineering capacity (A BS degree and additional years of experience may be substituted for MS degree)
Demonstrated ability to recognize and analyze problems, conduct research, summarize results, and make appropriate recommendations
Must have a working knowledge of computer systems and an understanding of Windows-based personal computers and Microsoft Office software and possess the ability to communicate effectively both orally and written


PREFFERED SKILLS:

Knowledge and skills with Electronic Warfare (EW) and the electromagnetic (EM) spectrum, computer software, threat warning, radio frequency (RF) jammers, electro-optical/infrared (EO/IR) jammers, expendables, threat analysis, foreign/US/radar/weapon systems, airborne EW computer software, avionics, systems integration, electronics engineering concepts, principles and practices applicable to a broad range of engineering assignments. Candidates must be analytical, methodical and detail oriented
Highly desire previous experience in RF integration, EM spectrum management, antenna design, and digital signal processing
Desire knowledge of EW weapons systems development, test and evaluation, and systems engineering


RESPONSIBILITIES:

Assist the 350th Spectrum Warfare Wing (350 SWW) at Eglin AFB, Florida, which is the technical focal point for all Electronic Warfare (EW) support of warfighter systems for the Combat Air Forces (CAF). The mission of the 350 SWW is to develop and test Mission Data (MD) to defeat enemy radar and infrared guided missile systems, thus enhancing aircrew and aircraft survivability in combat. This mission includes operational EW testing, MD development/validation/verification, force development evaluation execution and facilitating foreign materiel exploitation
Conduct appropriate EW research, MD development and MD testing. The successful candidate will support EW system programming/reprogramming, work with EW system engineers to coordinate programming/reprogramming requirements, prepare validation and verification test plans, and organize and participate in MD configuration control boards. The successful candidate will assist with the collection, recording, and post-test analysis of data generated during MD testing. The successful candidate may be required to travel


What we offer:

Competitive salaries
Continuing education assistance
Professional development allotment
Multiple healthcare benefits packages
401K with employer matching
Paid time off (PTO) along with a federally recognized holiday schedule


Who We Are

Oasis Systems is a premier provider of customer-driven, cost-effective, and quality Engineering Services; Enterprise Systems and Applications; Human Factors Engineering; Information Technology and Cyber Security; Professional Services; and Specialized Engineering Solutions to the Department of Defense, Federal Aviation Administration, Nuclear Regulatory Commission, and other Federal Agencies.


We strive to be an exciting and welcoming company that attracts, develops, motivates and retains the most talented, skilled and dedicated people in the industry; where they are encouraged to achieve personal excellence, purpose, and their full potential and career aspirations, while supporting mission-critical national security technologies and programs.


Oasis Systems is an Equal Employment Opportunity/Affirmative Action Employer. We provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.




This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.


""Oasis Systems Cyber Division""",1999,HR Consulting,$25 to $100 million (USD),Human Resources & Staffing,5001 to 10000 Employees,Company - Private,False
"AWS Data Engineer with API Hands on exp. (Onsite: Juno Beach, FL)","Cognizant Technology Solutions
","Juno Beach, FL",$95K - $105K (Employer est.),3.8,"We are Cognizant Artificial Intelligence

Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. However, clients need new business models built from analyzing customers and business operations at every angle to really understand them.

With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate, and scale the most desirable products and delivery models to enterprise scale within weeks.

* You must be legally authorized to work in United States without the need of employer sponsorship, now or at any time in the future *

Job Title: AWS Data Engineer with API Hands on exp. (Onsite)

Location: Juno Beach, FL

Roles and Responsibilities:

§ Demonstrate strong architecture and design skills building high-performance APIs using AWS services and Python.

§ Design and implement highly scalable interactive web applications with high usability.

§ Collaborate with product teams to iterate ideas on data monetization products/services and define feasibility.

§ Rapidly iterate on product ideas build prototypes and participate in proof of concepts

§ Collaborate with internal and external teams in trouble shooting functional and performance issues.

Required Qualifications:

§ 9 to 11 years of experience

§ Technical Skills: Amazon Web Services.

§ Nice to have technical skills: Graphql/Rest API, Dynamo DB, PostgresSQL, Cloud formation, CICD, GITHUB.

§ Domain Skills: Industrial Manufacturing Engineering & Design.

Salary and Other Compensation:

The annual salary for this position is between $95,000.00 – $105,000.00 depending on experience and other qualifications of the successful candidate.




This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.

Benefits: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:

Medical/Dental/Vision/Life Insurance
Paid holidays plus Paid Time Off
401(k) plan and contributions
Long-term/Short-term Disability
Paid Parental Leave
Employee Stock Purchase Plan

Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.

Cognizant is an Equal Opportunity Employer M/F/D/V. Cognizant is committed to ensuring that all current and prospective associates are afforded equal opportunities and treatment and a work environment free of harassment.

Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network Assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.




#LI-KV1 #CB #Ind123

Employee Status : Full Time Employee

Shift : Day Job

Travel : No

Job Posting : Nov 16 2023

About Cognizant
Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.

Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",1994,Information Technology Support Services,$10+ billion (USD),Information Technology,1001 to 5000 Employees,Company - Public,False
Cloud Data Migration Engineer,"Deloitte
","Lake Mary, FL",$72K - $103K (Glassdoor est.),4.0,"Are you an experienced, passionate pioneer in technology - a solutions builder, a roll-up-your-sleeves technologist who wants a daily collaborative environment, think-tank feel and share new ideas with your colleagues - without the extensive demands of travel? If so, consider an opportunity with our US Delivery Center - we are breaking the mold of a typical Delivery Center.

Our US Delivery Centers have been growing since 2014 with significant, continued growth on the horizon. Interested? Read more about our opportunity below ...

Work you'll do/Responsibilities

Work with the team to evaluate business needs and priorities, liaise with key business partners and address team needs related to data systems and management.
Translate business requirements into technical specifications; establish and define details, definitions, and requirements of applications, components and enhancements.
Participate in project planning; identifying milestones, deliverables and resource requirements; tracks activities and task execution.
Generate design, development, test plans, detailed functional specifications documents, user interface design, and process flow charts for execution of programming.
Develop data pipelines / APIs using Python, SQL, potentially Spark and AWS, Azure or GCP Methods.
Use an analytical, data-driven approach to drive a deep understanding of fast changing business.
Build large-scale batch and real-time data pipelines with data processing frameworks in AWS, Azure or GCP cloud platform.
Moving data from on-prem to cloud and cloud data conversions.

The Team

Artificial Intelligence & Data Engineering:

In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.

The Artificial Intelligence & Data Engineering team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-making. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets.

Artificial Intelligence & Data Engineering will work with our clients to:

Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms.

Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions.

Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements.

Qualifications

Required

3+ years of experience in data engineering with an emphasis on data analytics and reporting.
3+ years of experience with at least one of the following cloud platforms: Microsoft Azure, Amazon Web Services (AWS), Google Cloud Platform (GCP), others.
3+ years of experience in SQL, data transformations, statistical analysis, and troubleshooting across more than one Database Platform (Cassandra, MySQL, Snowflake, PostgreSQL, Redshift, Azure SQL Data Warehouse, Databricks, etc.).
3+ years of experience in the design and build of data extraction, transformation, and loading processes by writing custom data pipelines.
3+ years of experience with one or more of the follow scripting languages: Python, SQL, Kafka and/or other.
3+ years of experience designing and building solutions utilizing various Cloud services such as EC2, S3, EMR, Kinesis, RDS, Redshift/Spectrum, Lambda, Glue, Athena, API gateway, etc.


Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be a US Citizen
Must live near, or relocate to, the Lake Mary, FL; Gilbert, AZ; or Mechanicsburg, PA areas
Must be in your designated office location 10%-30% of each work week
Ability to travel up to 10%, on average, based on the work you do and the clients and industries/sectors you serve
Bachelor's degree, preferably in Computer Sciences, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience



Preferred

AWS, Azure and/or Google Cloud Platform Certification.
Master's degree or higher.
Expertise in one or more programming languages, preferably Scala, PySpark and/or Python.
Experience working with either a Map Reduce or an MPP system on any size/scale.
Experience working with agile development methodologies such as Sprint and Scrum.",1850,Accounting & Tax,$10+ billion (USD),Financial Services,10000+ Employees,Company - Private,False
"Lead Software Engineer, Data Engineering","S&P Global
","Tallahassee, FL",$85K - $170K (Employer est.),4.1,"The Role: Data Engineer
Location: Team is in Boston, but is available for remote or on-site throughout CST and EST Time zones
GL (for internal use only): 11

Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.
Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy!
Job Description
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.

You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets.
You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use.
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.

Responsibilities
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers
Optimizing slow-running database queries and data pipelines
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency

Qualifications
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience
7+ years of experience working with data-at-scale in a production environment
Experience designing and implementing large-scale, distributed systems
Experience in multi-threaded software development (or some form of parallelism)
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale
Strong understanding of relational databases and proficiency with SQL
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript)
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go)
Experience developing software on Linux-based operating systems
Experience with distributed version control systems
Nice-to-Haves
Familiarity with relational database internals (especially PostgreSQL)
Proficiency with cloud computing platforms, specifically AWS
Working knowledge of probability & statistics
Contributions to open-source software
Experience building customer-centric products

Compensation/Benefits Information (US Applicants Only):
S&P Global states that the anticipated base salary range for this position is $85,300 - $170,000 . Base salary ranges may vary by geographic location.
In addition to base compensation, this role is eligible for an annual incentive bonus plan.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires .
About S&P Global
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 277527
Posted On: 2023-09-21
Location: Cambridge, Massachusetts, United States",1860,Research & Development,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Scientist / Engineer (TS/SCI),"Cyberhill Partners LLC
","Tampa, FL",$90K - $128K (Glassdoor est.),1.0,"Data Scientist / Data Engineer
TS/SCI
Tampa, FL
Cyberhill Intel
Cyberhill Intel is a premier software services provider focused on partnering with the world's most high-profile software businesses and organizations. We have built our business around a passion for leveraging leading edge software to solve the world's most difficult national security and intelligence problems. Our goal is to partner with world-class software companies from around the world and leverage our mission expertise to help deliver their software to the U.S. Government and its partners.
The Role
We are seeking Mission Driven Data Scientist to join our team supporting Research and Development efforts of the Department of Defense in the heart of Downtown Tampa, FL! You will be responsible for defining, building, implementing and maintaining predictive data models through their full Lifecyle. You will do this by continuously engaging with, and gaining expertise in, emerging industry technology to support our team and our customers.
As a Cyberhill Data Scientist, you will be expected to leverage everything at your disposal: core industry products, open-source technologies, and anything you and your team can build to drive real impact. In this role, you work with customers around the globe, where you gain rare insight into the world’s most important industries and institutions.
Required or Core Knowledge, Skills, and Experience:
5 Years of experience with owning and delivering data Science products
Demonstrated experience in the manipulation and exploitation of data.
Proficiency with major tools and languages such as Java, Python, Postgresql/SQL
Proficiency with regular expressions.
Familiarity with industry best-practices for software-hardware optimization when processing large datasets:


What We Value
Strong engineering background, preferably in fields such as Computer Science, Mathematics, Software Engineering, Physics.
Familiarity with data structures, storage systems, cloud infrastructure, front-end frameworks, and other technical tools, as well as an understanding of how technical decisions impact the user of what you’re building.
Proficiency with programming languages such as Java, C++, Python, JavaScript, or similar languages.
Ability to work effectively in teams of technical and non-technical individuals.
Skill and comfort working in a rapidly changing environment with dynamic objectives and iteration with users.
Demonstrated ability to continuously learn, work independently, and make decisions with minimal supervision.
(As required by U.S. Government contract) U.S. citizenship.
(As required by U.S. Government contract) Varied clearance level TS/SCI.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,True
Data Link Test Engineer - Mid-Level - TGBC,"ERC
","Shalimar, FL",-1,3.6,"Overview:

Our data link test team is searching for new test engineer professionals that can help us design and execute test events. If you enjoy working in a fast-paced environment, learning new technology areas, this is the place for you. We provide a number of opportunities to learn ranging from on-the-job training with other team members to formal courses for unique technology areas.

We realize that no one will have all of these qualifications. We are looking for people that have experience with Link 16 and system testing. And have the drive and motivation to learn all other required areas.

This position provides support to the 96 Cyber Test Group, 46 Test Squadron, Data Link Test Flight at Eglin AFB as a member of an platform integration team responsible for planning, designing, and executing test events for tactical communications systems. This is NOT a telework or remote position; however, telework opportunities may be authorized as mission requirements allow.




LOCATION: Eglin AFB, FL

JOB STATUS: Full Time

TRAVEL: 25% CONUS / OCONUS TDYs


REQUIRED QUALIFICATIONS (Education, Certifications, Experience, Skills)

SECURITY CLEARANCE: Secret and be able to obtain and maintain a Top Secret clearance – US citizenship required

EDUCATION: BS Degree in a Computer Science, Computer Engineering, or a related technical field (i.e., CS, AE, ME, etc.)

CERTIFICATIONS: None

EXPERIENCE LEVEL: 3-10 years of applicable experience


OTHER QUALIFICATIONS/SKILLS:

US citizenship required
Active Top Secret clearance
Experience with tactical data link radios and terminals
Experience with computer network design concepts, configuration, and operation
Analytical skills and problem-solving skills
Excellent self-initiative and self-motivation with the ability to work under minimal supervision
Ability to work effectively in small and large team settings to solve complex problems
Capable of traveling to contractors' facilities, test sites, and other locations, both CONUS and OCONUS. Travel is on average is 25% of total time worked
Good organization, decision making, verbal and written communication skills
Proficiency in MS Office products to include Word, Excel and PowerPoint


PREFERRED SKILLS:

Relevant technical experience in the areas of software system and hardware integration testing
An understanding of DOD developmental test and evaluation processes
Knowledge of computer networking principles and configuration
Experience using interpreted languages (Python, Ruby, JavaScript, PHP, etc.)
Security+ certification


RESPONSIBILITIES:

Perform as a member of the Platform Integration Element test team
Interface directly with System Program Offices, users, test support organizations, and product development contractors
Plan, execute, and report on tests for Air Force advanced tactical communications programs to include Link 16, Situation Awareness Data Link (SADL) and emerging next generation tactical data links
Utilize Military Standards to evaluate system compliance
Proficient/familiar with various radios such as: MIDS-JTRS, SADL, PRC-117G, etc
Review customer requirements and participate in test planning meetings
Develop test plans and procedures, schedules, and execute tests within the constraints of customer requirements and produce timely test reports
Capable of performing as a team leader in directing and executing system testing
Author technical documents and briefings and conduct formal presentations
Travel to other locations as required to attend meetings and conduct tests


What we offer:

Competitive salaries
Continuing education assistance
Professional development allotment
Multiple healthcare benefits packages
401K with employer matching
Paid time off (PTO) along with a federally recognized holiday schedule


Who We Are

Oasis Systems is a premier provider of customer-driven, cost-effective, and quality Engineering Services; Enterprise Systems and Applications; Human Factors Engineering; Information Technology and Cyber Security; Professional Services; and Specialized Engineering Solutions to the Department of Defense, Federal Aviation Administration, Nuclear Regulatory Commission, and other Federal Agencies.


We strive to be an exciting and welcoming company that attracts, develops, motivates and retains the most talented, skilled and dedicated people in the industry; where they are encouraged to achieve personal excellence, purpose, and their full potential and career aspirations, while supporting mission-critical national security technologies and programs.


Oasis Systems is an Equal Employment Opportunity/Affirmative Action Employer. We provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.


This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
""Oasis Systems Cyber Division""
#CJ",1999,HR Consulting,$25 to $100 million (USD),Human Resources & Staffing,5001 to 10000 Employees,Company - Private,False
Mission Data Engineer - SE-4,"Oasis Systems LLC
","Shalimar, FL",$62K - $95K (Glassdoor est.),4.4,"Overview:
Oasis Systems has an exciting opportunity for SE-4 Mission Data Engineer in support of the 36th Electronic Warfare Squadron (EWS) 350th Spectrum Warfare Wing (SWW), located at Eglin AFB, FL. The 350 SWW is the technical focal point for all electronic warfare (EW) support of warfighter systems for the Combat Air Forces (CAF) fighter, bomber, airborne surveillance, and helicopter platforms.

LOCATION: Eglin AFB
JOB STATUS: Full-time
TRAVEL: 10%

REQUIRED QUALIFICATIONS A Bachelor’s or Master’s degree and 3-10 years of experience or equivalent work experience

SECURITY CLEARANCE: Active Secret Security Clearance Required & Fully Completed Application (US Citizenship Required)

EDUCATION: Master’s Degree in technical/engineering discipline
CERTIFICATIONS: N/A
EXPERIENCE LEVEL: 10+ years of experience or equivalent work experience


OTHER QUALIFICATIONS/SKILLS:

This position requires an active secret government security clearance for consideration
Candidates must have at least a Master’s degree in a technical/engineering discipline with at least 10 years of experience in an engineering capacity (A BS degree and additional years of experience may be substituted for MS degree)
Demonstrated ability to recognize and analyze problems, conduct research, summarize results, and make appropriate recommendations
Must have a working knowledge of computer systems and an understanding of Windows-based personal computers and Microsoft Office software and possess the ability to communicate effectively both orally and written


PREFFERED SKILLS:

Knowledge and skills with Electronic Warfare (EW) and the electromagnetic (EM) spectrum, computer software, threat warning, radio frequency (RF) jammers, electro-optical/infrared (EO/IR) jammers, expendables, threat analysis, foreign/US/radar/weapon systems, airborne EW computer software, avionics, systems integration, electronics engineering concepts, principles and practices applicable to a broad range of engineering assignments. Candidates must be analytical, methodical and detail oriented
Highly desire previous experience in RF integration, EM spectrum management, antenna design, and digital signal processing
Desire knowledge of EW weapons systems development, test and evaluation, and systems engineering


RESPONSIBILITIES:

Assist the 350th Spectrum Warfare Wing (350 SWW) at Eglin AFB, Florida, which is the technical focal point for all Electronic Warfare (EW) support of warfighter systems for the Combat Air Forces (CAF). The mission of the 350 SWW is to develop and test Mission Data (MD) to defeat enemy radar and infrared guided missile systems, thus enhancing aircrew and aircraft survivability in combat. This mission includes operational EW testing, MD development/validation/verification, force development evaluation execution and facilitating foreign materiel exploitation
Conduct appropriate EW research, MD development and MD testing. The successful candidate will support EW system programming/reprogramming, work with EW system engineers to coordinate programming/reprogramming requirements, prepare validation and verification test plans, and organize and participate in MD configuration control boards. The successful candidate will assist with the collection, recording, and post-test analysis of data generated during MD testing. The successful candidate may be required to travel


What we offer:

Competitive salaries
Continuing education assistance
Professional development allotment
Multiple healthcare benefits packages
401K with employer matching
Paid time off (PTO) along with a federally recognized holiday schedule


Who We Are

Oasis Systems is a premier provider of customer-driven, cost-effective, and quality Engineering Services; Enterprise Systems and Applications; Human Factors Engineering; Information Technology and Cyber Security; Professional Services; and Specialized Engineering Solutions to the Department of Defense, Federal Aviation Administration, Nuclear Regulatory Commission, and other Federal Agencies.


We strive to be an exciting and welcoming company that attracts, develops, motivates and retains the most talented, skilled and dedicated people in the industry; where they are encouraged to achieve personal excellence, purpose, and their full potential and career aspirations, while supporting mission-critical national security technologies and programs.


Oasis Systems is an Equal Employment Opportunity/Affirmative Action Employer. We provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.




This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.


""Oasis Systems Cyber Division""",1997,Aerospace & Defense,$100 to $500 million (USD),Aerospace & Defense,1001 to 5000 Employees,Company - Private,False
Senior Data Engineer,"BambooHR
","Orlando, FL",$101K - $138K (Glassdoor est.),3.8,"About Us

Our mission is simple: we want to set people free to do meaningful work. People love our software—and it turns out that people love working here too. We've been recognized as a ""Best Company to Work For"" and we're proud of our team for creating software that makes an impact in the lives of HR pros and employees all over the world.

What You'll Do

As a Senior Data Engineer on the data platform team, we'll rely on your expertise across multiple disciplines to develop, deploy and support data systems, data pipelines, data lakes, and lakehouses. Your ability to automate, performance tune, and scale the data platform will be key to your success.

Your initial areas of focus will include:

Collaborate with stakeholders to make effective use of core data assets
With Spark and Pyspark libraries, load both streaming and batched data
Engineer lakehouse models to support defined data patterns and use cases
Leverage a combination of tools, engines, libraries, and code to build scalable data pipelines
Work within an IT managed AWS account and VPC to stand up and maintain data platform development, staging, and production environments
Documentation of data pipelines, cloud infrastructure, and standard operating procedures
Express data platform cloud infrastructure, services, and configuration as code
Automate load, scaling, and performance testing of data platform pipelines and infrastructure
Monitor, operate, and optimize data pipelines and distributed applications
Help ensure appropriate data privacy and security
Automate continuous upgrades and testing of data platform infrastructure and services
Build data pipeline unit, integration, quality, and performance tests
Participate in peer code reviews, code approvals, and pull requests
Identify, recommend, and implement opportunities for improvement in efficiency, resilience, scale, security, and performance



What You Need to Get the Job Done (if you don't have all, apply anyway!)

Experience developing, scaling, and tuning data pipelines in Spark with PySpark
Understanding of data lake, lakehouse, and data warehouse systems, and related technologies
Knowledge and understanding of data formats, data patterns, models, and methodologies
Experience storing data objects in hadoop or hadoop like environments such as S3
Demonstrated ability to deploy, configure, secure, performance tune, and scale EMR and Spark
Experience working with streaming technologies such as Kafka and Kinesis
Experience with the administration, configuration, performance tuning, and security of database engines like Snowflake, Databricks, Redshift, Vertica, or Greenplum
Ability to work with cloud infrastructure including resource scaling, S3, RDS, IAM, security groups, AMIs, cloudwatch, cloudtrail, and secrets manager
Understanding of security around cloud infrastructure and data systems
Git-based team coding workflows



Bonus Skills (Not Required, So Apply Anyway!)

Experience deploying and implementing lakehouse technologies such as Hudi, Iceberg, and Delta
Experience with Flink, Presto, Dremio, Databricks, or Kubernetes
Experience with expressing infrastructure as code leveraging tools like Terraform
Experience and understanding of a zero trust security framework
Experience developing CI/CD pipelines for automated testing and code deployment
Experience with QA and test automation
Exposure to visualization tools like Tableau



Beyond the technical skills, we're looking for individuals who are:

Clear communicators with team members and stakeholders
Analytical and perceptive of patterns
Creative in coding
Detail-oriented and persistent
Productive in a dynamic setting

If you love to learn, you'll be in good company. You'll likely have a Bachelor's degree in computer science, information systems, or equivalent working experience.




An Equal Opportunity Employer-M/F/D/V
Because our team members are trusted to handle sensitive information, we require all candidates that receive and accept employment offers to complete a background check before being hired.

For information on our Privacy Policy, click here.",2008,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,True
Mission Data Engineer (Mid-Level),"Torch Technologies, Inc.
","Shalimar, FL",$53K - $84K (Glassdoor est.),4.3,"Job Description:
Torch Technologies is seeking a Mission Data Engineer to join a team developing and testing Mission Data, assisting the 350th Spectrum Warfare Wing (350 SWW) at Eglin AFB, Florida, which is the technical focal point for all Electronic Warfare (EW) support of warfighter systems for the Combat Air Forces (CAF). The mission of the 350 SWW is to develop and test Mission Data (MD) to defeat enemy radar and infrared guided missile systems, thus enhancing aircrew and aircraft survivability in combat. This mission includes operational EW testing, MD development/validation/verification, force development evaluation execution and facilitating foreign materiel exploitation. This position supports the TMAS2 Tenants contract, under our Air Force Weapons business unit.

Responsibilities:
This position also requires a highly motivated individual with experience in MD development and testing. Essential responsibilities include:

Conduct appropriate EW research, MD development and MD testing.

Support EW system programming/reprogramming

Work with EW system engineers to coordinate programming/reprogramming requirements, prepare validation and verification test plans, and organize and participate in MD configuration control boards.

Assist with the collection, recording, and post-test analysis of data generated during MD testing.

Required Qualifications:
Education - Candidates must have at least a Bachelors' degree in a technical/engineering discipline with three to ten years of experience in an engineering capacity.

Specific Work Experience - Must also have a demonstrated ability to recognize and analyze problems, conduct research, summarize results, and make appropriate recommendations. Applicants must have a working knowledge of computer systems and an understanding of Windows-based personal computers and Microsoft Office software and possess the ability to communicate effectively both orally and written.

Candidates without an active Secret security clearance must be a US Citizen able to obtain and maintain a Secret clearance.

Preferred Qualifications:
Highly desirable (but not required) attributes include previous experience in RF integration, EM spectrum management, antenna design, and digital signal processing.

Also desired (but not required) is knowledge of EW weapons systems development, test and evaluation, and systems engineering.

Additional Notes:
Knowledge, skills and attributes associated with this position(s) include:

EW and the electromagnetic (EM) spectrum, computer software, threat warning, radio frequency (RF) jammers, electro-optical/infrared (EO/IR) jammers, expendables, threat analysis, foreign/US/radar/weapon systems, airborne EW computer software, avionics, systems integration, electronics engineering concepts, principles and practices applicable to a broad range of engineering assignments. Candidates must be analytical, methodical and detail-oriented

This position is located at Eglin Air Force Base, Florida. Travel may be required.

U.S. Citizenship Required for this Position: Yes

Job Type: Regular Full-time

Security Clearance: Secret

Schedule: (M-F; 8-5)

Work Location: customer site

Travel: yes, likely

Relocation Assistance Available: possible

Position Contingent Upon Award of Contract: yes, (contingent offer on incumbent transition to GS position)

Benefits:
Torch Technologies is proud to offer a stable and professional work environment, a competitive salary, and an excellent, comprehensive benefit package including: ESOP participation, 401(k) match and safe-harbor contribution, medical, dental, vision, life insurance, short-term disability, long-term disability, flexible spending accounts, Health Saving Accounts and Health Reimbursement Accounts, EAP, education assistance, paid time off, and holidays.

Applying to Torch Technologies:
Only those candidates invited for an interview will be contacted. Employment at Torch Technologies is contingent upon the successful completion of a comprehensive background check.

Torch Technologies is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Employment Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability or any other protected class.",2002,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,1001 to 5000 Employees,Company - Private,False
Data Engineer (USSOCOM),"SimIS Inc.
","Tampa, FL",$77K - $130K (Glassdoor est.),4.2,"Data Engineer for USSOCOM IDST

Position Description. Support the USSOCOM J2 Intelligence Data Science Team (IDST)’s ongoing data analytic programs. Build and maintain data systems and construct datasets that are easy to analyze and support customer requirements. Implement methods to improve data reliability and quality. Combine raw information from different sources to create consistent and machine-readable formats. Develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling. Develop and deploy Application Programming Interfaces (API) to expose IDST maintained data to the enterprise. Collaborate with the Digital and Artificial Intelligence personnel, Knowledge Management teams, and other activities supporting data analysis for the intelligence community to include planning events, customer requirement discussions, and client intelligence capability development.

Knowledge.

Expert knowledge on data integration processes and supporting documentation requirements.
Expert knowledge using Python, SQL, noSQL, Cypher, POSTGRES and AGILE software development methodology.
Preferred: Working knowledge of

a. SOF community intelligence process and analysis tradecraft to compile, collate, analyze, produce, and evaluate all-source intelligence and support the Ops-Intel fusion process.

b. Various tools that support Special Operations Force (SOF) intelligence analysis, data sources relevant to the needs of the analyst, and the tradecraft associated with SOF intelligence analysis.

Skills.

Building, testing, and maintaining data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using modern data technologies
Developing analytics tools and transformative algorithms for data to provide actionable insights into customer processes, operational efficiency and other key business performance metrics
Creating new data validation methods for analytics and data scientist team members that assist them in building and optimizing products to fulfill customer objectives
Working with IDST stakeholders including USSOCOM leadership, customers, and design teams to assist with data-related technical issues and support their data infrastructure needs
Analyzing procedures for USSOCOM data separation, access, and security across users and the enterprise data architecture
Working with IDST data and analytics experts to strive for greater functionality in our data systems and capability integration
Creating and maintaining optimal data pipeline architecture and support associated process improvements for automating manual processes, data delivery, and infrastructure re-design for scalability

-Preferred - using Gitlab, and JIRA.

Providing written and verbal products and supporting business process documentation.
Working independently and as part of many teams.
Applying excellent time management and work prioritization to complex and integrated program requirements.
Executing complex projects within government defined timelines across a geographically dispersed workforce and user base.
Excellent communication, organizational, and problem-solving skills.

Experience.

Required:

Eight years' experience as a data engineer providing services similar in required tasks, scope, and complexity.
Documented experience employing data models, data mining, and segmentation techniques.
Documented experience developing, deploying and/or maintaining enterprise level data solutions.
Documented experience using SQL database design.

Preferred:

Using SOFNET-U, SOFNET-S, JIANT, SOIS, SOCRATES, NSANet and Commercial internet
Having Data Engineering certification
USSOCOM military or civil service experience.
Currently residing in the Tamps, FL area.

Education. Bachelor’s degree in a computer science discipline, IT or similar field.

Certifications. Preferred: Current certification for completion of the USSOCOM training and deployment requirements at the CONUS Replacement Center (CRC) as mandated by Principal Assistant for contracting (PARC) Policy Alert 12-01 dated 24 October 2011, SUBJECT: Contractor Deployment and Redeployment Requirements in Support of the U.S. Central Command Area of Responsibility.

Security. Required: Current DoD Top Secret clearance and eligible for SCI access and ACCM read-on and associated duty activities for access to SCI, FGI, and NATO material.

Travel. Some travel (estimate less than 10%) both within and outside the Continental United States. Current active US passport required.

Place of Performance. On-site at USSOCOM Headquarters, McDIll AFB, Florida; office space with utilities and Government-provided office equipment.

Full-Time employment. 11 Federal Holidays; core work hours are 0900-1500 hrs with military team is Monday-Friday; contractors can report as early as 0630 hrs and latest to depart time is 1730 hrs and adjusted as necessary to meet installation network support requirements.

Period of Performance. 1 year Base period (starting Aug 2023); option periods under consideration.


SimIS Offers:

Flexible Spending Account (FSA)
Medical, Dental, and Vision
Short Term Disability (SimIS provides Short-Term Disability benefits at no cost to you)
LTD
Life Insurance
401(k) Savings Plan
Tuition Assistance Program
Paid Time Off (PTO)
10 Holidays each year

SimIS, Inc. is an AA / EOE / M / F / Disability / Vet / V3 certified / Drug Free Employer

6qopbWtjAo",2007,National Agencies,$1 to $5 million (USD),Government & Public Administration,1 to 50 Employees,Company - Private,True
Senior Solutions Engineer - Data Center Immersion Cooling,Marathon Digital Holdings,"Tampa, FL",$77K - $113K (Glassdoor est.),-1.0,"Datacenter Immersion Cooling, Sr Solutions Architect Engineer

SUMMARY

The Senior Solutions Engineer - Data Center Immersion Cooling will be responsible for developing and refining our Two-Phase Immersion Cooling (2PIC) product use cases and product designs. He or she will also play an integral role in serving as the interface between potential partners and customers and our technical teams and answering customers' technical questions.

ESSENTIAL DUTIES AND RESPONSIBILITIES include the following. Other duties may be assigned.

Drive sales strategy and success leveraging deep technical familiarity of our products
Document and communicate customer technical and business requirements to internal stakeholders
Design and configure solutions which address customers unique needs
Develop and configure demos which position differentiated solutions
Quantify business and technical value of our HPC hardware in solving customer problems
Execute Proofs of Concept for custom deployments
Write accurate and compelling RFP content that position a unique HPC solution
Craft reusable technical content such as whitepapers, playbooks, and how-tos
Develop and maintain relationships with technical representative(s) at customer
Mentor teammates, share technical expertise and industry knowledge
Distill, prioritize, and communicate product feedback to internal teams
Present at marketing events, trade shows, and user conferences

QUALIFICATIONS: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform essential functions.

7+ years of solution engineering experience, including pre and post sales at a major semiconductor company
5+ years of experience working with datacenters, CSPs or cooling technologies
Exceptional speaking, writing, and presentation skills to all audiences
Boundless energy. Inspirational passion. Customer Service. Sense of ownership.
Bachelor's degree in Engineering, Computer Science, or similar preferred
Willingness to travel as needed

Benefits offered:

Company paid Health Insurance (base plan)
Company paid Dental Insurance (base plan)
Company paid Vision Insurance (base plan)
Company Paid Basic Life & AD&D Insurance
Supplemental Life Insurance
Aflac Voluntary Products
Legal Plans
Pet Insurance
Short-term and Long-term Disability
Paid time off

Marathon Digital Holdings is an Equal Opportunity Employer",-1,Internet & Web Services,Unknown / Non-Applicable,Information Technology,Unknown,Company - Public,True
Data Acquisition and Control Engineer,"Keller North America, Inc.
","Miami, FL",$67K - $105K (Glassdoor est.),4.0,"Company Logo:
Overview:

Keller is the world leader in geotechnical construction and deep foundations. With a North American presence of over 100 years, we operate as the market leader with over 50 offices throughout the US and Canada. By connecting global resources and local experience, Keller develops innovative, practical, and cost-effective solutions to geotechnical challenges. Our values of integrity, collaboration, and excellence enable us to lead the industry in providing the optimal solution for our clients.




We are looking for a DAQ Engineer based out of our office in Miami, FL.


Job Summary: Independently work to develop, maintain, and repair electrical and electronic components for our specialized construction equipment. Act as a technical lead in the business unit. Provide innovative solutions for the junior members of the DAQ team. Assist with technical R&D ideas for the business unit.
Responsibilities:
Responsible for developing, maintaining, and repairing electrical components.
Participates regularly in scheduling meetings.
Responsible for ensuring we have equipment needed for current and upcoming work.
Monitors and maintains tracking for all equipment this includes scheduling maintenance and submitting requests for new equipment when required.
Evaluate costs and time associated with various equipment.
Oversees troubleshooting, testing various designed systems, building electrical control panels, and assembling electrical components on heavy equipment/drill rigs and pumps.
Oversees assembly and installation of equipment at the shop facility and at various projects/jobsites.
Effectively troubleshoot by reading electrical signals via software interfacing with Keller’s data acquisition systems.
Repair and troubleshoot electrical components and equipment as needed.
Read, interpret, and analyze technical data from PLC’s.
Efficiently troubleshoot instrumentation, control systems, and read electrical schematics.
Specialize in one of the three areas: Data Acquisition Software for a Business Unit specific project/need, Electrical Drawings and Manuals or GPS Integration with Mobile Drill Rigs.
Responsible for R&D in the Branch and/or Business Unit.
Manages DAQ hardware for the Branch and/or Business Unit.
People Management
Act as technical lead in the business unit with the ability to manage multiple technicians.
Provides innovative solutions for the junior members of the DAQ team.
Safety and Quality Assurance
Ensures compliance with all Keller and OSHA safety requirements.


Qualifications:
Background Requirements (Knowledge, Skills, Experience)

Bachelor’s Degree in Electronics Engineering Technology or similar preferred.
Minimum 5 years relevant experience preferred.
Excellent computer, written and verbal communication skills necessary.
Equipment related technical knowledge.
Hands-on electrical experience.
Experience with sensors or instrumentation.

Keller is an Equal Opportunity Employer. We encourage qualified women, minorities, veterans, individuals with disabilities, and other legally protected characteristics to apply.


Keller is committed to working with and providing reasonable accommodation to applicants.


Equal Employment Opportunity",1860,Construction,$100 to $500 million (USD),"Construction, Repair & Maintenance Services",201 to 500 Employees,Company - Private,False
Data Scientist/GeoSpatial Engineer (SOUTHCOM),"SimIS Inc.
","Miami, FL",$65K - $111K (Glassdoor est.),4.2,"Data Scientist and GeoSpatial Engineer- SOUTHCOM

Position Description. Serve as the Data Scientist and GeoSpatial Engineer responsible for creation of innovative solutions and data connection frameworks for the design, development, and integration of the Enhanced Domain Awareness (EDA) Architecture Services for the United States Southern Command (USSOUTHCOM) so the staff can begin sharing Publicly Available Information (PAI) and Commercially Available Information (CAI) to include source-agnostic data and other non-traditional data sources such as Non-Government Organizations (NGOs), and USG and interagency in an unclassified (CUI) environment with Partner Nations in order to enhance overall USSOUTHCOM mission effectiveness and to have a more profound effect on counter-narcotics/counter-transnational organized crime(CN/CTOC) operations.


Knowledge

Expert knowledge for adapting broad or vague requirements and creatively engineering solutions while informing government leadership and customers on product development progress. Must be able to envision product ideas independently.
Working knowledge to develop, implement, and automate Extract, Transform, Load (ETL) multi-stage processes, retrieving data from API’s or flat files, using analytical programming tools to extract and fuse data from multiple sources across work units or vendors into a consistent format and load data into a specified target database.
Working knowledge building knowledge graphs and knowledge of Kubernetes and docker, experience deploying code in Jupyter Notebooks or Esri ArcGIS Enterprise Notebook Server, various data ingestion techniques, and significant script writing (primarily Python) for data ingestion.
Expert knowledge of ArcGIS Enterprise suite, ArcGIS Pro, and ArcGIS Web Application development.
Working knowledge of computer vision and machine learning concepts and OSINT methodologies, production, and intelligence writing.


Required Skills


Translating user stories into requirements, and writing scripts for ingesting new live feeds, documents, and data.
Creating mission domain awareness solutions using remote sensing technologies and real-time sensors.
Working directly with customers internal and external to the organization to analyze large amounts of raw data to help find patterns and enable informed decision making at the highest levels.
Providing technical leadership and influencing cross-functional teams to identify requirements, design, develop, and deploy geospatial solutions that support decision-making processes.
Working with the customer to develop conceptual solution designs, monitor and conduct regular maintenance on systems and data ingest feeds, provide troubleshooting and technical support, and occasionally provide executive level briefings and presentations.




Experience

Required: 2 yrs experience developing data solutions for client IT requirements and supporting platforms

2. Preferred:

a. USSOUTHCOM/DOD/Combatant Command/ Joint Staff military or civil service experience.

b. Currently residing in the Miami area to commute to USSOUTHCOM Headquarters.

Education Required: Bachelor’s Degree with 2+ years’ experience supporting DoD and/or Interagency data solution development and application requirements.


Certifications. None


Security. Required: Active personnel security clearance at the Top Secret clearance based upon a Tier 5 investigation completed within the past five (5) years, and eligible for access to Sensitive Compartmented Information (SCI) level.

Travel. US Passport required to travel as required in USSOUTHCOM area of responsibility (AOR); anticipate 10-15% of contract time allocated to travel in the supporting/supported agencies in the AOR.

Place of Performance. On-site at USSOUTHCOM Headquarters, Miami, Fl; office space with utilities and Government-provided office equipment.

Full-Time employment. 11 Federal Holidays; duty day is 7:30AM to 4:40PM Monday-Friday and adjusted as necessary to meet USSOUTHCOM requirements.

Period of Performance. 1 year Base period (starting Aug 2023) and four 1-year option periods.


SimIS Offers:

Flexible Spending Account (FSA)
Medical, Dental, and Vision
Short Term Disability (SimIS provides Short-Term Disability benefits at no cost to you)
LTD
Life Insurance
401(k) Savings Plan
Tuition Assistance Program
Paid Time Off (PTO)
10 Holidays each year

SimIS, Inc. is an AA / EOE / M / F / Disability / Vet / V3 certified / Drug Free Employer

3ukiTqB0vL",2007,National Agencies,$1 to $5 million (USD),Government & Public Administration,1 to 50 Employees,Company - Private,True
Data Warehouse Engineer,"Kalera, Inc.
","Orlando, FL",$80K - $126K (Glassdoor est.),2.6,"What You'll Do


Our Data Warehouse Engineer will be part of a team that will manage the operations and analytics of the product data warehouse at Kalera. The Data Warehouse Engineer role is to develop and maintain reporting and analysis databases using SQL, A/L, MS Synapse, and PowerBI ensuring high levels of data accessibility and availability. They will also evaluate and advise on database architecture in the product data warehouses. If you love cross-departmental collaboration, data warehouse design, technical execution, and thrive in an environment of project ownership then we want to hear from you.

Take a peek!

Works closely with IT partners and the product teams to lead and participate in the identification, planning, prioritizing, requirements gathering, design, development and implementation of all Data Warehousing and BI projects.
Architect and maintain data warehouses to support ease of data modeling, reporting, and analysis using dimensional model architecture (such as star schemas and OLAP cubes)
With support from the product team you will gather requirements to grow and improve the data warehouse for reporting, BI integration, and ad hoc analysis
Makes recommendations, based on data profiling and data analysis, for changes to existing/legacy systems particularly in the area of data warehouse architecture
Develop and maintain database stored procedures, views, and functions that support data models
Works with non-technical, subject matter experts to understand underlying data behavior and characteristics in ways that will be new for such non-technical people.
Develop and maintain ETL processes, diagnose and resolve database access and performance issues, and plan and coordinate backup and disaster recovery setup
Provide expert thought leadership in the development and implementation of data governance policies and processes
Provide data management support and work cooperatively with the product team to resolve data and process issues
Create and maintain technical documentation

What you’ll have!

Bachelor’s degree in Computer Science, Computer Engineering or relevant field.
At least five years or more of experience in ETL processes, data warehouse architecture and or administration within the Microsoft/SQL stack
Strong familiarity with Kimball methodologies of data warehousing
Ability to communicate verbally and in writing with end users and technical users to translate requirements from end users into useful visualizations and analysis
Comprehensive grasp of data visualization methods and data modeling for effective database architecture to streamline business analysis and reporting
SSMS, ETL Tooling, Reporting experience such as Power BI or equivalent tools
In-depth understanding of data management (e.g. permissions, recovery, security, and monitoring)
Broad business experience with proficient ability to talk in business terms
Excellent verbal and written communication skills



Equal Opportunity Employer

At Kalera, Inc. all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, veteran status, sexual orientation, gender identity or any other basis protected by applicable law.",-1,Crop Production,Unknown / Non-Applicable,Agriculture,51 to 200 Employees,Company - Private,False
Data Engineer - MacDill AFB- Tampa FL,"Peraton
","Macdill AFB, FL",$112K - $179K (Employer est.),3.6,"Peraton Overview
Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.
Responsibilities

In support of the Operational, Planning, Implementation, and Assessment Services (OPIAS) contract, Peraton is seeking a Data Engineer who can leverage experience and expertise in data exploration, engineering, and ETL to architect, develop, and deploy scripts for processing structured and unstructured data into usable data formats for long term storage, search, and analysis.

The successful Data Engineer candidate will work with a diverse team of data scientists, social scientists, cultural advisors, operations research systems analysts (ORSAs), and information operations (IO) planners to translate empirical research findings into operational assessments.
The Data Engineer will be responsible for developing software for user interfaces, data extraction and transformation to improve data reliability, quality and utility.
The candidate should also be comfortable working with military planners to break down and synthesize data in a fashion that best informs plans and operations.

Roles and responsibilities for this position include:

Utilize your experience with AWS, Azure, or Google Cloud
Creating a custom ingest pipeline to a Big Data platform with consistent performance and scalability
Understanding programming and data engineering concepts and best practice
Experience working with both structured, semi-structured, and unstructured data to include data parsing, transformation, schema definition, and query/analysis
Ability to manage and organize data while identifying trends and inconsistencies that will impact downstream analytics
Experience with data pipelines or be willing to learn a pipeline from bottom to top
Be able to troubleshoot files against an architecture to see where the upload process is failing
Be able to understand unit tests and add to them to increase stability to the entire pipeline
Be prepared to use GIT, Anaconda, Spyder, and Microsoft tools
Be prepared to express ideas and solutions and walk together with teammates through coding challenges

Qualifications

Basic Qualifications:

Bachelor of Science in computer programming, mathematics or a related degree with 8-10 years of experience, 6-8 yrs. with a Masters Degree
Demonstrated experience applying data engineering and software development expertise
Work / research history demonstrating applied experience with programming languages such as Python, SQL, Java, etc.
Linux OS (Ubuntu, CentOS, Red Hat), and Windows environments
Ability to work both independently and collaboratively
High levels of curiosity, creativity, and problem-solving capabilities
Strong written and verbal communication skills
Experience building ETL pipeline architectures
AWS, architectures
Experience with ETL tools such as NiFi or Informatica
Must be willing and able to travel within the CCMD area of responsibility as required by the program.
Current DoD SECRET security clearance
Current US Passport

Preferred Qualifications:

A graduate degree in computer programming / science, mathematics, or related degree an 10-14 years of experience
AWS certifications such as AWS solutions architect or developer
Cyber security certifications
Statistical package expertise in programs such as IBM SPSS/PASW, R, STATA or MS Excel statistics
Experience applying data science to address defense or social science issues
Experience using geospatial analytic package (e.g., ArcGIS, QGIS, etc.)
Joint intelligence or operational assessment experience with Combatant Commands
TS/SCI clearance
Target Salary Range

$112,000 - $179,000. This represents the typical salary range for this position based on experience and other factors.

SCA / Union / Intern Rate or Range

EEO
An Equal Opportunity Employer including Disability/Veteran.

Our Values

Benefits
At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.

Paid Time-Off and Holidays
Retirement
Life & Disability Insurance
Career Development
Tuition Assistance and Student Loan Financing
Paid Parental Leave
Additional Benefits
Medical, Dental, & Vision Care",2017,Information Technology Support Services,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Private,False
513th Electronic Warfare Mission Data Engineer,"DCS Corp
","Niceville, FL",$62K - $95K (Glassdoor est.),4.3,"Job Description

DCS Corp has an immediate opening for an Electronic Warfare (EW) Mission Data (MD) Engineer supporting the USRL and 513 th Electronic Warfare Squadron on Eglin AFB.

Essential Job Functions:
The EW MD Engineer will work with other members of the MD team to develop state-of-the-art MD for advanced 5 th generation fighter aircraft. The ideal candidate’s responsibilities will include:
Conduct research and perform intelligence collection to assist in F-35 EW Suite MD re-programming efforts.
Develop complex EW models and programs, including automation tool utilization/design, to increase efficiency for lab testing and analysis.
Program complex MD Files to provide enhanced situational awareness for F-35 pilots.
Advise on RF components, characteristics, and antenna performance parameters to assist in MD re-programming efforts.
Provide detailed feedback and support by performing validation and verification analysis, MD File Generation, as well as assisting in MD group management.

Required Skills:
Due to the sensitivity of customer related requirements, U.S. Citizenship is required.
Bachelor's Degree in an Engineering discipline with five years of relevant experience.
Electrical Engineering degree is preferred.
Must have a Secret security clearance.

Desired Skills:
Experience with programming 4 th or 5 th generation fighter MD.
Experience with developing SW supporting creating MD reports and automation.
Experience with training on MD SW and programming.
Experience with directing MD testing in a lab setting.
Experience with MATLAB.
Experience with Intel sources such as CED, EWIRDB, and NGES.
Experience with the MD repository & re-programming application, SPECTRE.
Experience with V&V test plans AESA radar systems, HFIM, and EW modulation on pulse.
Familiarity with F-35 avionics.",1977,Research & Development,$100 to $500 million (USD),Management & Consulting,1001 to 5000 Employees,Company - Private,False
DMATS JR. Network Data Engineer - 16622,"HII
","Hurlburt Field, FL",$41K - $66K (Glassdoor est.),3.6,"Requisition Number: 16622

Required Travel: 0 - 10%

Employment Type: Full Time/Salaried/Exempt

Security Clearance: Secret

Level of Experience: Entry Level

This opportunity resides with Live, Virtual, Constructive Solutions, a business group within HII's Mission Technologies division. As a trusted partner to our military customers, we design, develop and operate systems that bring together service members from across the globe to help you train like you fight, because we understand that preparation requires full coordination-not readiness in piece parts.

Meet HII's Mission Technologies Division
Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense - the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that's right for you. Apply today. We look forward to meeting you.

Summary

HII Mission Technologies is seeking a Junior Network Data Engineer for the Decisive Mission Actions and Technology Services (DMATS) with the US Air Force Special Operations Command (AFSOC) at Hurlburt Field, Florida. The selected candidate must The selected candidate will support the design, implementation and maintenance of DoD computer networks, enabling communication between multiple computer based systems. #LI-MJ1

What you will do

Assist in the Identification and resolution of network issues, perform routine maintenance and protect data from cyber-attacks.
Supports the design and maintenance of the hardware and software of a network.
Works with the senior Network Engineer to Conduct testing of network systems.
Performs routine network maintenance, including basic troubleshooting and installation of upgrades and service packs.
Consults with network engineering team to suggest network solutions
Test and install new computer systems, hardware, software, and applications as per DoD and customer guidance.
Explore ways to improve network performance or reduce network costs
Maintain analytical systems, verifies the accuracy of the data, and act as liaison.
Manage all aspects of end-to-end data processing utilizing customized report building functions of systems.
Maintain technical expertise in all areas of network and computer hardware and software interconnection and interfacing, such as routers, switchers, firewalls, hubs, bridges, gateways, etc.



What you must have

Must have 0 years experience with Bachelors in Computer Science, Data Scientist, Statistics or related field; High School Diploma or equivalent and 4 years relevant progressive experience.
Must have Knowledge of cloud architectures.
Must have a CompTIA Security + Certificate.
Must be proficient in creating reports and presentations with Microsoft Office 365 products
Must have excellent verbal and written communication skills to present technical information to clients, stakeholders, and team members in a clear and concise manner
Must be a self-starter able to work independently or as part of a larger professional team
Must hold a current or active DoD Secret Security Clearance.
Must be a U.S. Citizen.



Preferred

Experience in DoD programs
Experience with Air Force programs
Certified Analytics Professional (CAP)
Cloudera Data Platform Generalist Certification
IBM Data Science Professional Certificate
Microsoft Certified: Azure AI Fundamentals
Microsoft Certified: Azure Data Scientist Associate
Open Certified Data Scientist (Open CDS)
SAS Certified AI and Machine Learning Professional
SAS Certified Data Scientist
Tensorflow Developer Certificate



Physical Requirements

May require working in an office, industrial, shipboard, or laboratory environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances.

Why HII
We build the world's most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our diverse workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals.

Recognized as one of America's top large company employers, we are a values and ethics driven organization that puts people's safety and well-being first. Regardless of your role or where you serve, at HII, you'll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career.

Together we are working to ensure a future where everyone can be free and thrive.
Today's challenges are bigger than ever, and the nation needs the best of us. It's why we're focused on hiring, developing and nurturing our diversity. We believe that diversity among our workforce strengthens the organization, stimulates creativity, promotes the exchange of ideas and enriches the work lives of all our employees.

All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.

Do You Need Assistance?
If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Technical Solutions.",2011,Aerospace & Defense,$10+ billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
Senior/Staff Data Engineer,"EvenUp
",Florida,-1,3.9,"EvenUp is a venture-backed generative AI startup that ensures injury victims are awarded the full value of their claims, expanding the $100B+ in awards granted to injury victims every year. Every year, the legal system has made it difficult for millions of ordinary people to seek justice, especially for folks without means or who come from underrepresented backgrounds. Our vision is to help these injury victims get the justice they deserve, irrespective of their income, demographics, or the quality of their legal representation.

EvenUp operates across all types of injury cases, from police brutality and child abuse to California wildfires and motor vehicle accidents. Our ML-driven software empowers attorneys to accurately assess the value of these cases by doing a core part of their workflow (legal drafting), enabling them to secure larger settlements in record time. As EvenUp evaluates more cases, our proprietary data grows, enhancing the precision of our predictions and delivering more value to both attorneys and victims alike.

As one of the fastest growing startups ($0 to $10M in ARR in <2 years), we raised $65M in investment from some of the best investors in the world (Bessemer, Bain Capital, Signalfire, DCM, NFX, Tribe Capital), seasoned tech executives (i.e. founder of Quora, SVP at Google, former CPO at Uber), and public figures that care about our social mission (Nas, Jared Leto, Byron Jones). Our team comes from top tech, legal, and investing backgrounds including Waymo, Google, Amazon, Uber, Quora, Blizzard, Norton Rose, Warburg Pincus, Bain, and McKinsey.

Why we are hiring a Senior/Staff Data Engineer now?

We have experienced unprecedented growth and need to scale out our data warehousing, data tooling and internal analytics. We need to architect the future of our data infrastructure at EvenUp and we’re seeking engineering leaders to help drive that vision.

We will need to 10x our pipeline processing throughput over the next 12 months. We’ll need to rethink and rebuild how we extract, process and model our ingestion to enable our organization with precise and actionable data.

We need to design & build data warehousing that democratizes data for our entire organization. We will invest in identifying and integrating tools and services that empower our teams to build on top of our data and analytics.

What you’ll do:

Democratize data at EvenUp. Ensure our organization can scale with consistent, standardized access to our data stores and accelerate our ability to build and experiment with data products

Architect and build out the future of data warehousing at EvenUp

Enable and empower our Data Science team to rapidly iterate on model experimentation

Design, organize and refine data storage strategies that reduce development friction for our tech organization

Collaborate with cross functional teams to solve critical data problems

Help grow our nascent Data Insights team and define a “data first” mentality across our organization

What we are seeking:

8+ years of data engineering experience

Previous experience building out data warehousing, data pipelines, and internal analytics

Strong understanding and practical experience with data tooling, BI tools, and systems such as DBT, BigQuery, Elasticsearch

The ability to communicate cross-functionally with various stakeholders to derive requirements and architect scalable solutions

Have several years of industry experience building high-quality software, shipping production-ready code and infrastructure

You enjoy owning a project from start to finish and love to drive a project across the finish line

Interest in making the world a fairer place (we don’t get paid unless we’re helping injured victims and/or their attorneys)

Nice to haves:

Have previously built out a Data Insights team at a data-oriented startup

Have previously planned and architected data migrations at scale

Have stood up analytics tooling to enable cross-functional teams

Domain expertise in legal technology, medical records, and working with unstructured data

A successful first year may look like:

75% doing system design and contributing code, starting with shipping code within 2 weeks!

25% collaborating with stakeholders and mentoring, lunch and learns, and more

Leverage a self-starter mindset by taking a product concept and building the feature end to end (whether it’s a component of the system or a significant piece of functionality).

Collaborate with the team to scale the tech stack based on our rapidly growing user base!

Benefits & Perks:

We seek to empower all of our team members to fulfill our mission of making the world a more just place, regardless of our team’s function, geography, or experience level. To that end, we offer:

- Fully remote setup - work from wherever you feel is best (Plus a stipend to upgrade your home office!)

Flexible working hours to match your style

- Offsites - get to meet your coworkers on a fully-expensed trip every 6-12 months!

Choice of great medical, dental, and vision insurance plan options
Flexible paid time off
A variety of virtual team events such as game nights & happy hours


EvenUp is an equal-opportunity employer. We are committed to diversity and inclusion in our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",-1,Internet & Web Services,Unknown / Non-Applicable,Information Technology,Unknown,Company - Public,True
Software Engineer - Learning Engineering and Data (LEaD) Program,"Millennium
","Miami, FL",$69K - $114K (Glassdoor est.),3.7,"Software Engineer - Learning Engineering and Data (LEaD) Program

Millennium is a large global alternative investment manager with a strong commitment to leveraging innovations in technology and data. As a member of our Miami based Learning Engineering and Data (LEaD) program, LEaD engineers can expect to get comprehensive training and work alongside technology mentors and leaders to develop and maintain applications and tools spanning front-office, middle-office and back-office functions in a dynamic and fast paced environment. LEaD engineers can expect to have exposure to investment teams and technologists in different parts of Millennium’s organization while learning new skill sets through hands-on training and development opportunities.

Main Function:

Our technology teams are looking for Software Engineers with C++, Python or Java to design, implement, and maintain systems supporting our technology business functions. Candidate is expected to:

Work closely with technology teams to develop requirements and specifications for varying projects
Take part in the development and enhancement of the backend distributed system

Qualifications/Skills Required:

2-5 years of experience working with C++, Python, or Java
Experience with ML libraries, Pandas, NumPy, FastAPI (Python), Boost (C++), Spring Boot (Java)
Must be comfortable working in both Unix/Linux and Windows environments
Good understanding of various design patterns
Strong analytical and mathematical skills along with an interest/ability to quickly learn additional languages and quantitative concepts
Solid communication skills
Able to work collaboratively in a fast-paced environment with a passion to solving complex problems
Detail oriented, organized, demonstrating thoroughness and strong ownership of work

Desirable Skills/Knowledge:

Bachelor or Master’s degree in Computer Science, Engineering, Applied Mathematics, Statistics or related STEM field
Understanding of distributed messaging systems
Experience with Docker/Kubernetes, micro services architecture in a cloud environment (AWS, GCP preferred)
Experience with relational and non-relational database platforms",1989,Investment & Asset Management,Unknown / Non-Applicable,Financial Services,1001 to 5000 Employees,Company - Private,False
Sr Data Operations Engineer,"Wabtec
","West Melbourne, FL",$81K - $112K (Glassdoor est.),3.7,"Wabtec Corporation is a leading global provider of equipment, systems, digital solutions and value-added services for freight and transit rail. Drawing on nearly four centuries of collective experience across Wabtec, GE Transportation and Faiveley Transport, the company has unmatched digital expertise, technological innovation, and world-class manufacturing and services, enabling the digital-rail-and-transit ecosystems. Wabtec is focused on performance that drives progress, creating transportation solutions that move and improve the world. Wabtec has approximately 27,000 employees in facilities throughout the world. Visit the company’s new website at:
http://www.WabtecCorp.com
.

It’s not just about your career… or your job title…it’s about who you are and the impact you are going to make on the world. Do you want to go into uncharted waters…do things that haven’t been done to make yours and someone else's life better? Wabtec has been doing that for decades and we will continue to do so! Through our people, leadership development, services, technology and scale, Wabtec delivers better outcomes for global customers by speaking the language of industry.
Summary:
The Sr Data Operations Engineer will have deep, focused, and varied experience specifically with supporting production Cockroach database environments. This employee will plan, coordinate, and administer Cockroach databases in an environment that requires deep hands-on development, design, and implementation with an end goal being a fully automated environment using Ansible. This position will lead the deployment of Cockroach database in support of a major greenfield software development project and manage the transition into a sustainable support structure.
Duties and Responsibilities:
As a part of a cross-functional IT team, the Sr Data Operations Engineer will create and maintain all databases required for development, testing, and production usage.
Performs capacity planning required to create and maintain CRDBs. The Sr Data Operations Engineer works closely with System Administration Engineers to build capacity plans.
Performs ongoing tuning of all CRDBs.
Installs new versions of Cockroach and its tools.
Patches Cockroach on a consistent cycle.
Plans and implements backup and recovery for Cockroach databases.
Implements and enforces security for all Cockroach databases.
Use knowledge of Cockroach internals to help develop and implement application design and coding use of the database.
Provide technical support to the application development team.
Automation of database related activities using Ansible.
Train other Data Operations Engineers as a Cockroach SME.
Other duties as assigned
Minimum Qualifications: (To perform this job successfully, an individual must be able to perform each essential duty satisfactorily.)
BS/BA in Computer Science or related field, or equivalent work experience
5 to 7 years of deep experience in Cockroach Database Administration and design.
Hands-on, production support experience with troubleshooting Cockroach database issues.
Working knowledge of Oracle Database Administration.
Hands-on experience with migration of data cross database platforms.
Working knowledge of incident and service management. ITIL certification a plus.
Must be willing to work occasional on call weekday/weekend schedule.
Knowledge, Skills and Abilities:
The ability to seamlessly work with application developers, other strong technical leaders, and non-technical staff.
Ability to work unsupervised.
Strategic and creative thinking to analyze issues that may arise and create solutions.
Ability to respond positively to feedback and implement change in process and procedures as needed.
Familiarity with Kubernetes and other cloud related database concepts.
Experience with Datadog use and monitoring design.
Experience with using Gitlab to manage code.
Linux and Windows operating system understanding to setup and tune tools.
Ability and desire to self-train on infrastructure topics that arise in a dynamic environment.
Desire and ability to create documented processes, procedures and knowledge documents for a variety of technical and non-technical audiences.
Extremely strong written and verbal skills. Documentation will be a large part of the job.
Desire and flexibility to be on-call to support customers at varying contractual agreement levels.
Physical Demands: (The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.)
Employee is regularly required to talk and hear.
Work Environment: (The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job.)
The employee will normally work in a temperature-controlled office environment, with frequent exposure to electronic office equipment.
Wabtec Corporation is committed to taking on the world’s toughest challenges. In order to fulfill that commitment we rely on a culture of leadership, diversity and inclusiveness. We aim to employ the world’s brightest minds to help us create a limitless source of ideas and opportunities. We believe in hiring talented people of varied backgrounds, experiences and styles…people like you! Wabtec Corporation is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, or protected Veteran status. If you have a disability or special need that requires accommodation, please let us know.",1869,Transportation Equipment Manufacturing,$5 to $10 billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Big Data Platform Senior Engineer - Assistant Vice President,"Deutsche Bank
","Jacksonville, FL",$100K - $135K (Glassdoor est.),3.7,"Big Data Platform Senior Engineer - Assistant Vice President
Job ID: R0303626
Full/Part-Time: Full-time


Regular/Temporary: Regular
Listed: 2023-11-24


Location: Jacksonville


Position Overview

Job Title Big Data Platform Senior Engineer

Corporate Title Assistant Vice President

Location Jacksonville, FL

Overview

As a Big Data Platform Senior Engineer, you will work with Chief Investment Officers (CIO) teams, Group architecture, Support, and software development life cycle (SDLC) team to enable new features on the analytics platform. You will be responsible for building data solutions in collaboration with architects, product managers and other key program stakeholders. Also, you will be responsible for build, configure, and manage software on Cloud and/or on-prem for IaaS and PaaS Big Data solutions. Your role will also entail to build, tune, and perform operational efficiency (low cost/high automation) on production grade.

What We Offer You

A diverse and inclusive environment that embraces change, innovation, and collaboration

A hybrid working model, allowing for in-office / work from home flexibility, generous vacation, personal and volunteer days

Employee Resource Groups support an inclusive workplace for everyone and promote community engagement

Competitive compensation packages including health and wellbeing benefits, retirement savings plans, parental leave, and family building benefits

Educational resources, matching gift and volunteer programs

What You’ll Do

Responsible for building data solutions in collaboration with architects, product managers, and other key program stakeholders

Responsible for build, configure, and manage software on Cloud and/or on-prem for IaaS and PaaS Big Data solutions

Responsible to build, tune and perform operational efficiency (low cost/high automation) on production grade systems

Support the adoption of an agile way of working by working with agile coaches/leads to deliver in a scaled scrum approach, actively contributing and delivering on features, stories, tasks and ceremonies

Work with the wider community of engineers across the enterprise to increase standards and discipline

Work with the Chief Investment Officers (CIO) data leads to understand their requirement and provide platform capabilities to help them deliver business objectives, with product manager and product owner to help them in prioritizing the BoW, and with Support lead and Subject Matter Expert (SME) to improve platform stability and performance

Skills You’ll Need

Experience of the Hadoop ecosystem (preferably with Cloudera) and the technologies that comprise it

Expertise and knowledge in Data Structures and Algorithms, Structured Query Language (SQL) on Hadoop engines (e.g. Hive, Impala, Spark SQL) and OOP languages (like Java, C++, and Python). Knowledge in RDBMS, various NoSQL technologies and BI visualization tooling is a definite plus

Excellent problem solving skills within an agile team & process culture; ability to identify inefficiencies, duplication and look at ways and means for simplification

Demonstrable expertise in Data (or BigData) Engineering e.g. designing, building, operationalizing, securing and monitoring data processing systems with a particular emphasis on security and compliance or developing data pipelines using Cloud native data technologies (Storage accounts/ CloudSQL/ BigTable/ BigQuery/ Dataflow/ Dataproc etc)

Skills That Will Help You Excel

Excellent communication skills, both written and spoken

Certification in Hadoop stack or relevant

Certification in Cloud services

Self-starter

Believe in Collaboration and team player

Expectations

It is the Bank’s expectation that employees hired into this role will work in the Jacksonville office in accordance with the Bank’s hybrid working model.

Deutsche Bank provides reasonable accommodations to candidates and employees with a substantiated need based on disability and/or religion.

The salary range for this position in Jacksonville, FL is $78,000 to $111,800. Actual salaries may be based on a number of factors including, but not limited to, a candidate’s skill set, experience, education, work location and other qualifications. Posted salary ranges do not include incentive compensation or any other type of renumeration.

Deutsche Bank Values & Diversity

We believe talent is found in all cultures, countries, races, ethnicities, genders, sexual orientations, disabilities, beliefs, generations, backgrounds, and experiences. We pursue a working environment where everyone can be authentic and feel a sense of belonging. Click here to find out more about our diversity and inclusion efforts.

We are an Equal Opportunity Employer - Veterans/Disabled and other protected categories.

Click these links to view the following notices: EEO is the Law poster and supplement ; Employee Rights and Responsibilities under the Family and Medical Leave Act ; Employee Polygraph Protection Act and Pay Transparency Nondiscrimination Provision

Learn more about your life at Deutsche Bank through the eyes of our current employees: https://careers.db.com/life

The California Consumer Privacy Act outlines how companies can use personal information. If you are interested in receiving a copy of Deutsche Bank’s California Privacy Notice please email HR.Direct@DB.com .

Deutsche Bank Benefits

At Deutsche Bank, we recognize that our benefit programs have a profound impact on our colleagues. That’s why we are focused on providing benefits and perks that enable our colleagues to live authentically and be their whole selves, at every stage of life. We provide access to physical, emotional, and financial wellness benefits that allow our colleagues to stay financially secure and strike balance between work and home. Click here to learn more!

#LI-HYBRID

Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.
We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.

Visit Inside Deutsche Bank to discover more about the culture of Deutsche Bank including Diversity, Equity & Inclusion, Leadership, Learning, Future of Work and more besides.



We are an Equal Opportunity Employer - Veterans/Disabled and other protected categories. Click these links to view the following notices: ""EEO is the Law poster"" and supplement ; Employee Rights and Responsibilities under the Family and Medical Leave Act ; Employee Polygraph Protection Act and Pay Transparency Nondiscrimination Provision .",1870,Banking & Lending,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
"Associate Director, Engineering/Lead Engineer II (Data Center Network and WAN)","KPMG
","Orlando, FL",$91K - $133K (Glassdoor est.),3.8,"Known for being a great place to work and build a career, KPMG provides audit, tax and advisory services for organizations in today’s most important industries. Our growth is driven by delivering real results for our clients. It’s also enabled by our culture, which encourages individual development, embraces an inclusive environment, rewards innovative excellence and supports our communities. With qualities like those, it’s no wonder we’re consistently ranked among the best companies to work for by Fortune Magazine, Consulting Magazine, Working Mother Magazine, Diversity Inc. and others. If you’re as passionate about your future as we are, join our team.

KPMG is currently seeking an Associate Director, Engineering/ Lead Engineer II (Data Center Network and WAN) to join our Digital Nexus Technology organization.

Responsibilities:

Lead the direction of Network through the development of an information technology strategy that addresses overall firm’s information technology requirements
Define best practice and roadmaps for network products or solutions and support the development of network architecture
Collaborate with engineering and operational teams to drive the product roadmaps for network and WAN tools, by providing requirements that help to map controls and patterns to product features; work closely with the firm's network and information Security team and put a roadmap of products/solutions together
Develop business cases and conduct presentations to senior IT leadership of proposed network products, solutions, and studies
Stay abreast of the latest network information regulatory requirements, technologies, controls, practices, techniques, and threats and apply to network
Manage internal skills development activities for network architecture and engineering teams on new technologies and solutions driven by security and business requirements, by providing mentoring and by conducting knowledge sharing sessions; participate in network incident resolutions and root cause analysis where needed

Qualifications:

Minimum eight years of recent and progressive experience designing and implementing data center network, WAN architecture, cloud strategies, and reference architectures; from business requirements gathering to technology rollout oversight, including capacity management, definition of scoring methodologies for technology selection, integration of multiple tools and technical documentation
Bachelor's degree from an accredited college or university is preferred; Cisco CCIE, CCNP, CCDP or CISSP certification preferred
Strong understanding of TCP/IP and Data Center Routing & Switching; expert knowledge of switching technologies vPC, vPC+, OTV, VDC, VRF, VXLAN, VRF; Expert knowledge of routing technologies, EIGRP, OSPF, BGP, IPV4/V6, NAT, ACL’s, DNS; knowledge of NTP, SNMP, NetFlow, QOS, CEF, Security Protocols, network management tools; technical knowledge of remote access technology MPLS, VPN , IP Sec and ACLs; NAC technology; understanding of IDS/IPS such as SourceFire, and Palo Alto; understanding in firewall technologies; understanding of Proxies and Content Filtering technologies such as Bluecoat and ZScaler proxies; deep comprehension of SDWAN and wireless 802.11
Demonstrated experience in vulnerability scanning and related products; Knowledge of event correlation systems to diagnose and manage security events within the firm
Ability to program with one or more ‘scripting’ languages (such as Python, Ruby, Perl, Bash and JavaScript)
Knowledge or proven experience with public cloud deployments like AWS, Azure; solid knowledge of Network function virtualization Virtual router/Switch, Virtual FW, Virtual Load Balancers
US citizenship is required




KPMG complies with all local/state regulations regarding displaying salary ranges. If required, the ranges displayed below or via the URL below are specifically for those potential hires who will work in the location(s) listed. Any offered salary is determined based on relevant factors such as applicant's skills, job responsibilities, prior relevant experience, certain degrees and certifications and market considerations. In addition, the firm is proud to offer a comprehensive, competitive benefits package, with options designed to help you make the best decisions for yourself, your family, and your lifestyle. Available benefits are based on eligibility. Our Total Rewards package includes a variety of medical and dental plans, vision coverage, disability and life insurance, 401(k) plans, and a robust suite of personal well-being benefits to support your mental health. Depending on job classification, standard work hours, and years of service, KPMG provides Personal Time Off per fiscal year. Additionally, each year the firm publishes a calendar of holidays to be observed during the year and provides two firmwide breaks each year where employees will not be required to use Personal Time Off; one is at year end and the other is around the July 4th holiday. Additional details about our benefits can be found towards the bottom of our KPMG US Careers site at “Benefits & How We Work”.

Follow this link to obtain salary ranges by city outside of CA:
https://www.kpmg.us/work-for-kpmg/pay-transparency.html/?id=6682-9

KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, citizenship status, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.

KPMG does not currently require partners or employees to be fully vaccinated or test negative for COVID-19 in order to go to KPMG offices, client sites or KPMG events, except when mandated by federal, state or local law. In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site).",1987,Business Consulting,$1 to $5 billion (USD),Management & Consulting,10000+ Employees,Company - Private,False
Big Data Software Engineer III - AWS,"JPMorgan Chase & Co
","Tampa, FL",$86K - $124K (Glassdoor est.),4.0,"JOB DESCRIPTION


We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.

As a Software Engineer III at JPMorgan Chase within the Corporate and Investment Banking, you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.

Job responsibilities

Executes software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Creates secure and high-quality production code and maintains algorithms that run synchronously with appropriate systems
Gathers, analyzes, synthesizes, and develops visualizations and reporting from large, diverse data sets in service of continuous improvement of software applications and systems
Proactively identifies hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture
Adds to team culture of diversity, equity, inclusion, and respect

Required qualifications, capabilities, and skills

Formal training or certification on Java and AWS deployments concepts and 3+ years applied experience
Familiar with Kafka, API development, and large data volume processing
Hands-on practical experience in system design, application development, testing, and operational stability
Proficient in coding in one or more languages
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages
Demonstrated knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.)

Preferred qualifications, capabilities, and skills

Familiarity with modern back-end technologies and AWS implementations
Exposure to cloud technologies
EMR, MSK, S3, and Flink experience preferred
GraphQL and Swagger experience preferred
ABOUT US

JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)

We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.

JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans







ABOUT THE TEAM

The Corporate & Investment Bank is a global leader across investment banking, wholesale payments, markets and securities services. The world’s most important corporations, governments and institutions entrust us with their business in more than 100 countries. We provide strategic advice, raise capital, manage risk and extend liquidity in markets around the world.",1799,Banking & Lending,$10+ billion (USD),Financial Services,10000+ Employees,Company - Public,False
Data Engineer IV - Max Digital (Data Engineering),"ACV Auctions
",Florida,-1,3.7,"If you are looking for a career at a dynamic company with a people-first mindset and a deep culture of growth and autonomy, ACV is the right place for you! Competitive compensation packages and learning and development opportunities, ACV has what you need to advance to the next level in your career. We will continue to raise the bar every day by investing in our people and technology to help our customers succeed. We hire people who share our passion, bring innovative ideas to the table, and enjoy a collaborative atmosphere.

Who we are:
ACV is a technology company that has revolutionized how dealers buy and sell cars online. We are transforming the automotive industry. ACV Auctions Inc. (ACV), has applied innovation and user-designed, data driven applications and solutions. We are building the most trusted and efficient digital marketplace with data solutions for sourcing, selling and managing used vehicles with transparency and comprehensive insights that were once unimaginable. We are disruptors of the industry and we want you to join us on our journey. ACV’s network of brands includes ACV Auctions, ACV Transportation, ClearCar, MAX Digital and ACV Capital within its Marketplace Products, as well as, True360 and Data Services.
At ACV we focus on the Health, Physical, Financial, Social and Emotional Wellness of our Teammates and to support this we offer:

Multiple medical plans including a high deductible health plan that costs $0 out of your paycheck
Company-sponsored (paid) Short-Term Disability, Long-Term Disability, and Life Insurance
Comprehensive optional benefits such as Dental, Vision, Supplemental Life/AD&D, Legal/ID Protection, and Accident and Critical Illness Insurance
Generous paid time off options, including vacation time, sick days, Company holidays, floating holidays, parental leave, bereavement leave, jury duty leave, voting leave, and other forms of paid leave as required by applicable law or regulation
Employee Stock Purchase Program with additional opportunities to earn stock in the Company
Retirement planning through the Company’s 401(k)
Who we are looking for:
We are seeking a highly skilled Engineer IV in Data Engineering with a strong foundation in computer science and excellent problem-solving skills. You will be responsible for maintaining and extending our database operations, optimizing SQL queries, and designing scalable data services.

What you will do:

Actively and consistently support all efforts to simplify and enhance the customer experience.
Maintain and extend (as required) existing database operations solution for backups, index defragmentation, data retention, etc.
Troubleshoot any SQL Server or ETL stack outages during our operational support window.
Triage any issues with data stack (SSIS, C#, Web APIs).
Support development, integration, and stage SQL Server environments for application development and data science teams.
Ensure that new database development meets company standards for readability, reliability, and performance. Work with internal teams on transactional and analytical schema design.
Collaborate with software and DevOps engineers to design scalable services, plan feature roll-out, and ensure high reliability and performance of our products.
Architect and build entire services including but not limited to; data modeling, storage, message brokers, protocols and interfaces.
Design, build and maintain complex systems that can scale rapidly with little maintenance.
Conduct code reviews, develop high-quality documentation, and build robust test suites.
Own the overall performance of products and services within a defined area of focus.
Be empowered to lead and complete software projects with minimal guidance from managers.
Lead team discussions to define technical requirements on new and current products.
Respond-to and troubleshoot highly complex problems quickly, efficiently, and effectively.
Mentor junior engineers.
Perform additional duties as assigned.
What you will need:

Bachelor's degree in Computer Science, Information Technology, Computer Information Systems, Management Information Systems, or similar
5 years' building & supporting the database-tier of SaaS web applications.
Ability to read, write, speak, and understand English.
Expert understanding of SQL query execution fundamentals and query optimization principles.
Experience maintaining and extending an existing codebase, adapting to pre-existing patterns and tracing the code’s path of execution.
ETL workflow implementation (SSIS, Airflow, C#, Python)
Experience working with Cloud Services (AWS RDS, S3, SQS, SNS)
Experience working with NoSQL data stores (MongoDB)
Experience writing unit and integration testing (DBT, C#)
Expert SQL and data-layer development experience; OLTP schema design.
Experience integrating 3rd-party APIs, implementing authentication & authorization and developing asynchronous data flows.
Nice to Have
OLAP schema design experience.
Experience with Airflow, Snowflake, etc.
Experience with DBT
Our Values
Trust & Transparency | People First | Positive Experiences | Calm Persistence | Never Settling

At ACV, we are committed to an inclusive culture in which every individual is welcomed and empowered to celebrate their true selves. We achieve this by fostering a work environment of acceptance and understanding that is free from discrimination. ACV is committed to being an equal opportunity employer regardless of sex, race, creed, color, religion, marital status, national origin, age, pregnancy, sexual orientation, gender, gender identity, gender expression, genetic information, disability, military status, status as a veteran, or any other protected characteristic. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires reasonable accommodation, please let us know.

For information on our collection and use of your personal information, please see our Privacy Notice.",2014,Wholesale,Unknown / Non-Applicable,Retail & Wholesale,1001 to 5000 Employees,Company - Public,True
IP Data Network Customer Support Engineer,"Ribbon Communications
","Fort Lauderdale, FL",$63K - $91K (Glassdoor est.),3.7,"The incumbent will be responsible for remote support, configuration, testing and turn up of Ribbon’s Neptune platforms. The Neptune family is a carrier-class MPLS-based, multiservice IP-optical transport systems that offers the best-in-class carrier Ethernet and IP transport solutions and routing capabilities.
Job Description:
Provide high-quality technical support to customers via telephone, remote connection, and on customer site as required.
In-depth configuration and troubleshooting of Layer-2, Layer-3, IP/MPLS networks utilizing industry-standard test equipment.
Interface with Tier 3 support teams at Ribbon R&D centers when necessary to resolve hardware and software problems.
Knowledge of optical DWDM networks also a benefit but not required
Perform equipment and network management SW upgrades.
Provide technical support for Ribbon Field Engineers.
Provide semi-formal training classes as well as OJT to Customers as required.

Requirements:
Strong background and minimum of 5 years hands-on experience in the configuration, operation, and testing of Layer-2/3, and IP/MPLS networks. Required
In-depth knowledge of high-speed 100/400G optical networking interfaces as well as IP data protocols (examples: MPLS-IP, MPLS-TP, L2VPN, L3VPN, BGP OSPF, ISIS, Segment Routing, EVPN, Cisco certification, Juniper experience, etc).
Excellent verbal and written communication skills, problem-solving, project planning, and time management skills.
Familiarity with Network Management Systems (NMS).
Experience with Unix and Linux operating systems.
Knowledge of SNMP functionality and configuration including use of MIB browser applications.
Must be a US citizen or currently authorized to work in the US
Ability to travel when required.
Bachelors or Masters Degree in Engineering - OR applicable work experience
Please Note:
'All qualified applicants will receive consideration for employment without regard to race, age, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, on the basis of disability, or other characteristic protected by applicable law.'
US Citizens and all other parties authorized to work in the US are encouraged to apply.",-1,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,Unknown,Company - Public,False
Data Link Test Engineer - Mid-Level - TGBC,"Oasis Systems LLC
","Shalimar, FL",-1,4.4,"Overview:

Our data link test team is searching for new test engineer professionals that can help us design and execute test events. If you enjoy working in a fast-paced environment, learning new technology areas, this is the place for you. We provide a number of opportunities to learn ranging from on-the-job training with other team members to formal courses for unique technology areas.

We realize that no one will have all of these qualifications. We are looking for people that have experience with Link 16 and system testing. And have the drive and motivation to learn all other required areas.

This position provides support to the 96 Cyber Test Group, 46 Test Squadron, Data Link Test Flight at Eglin AFB as a member of an platform integration team responsible for planning, designing, and executing test events for tactical communications systems. This is NOT a telework or remote position; however, telework opportunities may be authorized as mission requirements allow.




LOCATION: Eglin AFB, FL

JOB STATUS: Full Time

TRAVEL: 25% CONUS / OCONUS TDYs


REQUIRED QUALIFICATIONS (Education, Certifications, Experience, Skills)

SECURITY CLEARANCE: Secret and be able to obtain and maintain a Top Secret clearance – US citizenship required

EDUCATION: BS Degree in a Computer Science, Computer Engineering, or a related technical field (i.e., CS, AE, ME, etc.)

CERTIFICATIONS: None

EXPERIENCE LEVEL: 3-10 years of applicable experience


OTHER QUALIFICATIONS/SKILLS:

US citizenship required
Active Top Secret clearance
Experience with tactical data link radios and terminals
Experience with computer network design concepts, configuration, and operation
Analytical skills and problem-solving skills
Excellent self-initiative and self-motivation with the ability to work under minimal supervision
Ability to work effectively in small and large team settings to solve complex problems
Capable of traveling to contractors' facilities, test sites, and other locations, both CONUS and OCONUS. Travel is on average is 25% of total time worked
Good organization, decision making, verbal and written communication skills
Proficiency in MS Office products to include Word, Excel and PowerPoint


PREFERRED SKILLS:

Relevant technical experience in the areas of software system and hardware integration testing
An understanding of DOD developmental test and evaluation processes
Knowledge of computer networking principles and configuration
Experience using interpreted languages (Python, Ruby, JavaScript, PHP, etc.)
Security+ certification


RESPONSIBILITIES:

Perform as a member of the Platform Integration Element test team
Interface directly with System Program Offices, users, test support organizations, and product development contractors
Plan, execute, and report on tests for Air Force advanced tactical communications programs to include Link 16, Situation Awareness Data Link (SADL) and emerging next generation tactical data links
Utilize Military Standards to evaluate system compliance
Proficient/familiar with various radios such as: MIDS-JTRS, SADL, PRC-117G, etc
Review customer requirements and participate in test planning meetings
Develop test plans and procedures, schedules, and execute tests within the constraints of customer requirements and produce timely test reports
Capable of performing as a team leader in directing and executing system testing
Author technical documents and briefings and conduct formal presentations
Travel to other locations as required to attend meetings and conduct tests


What we offer:

Competitive salaries
Continuing education assistance
Professional development allotment
Multiple healthcare benefits packages
401K with employer matching
Paid time off (PTO) along with a federally recognized holiday schedule


Who We Are

Oasis Systems is a premier provider of customer-driven, cost-effective, and quality Engineering Services; Enterprise Systems and Applications; Human Factors Engineering; Information Technology and Cyber Security; Professional Services; and Specialized Engineering Solutions to the Department of Defense, Federal Aviation Administration, Nuclear Regulatory Commission, and other Federal Agencies.


We strive to be an exciting and welcoming company that attracts, develops, motivates and retains the most talented, skilled and dedicated people in the industry; where they are encouraged to achieve personal excellence, purpose, and their full potential and career aspirations, while supporting mission-critical national security technologies and programs.


Oasis Systems is an Equal Employment Opportunity/Affirmative Action Employer. We provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.


This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
""Oasis Systems Cyber Division""
#CJ",1997,Aerospace & Defense,$100 to $500 million (USD),Aerospace & Defense,1001 to 5000 Employees,Company - Private,False
Data Engineer,"Brooksource
","Jacksonville, FL",$37.00 - $42.00 Per Hour (Employer est.),3.9,"Data Engineer

Contract

Jacksonville (Hybrid Preferred)

Brooksource is looking for an Associate Data Engineer to join one of our leading global pharmaceutical clients. This person willcreate prototype data engineering solutions for use cases across critical business priorities. They will also manage new data sources and drive business impact across the US for the Americas Region. This is an exciting and meaningful position as an integral part of the overall Business Intelligence Team!

Types of Responsibilities

· Identify and resolve quality issues during complex data migration & transformation.
· Support BI analysts in basic data engineering capabilities enabling throughput, complex analytics support.
Accountable for data engineering use cases that may have “limited time” life cycles.
· Writing queries / coding real-time, fast deployment within sandbox environment
· Data Engineering to support acceleration of E2E Reporting and Analytics
· Manage data catalog for the business.
· Pull disparate data sources together in the sandbox.
· Manage new data sources (conform w/ HIPAA, HCC) and access protocols.
· Problem solving for data issues in the lake in partnership with IT team.
· Analytics to answer urgent business priority questions to drive action.

Qualifications

A bachelor’s or advanced degree is required (Computer Science, Data Science, Business Administration, Engineering, with an Information Technology focus or related field)
A minimum of two years of progressive, broad-based information systems and technology experience in data warehousing, and decision support/reporting environments
Minimum of two years of software development experience, specifically in the area of data transformation scripting languages – proprietary (INFORMATICA, SQL) or open source (TALEND, Python) – required; open source transformation scripting strongly preferred.
Demonstrable data lifecycle capability required around data ingestion (ingest data from disparate systems into cloud computing environment), data contextualization (merging large data sets, developing algorithms to merge and clean data); data insights and analytics is required.
Demonstrated familiarity with large datasets and understanding of data analysis workflows is required – experience with data visualization tools like Tableau preferred.
· Superior attention to detail, organization skills, and the ability to balance multiple tasks.
· Ability to talk with business partners and help determine problem statement.
· Strong oral and written communication skills.

Eight Eleven Group provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state, and local laws.

Job Type: Full-time

Pay: $37.00 - $42.00 per hour

Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance
Paid time off
Vision insurance

Schedule:

Monday to Friday

Ability to commute/relocate:

Jacksonville, FL 32256: Reliably commute or planning to relocate before starting work (Required)

Experience:

SQL: 3 years (Preferred)
Data warehouse: 1 year (Preferred)
Python: 4 years (Preferred)

Work Location: Hybrid remote in Jacksonville, FL 32256",2000,HR Consulting,$100 to $500 million (USD),Human Resources & Staffing,201 to 500 Employees,Company - Private,True
Senior Big Data Engineer,"iCube Consulting Services
","Jacksonville, FL",$85K - $129K (Glassdoor est.),4.2,"Life at ICUBE CSI
Are you interested in working with a startup in cutting edge Technology space ?
Are you excited about Artificial Intelligence, Machine Learning, Data Analytics ?

Come join our ICUBE CSI team! Our team comes from all over the world with backgrounds in different types of industries. We are building a close knit team and meaningful culture.
Our benefits: We’re happy when you’re happy. To make this happen, we offer competitive compensation, big-company benefits and a startup culture with vibrant energy and cool perks of a startup.

Health care (medical and dental)
401k/Retirement Benefits
Life/LTD Insurance
Flexible schedules
Paid time off
Training & development
Fun, diverse and intellectually eager coworkers
Team happy hours and retreats
Workplace perks such as food/coffee

We are building innovation around Data Analytics, Data Management using open source technologies. Our company thrives on selling big data analytics solutions. Our in-house advanced big data analytics team comes with backing of its leadership team with 100+ combined years of experience in data engineering, data processing, infrastructure designs, machine learning and visualization. We are an equal opportunity employer.

Everyone can push forward in good times and when all is going perfectly as planned. But when it doesn’t go perfectly, you’re ready to attack problems head on. Business isn’t always easy, but you’re known for being there through thick and thin.




Responsibilities:

Design, Develop and Implement Big data engineering projects in Hadoop ecosystem.
Engineer solutions with Cloudera, MapR or HDP for both batch & streaming data with high quality and with a sense of urgency.
Develop application and custom integration solutions using spark streaming and Hive.
Understand specifications, plan, design and develop software solutions, adhering to process – either individually or collectively within a project team
Work in state-of-the art programming languages and utilize object-oriented approaches in designing, coding, testing and debugging programs.
Work with support teams in resolving operational & performance issues
Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities
Integrate data from multiple data sources, Implementing ETL process using APACHE NIFI
Monitoring performance and advising any necessary infrastructure changes
Management of Hadoop cluster, with all included services such as Hive, HBase, mapReduce and Sqoop
Cleaning data as per business requirements using streaming API’s or user defined functions.
Build distributed, reliable and scalable data pipelines to ingest and process data in real-time, defining Hadoop Job Flows.
Managing Hadoop jobs using scheduler.
Apply different HDFS formats and structure like Parquet, Avro, etc. to speed up analytics.
Work with various hadoop ecosystem tools like Hive, pig, Hbase , spark etc.
Reviewing and managing Hadoop log files.
Assess the quality of datasets for a hadoop data lake.
Fine tune Hadoop applications for high performance and throughput.
Troubleshoot and debug any Hadoop ecosystem run time issues.

Being a part of a POC effort to help build new Hadoop clusters

Education:

Bachelor’s Degree or higher in Computer Science, Information Systems or related engineering disciplines

General Knowledge, Skills & Abilities

Be a good detail-oriented data engineer
Systematic and organizational skills important.
Willing to commit for completing deliverable on time.

Preferred Qualifications:

Must have experience with Spark, Hive, Scala or py spark.
Preferred experience in one of the following technologies: Nifi, Kafka, or any other streaming technologies.
3+ years experience in data engineering building ETL pipelines using JAVA or Python or Scala
Should be good at Pig, HIVE scripting.
Solid understanding of HDFS is important.
Work experience within a Data Warehousing/Business Intelligence/Data analytics group, and have hand’s-on experience with Hadoop
Create tables/views in Hive or other relevant scripting language
Have experience with Agile development methodologies
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB.

Experience Architecting Solutions Utilizing any of the following:

JAVA or Python or Scala programming languages
Nifi, Kafka-topics, or any other streaming technologies
Parquet/Avro/ORC/XML/JSON/ORC/CSV/TXT formats

Location: Jacksonville, FL

Send your resumes to careers@ICUBE CSI.com",-1,Advertising & Public Relations,$1 to $5 million (USD),Media & Communication,1 to 50 Employees,Company - Private,False
Data Engineer,"Contact Government Services, LLC
","Miami, FL",$78K - $128K (Glassdoor est.),4.7,"Data Engineer
Employment Type: Full-Time, Mid-level
Department: Business Intelligence
CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.
Skills and attributes for success:
Complete development efforts across data pipeline to store, manage, store, and provision to data consumers.
Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices.
Write code to ensure the performance and reliability of data extraction and processing.
Support continuous process automation for data ingest.
Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing.
Work with program management and engineers to implement and document complex and evolving requirements.
Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork.
Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists.

Qualifications:
Must be a US Citizen.
Must be able to obtain a Public Trust Clearance.
7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.
Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats.
Proficiency in developing ETL processes, and performing test and validation steps.
Proficiency to manipulate data (Python, R, SQL, SAS).
Strong knowledge of big data analysis and storage tools and technologies.
Strong understanding of the agile principles and ability to apply them.
Strong understanding of the CI/CD pipelines and ability to apply them.
Experience with relational database, such as, PostgreSQL.
Work comfortably in version control systems, such as, Git Repositories.

Ideally, you will also have:
Experience creating and consuming APIs.
Experience with DHS and knowledge of DHS standards a plus.
Candidates will be given special consideration for extensive experience with Python.
Ability to develop visualizations utilizing Tableau or PowerBI.
Experience in developing Shell scripts on Linux.
Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions.
Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences.
Our Commitment:
Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:
Health, Dental, and Vision
Life Insurance
401k
Flexible Spending Account (Health, Dependent Care, and Commuter)
Paid Time Off and Observance of State/Federal Holidays

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:
https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:
Email: info@cgsfederal.com",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,True
Senior Data Engineer,"Vista Global
","Fort Lauderdale, FL",$101K - $137K (Glassdoor est.),4.0,"Job Profile:
About Team
The Data Foundation Team is highly critical for the organization to provide timely, accurate and most up to date data so that the business can take decisions accordingly. The team works with several application teams, data analytics, data science team etc. We are looking for a highly skilled and experienced Senior Data Engineer to design, implement, and maintain robust and scalable data pipelines.

About Company
Vista Tech plays a vital role in the Vista group operations by delivering and accelerating comprehensive technology solutions across all brands. Vista’s end-to-end and click-to-flight solutions offer the industry's only comprehensive flight booking platform, seamlessly integrating global operations, and leveraging AI and machine learning to optimize pricing and fleet movement. Comprised of the Product Management, Engineering, and IT teams, Vista Tech’s mission is to enhance transparency and accessibility in private aviation through the development of the world's largest digital private aviation marketplace. In achieving this, Vista Tech always ensures the utmost safety and efficiency for FLIGHT CREW, EMPLOYEES and Members, while fostering a culture of innovation and excellence.

You will report to Engineering Manager and play a crucial role in driving the technical direction of our projects and guiding the team in adopting best practices and cutting-edge technologies. This position is a 100% remote role with regular shif timings (9 AM to 6 PM EST). You will collaborate with cross-functional teams, provide technical leadership, and contribute to the entire software development lifecycle.
Your Responsibilities:
Scalable Data Infrastructure: Lead the development and maintenance of highly scalable data pipelines, playing a crucial role in fortifying our data foundation.
Technical Excellence: Demonstrate hands-on technical expertise in designing, building, and documenting complex data pipelines while adhering to data engineering best practices.
Cross-Functional Collaboration: Collaborate closely with data engineering, analytics, and data science leadership to continuously enhance the functionality and capabilities of our data systems.
Process Optimization: Identify opportunities for internal process improvements, spearheading automation of manual tasks, optimizing data delivery mechanisms, and redesigning infrastructure to ensure greater scalability and efficiency.
Data Integration Mastery: Define and construct the infrastructure necessary to facilitate efficient extraction, transformation, and loading (ETL) of data from a diverse array of sources.
Required Skills, Qualifications, and Experience:
Strong Analytical Foundation: A robust background in mathematics, statistics, computer science, data science, or a related discipline, showcasing your analytical prowess.
Programming Proficiency: Advanced expertise in programming languages, particularly Python and SQL, to tackle complex data challenges.
Production Experience: Proven experience in the production environment with a range of essential tools and platforms, including Snowflake, DBT, Airflow, Amazon Web Services (AWS), Docker/Kubernetes, and PostgreSQL.
Database Mastery: Proficiency in database technologies, including Snowflake, PostgreSQL, Redshift, and others, enabling efficient data management.
Exceptional Organizational Skills: Strong organizational capabilities, allowing you to manage multiple projects and priorities concurrently while consistently meeting deadlines.
Additional Assets: Familiarity and experience with additional tools and technologies, such as AWS certification, Kafka Streaming/Kafka Connect, MongoDB, and CI/CD tools like GitLab, Jira, and Confluence, are highly advantageous.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Company - Public,False
Senior Platform Operations Engineer - Content Management and Enriched Data Solutions (Remote),"Marriott Vacations Worldwide
","Orlando, FL",$57K - $87K (Glassdoor est.),3.9,"**Will consider remote candidates in states where MVW has eligible business entities**

Job Summary
The Senior Platform Ops Engineer - Content Management and Enriched Data Solutions plays a key role employing standards for MVW’s infrastructure and application environment. The role excels in a fast paced and dynamic environment with ability to multi-task and come up with solutions for complex applications & platforms. The Senior Platform Ops Engineer must have a strong Linux and Windows background with the ability to code/script and experience with automation and configuration management tools. Understanding and experience with a hybrid cloud environment and building and maintaining tools for deployment, monitoring, and operations to streamline the processes and provide self-service is key. Communication and collaboration across all teams and departments is a must. As a senior engineer the person will be looked on to lead projects and serve as a mentor and resource for more junior engineers on the team.

Expected Contributions

Supports, maintains, and own all aspects of the following technology components with the ability to automate, build, and customize the platforms to meet various needs of multiple applications.
Load Balancing (F5)
Service Bus and Orchestration Platforms (Mulesoft ESB, IBM Integration Bus)
Caching Services (Memcached, Terracotta)
Experience with distributed architecture, micro services, integration with legacy systems such as Rocket, iSeries, and BBJ. Provides guidance to legacy technologies as mentioned above in terms of threads, CPU, memory, and any other critical Linux/application KPIs.
Monitoring tools (Splunk, APM, AIOps, etc.); configures monitoring dashboards, monitors best practices, installs agents, performs custom configurations, installs, and upgrades platforms, and acts as a SME for monitoring practices as well as continual improvements. Engages with business leaders to promote and improve “business” monitoring to provide value to the Enterprise as a
whole.

Performance Tuning (Java/JVM, etc.); works hand in hand with QA teams to promote new business functions with 0 impact to production. This means tuning all platforms under performance/load testing conditions. Have a stake and ownership of performance problems before they reach production.
Strong problem solving and troubleshooting skills; handles on-call production impacting issues and work till resolution. Being middleware/platform operations means the buck stops here and troubleshooting issues until root cause and resolution is found even in a supporting role for issues outside of platforms owned by the team. This also spans troubleshooting across the full lifecycle
in over 27 environments from dev to prod.

Coding/Scripting (Perl, bash, PHP, Java, Python, SOAP, REST, PowerShell, etc.) expected to think in terms of “automation first”. Well versed in a few languages and expected to contribute daily to GIT repos. Experience in some automation/CICD/pipelines framework (Jenkins, Chef, Ansible,
Bamboo…) not just as a user but as a contributor to the platform.

Understanding of the full layer 7 http stack and can investigate problems using netcat and tcpdumps; provide guidance to network team regarding problems at this layer. Understand UDP/TCP connection types, interpret timeouts, connection hung situations, and typical faulty connection problems.
PCI and SOX knowledge to remediate, mitigate, and document all security postures within the above platforms and systems.
SSL know how. Must be able to explain and functionally apply practices around key exchanges, tokens, keystores, certs, keys, CSRs, CRLs, protocols, and cipher suites. Understanding of encryption and able to implement security requirements into all supported platforms. Sound off as an SME regarding wildcard certificates, implementation strategies for certs, and certificate renewal/storage/access practices.
Disaster Recovery; provide plans for recovery of all above platforms in case of a disaster. Hands on involvement yearly in the recovery activities during DR tests. Write and maintain scripts to recover systems quickly and efficiently.
IBM SPSS CnDS Inventory Forecast
Hybris Content Application Server
Jahia Content Application Server
AppDynamics APM
Enterprise Splunk Deployment (including ES and ITSI)
IBM ODM Rules Engine System
In depth knowledge of Platform Technologies (IIS, I.H.S., Apache, .NET, .NET Core, PHP, SharePoint, Tomcat, WebSphere Application Server, etc.)
Load Balancing (F5, TMG, etc.) – Knowledge of Application dependencies on the load balancing configuration and ramifications if incorrectly configured.
Performance Tuning of Platform Technologies
Candidate Profile

Education

Bachelor’s degree in Information Technology preferred and or equivalent experience.
Experience

At least seven years in a related computer field with at least 5 years in Web application platforms in an enterprise multi-platform environment.
Skills/Attributes


Ability to work independently, as well as part of a team with little oversight.
Demonstrate proficiency in methodical troubleshooting to provide resolution to incidents.
Desire to always be learning, as this role will require the candidate to always be up to date on the latest technologies and tools.
Strong oral and written communication skills, including presentation skills (MS Visio, MS PowerPoint).

Strong verbal and written communication skills, with the ability to communicate core concepts.
Completes tasks assigned and project work within scope, priority, timelines, and budget.
Ability to work in a team that utilizes principles, which enable and empower the employee to act on behalf of the team and within the boundaries of clearly defined policies and objectives.
High energy, clear goal orientation and strong work ethic; can do attitude; professional attitude.",1984,Hotels & Resorts,$100 to $500 million (USD),Hotels & Travel Accommodation,10000+ Employees,Company - Public,False
"Network Engineer II, Data and Video, Spectrum Enterprise","Spectrum
","Tampa, FL",-1,3.3,"Ready to guide the identification, forecasting and implementation of resource requirements? You can do that. Do you know edge networks, but want to grow your network skills and work in the core? As a Network Engineer II at Spectrum Enterprise, you can do that.

Spectrum Enterprise provides modern enterprise technology solutions that meet the unique needs of some of the country’s biggest brands. If you’re looking to build your most successful career, support client growth and work alongside intelligent, driven professionals, you can do that. We're ready to go all in on your future and create an engaging environment.

BE PART OF THE CONNECTION
Using your expert technical skills, you plan resource requirements for Spectrum Enterprise Core and client network systems. You drive the implementation process while monitoring protocols and compatibility standards. You collaborate with teams in person and digitally within an office environment. Depending on the business unit, you may be part of a 24/7/365 on-call environment.

WHAT OUR NETWORK ENGINEERS ENJOY MOST
Drive engineering projects by participating in planning the architecture design.
Complete network configuration projects by integrating communication architecture, topologies, hardware, software, transmission and signaling links.
Enhance the product base through product evaluations and network issue resolution.
Maintain product and service quality by developing and documenting technical standards.
Optimize existing networks by completing medium- to highly-complex projects and systems.
Provide escalated troubleshooting and issues resolutions to support tiers during program implementation.
Guide and mentor less experienced team members to improve productivity.

WHAT YOU'LL BRING TO SPECTRUM ENTERPRISE
Required Qualifications
Experience: Three or more years of data network experience.
Education: Bachelor’s degree in computer science, electrical engineering, a related field or equivalent experience.
Technical Skills: Familiar with fiber, multi-mode, single-mode and UTP; Clear understanding of bridging, switching, routing, Ethernet, transport technologies and IEEE and ANSI standards; Knowledge of network design, devices, network appliances, network architecture, protocols (ISIS, OSPF, BGP and MPLS) and network topology; In-depth data network knowledge of TCP/IP, OSI model and optical networking; Knowledge of CWDM and DWDM; Proficient in Microsoft Office.
Skills: English communication skills.
Abilities: Deadline-driven with the ability to learn new technologies.

Preferred Qualifications
Proficiency with IP multicast, PIM and IGMP.
Well-versed in DOCSIS Technology.
Knowledge of IPv6 and IPv4 basic and advanced networking.
CCNP certification.
Knowledge of Spectrum Enterprise products and services.

SPECTRUM ENTERPRISE CONNECTS YOU TO MORE
Embracing Diversity: A culture of excellence that celebrates diversity, innovative thinking and dedication to exceeding client expectations.
Learning Culture: Company support in obtaining technical certifications.
Dynamic Growth: Paid training and clearly defined paths to advance within the company.
Total Rewards: Comprehensive benefits that encourage a work-life balance.


Apply now, connect a friend to this opportunity or sign up for job alerts!

ENE309 2023-25005 2023

Here, employees don’t just have jobs, they build careers. That’s why we believe in offering a comprehensive pay and benefits package that rewards employees for their contributions to our success, supports all aspects of their well-being, and delivers real value at every stage of life.

A qualified applicant’s criminal history, if any, will be considered in a manner consistent with applicable laws, including local ordinances.

Get to Know Us Charter Communications is known in the United States by our Spectrum brands, including: Spectrum Internet®, TV, Mobile and Voice, Spectrum Networks, Spectrum Enterprise and Spectrum Reach. When you join us, you’re joining a strong community of more than 101,000 individuals working together to serve more than 32 million customers in 41 states and keep them connected to what matters most. Watch this video to learn more.

Who You Are Matters Here We’re committed to growing a workforce that reflects our communities, and providing equal opportunities for employment and advancement. EOE, including disability/vets. Learn about our inclusive culture.",2016,Telecommunications Services,$10+ billion (USD),Telecommunications,10000+ Employees,Company - Public,False
Data Engineer - Active Secret Clearance required,"Redhorse
","Tampa, FL",$84K - $124K (Glassdoor est.),3.7,"About the Organization
Now is a great time to join Redhorse Corporation. Redhorse specializes in developing and implementing creative strategies and solutions with private, state, and federal customers in the areas of cultural and environmental resources services, climate and energy change, information technology, and intelligence services. We are hiring creative, motivated, and talented people with a passion for doing what's right, what's smart, and what works.

Redhorse Corporation is building a cross-functional team to support the United States Central Command (USCENTCOM) Directorate of Logistics (CCJ4) and help to accelerate the delivery of AI-enabled capabilities and to synchronize AI activities in order to expand customer advantages. This effort supports the Joint Logistics Enterprise in support of USCENTCOM missions in order to promote cooperation among nations, respond to crisis, deter and defeat trans-regional aggression, while support the development of resilient logistics and engineering capabilities of our partners. The current Joint Logistics Common Operating Picture (JLOGCOP) is comprised of dozens of data feeds, both automated and manual, from across DoD. This effort is a custom build of artificial intelligence/machine learning (AI/ML) capabilities into the JLOGCOP in order to leverage the data, enhance decision making, and increase the speed of planning.

Position Description

Redhorse Corporation is currently seeking a Data Engineer to join our team. The place of performance for this work is at MacDill AFB, near Tampa, FL, with the possibility of up to 10% travel.

Primary Duties and Responsibilities for this position include:
Automation and Continuous Integration:
Set up automation tools to handle repetitive tasks such as data extraction, transformation, model training, etc.
Establish continuous integration (CI) pipelines to automatically test and deploy code.
Scalability and Performance:
Refactor code to be more efficient, using algorithms and data structures best suited for the tasks.
Scale pipelines to handle larger datasets, possibly in distributed computing environments like Spark.
Testing and Validation:
Implement unit tests, integration tests, and system tests to ensure code quality.
Develop validation strategies to ensure that data processing and model predictions are accurate.
Collaboration:
Work closely with data scientists to understand to come up with innovative tech-driven solutions.
Develop custom tools and utilities that can accelerate data pipelines for the data science team.
Ensure compatibility and integration of these tools with existing systems.
Code Quality and Review:
Conduct regular code reviews to ensure that code adheres to best practices.
Implement coding standards and guidelines tailored to the team's needs.
Mentor junior data scientists in writing clean, modular, and efficient code.
Minimum Basic Requirements for Skills, Experience, and Credentials include:
US citizen with a Secret US government clearance. Applicants who are not US Citizens and who do not have a current and active Secret security clearance will not be considered for this role.
Ability to work independently to recommend solutions to the client and as part of a team to accomplish tasks.
Experience in setting up CI/CD pipelines
Knowledge of Advanced Algorithms and Data Structures
Hands-on work with distributed systems like Apache Spark or Hadoop
Experience in writing unit, integration, and system tests using frameworks
Knowledge of tools and methodologies to validate data quality and model accuracy
Ability to articulate technical solutions to a non-technical audience and collaborate effectively with data scientists
Demonstrated experience in developing bespoke tools for specific project needs
Proficiency in ensuring that newly developed tools integrate seamlessly with existing systems
Experience conducting and participating in rigorous code reviews
Awareness of industry best practices and willingness to guide junior team members in best practices
Preferred Qualifications
Experience with data visualization tools.
Prior DoD Operational Experience.
Equal Opportunity Employer/Veterans/Disabled
Accommodations:
If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to access job openings or apply for a job on this site as a result of your disability. You can request reasonable accommodations by contacting Talent Acquisition at Talent_Acquisition@redhorsecorp.com
Redhorse Corporation shall, in its discretion, modify or adjust the position to meet Redhorse’s changing needs.
This job description is not a contract and may be adjusted as deemed appropriate in Redhorse’s sole discretion.",2008,Information Technology Support Services,$25 to $100 million (USD),Information Technology,51 to 200 Employees,Company - Private,True
"Senior Data Engineer, Public Company","Recruiting From Scratch
","Miami, FL",$100K - $200K (Employer est.),4.0,"This is for a client of Recruiting from Scratch.
Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Our Client:

Our next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we’re blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.

With a track record of strong financial performance and plans for continued headcount growth, we’re looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us.

What’s so interesting about this role?

Our client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .

In this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.

What’s the job?

Design, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.
Moving implementation to ownership of real-time and batch processing and data governance and policies.
Maintain and enforce the business contracts on how data should be represented and stored.
Stay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users
Implementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.
Work closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.

What we’ll love about you

5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.
7+ years experience using Python,
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )
Significant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.
Experience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Experience with dimensional data modeling and schema design in Data Warehouses
Familiar with ETL (managing high-quality reliable ETL pipelines)
Be familiar with legal compliance (with data management tools) data classification, and retention.

Salary Range: $165,000-$210,000 USD base. Equity. Medical, Dental, Vision.
https://www.recruitingfromscratch.com/",2019,Staffing & Subcontracting,$1 to $5 million (USD),Human Resources & Staffing,1 to 50 Employees,Company - Private,True
Sr. Electrical Engineer - Data Center,"Barge Design Solutions
","Miramar, FL",$75K - $111K (Glassdoor est.),4.5,"Sr. Electrical Engineer - Data Center

Career Area: Engineering - Electrical

What We're Looking For:
Barge Design Solutions is seeking an experienced Electrical Engineer with expertise in designing distribution and controls for low, medium, and high voltage systems associated with mission-critical infrastructure for data centers, industrial, and healthcare facilities. The selected candidate will be part of our growing Mission-Critical team and will be responsible for electrical designs to achieve enhanced efficiency, reliability, and safety.

Responsibilities:

Collaborates with project team members, client representatives, and review agencies to provide a comprehensive project design.
Develops design criteria for protective device coordination, relay applications, medium voltage transformers, switchgear, medium and low voltage distribution.
Leads technical electrical design portions of a projects in a multi-discipline environment.
Develops concepts, studies, and narratives to help clients understand options available to meet project requirements.
Selects equipment and designs code compliant electrical systems to achieve client objectives related to uptime and reliability of mission-critical facilities.
Conducts fault current analysis, short circuit analysis, and protective device coordination studies.
Oversees installation of systems to ensure functionality and compliance with design intent.
Participates in project site visits.
Mentors, directs, and oversees work of junior staff and designers.
Participates in the strategy, growth, and development of Barge's Mission-Critical sector.



Education & Experience Qualifications:
Bachelor's degree in Electrical Engineering from an ABET-accredited university.
Professional Engineering license (PE)
10 years of progressive experience in the electrical engineering field with emphasis on design of power distribution systems for data centers or other mission-critical facilities.
Strong knowledge of electrical codes and standards (NEC, IECC, IEC, etc.)
Strong knowledge of electrical equipment design ANSI and IEEE standards.
Ability to communicate technical information clearly and effectively with a wide range of audiences.
Experience with Revit a plus.
Familiarity with sustainable design practices and energy-efficient systems a plus
RCCD, DCDC, CDCDP, and DCEP certifications all considered a plus



Why join us?

Barge Design Solutions, Inc., is an engineering and architecture firm with diverse in-house multidisciplinary practice areas. The employee-owned company is more than 400-people strong and serves clients nationwide from multiple U.S. locations. Barge is ranked No. 171 on Engineering News-Record (ENR)'s 2021 Top 500 Design Firms list, is No. 177 on Architectural Record's Top 300 Architecture Firms and is a certified Great Place To Work®.

Our primary purpose for being in business is ultimately to create a better life by unleashing the potential of our people, clients and communities. This purpose is supported by our company's core values because at the end of the day, Barge CARES:


Collaborate - Help and expect help. Teamwork is essential in what we do.
Authentic - Honesty, integrity and trust are at the heart of everything we do. We are who we say we are.
Responsible - We are accountable for our work, our attitude, and our actions. We make Barge better.
Excellence - We go all in and expect more of ourselves than others expect of us.
Service - We are humble. We use our gifts in service of others.

We believe that if we are living out our purpose for being in business and integrating our values into everything we do, we will ultimately achieve our vision to be the firm best known for being selected when it matters most.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status or on the basis of disability. Equal Opportunity Employer/Veterans/Disabled",1955,Architectural & Engineering Services,$25 to $100 million (USD),"Construction, Repair & Maintenance Services",201 to 500 Employees,Company - Private,False
Voice/ Data Communications Engineer,"Global Enterprise Services, LLC
","Tampa, FL",$54K - $84K (Glassdoor est.),4.0,"Voice/Data Communications Engineer - Master


The Voice/Data Communications Engineer - Master provides technical direction and engineering knowledge for communications activities including planning, designing, developing, testing, installing and maintaining large communications networks. Ensures that adequate and appropriate planning is provided to direct building architects and planners in building communications spaces and media pathways meet industry standards.

Education and Experience:

Bachelors Degree and 8-12 years of prior relevant experience or Masters with 6-10 years of relevant experience. Specific experience, education and training may be considered in lieu of degree.
Cisco Certified Network Professional (CCNP)
Security+ certification or equivalent DoD 8570 IAT II certification within 60 days of start date


Responsibilities:

Serve as the Tier III System Engineering Lead, responsible for review of new capabilities or assessment of current capabilities for areas of improvement in support of the JCSE end-to-end enterprise infrastructure.
Assist the government with identifying any derived design objectives, technical specifications, performance requirements, and interoperability specifications to ensure the system design will meet stakeholder end-to-end requirements.
Provide systems engineering support with hands on experience improving and maintaining the enterprise infrastructure, as well as support execution of new system increments.
Provide assessment for limitations, gaps, shortfalls, or end of support products that should be resolved to meet critical C2.
Enhance mission support, or emerging technologies that will make the enterprise operate more efficiently.
Assist the government with development, updates, and review of program/project Systems Engineering Plan (SEP), Information Support Plan (ISP), and Technology Readiness Assessment (TRA) on new or emerging technologies or capabilities.
Develop, review, and update briefings, papers, or spreadsheets in support of this task.
Plan and coordinate internal and external working groups with JCSE stakeholders to support the engineering process. The contractor shall attend modernization program reviews and document comments, needs, and gaps from the JCSE stakeholders.
Support the Program/Project manager, J6 Director, and Innovation Office with management and technical synchronization of cost, schedule, and performance associated with the technical solutions being proposed or procured to meet stakeholder requirements.
Ensure the system design adheres to industry standards, DOD standards, DOD policies, DOD instructions, DOD directives, cybersecurity policies, and best commercial practices.


Clearance/Citizenship:

Top Secret
Must be US Citizen


Travel Requirements:


This position will involve less than 10% travel


Location: Tampa, FL – MacDill AFB",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,True
Senior Principal Data Engineer (Melbourne FL),"Northrop Grumman
","Melbourne, FL",$112K - $168K (Employer est.),4.0,"Requisition ID: R10138072
Category: Research and Sciences
Location: Melbourne, Florida, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: Any (United States of America)
Travel Required: Yes, 10% of the Time
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.

Are you motivated to work in an environment that will challenge you, force you to continuously innovate, and work on solutions that make a difference for your customers?

Northrop Grumman Aerospace Systems is looking for a passionate Senior Principal Data Engineer in Melbourne Florida to design and develop automated, end-to-end, ETL pipelines and Data Analytics/Visualization solutions from disparate data sources. You will share in the ownership of the technical vision and direction for advanced analytics systems that change the way we see and use data. We are looking for people who are self-motivated, hardworking, and have demonstrated the ability to find innovative solutions to complex technical problems.

Job Responsibilities:

Design, develop, and maintain a scalable ETL pipelines.
Enable storing, searching, processing, and securing of extremely large structured or unstructured data sets.
Data preparation/cleaning, integration, and automation from heterogeneous sources
Ensure data integrity and system availability
Identify, evaluate, and recommend core technologies and strategies
Monitor and optimize system performance
Decomposition of user requirements into logical functions/components

Basic Qualifications for Senior Principal Data Engineer:

Bachelor’s in a STEM related field with 9 years of experience; Master’s in a STEM related field with 7 years of experience. PhD with 4 years of experience.
5+ years of experience working with ETL techniques and frameworks
Understanding of elastic data storage and archive storage lifecycle management
Experience with integration of data from multiple sources
Experience with Python, SQL (structure query language), and relational databases.
Experience with data visualization tools (e.g. Tableau)
Experience with Agile Software Development
US Citizenship with the ability to obtain/maintain an active DoD Secret Clearance.
Must be able to obtain Program Access (PAR) within a reasonable amount of time

Preferred Qualifications:

Master’s degree with 7 years of relevant experience.
5+ years of experience working with ETL techniques and frameworks.
Expert in Python, SQL, and data visualization tools.
Development experience utilizing Hadoop, Spark, PowerShell, and automation scripts
Familiarity with Data Virtualization and Data Cataloging tools (e.g. Denodo, Collibra).
Experience with NoSQL Databases (e.g., MongoDB, Neo4J, etc.)
CompTIA Security+ Certification.
Current DOD Top Secret clearance.
Salary Range: $112,000 - $168,000
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.

Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",1939,Aerospace & Defense,$10+ billion (USD),Aerospace & Defense,10000+ Employees,Company - Public,False
