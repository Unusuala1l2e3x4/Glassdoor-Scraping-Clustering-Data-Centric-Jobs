Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply
FLS Production Engineer – Production Data Analyst,"ASML
","Wilton, CT",$62K - $90K (Glassdoor est.),4.1,"Location

Wilton, US

Team

Design Engineering and Architecture

Work experience

0-1 year

Educational background

Other technical backgrounds

Technical field

System Integration and Testing

Travel

No

Remote work

On-Site

Fulltime/parttime

Full time



Job ID: J-00287108
Introduction to the job

Join ASML Wilton today to receive your sign on bonus and relocation.

*Offer valid for Wilton, CT new hire offers made between now and December 31, 2023.

ASML US brings together the most creative minds in science and technology to develop lithography machines that are key to producing faster, cheaper, more energy-efficient microchips. We design, develop, integrate, market and service these advanced machines, which enable our customers - the world’s leading chipmakers - to reduce the size and increase the functionality of their microchips, which in turn leads to smaller, more powerful consumer electronics. Our headquarters are in Veldhoven, the Netherlands, and we have 18 office locations around the United States including main offices in Chandler, Arizona, San Jose and San Diego, California, Wilton, Connecticut, and Hillsboro, Oregon.

ASML is the world’s leading provider of lithography systems for the semiconductor industry, manufacturing complex machines that are critical to the production of integrated circuits or microchips. This position is for a First Line Support Production Engineer to analyze production data (ex: Disturbance Notifications (DN), Material Notifications (MN)) and push for structural resolutions. Candidate will work with cross-sector teams to determine root causes for disturbances and develop action plans for containments and structural solutions.

T his position requires access to controlled technology, as defined in the Export Administration Regulations (15 C.F.R. § 730, et seq.). Qualified candidates must be legally authorized to access such controlled technology prior to beginning work. Business demands may require ASML to proceed with candidates who are immediately eligible to access controlled technology.

Role and responsibilities

Enrich production data using SAP environment (ex: Disturbance Notifications (DN), Material Notifications (MN)).

Facilitate cross-sector meetings to present/analyze DN/MN data to determine root causes of disturbances, ensure ownership, and advance follow up actions.

Ensure follow ups for disturbances are completed with cross-sector action owners on a regular basis.

Present DN/MN reports for multiple modules on a weekly basis.

Support in-production issues by assisting with historical DN/MN data and analysis.

Support production engineering team with involving cross-sector resources needed for multi-discipline structural solutions.

Support the development and maintenance of DN/MN performance charts.

Support the development and the maintenance of internal DN/MN KPIs.

Support management with headcount analysis using DN/MN data.

Support DN/MN reduction plans through cross-sector process improvements.

Support CT/LH roadmaps using DN/MN data.

The employee is required to work in a cleanroom environment:

full gowning (full body coveralls, hood, CR safety shoes, face mask, nitrile gloves and safety glasses. Working under ISO 9000/14000 standards.

Working around overhead cranes, fork trucks and motorized pallet movers.

Working around lasers; working with ladders; working on platforms; and working around chemicals.

Education and experience

BS/MS in Engineering orequivalent experience.

Minimum of 1 year experience in an Engineering environment.

Experience in collaborating with cross-sector functional groups.

Experience with Lean Six Sigma and additional problem solving methodologies.

Strong presentation skills.

Understanding of optical, mechanical and electrical drawings.

MS Excel and development of VBA code is a plus.

Knowledge of dashboard software, such as Spotfire, is a plus.

Experience in the field of technical Production Engineering and quality methodology such as statistical process control (SPC) and FMEA is a plus.

Working knowledge of Teamcenter and SAP is a plus.

Skills

Working at the cutting edge of tech, you’ll always have new challenges and new problems to solve – and working together is the only way to do that. You won’t work in a silo. Instead, you’ll be part of a creative, dynamic work environment where you’ll collaborate with supportive colleagues. There is always space for creative and unique points of view. You’ll have the flexibility and trust to choose how best to tackle tasks and solve problems.


To thrive in this job, you’ll need the following skills:

Can observe and respond to people and situations and interact with others encountered in the course of work.

Can learn and apply new information or skills.

Must be able to read and interpret data, information, and documents.

Strong customer focus and commitment to customer satisfaction through prioritization, quality, efficiency and professionalism.

Ability to complete assignments with attention to detail and high degree of accuracy.

Proven ability to perform effectively in a demanding environment with changing workloads and deadlines.

Result driven-demonstrate ownership and accountability.

Identifies bottlenecks and drives improvements.

Work independently or as part of a team and follow through on assignments with minimal supervision.

Demonstrate open, clear, concise and professional communication.

Ability to establish and maintain cooperative working relationships with manager, co-workers and customer.

Work according to a strict set of procedures within the provided timelines.

Capability to interface with multidisciplinary groups (including senior leadership), and be willing to take on responsibility and follow through.

Have strong written and oral communicative skills – ability to communicate effectively to your team and to senior management.

Focus on quality and continuous improvements.

Demonstrated “team player” with a quality orientation and interpersonal skills.


Diversity and inclusion

ASML is an Equal Opportunity Employer that values and respects the importance of a diverse and inclusive workforce. It is the policy of the company to recruit, hire, train and promote persons in all job titles without regard to race, color, religion, sex, age, national origin, veteran status, disability, sexual orientation, or gender identity. We recognize that diversity and inclusion is a driving force in the success of our company.

Other information

Role within Office
Responsibilities:

Routinely required to sit; walk; talk; hear; use hands to keyboard, finger, handle, and feel; stoop, kneel, crouch, twist, reach, and stretch. Occasionally required to move around the campus.

Occasionally lift and/or move up to 20 pounds.

May require travel dependent on business needs.

Specific vision abilities required by this job include close vision, color vision, peripheral vision, depth perception, and ability to adjust focus.

Role within the Factory

Responsibilities:

Must be willing to work in a clean room environment, wearing coveralls, hoods, booties, safety glasses and gloves for entire duration of shift.

While performing the duties of this job, the employee routinely is required to sit; walk; talk; hear; use hands to keyboard, finger, handle, and feel; stoop, kneel, crouch, twist, reach, and stretch.

The employee may occasionally lift and/or move up to 50 pounds.

Specific vision abilities required by this job include close vision, color vision, peripheral vision, depth perception, and ability to adjust focus.

Can work under deadlines.

The environment generally is moderate in temperature with moderate to high noise level.

Must be willing to work a compressed work week schedule – twelve-hour long shift and rotating from three to four days a week.

This must include references to day and night shifts for accommodation purposes.

Additional responsibilities for Wilton Factory:

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

The employee is required to work in a cleanroom environment: full gowning (full body coveralls, hood, CR safety shoes, face mask, nitrile gloves and safety glasses. Working under ISO 9000/14000 standards).

Operating/working around overhead cranes, fork trucks and motorized pallet movers.

Working around lasers; working with ladders; working on platforms; and working around chemicals.

The employee is occasionally required to move around the campus.

The employee may occasionally lift and/or move up to 20 pounds.

May require travel dependent on company needs.

The environment generally is moderate in temperature and noise level.

EOE AA M/F/Veteran/Disability

Need to know more about applying for a job at ASML? Read our frequently asked questions .",1984,Electronics Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Senior Data Engineer (Snowflake) - Contractor,"EY
",United States,$90.00 - $130.00 Per Hour (Employer est.),3.9,"The primary responsibility for the Sr. Data Engineer / Tech Lead is to ensure data accessibility, quality, and reliability within the client's data platform ecosystem.

RESPONSIBILITIES

Design and develop end-to-end data pipelines and ETL processes using Snowflake, Denodo, DBT Cloud, Fivetran, and AWS Glue, ensuring seamless data integration, transformation, and loading.
Collaborate with cross-functional teams to gather data requirements and implement scalable data models and schemas within Snowflake and Denodo, ensuring optimal performance and data consistency.
Implement and maintain data orchestration workflows using Stonebranch, ensuring efficient and reliable scheduling and automation of data processes.
Work with EnterpriseDataLake for ingestion and storage of data from various sources, ensuring the availability and accessibility of data for analytics and reporting purposes.
Utilize Azure DevOps and Teraform to implement and manage infrastructure as code, ensuring streamlined deployment and scalability of data engineering solutions.
Skills

snowflake

denodo

dbt cloud

fivetran

Qualifications

REQUIREMENTS

Proficiency in Snowflake and Denodo: Strong understanding and hands-on experience in working with Snowflake and Denodo for data integration, transformation, and analysis.
Knowledge of DBT Cloud: Familiarity with DBT Cloud, including experience in building and maintaining efficient data transformation workflows and deploying reliable data pipelines.
Experience with Fivetran: Demonstrated experience in utilizing Fivetran for data ingestion, source connectivity, and ensuring data accuracy and completeness.
Understanding of EnterpriseDataLake: Knowledge of EnterpriseDataLake principles and practices, including data ingestion, storage, and organization for analytics and reporting purposes.
Familiarity with Stonebranch: Proficiency in using Stonebranch for data orchestration and scheduling, ensuring efficient and reliable execution of data pipelines and workflows.
Proficiency in Azure DevOps and Teraform: Experience in leveraging Azure DevOps and Teraform for infrastructure as code, enabling streamlined deployment and scalability of data engineering solutions.

The expected pay rate range for this contract assignment is $90 to $130 per hour. The exact pay rate will vary based on skills, experience, and location. The position is approximately 65-70% remote and 30-35% travel to the client as needed.

#GigNowTechOpportunities

GigNowOpportunities

Equal Employment Opportunity Information
EY provides equal opportunities to applicants, employees, contractors, vendors, and stakeholders without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. If you are an individual with a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please email gignow.recruiting@ey.com.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,False
Data Center Cabling & Hardware Support Engineer.,"ONNEC Group
","Stamford, CT",,3.3,"ONNEC builds, supports, and optimizes the IT infrastructure, networks, and connectivity which drive global business performance.

We are a rapidly growing organization and finding and retaining the highest caliber of people is fundamental to us for the success of our business, we work hard to create a challenging, supportive and satisfying working environment for all our employees. ONNEC has successfully achieved the Investors in Diversity Foundational Award for our commitment to equality, diversity and inclusion in the workplace.

We re recruiting for Engineers to work within a team carrying out cabling infrastructure and network hardware support at Onnec client sites. The work will include all types of patching, break-fix, circuit provision and recovery, disconnect/reconnect of desktop and networking equipment, rack and stack of Data Centre Hardware (eg Server, Network and Storage) and provision of connectivity to DC Hardware. The position will be site based as required and reports to the Service Delivery Manager.

For this role candidates will need to:

Be able to work on multiple client sites across allocated regions.
Be available for out-of-hours working, being part of an on-call rota to include weekends and evenings as business demands.
Work the following hours: Monday to Friday, a mixture of early shifts (7 am to 4 pm), mid shifts (11 am to 8 pm), and/or late shifts (2 pm to 11 pm)

Responsibilities of our Connectivity & Hardware Support Engineers will include:

Monitor the client’s ticket system and ensure tickets are assigned and completed within SLA.
Audit and document existing cabling installations.
Audit and document desktop configuration, including patching and power, for existing and proposed user locations.
Compile patching schedules as required.
Utilise Cable Management Software as required for patching planning.
Power down and disconnect all desktop equipment including any peripherals ensuring all identified and labelled correctly ready for reconnection.
IMAC-D of all desktop equipment including any peripherals
Carry Out Data Wiping activities by use of Software tools.
Carry out all types of patching / jumpering including all types of voice & data, copper & fiber.
Carry out testing and fault finding on Copper and Fibre Cabling Infrastructure (including ISDN Line Tests) using a variety of modern testers including continuity testers, tone generators and modern cabling standards testers.
Carry out all types of Copper Voice and Data terminations as required by the Onnec portfolio of cabling systems.
Maintain accurate records of all stock delivered and update as stock is used and advise line manager of any requirement shortfalls.
Carry out surveys and update drawings and schedules.
Install and test analog, digital, and VOIP telephone handsets and provide headset support as required.
Build, Rack and Stack Network and Server hardware in Data Center Halls and provide connectivity.
Perform Network Hardware break-fix activities e.g. replacing power supplies, modules, fans etc.

What we’re looking for in our Connectivity & Hardware Support Engineers:

Experience of working in Voice and Data Cabling environment
Experience of Moves Adds and Changes environment
Thorough understanding of modern computer network infrastructure
Thorough understanding and practical experience of fibre and copper voice and data cabling, including terminating, test equipment, test parameters and test techniques
Knowledge of Rack and Stack of Server Hardware and Rack and Stack Systems
Good knowledge of Service Now (and other Process and Asset Management Tools)
Good knowledge of Server Patching
Knowledge of LAN / WAN and Active devices
Able to use all types of Modern Hand Held Cable Standards Testers
Able to use light Source and Power Meter

If you feel you have the required skills and experience, click apply now to be considered as our Connectivity & Hardware Support Engineers – we’d love to hear from you!",-1,-1,Unknown / Non-Applicable,-1,501 to 1000 Employees,Company - Private,True
Data Engineer - Hybrid,"The Hartford
","Hartford, CT",-1,3.7,"Sr Data Engineer - GE07BE
We’re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals – and to help others accomplish theirs, too. Join our team as we help shape the future.

Do you enjoy problem solving?
Do you enjoy cross-team collaboration?
Are you ready to make a difference?
Join an exciting team of motivated Data Engineers focused on delivering meaningful value through highly tailored data and software solutions. You will work in an agile environment with technology and investment professionals to solve real world problems that directly impact the business. This is an opportunity for an individual with a passion for understanding business challenges to help develop creative solutions on business-critical systems. You will work with a high performing and collaborative team while utilizing agile principals to pivot quickly and deliver outcomes.
What’s in it for you?
Work on visible and business-critical systems.
Ability to brainstorm and develop creative and unique solutions.
An environment for learning and personal development through cross team collaboration.
What are we looking for?
The successful candidate must be able to work with several different tools and technologies.
Much of the systems development will require an understanding of object-oriented design as well as having some background in database technologies.
A creative individual with strong software development and communications skills.
This role will have a Hybrid work arrangement, with the expectation of working in an office (Hartford, CT) 3 days a week (Tuesday through Thursday).
Responsibilities:
Design and develop high quality, scalable data assets that support contemporary BI tools and advanced analytics.
Help to design and implement best in class data-visualization and reporting solutions leveraging a number of modern BI solutions.
Prototype high impact innovations, catering to changing business needs, by leveraging new technologies (AWS – Cloud)
Possesses functional knowledge and skills reflective of a competent practitioner with the ability to deliver on work of highest technical complexity.
Migrate on-prem databases/data warehouses/applications to Cloud (AWS)
Consults with functional management in the analysis of short and long-range business requirements and recommends innovations which anticipate the future impact of changing business needs.
Provides highly technical consulting and leadership in identifying and implementing new uses of information technologies that assist the functional business units in meeting their strategic objectives.
Review and implement the disaster recovery plan to ensure that new systems promote uninterrupted systems operation.
Coordinate activities with cross-functional IT unit stakeholders (e.g., database, operations, telecommunications, technical support, etc.)
Work closely with the product owner to evaluate stakeholder requested features and provide input on estimating effort and feasibility for release level and sprint planning.
Formulates logical statements of business problems and devises, tests and implements efficient, cost-effective application program solutions (e.g., codes and/or reuses existing code through the use of program development software alternatives and/or integrates purchased solutions)
Prepares charts, tables, and diagrams to assist in analyzing problems, utilizing various business, scientific, engineering, and mathematical techniques. Analyzes existing system and programming logic to provide more efficient machine operations or to identify difficulties, and revises the logic and procedures involved as necessary.
Qualifications:
Candidate must be authorized to work in the US without company sponsorship.
Bachelors in computer science or a related discipline and at least 4 years or an equivalent combination of education and work experience
3+ years ETL / Data Integration / Cloud (AWS) Technologies experience
Relevant development experience with .NET, C#, or C++ is desired.
Experience designing and integrating quality data assets for optimal use in BI tools like Tableau, ThoughtSpot, and PowerBI.
Experience with Snowflake cloud data platform including hands-on experience with snowflake utilities like SnowSQL, Snow pipe.
Experience developing code in one or more programming languages (e.g. Java, Python, Scala, Hive, R, Spark etc.)
Knowledge of Erwin modeling, data vault 2.0, Big Data distributed processing preferred.
Knowledge of MS SQL, Oracle, Talend, Unix/Linux Shell scripting, Autosys scheduling tool, version control Tools
Strong data warehouse applications knowledge in financial/insurance domain
Experience working with semi-structured data (XML, JSON)
Experience in building and automation of data ingestion in near-real time from cloud blob storage
Experience working on change data capture (CDC) with Streams & Tasks
Experienced in Agile Scrum and Kanban Methodologies
Requires excellent business communication skills, analytical ability, strong judgment and management skills, and the ability to work effectively with Business and IT management and staff.
Knowledge of general operational data & processes and related business and employee performance metrics.
AWS Technologies certification preferred.
As a condition of your employment for HIMCO, you will be required to affirm to HIMCO’s Code of Ethics and understand that you will be required to comply with the disclosure of accounts, holdings and pre-clearance of trades for the accounts of you and your household family members as more fully described in the Code of Ethics Key Points. If you will be deemed to be a “Covered Associate” under HIMCO’s Pay to Play Policy, you will also need to disclose all political contributions that you have given within the past 2 calendar years.
Compensation
The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:
$110,560 - $165,840
Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age",1810,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Public,False
Junior Data Engineer,Bridgeton Research Group,"Westport, CT",$55K - $65K (Employer est.),-1.0,"We are a technology-based firm that utilizes our proprietary platform to develop and implement quantitative strategy overlays for our clients. We deploy our strategies across equities, futures, and foreign exchange instruments. Our clients include institutional investors and commercial hedgers who use our data driven insights to complement their existing investment process and fundamental market expertise.

We are looking for a motivated and focused individual with a passion for solving complex problems to join our data ingestion team.
You will have the opportunity to work on a high-volume data ingestion system, setting the foundation for our analysis.

Requirements

Proficiency in Python and SQL
Familiarity with Python libraries such as Pandas, Numpy, Matplotlib, SQLAlchemy, etc.
Experience with numerical data manipulation and processing
Experience with Microsoft Excel
Attention to detail
A bachelor’s degree with a GPA above 3.0 (STEM preferred)
Ability to solve unfamiliar problems under pressure
Ability to communicate clearly and concisely, verbally and in writing
Desire to take ownership and work autonomously in a fast-paced and dynamic environment

Job duties include:

Support, maintain, and configure data ingestion infrastructure and documentation.
Provide technical support to clients and other project team members.
Assist the team in resolving production issues on nights and weekends as needed.
Perform administrative tasks as needed.
Collaborate with the data science team in the creation and distribution of client reports.

Job Type: Full-time

Pay: $55,000.00 - $65,000.00 per year

Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance
Professional development assistance
Vision insurance

Compensation package:

Yearly pay

Experience level:

1 year

Schedule:

Day shift
Monday to Friday
On call
Weekends as needed

Ability to commute/relocate:

Westport, CT 06880: Reliably commute or planning to relocate before starting work (Required)

Application Question(s):

Why are you interested in this position?

Education:

Bachelor's (Required)

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Data Engineer,"Aspen Insurance Holdings
","Rocky Hill, CT",$90K - $113K (Glassdoor est.),3.7,"Reference: ASPUS00490
Rocky Hill, Connecticut
Permanent - Full Time

$85600 - $107000

About us
Since Aspen was founded in 2002, we have become a leading, diversified specialty insurance and reinsurance company. We respond thoughtfully and creatively to find the best outcomes for our clients and business partners through carefully tailored solutions. We believe the way we work is just as important as the work we do, and we are guided by our core values of respect, honesty, trust and professionalism. Aspen is a great place to develop your career offering an exciting and challenging environment where achievement is rewarded.
The role



Aspen’s vision is to be the global reference point for quality in all its markets. To achieve this goal, Aspen has launched our Data and Analytics strategy which introduces a preconnected, 360 view of data to power company wide analytics and embed data focused decision making from every seat. Through the creation of our single version of data truth, we ensure that all data used for decision making is accurate and fit for purpose, building trust in reporting and provide client intimacy.

As a cloud data engineer you will have a passion for sourcing data of all types and building high quality, scalable data pipelines creating out single version of data truth to power analytics across the enterprise. Partnering with our internal leaders, users and clients, you will design and integrate data from customers, external data providers and our internal applications to create a 360-insurance data platform which will be the foundation for our ML/AI services and power the delivery of all insights used for decision making. As a member of our engineering unit, you will support the design and implementation of data integration capabilities making the most use of our Cloud Tech data services. You will have the autonomy to explore and find innovative ways or delivering our data landscape utilizing the tech and data we have access to.

If you have a real drive to make a difference, add value for our clients in an industry that creates resilience and sustainability globally then this is an opportunity that you don’t want to miss out on.




Key accountabilities
Contribute to Aspen's Data & Analytics Strategy to embrace tech and data to support our user’s demand for insights and informed decision making
Contributes to functional strategy and prioritizes deliverables to support delivery of business targets
Manages tactical plan/support to others to achieve positive results for business in line with strategy
Ensure data pipelines are scalable, repeatable, and secure across enterprise
Explains technical considerations at meetings, including those with internal clients and less experienced team members
Tests code thoroughly for accuracy of intended purpose
Reviews end-product with client to ensure adequate understanding of data assets you and other data engineers are delivering
Co-Create coding and delivery standards embedding a focus across the engineering unit on consistent, high quality data pipelines and access
Experience with integrating large scale data from a variety of sources for business partners to generate insight/decisions
Translates business specifications into design specifications and code
Ensures all code is well structured, includes sufficient documentation, and is easy to maintain and reuse
Gains expertise in tools, technologies, and applications/databases in specific business areas and company-wide systems
Create awareness across the business of data made available in Single Version of Truth
Works with key stakeholders/business managers to encourage adoption of single version of data truth
Demonstrate extensive experience in building data pipelines in both Data Warehouse and Data Lake environments
Apply experience in working within cloud-based data infrastructure most notably Azure including tools such as Data Factory, Data Bricks
Apply experience coding in both python and SQL in spark-based environments
Support the design of our single version of data truth data model
Working with the Data Leadership Team, ensure Data Integration Framework for our single version of data truth is designed, supported, and managed in accordance with business needs
Skills & experience
Experience with SQL, SSIS and SSRS
Experience with Microsoft Azure Cloud
Knowledge and awareness of technology services which could the data and analytics space
Deep knowledge of data modelling for analytics – i.e. Data Warehousing, Data Lakes, Data Mesh architecture
Aware of data science methodologies and frameworks
Excellent understanding of Agile frameworks and processes
Knowledge of insurance industry’s processes
Sound knowledge of problem analysis, structure analysis, and design techniques
Strong understanding of underlying needs of the business and how own role contributes to these
Strong coding experience using python
Experienced in building integration frameworks focused on reusability and consistency across data engineering
Experienced in creating engineering standards and monitoring the adoption and benefits across the engineering unit
People management – ability to engage and lead a team
Able to execute within agile processes, tracking capacity and deliverables in collaboration with team members
Resource and budget management
Specific professional qualifications at the level of degree or equivalent within topics such as computer or data science , information systems or similar
Experience within Financial Services (especially Insurance)
Evidence of supporting technical and operational strategy
Working as part of a senior team within a complex organization (preferably within financial services industry)
Hands-on experience with computer networks, network administration and network installation
Other
We are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Apply now

Share",2002,Insurance Carriers,$1 to $5 billion (USD),Insurance,1001 to 5000 Employees,Company - Private,False
Lead Data Engineer,XO Health Inc.,"Stamford, CT",$108K - $148K (Glassdoor est.),-1.0,"XO Health believes healthcare is fixable. Become part of the community changing the face of the industry.

XO Health is the first health plan designed by and for self-insured employers that delivers a more unified health experience for everyone – from those who receive care, to those who deliver it, to those who pay for it.

We are growing a multi-disciplinary team of diverse and digitally empowered employees ready to rebuild trust in healthcare through comprehensive and unified transformation.




About the Role:

The Lead Data Engineer is a critical role in our Data Engineering team who will work closely with Product Managers, Data Scientists and Software Engineers to support product launches and roadmaps by building the data architecture that informs and drives insight. In this role, you'll influence technology strategies, ensure that the technological solutions are aligned with the company's business needs and bring to life data and how it can impact positive healthcare outcomes.

The perfect candidate will have strong data infrastructure and data architecture skills, a proven track record of technical leadership, strong operational skills to drive efficiency and speed, strong project management skills, and a vision for how data can be an enabler.

In This Role, You will:

Possess a hardworking ""can-do"" mindset with focus on the collective success of the scrum team to iteratively deliver high quality products to enable the XO Health business architecture, intelligence, and creation of intellectual property.
Collaborates with the Product Owner, Project Manager / Business Analyst, Scrum Master, Subject Matter Experts and Development team to define and analyze user stories tracked in Jira.
Collaborate in design, development, and implementation of software/data solutions for using modern cloud native, API first technology stack.
Build cross-functional relationships with Data Scientists, Product Managers and Software Engineers, and PMO to understand data needs and deliver on those needs.
Drive the design, building, and launching of new data models and data pipelines in production.
Continually enhance full delivery pipeline through automation, expanded yet increasingly efficient test coverage, ultimately optimizing time-to-market and quality.
Participate in innovation in the team through continuous learning and building prototyping complex, cross platform business solutions.
Drive data quality across the product vertical and related business areas.
Support the delivery of high impact dashboards and data visualizations.
Define and manage SLA's for all data sets and processes running in production.
Mentor new or junior team members and participate in code reviews.

We're Looking for People Who Have:

A Bachelor's or Master's degree in a technical or business discipline, or equivalent experience.
5+ years of related data engineering, data science and/or business intelligence experience.
Extensive knowledge of contemporary frameworks, data/software engineering languages, diverse and emerging technologies.
3+ years data architecture experience.
3+ years development experience in at least one object-oriented language (Python, R, Java, etc.).
Hands on experience in building cloud native applications using AWS platform.
Progressive experience with SQL and related data base technologies.
Progressive experience with a variety of data management tools and technologies, and related tools, data visualization and data extraction and transformation tools.
Hands on experience in Python (ETL tools- Pandas/NumPy, Python unit testing etc.).
Experience with business intelligence tools and reporting solutions (PowerBI, Tableau etc.).
Experience with build/deploy automation & DevOps frameworks (CI/CD, Bamboo, GitHub Actions, pipeline-as-code, AWS CDK)
Familiarity and experience in building and consuming APIs (REST, API Gateway, etc.) in an environment that uses multiple external applications.
Strong testing and version control methodology.
Must have strong problem-solving, analytical and in-depth research skills.
Possess the ability to communicate effectively, with internal and external partners, both orally and written.



XO Health is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. XO Health promotes a drug-free workplace.",2018,Advertising & Public Relations,Unknown / Non-Applicable,Media & Communication,1 to 50 Employees,Company - Private,True
Data Engineer - 5050304,"Accenture
","Hartford, CT",-1,3.9,"Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.

As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.

You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.

Utilize strong SQL Python skills to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features.

Build reporting dashboards and visualizations to design, create and track campaign program KPIs.

Perform analyses on large data sets to understand drivers of operational efficiency.

Manage end to end process of analytic tooling feature development, including request intake, requirements evaluation, cross functional team alignment, feature execution, QA testing, and stakeholder communication.

Consult with business analysts, technical data SMEs, and cross functional partners to understand their reporting and data needs, serving as the point of contact for requests, inquiries, and actions.

Interface with other data engineering, product, and data science teams to implement client needs and initiatives.




Basic Qualifications:

Minimum 2 years experience with Python.

Minimum 3 years experience SQL.

Minimum 3 years experience Big Data Analytics.

High School Diploma or GED.

Preferred Qualifications:

Experience with large enterprise data sets.

Bachelors Degree

Compensation at Accenture varies depending on a wide array of factors, which may include but are not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York, or Washington as set forth below.

Information on benefits is here.

Role Location

California: $61.53 to $71.53/hour

Colorado: $61.53 to $71.53/hour

New York: $61.53 to $71.53/hour

Washington: $61.53 to $71.53/hour


What We Believe


We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.


Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here


Equal Employment Opportunity Statement


Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.


All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.


Accenture is committed to providing veteran employment opportunities to our service men and women.


For details, view a copy of the Accenture Equal Employment Opportunity and Affirmative Action Policy Statement.


Requesting An Accommodation


Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.


If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.


Other Employment Statements


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.


Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.


Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.


The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",1989,Business Consulting,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Software Engineer/Data Engineer - Hybrid,"The Hartford
","Hartford, CT",-1,3.7,"Data Engineer - GE08AE
We’re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals – and to help others accomplish theirs, too. Join our team as we help shape the future.

The Hartford's Enterprise Data Services is seeking a Software Engineer with data engineering skills, hands on full stack development experience with front-end/API and database skills.
The ideal candidate should have a passion for software development, automation, be self-motivated, able to work across teams, and have the drive to learn new technologies and be willing to experiment.
As a java full stack developer, you will be a hands-on developer on an agile team. This team is passionate for technology and strives to build well architected and innovative solutions for the business using latest technologies and a highly scalable platform. The team has adopted Scaled Agile development Framework (SAFe) and core DevOps engineering practices such as continuous integration, continuous deployment and is working towards cloud adoption. This position is full-time and based in our Hartford Office.
To be a developer on our team, you need to love building great solutions collaborating with our product owners, designers, and architects. You will write awesome software and collaborate with other developers. You will be challenged and able to grow your career at a place that has limitless opportunities. If you relish a chance to serve as a technology enthusiast, this is a great opportunity for you.
We are looking for a detail-oriented, results-driven individual who is ready for a challenge! Joining members of a motivated team, working closely with our business partners in supporting their initiatives within an agile environment. You will be collaborating with team members while building strong relationships, actively participating in teamwork, and developing an understanding of the dynamics and critical nature of the business.
This role will have a Hybrid work arrangement, with the expectation of working in an office (Hartford, CT) 3 days a week (Tuesday through Thursday).
Responsibilities include but are not limited to:
Perform hands-on development work in Java stack leveraging Java, JavaScript, Angular, Spring Boot API
With some guidance, research evaluate solutions, and recommend/develop/test the most efficient and cost-effective solution to meet business requirements that conforms to The Hartford’s coding standards.
Solicit, understand, and document technical requirements to meet business objectives.
Design, test, develop, deploy, maintain, and improve software assets and ensure high quality code conforms to The Hartford coding standards and industry best practices.
Work closely as a member of an agile team, contributing towards the team’s goals of improving our Agile delivery, Dev Ops practices, and improving overall quality of our delivered code. Work with continuous integration and DevOps methodologies following industry best practices with tools such as Git, Jenkins, Nexus, Rally, etc.
Participate as an active agile team member to help drive feature refinement, user story completion, code review, etc.
Identify, document, and communicate technical risks, issues and alternative technical solutions discovered during project.
Mentoring less experienced engineers
Advocate for code reusability across multiple products and can span the full stack whenever necessary.
Proactively identify, analyze/research and address technical issues/defects along with risks that could impact projects, enhancements or an applications stability and provide solutions to quickly resolve them.
Willingness and proven ability to learn new technologies/methodologies and apply them.
Qualifications
Bachelor’s degree in computer science or a related discipline and 3 or more years’ experience in IT systems analysis and application program development, or an equivalent combination of education and work experience
Minimum of 3+ years hands on development experience with HTML, CSS, JavaScript/TypeScript, Angular, Java, Spring batch and Spring Boot.
Hands-on experience with Java, Angular, React, JavaScript, Node.js, CSS, JSON, Document Object Model, SQL
Experience with relational databases – Oracle, MySQL, SQL Server
Experience with Git and version control concepts
Familiarity with Restful APIs and Microservices
Familiarity with continuous integration and DevOps methodologies, best practices and tools such as Github, Jenkins and Udeploy.
Extensive experience with GIT and working with cross-functional project teams using Scrum Agile with remotely located team members.
Experience in Cloud technologies a plus – AWS Services (Lambda, RDS, API Gateway, S3)
Experience with containers and related technologies, services a plus – Openshift, ECS, Kubernetes
Experience with AWS Code* a plus - AWS CICD tools ( AWS codebuild , AWS codedeploy, AWS cloud formation)
Experience with application architecture, software design and design patterns
Willingness and proven ability to learn new technologies/methodologies and apply them.
Ability to work well in both a team environment and independently to design and deliver business solutions.
Experience working with cross-functional project teams using Agile methodology.
Strong consulting and communication skills. Ability to work effectively with various organizations in pursuit of problem solutions.
Compensation
The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:
$95,200 - $142,800
Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age",1810,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Public,False
Data Governance Technology Engineer,"Interactive Brokers
","Greenwich, CT",$108K - $147K (Glassdoor est.),3.8,"Interactive Brokers Group is at the forefront of trading innovation, starting with the invention of the first floor-based, handheld computer in 1983. We pride ourselves on being primarily a technology company. We continue to challenge the status quo and push boundaries to offer the best trading platform with the most sophisticated features, all to help minimize our clients' costs. Software development is the lifeblood of our firm and it shows in our award-winning desktop, mobile and web applications that provide our clients with the tools they need to be successful. For five consecutive years, Interactive Brokers Group, Inc. (IBKR) has been rated ""#1 - Best Online Broker"" by Barron's. (read article)

About the Team

Our Data Operations team is looking for a Data Governance Operations Analyst. The analyst assists the data organization with installing, maintaining and supporting the data governance tool suite. In addition, this position helps with implementing an enterprise data governance program.

We are looking for someone who will:

Work with technology partners to gather and understand application, lineage and reporting data requirements.
Help install and maintain data governance tools and infrastructure.
Lead the initial use of these tools.
Document procedures and troubleshooting techniques.
Assist with onboarding and supporting users in the use of these tools.
Work with the data quality team to design and implement data quality reporting dashboards.

You will need to have:

Bachelor's degree in Information science, Data Management, Computer Science or a related field.
Strong Linux knowledge with some administration experience preferred
Strong SQL background, able to create efficient queries
Python programming to automate tools that provide a REST API
Preferred prior experience in data management and governance, including working with at least one industry-standard data governance tool (data catalog, data lineage, data quality)
Familiar with working in a DevOps-driven environment utilizing Git
Preferred One+ years of cloud experience (AWS)
Experience with container orchestration technologies (Kubernetes preferred)
Experience with relational databases (Oracle, MySQL) and JDBC connection URLs
Strong analytical and technical skills to troubleshoot issues, analyze the cause, quickly develop the possible solution(s), document the changes, and communicate the change to the organization.

Qualities we'd love to see:

Good analytical and problem-solving skills.
Excellent collaboration and communication (verbal and written) skills.
Good organizational and time management skills.

Company Benefits & Perks

Competitive salary, annual performance-based bonus and stock grant
Retirement plan 401(k) with a competitive company match
Excellent health and welfare benefits, including medical, dental, and vision benefits
Wellness screenings and assessments, health coaches and counseling services through an Employee Assistance Program (EAP)
Paid time off and a generous parental leave policy
Daily company lunch allowance provided and a fully stocked kitchen with healthy options for breakfast and snack
Corporate events, including team outings, dinners, volunteer activities and company sports teams
Education reimbursement and learning opportunities
Modern offices with multi-monitor setups.
Company Overview

Interactive Brokers Group, Inc. (Nasdaq: IBKR) is a global financial services company headquartered in Greenwich, CT, USA, with offices in over 15 countries. We have been at the forefront of financial innovation for over four decades, known for our cutting-edge technology and client commitment.

IBKR affiliates provide global electronic brokerage services around the clock on stocks, options, futures, currencies, bonds, and funds to clients in over 200 countries and territories. We serve individual investors and institutions, including financial advisors, hedge funds and introducing brokers. Our advanced technology, competitive pricing, and global market help our clients to make the most of their investments.

Barron's has recognized Interactive Brokers as the #1 online broker for six consecutive years. Join our dynamic, multi-national team and be a part of a company that simplifies and enhances financial opportunities using state-of-the-art technology.",-1,Investment & Asset Management,$1 to $5 billion (USD),Financial Services,1001 to 5000 Employees,Company - Public,True
Sr. AWS Data Engineer,"LTIMindtree
","Hartford, CT",$81K - $115K (Glassdoor est.),3.5,"Role: Senior Developer

Experience 4-6 Years

Location: USA – Hartford, CT

Must Have: AWS (S3), Python, Databricks

Good to have: Snowflake, Spark

Overview:

Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming analytics landscape.

Looking for Data Migration Engineer having an experience migrating data from on prem to cloud.

Must Have: AWS (S3), Python, Databricks

Good to have: Snowflake, Spark

Requirements:

• Strong python skills

• AWS/Cloud infrastructure knowledge (commonly used AWS services, IAM)

• Experience with building data pipelines using Databricks on AWS

• Knowledge and Hands-on Snowflake

• Experience in Agile methodologies and Atlassian tools like JIRA.

• Expertise in using version control tools like Git, Bitbucket

• Experience on CI/CD using Kubernetes, GIT and Monitoring and Alerting tools

• Experience on data migration from On-Prem databases to AWS Cloud on S3

Roles & resposibilities:

• Acts as a single point of contact for data migration to AWS projects for customer

• Provides innovative and cost-effective solution using AWS, Spark, python & databricks

• Develops solutions to meet business needs that reflect a clear understanding of the objectives, practices and procedures of the corporation, department and business unit

• As a leader in the Cloud Engineering you will be responsible for the overseeing development

• Learn/adapt quickly to new Technologies as per the business need

• Develop a team of Operations Excellence, building tools and capabilities that the Development teams leverage to maintain high levels of performance, scalability, security and availability

• Understand where to obtain information needed to make the appropriate decisions

• Demonstrate ability to break down a problem to manageable pieces and implement effective, timely solutions

• Identify the problem versus the symptoms

• Develop solutions to meet business needs that reflect a clear understanding of the objectives, practices and procedures of the corporation, department and business unit

Skills:

• The Candidate must have 3-5 yrs of experience in AWS, Python, Databricks

• Hands on experience on AWS Cloud platform especially S3, lamda, EC2, EMR

• Experience on spark scripting

• Has working knowledge on migrating relational and dimensional databases on AWS Cloud platform

• Relevant experience with ETL methods and with retrieving data from dimensional data models and data warehouses.

• Strong experience with relational databases and data access methods, especially SQL.

• Knowledge of Amazon AWS architecture and design

Job Type: Full-time

Salary: $100,000.00 - $1,500,000.00 per year

Benefits:

401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance

Schedule:

8 hour shift
Day shift
Monday to Friday

Work Location: In person",1997,Information Technology Support Services,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Public,True
Data Engineer II,"Nuvance Health
","Danbury, CT",$40.00 - $70.00 Per Hour (Employer est.),2.9,"Nuvance Health is a network of convenient hospital and outpatient locations — Danbury Hospital, New Milford Hospital, Norwalk Hospital, and Sharon Hospital in Connecticut and Northern Dutchess Hospital, Putnam Hospital Center, and Vassar Brothers Medical Center in New York — plus multiple primary and specialty care physician practice locations including The Heart Center, a leading provider of cardiology care, and urgent care offices. Non-acute care is offered through our affiliates and the Home Care organizations.

YOU MUST HAVE A MINIMUM OF 4 YR. OF MEDICAL / HEALTHCARE AND EMR EXPERIENCE TO BE CONSIDERED

AND THE LEGAL RIGHT TO WORK IN THE U. S. --- SPONSORSHIP IS UNAVAILABLE

Summary:
The Data Engineer II is responsible for the technical implementation of reporting and analytic tools across Nuvance Health. Establish data reporting standards, tools, and content aligned with our strategic needs. Transform data from internal and external sources to provide timely, meaningful, and actionable insight to clinical teams and leaders to drive organizational improvement. Collaboration with end-users to determine information and data needs, conceptualize, design, and develop data visualization solutions into clear communications for key stakeholders and decision makers.

Responsibilities:
YOU MUST HAVE A MINIMUM OF 4 YR. OF MEDICAL / HEALTHCARE AND EMR EXPERIENCE TO BE CONSIDERED

AND THE LEGAL RIGHT TO WORK IN THE U. S. --- SPONSORSHIP IS UNAVAILABLE

Extract, Load, and transform (ETL) data into our enterprise data warehouse (EDW) from various clinical and non-clinical sources using SQL, Python, Glue and cloud data warehousing technologies (AWS, Redshift).

Develop and maintain robust quality control processes to ensure data integrity

Collaborate with technology and platform management partners to optimize data sourcing and processing rules to ensure appropriate data quality

Data modelling: Work with subject matter experts to define data requirements, source of the data, and format required

Develop and maintain front-end analytics tools and dashboards (Tableau/PowerBI/QuickSight) that utilize the data pipelines to provide actionable insights on performance KPIs and other metrics.

Troubleshoot production issues related to data flows within the enterprise

Identify, design, and implement internal process improvements optimizing data delivery and automating manual processes

Ensure relevant data is captured in source systems and made available for teams within Nuvance business intelligence applications

Participate in continually improving processes and procedures for enhancing the efficiency and effectiveness of Data Engineering services to analytic users

Aggregate and analyze various data sets to provide actionable insight

Coordinate multiple work efforts at once and complete deliverables within stated timelines

Requirements:
ONLY APPLICANTS WITH A MINIMUM OF 4 YR. OF MEDICAL / HEALTHCARE AND EMR EXPERIENCE WILL BE CONSIDERED

Minimum of 4 years of experience in a Data Engineering role in a healthcare field

Undergraduate degree in Computer Science, Information Systems, or related discipline

Proficiency in SQL

Experience with Python, R, PySpark, or other programming language

Excellent communication skills - written and verbal

Applied knowledge of database management tools and data warehousing best practices

Proven experience in managing structured data: application data bases, operational data stores, data marts and data warehouses

Working knowledge of EMR systems including system-wide hospital or ambulatory information systems.

Cloud experience ( S3/Glue/Redshift/ AWS/Azure/GCP), preferred

GitHub/GitLab or CI/CD experience, preferred

SSIS experience, preferred

Master’s Degree, preferred

Location: REMOTE-NJ07/Corp. HQ is located in Danbury, CT

Work Type: Full-Time/40 Hr.

Work Shift: M-F, 8AM-4:30PM - EDT/EST PREFERENCE

Exempt: Yes

Salary Range:
$40 - $70 Hourly = $83K - $140K

Working Conditions:
Little or no manual skills / motor coordination & finger dexterity

Little or no potential for occupational risk

Sedentary/light effort; may exert up to 10 lbs. force

Generally pleasant working conditions

EOE including disability/veterans

We will endeavor to make a reasonable accommodation to the known physical or mental limitations of a qualified applicant with a disability unless the accommodation would impose an undue hardship on the operation of our business. If you believe you require such assistance to complete this form or to participate in an interview, please contact Human Resources at 203-739-7330 (for reasonable accommodation requests only). Please provide all information requested to assure that you are considered for current or future opportunities.",2019,Health Care Services & Hospitals,$1 to $5 billion (USD),Healthcare,10000+ Employees,Hospital,False
AWS Data Engineer,"Plaxonic
","Hartford, CT",$120K - $130K (Employer est.),4.4,"Role: AWS Data Engineer

Location: Hartford, CT(onsite)

Job Type: Full Time Role

Job Description:

Overview: Data Migration Engineer having an experience migrating data from on prem to cloud.

Must Have: AWS (S3, Aethna, EMR, EC2), Spark, PySpark

Good to have: Databricks, Snowflake

Requirements:

Candidate must be experienced working in projects involving data migration on AWS
Experience on data migration from On-Prem databases to AWS Cloud on S3
Understands where to obtain information needed to make the appropriate decisions
Demonstrates ability to break down a problem to manageable pieces and implement effective, timely solutions
Identifies the problem versus the symptoms
Manages problems that require involvement of others to solve
Reaches sound decisions quickly
Develops solutions to meet business needs that reflect a clear understanding of the objectives, practices and procedures of the corporation, department and business unit

Roles & resposibilities:

Acts as a single point of contact for data migration to AWS projects for customer
Provides innovative and cost-effective solution using AWS, Spark, python & customer suggested toolset
Optimizes the use of all available resources
Develops solutions to meet business needs that reflect a clear understanding of the objectives, practices and procedures of the corporation, department and business unit
As a leader in the Cloud Engineering you will be responsible for the overseeing development
Learn/adapt quickly to new Technologies as per the business need
Develop a team of Operations Excellence, building tools and capabilities that the Development teams leverage to maintain high levels of performance, scalability, security and availability

Skills:

The Candidate must have 3-5 yrs of experience in AWS, PySpark & Python
Hands on experience on AWS Cloud platform especially S3, lamda, EC2, EMR
Experience on spark scripting
Has working knowledge on migrating relational and dimensional databases on AWS Cloud platform
Relevant experience with ETL methods and with retrieving data from dimensional data models and data warehouses.
Strong experience with relational databases and data access methods, especially SQL.
Knowledge of Amazon AWS architecture and design

Please fill the below table:

Linked In URL

Location

DOB(MM/DD)

Last four digit of SSN

In which year came to USA on which Visa

Education

Thanks & Regards

Manvendra Yadav

Plaxonic Technologies Inc

manvendra@plaxonic.com

727-241-5655

Job Type: Full-time

Salary: $120,000.00 - $130,000.00 per year

Experience:

AWS: 10 years (Required)
Spark: 10 years (Required)
Pyspark: 8 years (Required)
Data Brick: 8 years (Required)

Work Location: On the road",2013,Information Technology Support Services,$1 to $5 million (USD),Information Technology,51 to 200 Employees,Company - Private,True
"Data Engineer II, Machine Learning Ops - Bond & Specialty Insurance","The Travelers Companies, Inc.
","Hartford, CT",$121K - $200K (Employer est.),4.2,"Who Are We?
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Job Category
Data Analytics, Technology
Compensation Overview
The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
Salary Range
$121,000.00 - $199,600.00
Target Openings
1
What Is the Opportunity?
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Machine Learning and business intelligence/insights.
What Will You Do?
Lead our ML Ops Agile teams
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
Design complex data solutions
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Test data movement, transformation code, and data components.
Perform other duties as assigned.
What Will Our Ideal Candidate Have?
Bachelor’s Degree in STEM related field or equivalent
Eight years of related experience
Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
What is a Must Have?
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
What Is in It for You?
Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
Employment Practices
Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an
email
so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit
http://careers.travelers.com/life-at-travelers/benefits/
.",1853,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Public,False
Data Engineer II - Tech Lead,"The Travelers Companies, Inc.
","Hartford, CT",$121K - $200K (Employer est.),4.2,"Who Are We?
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Job Category
Technology
Compensation Overview
The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
Salary Range
$121,000.00 - $199,600.00
Target Openings
2
What Is the Opportunity?
Corp Tech currently has opportunities for experienced Data Engineers on several cloud data initiatives. The individuals hired into these roles will lead teams of data engineers to develop the necessary components of a modernized, scalable, performant and extensible ecosystem of data and analytics capabilities. Through technical acumen and leadership you will build and deliver cloud native solutions to deliver data as a product to the business using a range of modern technologies and tools. Successful candidates will not only demonstrate advanced knowledge of AWS, Databricks, Snowflake, Python, Spark APIs and Event Driven patterns – but have tangible experience with similar efforts to modernize legacy data & analytics platforms from on-premise to cloud.
As a technical lead you will contribute to, support and build upon the Corp Tech data strategy that will enable best in the industry capabilities to organize, standardize, and process complex data across a landscape of on-prem and cloud based data lake and warehouse technologies.

Work arrangement is hybrid in a Travelers office.
What Will You Do?
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
Design complex data solutions
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Test data movement, transformation code, and data components.
Perform other duties as assigned.
What Will Our Ideal Candidate Have?
Bachelor’s Degree in STEM related field or equivalent
Eight years of related experience
Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
What is a Must Have?
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
What Is in It for You?
Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
Employment Practices
Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an
email
so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit
http://careers.travelers.com/life-at-travelers/benefits/
.",1853,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Public,False
Data Engineer,"Farm Credit East
","Enfield, CT",$74K - $125K (Employer est.),4.1,"Be part of a team focused on the success of our customers, the success of our communities, and the success of each other. Farm Credit East is the leading provider of loans and farm advisory services to farm, forest product, fishing, and other agricultural business owners across the northeast. We are One Team Working Together with a focus on our five pillars: Outstanding Customer and Employee Experience, Quality Growth, Operational Excellence, Commitment to our Communities, and Protecting Customer Information.

Position Summary
The Data Engineer is responsible for cleaning, managing, and sharing data that guides business decisions. Using ETL tools you will gather data from a variety of sources, checking for anomalies, automating processes, and generally making it easier for business stakeholders to generate valuable insights. This position will collaborate with internal and external organization to capture requirements, design, create, document, manage, and fulfill requests for on-going and/or ad-hoc reports, dashboards, and scorecards.

Duties and Responsibilities
Work with product stakeholders to implement, maintain, and enhance data models and solutions used to define and measure quality of data domains.
Design data models to meet requirements.
Perform ETL (Extract, Transform, and Load) on data to meet stakeholder specifications.
Design and develop data access methods, datasets, views etc.
Develops data modeling and is responsible for data acquisition, access analysis, archive, recovery, load design and implementation.
Coordinates new data developments to ensure consistency with existing warehouse structure.
Collaborates with internal customers to capture requirements, design, create, document, manage and fulfill requests for on-going and/or ad-hoc reports, dashboards, and scorecards.
Assists with the development, implementation, and maintenance of front-end presentation (dashboards), automated report solutions and other BI solutions to support tactical and strategic reporting needs of the organization.
Assists in identification of data integrity problems and recommends solutions.
Work collaboratively with key stakeholders both internally and externally, including but not limited to Senior Management, Business Unit Leaders, Knowledge Exchange, and Farm Credit Financial Partners (FPI).

Job Qualifications/Requirements
Bachelor’s Degree in Computer Science, Business, Finance, or other related field from an accredited University.
Experience with MSFT SQL Server
Proficient in Python, PySpark, Spark SQL
Microsoft Azure (Data Bricks, Data Factory, Logic Apps, Functions, etc.)
2 plus years of experience in Finance related informatics, performance measurement, or analysis with strong relational database SQL skills.
1 + years of experience using Microsoft Azure product to perform ETL
Familiar with Databricks Unity catalog
Salary range: $74,000- $125,000 commensurate with experience

Farm Credit East is an Equal Opportunity Employer. As an Equal Opportunity Employer, we do not discriminate on the basis of race, color, religion, national origin, sex, sexual orientation, gender identity or expression, age, marital status, parental status, political affiliation, disability status, protected veteran status, genetic information or any other status protected by federal, state or local law. It is our goal to make employment decisions that further the principle of equal employment opportunity by utilizing objective standards based upon an individual's qualifications for a specific job opening. In compliance with the Americans with Disabilities Act (“ADA”), if you have a disability and would like a reasonable accommodation in order to apply for a position with Farm Credit East, please call 1-800-562-2235 or e-mail FarmCreditCareers@farmcrediteast.com .",1916,Banking & Lending,$100 to $500 million (USD),Financial Services,201 to 500 Employees,Company - Private,False
Senior Data Quality Engineer,"The Hartford
","Hartford, CT",-1,3.7,"IT Quality Analyst - QI08EE
Sr Analyst SDET - QI07DE
We’re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals – and to help others accomplish theirs, too. Join our team as we help shape the future.
Group Benefits – Enterprise Data Services is undergoing a transformation to Cloud and we are looking for a Senior Data Quality Engineer to bring business focus to QA practices. As a Quality Engineer, you will play a pivotal role to establish frameworks for data warehouse & data lake testing, automated testing, Service virtualization, Enterprise data and data quality assurance in addition to helping the organization move towards Continuous testing practices. The individual will work with multiple vendors, IT leaders, and business teams to align automation priorities with IT strategies. Champion the usage and adoption of automated testing and related tools (in-house and new external tools) across the organization. Help defining quality engineering standards, best practices, provide technical recommendations to continuously improve testing efficiencies, mentor the scrum QA teams to adopt defined practices, and report KPIs. Partner with the Scrum Masters, Data Engineers and business leads to increase test coverage and optimize automated test executions time to achieve faster release readiness, support post implementation reviews, driving for root cause to improve test processes and key quality metrics.
Responsibilities:
Accountable for overall test planning and test execution of data & ETL pipelines and downstream reporting
Thorough understanding of DevOps & DataOps practices and make advancements to shift left the QA pipelines in overall CICD process.
Contribute to the quality engineering activities throughout the SDLC phases - requirements, design, development, and testing.
Thorough understanding Data masking, Test data management & Environment engineering practices.
Advanced knowledge of SQL and hands on experience with various on-prem and on-cloud databases like Oracle, Postgres, Redshift & Snowflake etc.
Lead initiatives for Performance testing and Security testing to build quality into the data products, reports, dashboards & APIs.
Experience with testing of reports and dashboards on standard toolsets like ThoughtSpot, Tableau, Micro-Strategy etc.
Identify industry accepted tools and technology for implementation that align with business goals, application landscape and cloud first approach.
Develop automated Test Data Management capabilities across the program ecosystem.
Provide technical leadership to Scrum QA engineers to adopt shift left approach in testing.
Design, develop, review, and maintain test artifacts – test cases, frameworks, code library, common capabilities, etc. adhering to the quality engineering best practices and meet expected quality standards.
Be passionate about new technologies and help bring in outside- in view to teams on the ground to drive transformation.
Evaluate efficiency of existing QA practice and recommend for improvements.
Display critical thinking skills by identifying and resolving risks and issues in proactive manner.
Qualifications:
Must be authorized to work in the U.S.
BS in Computer Science or equivalent experience
5+ years of experience in Quality Engineering
3+ years of experience in leading Quality engineering teams
Knowledge on any Cloud tech stack
Advanced knowledge of SQL as it pertains to data & analytics and reporting
Experience with any scripting or programing language – Python, JavaScript etc.
Experience with Test automation & DevOps tools
Strong experience in risk-based approach for implementing End to End test strategies
Knowledge of Agile Scrum/SAFE methodology
Effectively use collaboration tools like Rally, Jira etc.

Nice to Have:
Experience with AppScan, Checkmarx, CA DevTest
Experience with any of the reporting tools –Tableau, Business Objects, Micro-Strategy
Insurance & Financial services domain knowledge
Knowledge of AWS cloud technology – Code Build, Code Pipeline, Containers
Additional Details:
Must be Authorized to work in the United States
The Hartford is proud to offer a hybrid work location model that is designed to support flexibility.
This partial remote position requires in office presence Tuesday, Wednesday & Thursday with remote work flexibility Monday, and Friday.
Office Locations include Hartford, CT, San Antonio, TX, Lake Mary, FL, Phoenix, AZ, Aurora, IL, New York City, NY and Danbury, CT
Compensation
The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:
$98,800 - $148,200
The posted salary range reflects our ability to hire at different position titles and levels depending on background and experience.
Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age",1810,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Public,False
Sr. Data Engineer,"The Travelers Companies, Inc.
","Hartford, CT",$138K - $228K (Employer est.),4.2,"Who Are We?
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Job Category
Technology
Compensation Overview
The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
Salary Range
$138,100.00 - $227,800.00
Target Openings
1
What Is the Opportunity?
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
What Will You Do?
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate.
Collaborate across team to support delivery and educate end users on complex data products/analytic environment.
Perform other duties as assigned.
What Will Our Ideal Candidate Have?
Bachelor’s Degree in STEM related field or equivalent
Ten years of related experience
Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices.
Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems.
Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers.
Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize.
Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas.
Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members.
Experience with some of the following tools & platforms (or similar): AWS (s3, Lambda, Kinesis, API Gateway, IAM, Glue, SNS, SQS, EventBridge, EKS, VPC, Step Functions, ECS/EKS, DynamoDB, etc.), Databricks, Python, JavaScript, Kafka, dbt, Terraform, Snowflake, SQL, Jenkins, Github, Airflow, OpenSearch (Elasticsearch & Kibana), Talend, Alation, Neo4j, Hashicorp Vault / AWS Secrets Manager, Docker / OpenShift / Open Cloud Foundry, MongoDB, Docker, BlackDuck, SonarQube.
Knowledge and experience with the some of the following concepts: Real-time & Batch Data Processing, Workload Orchestration, Cloud, Datalakes, Data Security, Networking, Serverless, Testing/Test Automation (Unit, Integration, Performance, etc.), WebServices, DevOps, Logging, Monitoring, and Alerting, Containerization, Encryption / Decryption, Data Masking, Cost & Performance Optimization.
What is a Must Have?
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Five years of data engineering or equivalent experience.
What Is in It for You?
Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
Employment Practices
Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an
email
so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit
http://careers.travelers.com/life-at-travelers/benefits/
.",1853,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Public,False
Lead Data Engineer,"CVS Health
","Hartford, CT",$121K - $240K (Employer est.),3.1,"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.

Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

Position Summary

Join our fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability and performance of CVS Health’s IT operations. As a lead data engineer, you will be responsible for designing, developing and maintaining the data pipelines, databases and systems required for efficient data processing, storage and retrieval. You will collaborate with data scientists, developers and other stakeholders in an agile team environment.

Key Responsibilities include:

Design, implement and manage data pipelines for extracting, transforming and loading data from various sources into data lakes for processing, analytics, and correlation.
Create and maintain data models ensuring data quality, and efficiency. Design solutions that can scale with growing data volumes and evolving business needs
Develop and automate processes to clean, transform and prepare data for analytics, ensuring data accuracy and consistency
Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data
Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently
Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation
Create/maintain documentation for data processes, data flows and system configurations
Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness


Required Qualifications

7+years programming experience in languages such as Python, Java, SQL
5+ years experience with ETL tools and database management (relational, non-relational)
Proficiency in data modeling techniques and tools to design efficient scalable data structures
Skills in data quality assessment, data cleansing and data validation
Team Player: Mentor, share knowledge, and work with others to make the team successful. Provide guidance to others ensuring successful execution of projects.
Communication: Exceptional verbal, written, organizational, presentation, and communication skills.
Creativity: Ability to take written and verbal requirements and come up with other innovative ideas.
Attention to detail: Systematically and accurately research future solutions and current problems.
Strong work ethic: The innate drive to do work extremely well.
Passion: A drive to deliver better products and services than expected to customers.


Preferred Qualifications

Knowledge of big data technologies and cloud platforms
Experience with technologies like PySpark, Databricks, Azure Synapse, Delta Lake


Education

Bachelor’s degree in Computer Science, Information Technology or related filed, or equivalent working experience

Pay Range

The typical pay range for this role is:

$120,750.00 - $240,000.00


This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company’s equity award program.

In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.

For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.",1963,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Company - Public,False
"Systems Engineer (Data Recovery, Internet Trace Evidence Recovery & Analysis, Forensics Analysis Experience Required)",Quantam,"Glastonbury, CT",$34.73 - $44.73 Per Hour (Employer est.),-1.0,"Quantam Solutions provides IT solutions and consulting for various clients. We offer a competitive hourly wage, health benefits, paid time off, and a 401(k) plan. We're currently seeking a Systems Engineer.

THE SCOPE OF SERVICES REQUIRED FOR THE SYSTEMS ENGINEER INCLUDES:

Working independently with supervisory guidance from our client to search personal computers of sex offenders.
Development of documentation for purposes of court hearings.
Preparation of periodic status reports.

THE MINIMUM SKILLS AND EXPERIENCE REQUIRED FOR A CANDIDATE TO BE CONSIDERED FOR THIS POSITION INCLUDE:

Basic Data Recovery and Analysis for computers and all types of electronic devices, including cell phones.
Internet Trace Evidence Recovery and Analysis.
Data Recovery and Analysis in various technologies.
Knowledge of Encase, Magnet Axiom, Cellebrite or similar software for advanced computer forensics.
Internet Crime Investigation Training.
Forensic Analysis of computers and networks.
Applicants should have experience in conducting computer forensic investigations, to include but not limited to internet-related Fraud/Larceny, Child Pornography/Exploitation, Assault/Threatening/Harassment, Internet Enticement, Computer intrusions.

TIMETABLE:

The services of this individual will require 40 hours per week. Travel within the state is required with Glastonbury and Meriden as primary office locations. This position is not eligible for remote work.",2004,Investment & Asset Management,Unknown / Non-Applicable,Financial Services,1 to 50 Employees,Company - Private,False
Data Movement Engineer,The Cimino Group,Connecticut,-1,-1.0,"Location
Southern CT

Data Movement Engineer

Summary:

Our client is embarking on the modernization of its core data platforms. They are currently seeking a Data Movement Engineer who can assist them with modernizing their current ETL environment, as well as begin building new ETL/ELT workflows and data pipelines as they move towards a cloud environment. The Data Movement Engineer will support their data architects, data analysts, and business intelligence developers on various data initiatives. They must be self-directed and comfortable supporting the data requirements of multiple teams and systems. The ideal candidate will also possess experience in the data management domain and be willing to contribute their technical skills and experience towards the development of elegant and efficient data processes and systems.

Core Responsibilities:

Complete full life cycle of ETL/ELT development to address business needs or resolve issues including design, mappings, data transformations, scheduling, and testing.
Translate data movement requirements into technical designs.
Develop ETL/ELT workflows, mappings, and data pipelines to extract, transform, and load data into target environments.
Develop data extraction and transmissions to external vendors.
Develop test plans and perform unit testing.
Create supporting documentation for new processes.
Work closely with data analysts to gain understanding of business processes and corporate data.
Determine impacts to data warehouse structures and information flows due to changes in business or technical requirements.
Contribute to architectural decisions to support business processes.
Provide production support for data solutions.
Complete root cause analysis and contribute to remediation planning and implementation.
Perform data quality analysis, report data quality issues and propose solutions for data quality management.
Learn and expand upon internal controls and participate in customer support.
Prepare effort estimation including researching and estimating costs of software development, unit testing. May provide estimates for upgrades of vendor packages upgrades and integration with existing systems.
On Call and/or after-hours work required.

Essential Competencies
Professionalism/Personal Accountability, Collaboration and Teamwork, Communication, Flexible and Adapts to Change, Service to Customers and Clients

Skill Qualifications
Required:

Minimum of 5 years of relevant experience in data warehousing, business intelligence tools, and the analysis of data
Minimum of 3 years of SQL query development, preferably in multiple database management platforms, and working with normalized relational databases and dimensional data warehouse implementations
Proficiency in ETL/ELT concepts and tools (Informatica IICS and PowerCenter preferred)
Some experience with cloud-based database technologies
Working knowledge of data warehousing concepts, structures and ETL best practices
Experience using query tools (e.g. AQT, MS Query)
Ability to problem solve using analytical thinking skills
Must work well independently - must be inquisitive and seek answers to complex questions without being prompted
Strong organizational and time management skills
Strong communication skills including verbal and written to communicate effectively with clients and management
Strong project management skills to ensure that projects get done on time and within budget
Effectively participates in teams and moves the team toward completion of goals

Preferred:

Some experience with data visualization tools (e.g. Tableau)

Education and Experience Qualifications
Required:

BA or BS in Computer Science, Information Systems or related field
5+ years of development experience is a MUST
Strong Talend Developer
Need to have Snowflake or SQL Server
API development is a huge plus.

Compensation:

W-2 Hourly Rate - $60
This is a “Contract to Perm” position
100% Remote Position, BUT client prefers local candidates, East Coast will work",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,False
Cloud Data Engineer II,"The Travelers Companies, Inc.
","Hartford, CT",$121K - $200K (Employer est.),4.2,"Who Are We?
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Job Category
Data Analytics, Technology
Compensation Overview
The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
Salary Range
$121,000.00 - $199,600.00
Target Openings
1
What Is the Opportunity?
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
What Will You Do?
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
Work with the ingestion and consumption of data through the use of tools/languages such as: Jenkins, Glue, Airflow, BigQuery, Tealium, Python, Lambda, Snowflake, SQL, dbt, etc.
Design complex data solutions
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Test data movement, transformation code, and data components.
Perform other duties as assigned.
What Will Our Ideal Candidate Have?
Bachelor’s Degree in STEM related field or equivalent
Eight years of related experience
Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
Experience with some of the following tools & platforms (or similar): AWS (s3, Lambda, Kinesis, API Gateway, IAM, Glue, SNS, SQS, EventBridge, VPC, Step Functions, ECS/EKS, DynamoDB, etc.), dbt, Terraform, Databricks, Python, JavaScript, Kafka, Snowflake, SQL, Jenkins, Github, Airflow, OpenSearch (Elasticsearch & Kibana), Hashicorp Vault / AWS Secrets Manager, BlackDuck
Knowledge and experience with the some of the following concepts: Real-time & Batch Data Processing, Workload Orchestration, Cloud, Data lakes/warehouses, Data Security, Networking, Serverless, Testing/Test Automation (Unit, Integration, Performance, etc.), Web Services, DevOps, Logging, Monitoring, and Alerting, Containerization, Encryption / Decryption, Data Masking, Cost & Performance Optimization
What is a Must Have?
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
What Is in It for You?
Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
Employment Practices
Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an
email
so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit
http://careers.travelers.com/life-at-travelers/benefits/
.",1853,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Public,False
Data Engineer,"EXL Services
","Hartford, CT",$94K - $139K (Glassdoor est.),3.7,"Company Overview and Culture
EXL (NASDAQ: EXLS) is a global analytics and digital solutions company that partners with clients to improve business outcomes and unlock growth. Bringing together deep domain expertise with robust data, powerful analytics, cloud, and AI, we create agile, scalable solutions and execute complex operations for the world’s leading corporations in industries including insurance, healthcare, banking and financial services, media, and retail, among others. Focused on creating value from data for driving faster decision-making and transforming operating models, EXL was founded on the core values of innovation, collaboration, excellence, integrity and respect. Headquartered in New York, our team is over 40,000 strong, with more than 50 offices spanning six continents. For information, visit www.exlservice.com.

For the past 20 years, EXL has worked as a strategic partner and won awards in its approach to helping its clients solve business challenges such as digital transformation, improving customer experience, streamlining business operations, taking products to market faster, improving corporate finance, building models to become compliant more quickly with new regulations, turning volumes of data into business opportunities, creating new channels for growth and better adapting to change. The business operates within four business units: Insurance, Health, Analytics, and Emerging businesses.

EXL is hiring a Data Engineer for its Data and Analytics business. This position is based out of our Hartford, CT office.

Required Skills:
Knowledge in building data pipelines using SQL, Hive and Python.

Desired Skills:
Logical thinking, problem-solving, knowledge in statistical theories and analysis.

Job Description:

Coordinate with data scientists, product managers and business leaders to understand data needs and deliver on those needs
Define technical roadmap and drive key technology decisions with senior technology stakeholders
Build the infrastructure for optimal extraction, transformation and loading data from a wide variety of data sources using big data technologies
Work on pipeline creation, data ingestion, storage, wrangling, cataloguing, quality, security features
Automate jobs (ingestion & pipelines), notifications and reports
Prioritize to manage ad-hoc requests in parallel with ongoing sprints
What We Offer:

EXL Health offers an exciting, fast-paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world-class Healthcare consultants.
You can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth
We provide guidance/coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisors.
The sky is the limit for our team members. The unique experiences gathered at EXL Health sets the stage for further growth and development in our company and beyond.
EEO/Minorities/Females/Vets/Disabilities

To view our total rewards offered click here — > https://www.exlservice.com/us-careers-and-benefits

Base Salary Range Disclaimer: The base salary range represents the low and high end of the EXL base salary range for this position. Actual salaries will vary depending on factors including but not limited to: location and experience. The base salary range listed is just one component of EXL's total compensation package for employees. Other rewards may include bonuses, as well as a Paid Time Off policy, and many region specific benefits.

Please also note that the data shared through the job application will be stored and processed by EXL in accordance with the EXL Privacy Policy.

Application & Interview Impersonation Warning – Purposely impersonating another individual when applying and / or participating in an interview in order to obtain employment with EXL Service Holdings, Inc. (the “Company”) for yourself or for the other individual is a crime. We have implemented measures to deter and to uncover such unlawful conduct. If the Company identifies such fraudulent conduct, it will result in, as applicable, the application being rejected, an offer (if made) being rescinded, or termination of employment as well as possible legal action against the impersonator(s).

EXL may use artificial intelligence to create insights on how your candidate information matches the requirements of the job for which you applied. While AI may be used in the recruiting process, all final decisions in the recruiting and hiring process will be taken by the recruiting and hiring teams after considering a candidate’s full profile. As a candidate, you can choose to opt out of this artificial intelligence screening process. Your decision to opt out will not negatively impact your opportunity for employment with EXL.",1999,Business Consulting,$500 million to $1 billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
"AWS Data Engineer Onshore_HartMap - C102534 6.0 Hartford, CT",CapB InfoteK,"Hartford, CT",$91K - $116K (Glassdoor est.),-1.0,"For one of our long-term multiyear projects we are looking for an AWS Data Engineer Onshore_HartMap out of Hartford, CT.

Required qualifications to be successful in this role:
Experience using Amazon RDS, AWS Glue, AWS Lake Formation, Amazon EMR, AWS Data Pipeline
Additional Skills: Amazon Athena, Amazon Redshift, Amazon Kinesis, Kafka, Amazon Neptune, Amazon DynamoDB
Prior Experience as AWS Architect across multiple projects with go-live milestones
Leadership and mentoring skills are mandatory to lead diverse global architecture teams.

Desired AWS certifications:
Specialty: AWS Certified Security Specialist, AWS Certified Big Data Specialist
Professional: AWS Certified Solutions Architect professional""",-1,Business Consulting,Unknown / Non-Applicable,Management & Consulting,Unknown,Company - Private,True
Data Engineer,"Mitsubishi HC Capital America Inc
","Norwalk, CT",$97K - $112K (Employer est.),3.1,"For this role, we will consider candidates located near our Norwalk, CT office or Itasca, IL office.

Position Overview:

The Data Engineer holds the primary responsibility for skillfully designing, developing, implementing, and supporting Mitsubishi HC Capital America, Inc. (MHCCNA)'s enterprise Microsoft Azure Data Warehouse. This role assumes accountability for ensuring the dependable, efficient, and secure operation and advancement of MHCCNA's On-Premise and Azure Synapse Data Warehouses to effectively meet crucial business needs.


Commitment to Internal Control:

The Data Engineer is required to possess a comprehensive understanding of and adhere to the system of internal controls associated with the fundamental duties and responsibilities of the role. This includes compliance with SOX and all other pertinent regulatory and compliance policies and requirements.


Essential Duties and Responsibilities:

The responsibility of Data Engineer encompasses the entire lifecycle of the Data Warehouse environments that underpin the vital business requirements of MHCCNA. This includes the design, development, implementation, operation, and ongoing support of these critical systems.

The individual in this position is tasked with developing a flexible, enterprise-level environment that integrates multiple warehouses to guarantee precise, comprehensive, consistent, and timely data. Their primary goal is to create a cohesive system that fulfills these demands while catering to diverse business requirements.

The role necessitates the capacity to explore and grasp emerging technologies while collaborating closely with peer teams to establish strategic roadmaps and priorities. The ability to swiftly acquire and proficiently apply hands-on administration skills is essential. As a Subject Matter Expert in technical requirements, this position will play a crucial role in supporting and implementing data projects, as well as engaging effectively with users and other IT staff.

The Data Engineer responsibilities include:
Provide support in designing and overseeing enterprise-grade data pipelines and data stores.
Implement automation and streamline processes to optimize the entire data and analytics platform, ensuring efficient throughput and high-performance outcomes.
Recognize, devise, and execute internal process enhancements, including automation of manual tasks, optimizing data delivery, and redesigning architecture or infrastructure to enhance scalability.
Collate large, intricate datasets that align with functional and non-functional business demands.
Develop processes that facilitate data transformation, manage data structures, metadata, dependencies, and workload management.
Collaborate with business users to understand functional and data requirements, contributing to the enhancement of data models and pipelines.
Apply analytical and problem-solving skills to diagnose and resolve intricate technical issues.
Create, maintain, and continuously enhance scalable data pipelines, while also developing new data source integrations to accommodate the growing volume and complexity of data.
Designing, implementing, and managing data extraction, transformation, and loading (ETL) processes.
Creating comprehensive technical specification documents and application interface designs.
Creating data processing and integration solutions for both batch and real-time scenarios, proficiently handling structured and unstructured data.
Participate in design discussions, code reviews, and project-related team meetings.
Ensuring data security and compliance with relevant regulations and best practices in all data operations.
Troubleshooting and resolving data and system issues, stepping in when necessary to address outages and challenges.
Other duties and responsibilities as assigned or needed.


KPI’s (Key Performance Indicators):

Deliver Business Intelligence solutions that are 95% defect-free providing that adequate written business requirements, development time, and business test review were afforded during the project. This standard does not apply to legacy remediation efforts or ready to serve emergency production response activities.
Effectively utilize consulting resources on all significant projects (over 40 hours) to allow for development power of scale. Consultants should do lower value work that is considered heavy lift, freeing up programmer analysts to spend more time in analysis and design while maintaining tight control over quality, code, and company intellectual property.
These are overarching KPI metrics that are applicable to all goals that are defined over the course of the business year.

Responsibility and Decision-Making Authority:
Exercise independent judgment and decision-making while adhering to Company Policy.


Management/Supervisory Responsibilities:

N/A


Qualifications/Competencies:

Key Technical Knowledge, Skills, and Abilities:
Must have experience deploying modern data solutions leveraging components like Azure functions, Azure Synapse, Azure Data Factory, Data Flows, Azure Data Lake, Azure SQL.
Strong level of understanding on Azure Synapse, ADLS, and Azure DevOps.
Exhibit an understanding of Data Lake architectures, including raw, enriched, and curated layer concepts, and ETL/ELT operations.
Exhibit a solid understanding of database design, data warehousing concepts, big data platforms, and ETL operations.
Experience working with data integration techniques & self-service data preparation.
Experience in requirements analysis, design, and prototyping.
Experience with DevOps tools like Azure DevOps, Jenkins, Maven etc.
Experience in building/operating/maintaining fault tolerant and scalable data processing integrations.
Demonstrated experience of turning business use cases and requirements into technical solutions.
Ability to conduct data profiling, cataloging, and mappings for technical design and construction of data flows.
Strong collaboration and experience working with remote teams.
Strong problem-solving skills with emphasis on optimization data pipelines.
Showcase excellent communication and presentation skills for effective collaboration with technical and non-technical stakeholders.
Strong analytical skills and a drive to learn and master new technologies and techniques.
Experience working with third party providers and vendors for critical support requirements.

Competencies:
Possesses the professional or technical skills required to effectively assume job responsibilities and perform tasks.
Conscientiously attends to detail in order to produce precise and error-free work.
Able to identify and analyze a problem, evaluate possible solutions, and select the most suitable one.


Education and Experience:
Demonstrated expertise in Microsoft Azure development.
3-5 years of hands-on Data Warehouse architecture and development experience within the Microsoft Azure environment.
Bachelor’s degree with a minimum of 3-5 years of related work experience outside of educational studies.

Working Hours / Travel Requirements:

Hours may vary and will require periodic overtime, including occasional evening and weekends, depending on business needs.
On call 24x7 for emergency support
Occasional travel for business meetings, seminars or training may be required.

Physical Demands:
Digital dexterity and hand/eye coordination in operation of office equipment.
Light lifting and carrying of supplies, files, etc.
Ability to speak to and hear customers and/or other employees via phone, in-person or virtually.
Body motor skills sufficient to enable incumbent to move from one office location to another.

The job description does not constitute an employment contract, implied or otherwise, other than an “at will” relationship and is subject to change by the employer as the needs of the employer and requirements of the job change.


Salary Range: ($97,400 to $111,700) per year, plus a discretionary Bonus.

The salary range is determined and based on internal equity, market data/ranges, applicant's skills, prior relevant experience, and education.


Additional Benefits:

Medical, Dental and Vision Plans
401(k) and matching
Generous Paid Time Off
Company paid Life Insurance
Employee assistance program
Training and Development Opportunities
Employee discounts",1952,Banking & Lending,Unknown / Non-Applicable,Financial Services,51 to 200 Employees,Company - Private,True
"Principal Engineer, Digital Data Development","AXA
","Stamford, CT",$95K - $187K (Employer est.),4.0,"Stamford, CT I Hartford, CT I New York, NY I Morristown, NJ I USA
AXA XL recognizes data and information as critical business assets, both in terms of managing risk and enabling new business opportunities. This data should not only be high quality, but also actionable – enabling AXA XL’s executive leadership team to maximize benefits and facilitate sustained competitive advantage. Our Chief Data Office also known as our Innovation, Data & Analytics team (IDA) is focused on driving innovation through optimizing how we leverage data to drive strategy and create a new business model – disrupting the insurance market.
This role is part of Digital Data Dev Division within Digital Transformation vertical of IDA and will be responsible for close collaboration with Project Managers, Developers, Testers, Product Managers, DevOps engineers towards ensuring an optimized Build & Release management life cycle and services. The role will also require continuous enhancements, adaptation and thought leadership in this space for evolving Data Products and the dependent technical and infrastructure ecosystem.
DISCOVER your opportunity
What will your essential responsibilities include?
Develop and enhance strategies and governance for Data solutions rollout for multiple portfolios / workstreams / Product teams
Provide technical, thought and implementation leadership for Release automation in Cloud environment through DevOps/DevSecOps/DataOps practices.
Engage with Data Product Owners, Delivery leads, and Product Teams for detailed planning and ensuring requirements are properly captured and tracked through the Build & Release life cycle for Data Products and supporting Cloud/Infrastructure environments.
Implement and manage Data solutions rollout processes for code, tools and related artifacts through Development, Test, UAT, Staging and Production Environments
Analyze and mitigate risk pertaining to solution delivery timelines, quality, stability, and performance.
Collaborate with relevant IDA Divisions on optimizing data operational processes to continuously improve and shift left for early detection of issues/challenges in Data Solution lifecycle.
Adopt best practices and standards to capture Data Solution (including Data pipelines) and Axiom Platform performance indicators and develop feedback loops for IDA Product Teams. Lead and collaborate on remediations (through automation/tools/process enhancements)
Plan and forecast demands based on product needs for Cloud Platform resources and identify opportunities for greater efficiency/productivity across environments.
Optimize & manage Production & Non-Production environments, highlighting potential risks with proposed solutions and/or implementations
Support for Data pipeline and DataOps in cloud and big data environment. Develop process optimization using operational metrics.
Participate in efforts to identify root cause analysis for production, non-production, environment and process issues and deliver solutions
Work in the “Follow the sun” support model
Ensure documentation and auditability of Build/Release function and processes
Work with various infrastructure teams to implement automated recovery steps or preventative measures
Achieve & maintain highest business customer confidence and net promoter score (NPS)
You will report to the Division Lead, Digital Data Development.
SHARE your talent
We’re looking for someone who has these abilities and skills:
A minimum of an Undergraduate University Degree in Computer Science or related fields with several years of experience.
Extensive Cloud Platform experience with one or more Public Clouds (Azure / AWS / GCP). MS Azure background and experience a plus.
Experience in developing and maintaining build platforms, packaging, deployment, testing, and releases
Experience in managing source code, change control, configuration management, and build deployment activities
Data engineering background with ETL, Big data platform (ADLS / Data Bricks / AI / ML / Synapse / DBT)
Experience in systems integration, and developer support tools GITHUB, CICD / Harness, Release management, and configuration management, Python.
Proficiency in Microservices, Web Services, Web Applications
Experience in UI design/front-end development a plus
Experience working in AGILE Development environment.
Experience in performance management (APM) tools, Query Performance analysis.
Outstanding analytical and problem-solving skills
Outstanding interpersonal skills and relationship building and able to liaise with staff at all levels in the organization
Excellent writing skills, with the ability to create clear requirements, specifications, and documentation for data systems
Experience leading small teams and delivery with a mix of onshore/offshore developers a plus.
FIND your future
AXA XL, the P&C and specialty risk division of AXA, is known for solving complex risks. For mid-sized companies, multinationals and even some inspirational individuals we don’t just provide re/insurance, we reinvent it.
How? By combining a comprehensive and efficient capital platform, data-driven insights, leading technology, and the best talent in an agile and inclusive workspace, empowered to deliver top client service across all our lines of business property, casualty, professional, financial lines and specialty.
With an innovative and flexible approach to risk solutions, we partner with those who move the world forward.
Learn more at axaxl.com
Inclusion & Diversity
AXA XL is committed to equal employment opportunity and will consider applicants regardless of gender, sexual orientation, age, ethnicity and origins, marital status, religion, disability, or any other protected characteristic.
At AXA XL, we know that an inclusive culture and a diverse workforce enable business growth and are critical to our success. That’s why we have made a strategic commitment to attract, develop, advance and retain the most diverse workforce possible, and create an inclusive culture where everyone can bring their full selves to work and can reach their highest potential. It’s about helping one another — and our business — to move forward and succeed.
Five Business Resource Groups focused on gender, LGBTQ+, ethnicity and origins, disability and inclusion with 20 Chapters around the globe
Robust support for Flexible Working Arrangements
Enhanced family friendly leave benefits
Named to the Diversity Best Practices Index
Signatory to the UK Women in Finance Charter
Learn more at axaxl.com/about-us/inclusion-and-diversity. AXA XL is an Equal Opportunity Employer.
Sustainability
At AXA XL, Sustainability is integral to our business strategy. In an ever-changing world, AXA XL protects what matters most for our clients and communities. We know that sustainability is at the root of a more resilient future. Our 2023-26 Sustainability strategy, called “Roots of resilience,” focuses on protecting natural ecosystems, addressing climate change, and embedding sustainable practices across our operations.
Our Pillars:

Valuing nature:

How we impact nature affects how nature impacts us. Resilient ecosystems - the foundation of a sustainable planet and society – are essential to our future. We’re committed to protecting and restoring nature – from mangrove forests to the bees in our backyard – by increasing biodiversity awareness and inspiring clients and colleagues to put nature at the heart of their plans.

Addressing climate change:

The effects of a changing climate are far reaching and significant. Unpredictable weather, increasing temperatures, and rising sea levels cause both social inequalities and environmental disruption. We're building a net zero strategy, developing insurance products and services, and mobilizing to advance thought leadership and investment in societal-led solutions.

Integrating ESG:

All companies have a role to play in building a more resilient future. Incorporating ESG considerations into our internal processes and practices builds resilience from the roots of our business. We’re training our colleagues, engaging our external partners, and evolving our sustainability governance and reporting.

AXA Hearts in Action

: We have established volunteering and charitable giving programs to help colleagues support causes that matter most to them, known as AXA XL’s “Hearts in Action” programs. These include our Matching Gifts program, Volunteering Leave, and our annual volunteering day – the Global Day of Giving.
For more information, please see Sustainability at AXA XL.
The pay range for this position is $ 95,000 – $ 186,500. Actual pay will be determined based upon the individual’s skills, experience and location. We strive for market alignment and internal equity with our colleagues’ pay.",1985,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Private,False
Pyspark AWS Data Engineer(Onsite),"Cognizant Technology Solutions
","Hartford, CT",$86K - $121K (Glassdoor est.),3.8,"ROLE: Pyspark AWS Data Engineer (Onsite)

We are Cognizant Artificial Intelligence

Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. However, clients need new business models built from analyzing customers and business operations at every angle to really understand them.

With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate, and scale the most desirable products and delivery models to enterprise scale within weeks

You must be legally authorized to work in United States

This is a position open to any qualified applicant in the United States.

Qualification:

Bachelors in science, engineering or equivalent

Salary and Other Compensation:

The annual salary for this position is between $[100,000– 125,000] depending on experience and other qualifications of the successful candidate.

This position is also eligible for Cognizant’s discretionary annual incentive program and stock awards, based on performance and subject to the terms of Cognizant’s applicable plans.

Benefits: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:

Medical/Dental/Vision/Life Insurance
Paid holidays plus Paid Time Off
401(k) plan and contributions
Long-term/Short-term Disability
Paid Parental Leave
Employee Stock Purchase Plan

Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.




ROLE: Data Engineer with Pyspark and AWS (Onsite)

Must Have:Data Engineer with AWS, Pyspark

Good To Have Skills: SQL Server, 3NF Data Modeling, PL/SQL

Job summary

Job title: AWS Pyspark Data Engineer

Experience: 8to10yrs

Work on client projects to deliver AWS, PySpark, Databricks/EMR based Data engineering Analytics solutions.
Design, build and configure applications to meet business process and application requirements.
Designing, coding, tuning big data processes.
Build data pipelines applications to process datasets at low latencies.
Show efficiency in handling data - tracking data lineage, ensuring data quality.
Experience with AWS Cloud on services like Glue, Lambda, Step Function, EMR
Strong real-life experience in python development especially in pySpark
Good Database knowledge (Snowflake or any cloud based)
Experience with source control systems such as Git, Jenkins and continuous integration tools.

Employee Status : Full Time Employee

Shift : Day Job

Travel : No

Job Posting : Nov 15 2023

About Cognizant
Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.

Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",1994,Information Technology Support Services,$10+ billion (USD),Information Technology,1001 to 5000 Employees,Company - Public,False
"Lead Software Engineer, Data Engineering","S&P Global
","Hartford, CT",$85K - $170K (Employer est.),4.1,"The Role: Data Engineer
Location: Team is in Boston, but is available for remote or on-site throughout CST and EST Time zones
GL (for internal use only): 11

Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.
Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy!
Job Description
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.

You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets.
You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use.
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.

Responsibilities
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers
Optimizing slow-running database queries and data pipelines
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency

Qualifications
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience
7+ years of experience working with data-at-scale in a production environment
Experience designing and implementing large-scale, distributed systems
Experience in multi-threaded software development (or some form of parallelism)
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale
Strong understanding of relational databases and proficiency with SQL
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript)
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go)
Experience developing software on Linux-based operating systems
Experience with distributed version control systems
Nice-to-Haves
Familiarity with relational database internals (especially PostgreSQL)
Proficiency with cloud computing platforms, specifically AWS
Working knowledge of probability & statistics
Contributions to open-source software
Experience building customer-centric products

Compensation/Benefits Information (US Applicants Only):
S&P Global states that the anticipated base salary range for this position is $85,300 - $170,000 . Base salary ranges may vary by geographic location.
In addition to base compensation, this role is eligible for an annual incentive bonus plan.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires .
About S&P Global
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 277527
Posted On: 2023-09-21
Location: Cambridge, Massachusetts, United States",1860,Research & Development,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
"Senior Data Engineer, Public Company","Recruiting From Scratch
","Fairfield, CT",$100K - $200K (Employer est.),4.0,"This is for a client of Recruiting from Scratch.
Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Our Client:

Our next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we’re blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.

With a track record of strong financial performance and plans for continued headcount growth, we’re looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us.

What’s so interesting about this role?

Our client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .

In this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.

What’s the job?

Design, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.
Moving implementation to ownership of real-time and batch processing and data governance and policies.
Maintain and enforce the business contracts on how data should be represented and stored.
Stay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users
Implementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.
Work closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.

What we’ll love about you

5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.
7+ years experience using Python,
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )
Significant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.
Experience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Experience with dimensional data modeling and schema design in Data Warehouses
Familiar with ETL (managing high-quality reliable ETL pipelines)
Be familiar with legal compliance (with data management tools) data classification, and retention.

Salary Range: $165,000-$210,000 USD base. Equity. Medical, Dental, Vision.
https://www.recruitingfromscratch.com/",2019,Staffing & Subcontracting,$1 to $5 million (USD),Human Resources & Staffing,1 to 50 Employees,Company - Private,True
Senior Clinical Data Engineer,"BI Pharmaceuticals, Inc.
","Ridgefield, CT",$92K - $129K (Glassdoor est.),4.2,"Key contact partner in cultivating the ""power of data"" by means of (i) data collection/curation, data review, data delivery, (ii) data standardization or (iii) process definition, testing and training. Translate the science into technical specifications. Collect, ingest, structure, curate and standardize all kinds of Clinical Trial related data from internal and external sources. Ensure Data Quality and Integrity by implementing plausibility checks, anomaly detection, and fraud detection methods in data collection systems. Supports the clinical research development process through the provision of advanced expertise in the areas of (i) data collection/curation, data review, delivery (ii) data standardization or (iii) process definition, testing and training. This position interprets scientific/clinical requirements to translate and document them into Project/Trial level technical specifications for new substances, indications or marketing claims.As an employee of Boehringer Ingelheim, you will actively contribute to the discovery, development and delivery of our products to our patients and customers. Our global presence provides opportunity for all employees to collaborate internationally, offering visibility and opportunity to directly contribute to the companies' success. We realize that our strength and competitive advantage lie with our people. We support our employees in a number of ways to foster a healthy working environment, meaningful work, diversity and inclusion, mobility, networking and work-life balance. Our competitive compensation and benefit programs reflect Boehringer Ingelheim's high regard for our employees.

Duties & Responsibilities

Accountable/Responsible to interpret requirements to translate and document them into trial / project level technical specifications. Provision clinical trial/project data to business consumers. Facilitate requirements gathering from consumers and develop solutions to meet immediate and long-term needs of the business. Monitor and maintain ongoing trial/project level operations of clinical data environments and respond to trial/project issues.
Accountable/Responsible for oversight of
Data collection/curation, data review, delivery or
Data standardization or
Process definition, testing and training tasks within a trial performed by a BPO/CRO
Recommend/test different ways to constantly improve data reliability, integrity and quality. Ensures real-time inspection readiness of all data collection, data review/data delivery (DBL) deliverables for a trial and participates in regulatory agency and BI internal audits as necessary.
Collaborate with members of the development team within BDS and with neighboring colleagues at BI on the project/product goals. Contributes to cross-functional- and team-based thinking.
Keep abreast of data science and in particular new data collection/curation/standardization/digital tech solutions and innovative processes/tools within and outside BI.
Conduct and support data collection/curation/standards process & tool trainings for Clinical Data Engineers.
Participate in cross-functional BI internal process development teams and drive/plan relevant CDE (data collection/curation/standardization) aspects.

Requirements

Bachelor’s degree from an accredited institution, in Life Sciences, Computer Science, Software/Computer Engineering, or similar preferred. Initial experience within the pharmaceutical industry, CROs or academic sites: several (greater than or equal to five (&gt;/= 5) years of professional experience. (DE: Can be replaced by high-quality/multifaceted professional qualifications with relevant professional experience); Or
Master’s degree (e.g. MBA, MSc) from an accredited institution. Initial experience within the pharmaceutical industry, CROs or academic sites: three (3) years of professional experience.
Advanced experience in understanding of clinical trial development process required.
Demonstrated ability to build/test, curate, oversee and interpret data in routine clinical trials.
Intellectual curiosity to find new and unusual ways solving data collection / curation / standardization / process definition, testing and training issues.
Basic leadership experience required.
Sound knowledge and experience with the use of Data Collection Tools (EDC systems), Data Review Tools, and/or Data Standardization methods, requirements.
Sound knowledge/experience in design of clinical trials, basic medical terminology and on processing clinical trial information.
Excellent organizational skills, problem solving abilities, negotiation skills, time management skills and initiative required.
Strong communication skills: Confident and persuasive communicator to ensure that the message is clear and well understood.
Ability to work collaboratively on multi-disciplinary project teams and proactively manage relationships with external vendors required.
Mindful of local, global, internal and external cultures to ensure that messages are received positively and effectively.
Ability to lead and facilitate meetings required.
Language skills: English: fluent (Read/Write/Speak).
Know, understand, and implement:
International regulations and guidelines for good clinical and statistical practice from all ICH regions
The various international guidelines on clinical development, data standardization, and
BI processes and SOPs that govern clinical development in particular with respect to strategic areas (e.g. Clinical Development Plan)

Desired Skills, Experience and Abilities

Job Type: Full-time

Work Location: In person",1885,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,1001 to 5000 Employees,Company - Private,False
Business Engineer - Manufacturing Data Analyst,"ASML
","Wilton, CT",$86K - $115K (Glassdoor est.),4.1,"Location

Wilton, US

Team

Data and Analytics

Work experience

4-9 years

Educational background

Computer Science, Data Science, Other technical backgrounds

Travel

No

Remote work

Hybrid

Fulltime/parttime

Full time



Job ID: J-00288070
Introduction to the job

Join ASML Wilton today to receive your sign on bonus and relocation.

*Offer valid for Wilton, CT new hire offers made between now and December 31, 2023.

ASML US brings together the most creative minds in science and technology to develop lithography machines that are key to producing faster, cheaper, more energy-efficient microchips. We design, develop, integrate, market and service these advanced machines, which enable our customers - the world’s leading chipmakers - to reduce the size and increase the functionality of their microchips, which in turn leads to smaller, more powerful consumer electronics. Our headquarters are in Veldhoven, the Netherlands, and we have 18 office locations around the United States including main offices in Chandler, Arizona, San Jose and San Diego, California, Wilton, Connecticut, and Hillsboro, Oregon.

Do you want to enable data driven decision making in a manufacturing environment?

Do you possess a keen eye for detail as well as a birds eye view on the production process?

Do you have the ambition to build world class analytical solutions to drive ASML towards industry 4.0?

Then you are the candidate we are looking for to join the Business Engineering team as Manufacturing Data Analyst!

Please apply and challenge us to hire YOU !

This position requires access to controlled technology, as defined in the Export Administration Regulations (15 C.F.R. § 730, et seq.). Qualified candidates must be legally authorized to access such controlled technology prior to beginning work. Business demands may require ASML to proceed with candidates who are immediately eligible to access controlled technology.

Role and responsibilities

You will have strong stakeholder management skills both towards internal customers and internal suppliers.

You are able to translate internal customer demands into concrete requirements.

You develop quality reports to make the performance of factory processes transparent, translating data into actionable insights following agreed timelines.

You focus on customer experience, maintainability and automation of your analytical solutions.

Collaborate across sectors to define, develop, and implement structural reporting that supports long-term business objectives.

Be a Mentor/Coach within the team for more junior level team members

Provide data-driven analysis to support identification of patterns in product deviations.

In this position you will be able to further develop your analytical skills, business perspective, influencing skills, presenting techniques and project management capabilities.

There is always space for creative and unique points of view. You will have the flexibility and trust to choose how best to tackle tasks and solve problems.

Education and experience

BS degree in Data Science, Analytics, Engineering, Business, Finance, Computer Science or equivalent education experience.

Minimum of 4+ years of working experience as a Data Analyst/Analytics Developer including experience building Analytical products for internal consumption(E.g. Dashboards, automatic analysis, algorithms,).

Experienced with IT-systems in the area of production-control, preferably with Spotfire, Tableau, Power BI (Excel, SAP, SAP ME/BO, SAP HANA ), SQL.

Experience with advanced analytics (e.g. Process Mining, Machine Learning, AI, Imagine recognition, etc) or Industry 4.0 concepts (Digital twin, IOT, predictive/prescriptive manufacturing) preferred.

Skilled with internal stakeholder management.

Experience within a manufacturing environment or semi-conductor industry including ASML experience is a plus.

Experience with Scrum/Agile way of working is advantageous.

Skills

Working at the cutting edge of tech, you’ll always have new challenges and new problems to solve – and working together is the only way to do that. You won’t work in a silo. Instead, you’ll be part of a creative, dynamic work environment where you’ll collaborate with supportive colleagues. There is always space for creative and unique points of view. You’ll have the flexibility and trust to choose how best to tackle tasks and solve problems.

To thrive in this job, you’ll need the following skills:

Can observe and respond to people and situations and interact with others encountered in the course of work.

Can learn and apply new information or skills.

Must be able to read and interpret data, information, and documents.

Strong customer focus and commitment to customer satisfaction through prioritization, quality, efficiency and professionalism.

Ability to complete assignments with attention to detail and high degree of accuracy.

Proven ability to perform effectively in a demanding environment with changing workloads and deadlines.

Result driven-demonstrate ownership and accountability.

Identifies bottlenecks and drives improvements.

Work independently or as part of a team and follow through on assignments with minimal supervision.

Demonstrate open, clear, concise and professional communication.

Ability to establish and maintain cooperative working relationships with manager, co-workers and customer.

Work according to a strict set of procedures within the provided timelines.

Strong analytical skills and ambition to keep developing these.

Self-starter that shows high drive, creativity, ambition and accountability.

Growth mindset: you believe in continuous learning by dedication of time, effort and energy.

Strong communication skills, able to align with all levels in the organization.

Strong customer focus and commitment to customer satisfaction through prioritization, quality, efficiency and professionalism.

Diversity & Inclusion

ASML is an Equal Opportunity Employer that values and respects the importance of a diverse and inclusive workforce. It is the policy of the company to recruit, hire, train and promote persons in all job titles without regard to race, color, religion, sex, age, national origin, veteran status, disability, sexual orientation, or gender identity. We recognize that diversity and inclusion is a driving force in the success of our company.

Other information

Role within Office

Responsibilities:

Routinely required to sit; walk; talk; hear; use hands to keyboard, finger, handle, and feel; stoop, kneel, crouch, twist, reach, and stretch.

Occasionally required to move around the campus.

Occasionally lift and/or move up to 20 pounds.

May require travel dependent on business needs.

Specific vision abilities required by this job include close vision, color vision, peripheral vision, depth perception, and ability to adjust focus.

Role within the Factory
Responsibilities:

Must be willing to work in a clean room environment, wearing coveralls, hoods, booties, safety glasses and gloves for entire duration of shift.

While performing the duties of this job, the employee routinely is required to sit; walk; talk; hear; use hands to keyboard, finger, handle, and feel; stoop, kneel, crouch, twist, reach, and stretch.

The employee may occasionally lift and/or move up to 50 pounds.

Specific vision abilities required by this job include close vision, color vision, peripheral vision, depth perception, and ability to adjust focus.

Can work under deadlines.

The environment generally is moderate in temperature with moderate to high noise level.

Must be willing to work a compressed work week schedule – twelve-hour long shift and rotating from three to four days a week.

This must include references to day and night shifts for accommodation purposes.

Additional responsibilities for Wilton Factory:

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

The employee is required to work in a cleanroom environment: full gowning (full body coveralls, hood, CR safety shoes, face mask, nitrile gloves and safety glasses. Working under ISO 9000/14000 standards).

Operating/working around overhead cranes, fork trucks and motorized pallet movers.

Working around lasers; working with ladders; working on platforms; and working around chemicals.

The employee is occasionally required to move around the campus.

The employee may occasionally lift and/or move up to 20 pounds.

May require travel dependent on company needs.

The environment generally is moderate in temperature and noise level.

EOE AA M/F/Veteran/Disability

Need to know more about applying for a job at ASML? Read our frequently asked questions .",1984,Electronics Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Data Engineer IV - Max Digital (Data Engineering),"ACV Auctions
",Connecticut,-1,3.7,"If you are looking for a career at a dynamic company with a people-first mindset and a deep culture of growth and autonomy, ACV is the right place for you! Competitive compensation packages and learning and development opportunities, ACV has what you need to advance to the next level in your career. We will continue to raise the bar every day by investing in our people and technology to help our customers succeed. We hire people who share our passion, bring innovative ideas to the table, and enjoy a collaborative atmosphere.

Who we are:
ACV is a technology company that has revolutionized how dealers buy and sell cars online. We are transforming the automotive industry. ACV Auctions Inc. (ACV), has applied innovation and user-designed, data driven applications and solutions. We are building the most trusted and efficient digital marketplace with data solutions for sourcing, selling and managing used vehicles with transparency and comprehensive insights that were once unimaginable. We are disruptors of the industry and we want you to join us on our journey. ACV’s network of brands includes ACV Auctions, ACV Transportation, ClearCar, MAX Digital and ACV Capital within its Marketplace Products, as well as, True360 and Data Services.
At ACV we focus on the Health, Physical, Financial, Social and Emotional Wellness of our Teammates and to support this we offer:

Multiple medical plans including a high deductible health plan that costs $0 out of your paycheck
Company-sponsored (paid) Short-Term Disability, Long-Term Disability, and Life Insurance
Comprehensive optional benefits such as Dental, Vision, Supplemental Life/AD&D, Legal/ID Protection, and Accident and Critical Illness Insurance
Generous paid time off options, including vacation time, sick days, Company holidays, floating holidays, parental leave, bereavement leave, jury duty leave, voting leave, and other forms of paid leave as required by applicable law or regulation
Employee Stock Purchase Program with additional opportunities to earn stock in the Company
Retirement planning through the Company’s 401(k)
Who we are looking for:
We are seeking a highly skilled Engineer IV in Data Engineering with a strong foundation in computer science and excellent problem-solving skills. You will be responsible for maintaining and extending our database operations, optimizing SQL queries, and designing scalable data services.

What you will do:

Actively and consistently support all efforts to simplify and enhance the customer experience.
Maintain and extend (as required) existing database operations solution for backups, index defragmentation, data retention, etc.
Troubleshoot any SQL Server or ETL stack outages during our operational support window.
Triage any issues with data stack (SSIS, C#, Web APIs).
Support development, integration, and stage SQL Server environments for application development and data science teams.
Ensure that new database development meets company standards for readability, reliability, and performance. Work with internal teams on transactional and analytical schema design.
Collaborate with software and DevOps engineers to design scalable services, plan feature roll-out, and ensure high reliability and performance of our products.
Architect and build entire services including but not limited to; data modeling, storage, message brokers, protocols and interfaces.
Design, build and maintain complex systems that can scale rapidly with little maintenance.
Conduct code reviews, develop high-quality documentation, and build robust test suites.
Own the overall performance of products and services within a defined area of focus.
Be empowered to lead and complete software projects with minimal guidance from managers.
Lead team discussions to define technical requirements on new and current products.
Respond-to and troubleshoot highly complex problems quickly, efficiently, and effectively.
Mentor junior engineers.
Perform additional duties as assigned.
What you will need:

Bachelor's degree in Computer Science, Information Technology, Computer Information Systems, Management Information Systems, or similar
5 years' building & supporting the database-tier of SaaS web applications.
Ability to read, write, speak, and understand English.
Expert understanding of SQL query execution fundamentals and query optimization principles.
Experience maintaining and extending an existing codebase, adapting to pre-existing patterns and tracing the code’s path of execution.
ETL workflow implementation (SSIS, Airflow, C#, Python)
Experience working with Cloud Services (AWS RDS, S3, SQS, SNS)
Experience working with NoSQL data stores (MongoDB)
Experience writing unit and integration testing (DBT, C#)
Expert SQL and data-layer development experience; OLTP schema design.
Experience integrating 3rd-party APIs, implementing authentication & authorization and developing asynchronous data flows.
Nice to Have
OLAP schema design experience.
Experience with Airflow, Snowflake, etc.
Experience with DBT
Our Values
Trust & Transparency | People First | Positive Experiences | Calm Persistence | Never Settling

At ACV, we are committed to an inclusive culture in which every individual is welcomed and empowered to celebrate their true selves. We achieve this by fostering a work environment of acceptance and understanding that is free from discrimination. ACV is committed to being an equal opportunity employer regardless of sex, race, creed, color, religion, marital status, national origin, age, pregnancy, sexual orientation, gender, gender identity, gender expression, genetic information, disability, military status, status as a veteran, or any other protected characteristic. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires reasonable accommodation, please let us know.

For information on our collection and use of your personal information, please see our Privacy Notice.",2014,Wholesale,Unknown / Non-Applicable,Retail & Wholesale,1001 to 5000 Employees,Company - Public,True
Senior Software Engineer - Data Strategy (NYC-Hybrid),Rad Hires,"Stamford, CT",$215K - $245K (Employer est.),-1.0,"Role
The Senior Software Engineer position in the Data Strategy team presents a chance to create and execute data products for the world's biggest and most reputable reinsurance brokerage. Data Strategy has a “start-up style” mandate (within a $2 billion company) to enhance the acquisition, storage, analysis, fidelity, and monetization of client, internal, and third-party data across the organization. This innovation spans our petabyte-scale insured assets, including property, business, marine, and aviation entities, and their associated risks, such as hurricanes, wildfires, cyber-attacks, and wars, in a financial and economic context.
As a member of the Data Strategy group, the Senior Software Engineer will work with fellow data and web engineers, data scientists, product managers, business analysts, and stakeholders from other internal groups to design and improve data-centric projects with the dual mandate of (1) increasing the efficiency of the data collection and analysis process across the company and (2) driving the monetization of data via newly designed and existing products for the company’s reinsurance clients. The Senior Software Engineer will be the head facilitator on multiple innovative initiatives and will have ownership over the design, development, and delivery of projects requiring direct reporting to senior-level management in both business and technical groups.
Leadership Responsibilities
Work with a product manager as technical lead of a team of ~5 engineers, data scientists, and analysts to design, scope, and oversee work in an Agile environment.
Manage junior data and web engineers, focusing on productivity, quality, and professional development.
Partner with the head of Data Strategy and other senior engineers to create and evangelize best-in-class engineering competency and tooling within the organization.
Enforce strong development standards across the team through code reviews, automated testing, and monitoring.
Establish strong relationships with internal clients as an engineering representative for data strategy.
Contribute to the overall Data Strategy vision and execution via quarterly planning and executive committee reporting.
Partner regularly improving engineering recruiting process for the required skillsets and resourcing demands.
Learn the complex business of reinsurance to coach data technologists and execute the team's initiatives more effectively.
Software Engineer Responsibilities
Develop, implement, and deploy custom data pipelines powering machine learning algorithms, insights generation, client benchmarking tools, business intelligence dashboards, reporting, and new data products.
Innovate new ways to leverage large and small datasets to drive revenue via the development of new products with the Data Strategy team, as well as the enhancement of existing products.
Architect engineering solutions using the latest cloud technologies in a process that spans hypothesis-validating prototypes to large-scale production data products, ensuring internal security and regulatory compliance.
Design solutions that account for unstructured data and document management system(s), including ingesting, tracking, parsing, analyzing, and summarizing documents at scale.
Perform exploratory and goal-oriented data analyses to understand and validate the requirements of data products and help create product roadmaps.
Develop, implement, and deploy front-ends and APIs, which may involve business intelligence dashboards, data pipelines, machine learning algorithms, and file ingestion mechanisms.
Work closely with data scientists, data engineers, web engineers, PMs, and other stakeholders to design & develop products.
Keep current on the latest trends and innovations in data technology and how these trends apply to the company's business and data strategy.
Required Qualifications
5-8+ years of relevant experience in data-focused software engineering
Master’s Degree or Ph.D. in data science, computer science, or related quantitative field such as applied mathematics, statistics, engineering or operations research, or equivalent experience
Experience in Python and familiarity with OOP and functional programming principles
Strong knowledge of SQL and familiarity with the high-level properties of modern data stores.
Strong understanding of the contemporary SDLC, including dev/QC/prod environments, unit/integration/UA testing, CI/CD, etc.
Experience building and maintaining CI/CD pipelines with tools such as Azure DevOps, GitLab, Travis, Jenkins, etc.
At least two and ideally all of the following sets of experience:
Data Engineering
2+ years’ experience with data engineering
Extensive experience with (py)Spark, Python, JSON, and SQL
Experience integrating data from semi-structured and unstructured sources
Knowledge of various industry-leading SQL and NoSQL database systems
Backend Web
2+ years of backend/full-stack web engineering
Experience working with Python-based server-side web frameworks like FastAPI or Django
Experience with complex backends involving multiple data stores, asynchronous worker queues, pub-sub messaging, and the like
Knowledge of cloud-based web deployments (AWS/Azure/GCP, Kubernetes, auto-scaling, etc.)
Experience with one or more major frontend frameworks (React strongly preferred)
Data Science/Analytics
2+ years of data analysis, AI, or data science work
Experience with data cleaning, enrichment, and reporting to business users
Experience selecting, training, validating, and deploying machine-learning models
Experience with or strong interest in learning about LLMs in a productized context
Experience working in an Agile environment to facilitate the quick and effective fulfillment of group goals
Good interpersonal and communication skills for establishing and maintaining sound internal relationships, working well as part of a team, and for presentations and discussions
Strong analytical skills and intellectual curiosity (interest in the meaning and usefulness of the data), as demonstrated through academic experience or work assignments
Excellent English verbal and writing skills for complex communications with company colleagues in all departments and levels of the organization, including communicating technical concepts to a non-technical audience
Good ability to prioritize workload according to volume, urgency, etc., and to deliver on required projects in a timely fashion
Preferred Qualifications
Strong understanding of entity resolution, streaming technologies, and ELT/ETL frameworks
Experience with web scraping and crowdsourcing technologies
Experience with Databricks and optimizing Spark clusters
Experience architecting web ecosystems from the ground up, including monolith vs. microservice decisions, caching technologies, security integrations, etc.
Experience working with data visualization dashboarding tools (PowerBI, Tableau)
Insurance domain knowledge or strong interest in developing it
Experience with the MS Azure cloud environment",2019,Staffing & Subcontracting,Unknown / Non-Applicable,Human Resources & Staffing,1 to 50 Employees,Company - Private,True
Senior Staff AI Data Engineer,"Recruiting From Scratch
","Fairfield, CT",$160K (Employer est.),4.0,"Who is Recruiting from Scratch :
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
https://www.recruitingfromscratch.com/

This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays.

What’s so interesting about this role?

We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety.

What’s the job?

We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.

In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.

Responsibilities:

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn’t always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams
Build data processing streams for cleaning and modeling text data for LLMs
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure

What we’ll love about you

Bachelors in Computer Science, Mathematics, Physics, or a related fields
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Experience in statistical analysis & visualization on datasets using Pandas or R
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines)

We’ll really swoon if you have

2+ years of experience of technical leadership in building data engineering pipelines for AI
Previous experience in building data pipeline for conversational AI APIs and recommender systems
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Strong understanding of applied machine learning topics
Be familiar with legal compliance (with data management tools) data classification, and retention
Consistent track record of managing and implementing complex data projects

What you'll love about us

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events
Base Pay Range
$160,000—$280,000 USD
https://www.recruitingfromscratch.com/",2019,Staffing & Subcontracting,$1 to $5 million (USD),Human Resources & Staffing,1 to 50 Employees,Company - Private,True
