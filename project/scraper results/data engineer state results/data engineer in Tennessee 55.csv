Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply
Senior Data Engineer,"Transport Enterprise Leasing
","Chattanooga, TN",$110K - $130K (Employer est.),5.0,"Senior Data Engineer
Share with a friend by copying and using this link: https://tel360.com/careers/openpositions/?gnk=job&gni=8a78859e8a48e57e018a8f81127d18e3&gns=Company+Website

Position Purpose:
We are seeking a highly skilled Senior Data Engineer to join our dynamic team. In this role, you will be responsible for developing and maintaining both back-end ETL integrations and front-end user-facing metrics and dashboards. You will work closely with cross-functional teams, including other data engineers, business analysts, and software engineers, to ensure efficient data integration, processing, and visualization. You will play a crucial role in transforming raw data into actionable insights, enabling data-driven decision-making across the organization.
(THIS POSITION IS ONSITE IN CHATTANOOGA, TN)
Position Responsibilities:
Continuously learn, share, and implement improvements in all processes and responsibilities as needed to enhance effectiveness of providing world class service and support.
Design, develop, and maintain robust ETL pipelines from various data sources.
Implement scalable and optimized solutions for data processing, storage, and retrieval.
Collaborate with stakeholders to understand data requirements and translate them into technical specifications.
Coordinate with multi-platform development team to support a unified strategy for data governance and architecture.
Build user-facing dashboards and visualizations to effectively present data insights and key metrics.
Ensure data quality and integrity throughout the data pipeline and create tools to better identify and resolve any issues or bottlenecks.
Optimize performance and scalability of data processing and storage systems.
Support data validation efforts with stakeholders and development team as needed.
Stay up-to-date with emerging technologies and industry trends in data engineering and analytics.
Mentor and provide guidance to other team members, fostering knowledge sharing and professional development.
Knowledge, Skills, and Abilities:
Bachelor’s or higher degree in Computer Science, Engineering or a related field.
Proven Experience as a Data Engineer, preferably in a lead role.
Strong expertise in developing and maintaining ETL pipelines using tools such as Apache Spark, Airflow, or similar frameworks.
Proficiency in programming languages such as Python, Java, or Scala for data processing and integration.
Solid understanding of data warehousing concepts, relational and NoSQL databases, and data modeling.
Experience with front-end development and visualization tools such as Domo, Tableau, Power BI, or D3.js.
Familiarity with cloud platforms such as AWS, Azure, or GCP and their data services (e.g., S3, Redshift, BigQuery).
Comfortable working with a variety of APIs to push and pull data from various data systems and platforms.
Excellent problem-solving and analytical skills with a keen attention to detail.
Strong communication skills and the ability to collaborate effectively with cross-functional teams.
Wage:
$110,000 to $130,000K based on experience.
Benefits:
100% employer paid medical and dental (single and family coverage) premiums through BlueCross BlueShield of TN.
HSA with $800 annual employer contribution
Voluntary Life, Short- and Long-Term Disability
8-week paid Maternity Leave (mothers) and 2-week paid Paternity Leave (fathers)
PTO
10 Holidays (including birthday)
Paid day off on Veterans Day for Veterans
401(k) with up to 4% employer match
Profit Sharing (some exclusions apply)
Retirement Pay Program
Years of Service Cash Incentive
Smart Dollar financial wellness program",2004,Banking & Lending,Unknown / Non-Applicable,Financial Services,51 to 200 Employees,Company - Private,True
"Data Engineer (Hybrid - Franklin, TN)","Vaco
","Franklin, TN",$100K - $140K (Employer est.),3.6,"Title: Data Engineer (Azure) - Hybrid (Franklin, TN)
Why is this position open: Growth
Pay/Salary/Benefits/Perks: Up to $140K, bonus, competitive benefits
Work from Home Policy: Hybrid (Franklin, TN), flexible hours
Interview Process: 3 Interviews, streamlined process
Key Skills: 2+ years of data engineering, Python, ETL, Azure, SQL

Responsibilities:

Design, build, and maintain Azure data pipelines that connect with multiple data sources
Develop and maintain ETL processes using Azure Data Factory
Create and manage jobs in Azure Data Bricks
Create and maintain optimal data pipeline(s) architecture on our Azure platform
Collaborate with other teams to understand data requirements and implement solutions
Ensure security, performance, and oversight on existing databases in SQL Server and Oracle
Troubleshoot and resolve data-related issues in a timely manner
Visiting our various facilities to collaborate with our internal customers

Qualifications:



2+ years experience
At least one year of previous data engineering experience on an Azure data platform
Proficiency in Python and ETL
Bonus Skills:
Experience with Azure Data Factory, Azure Data Bricks, and Data Lakes
Experience with SSAS, SSIS, SSRS, and Power BI
Experience sourcing structured and unstructured data from databases, files, RESTful API's
Manufacturing industry experience",2002,Staffing & Subcontracting,$500 million to $1 billion (USD),Human Resources & Staffing,501 to 1000 Employees,Company - Private,True
Data Analyst/Engineer,"Beacon Specialized Living Services
","Nashville, TN",,3.0,"Applicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time.

Primary Responsibilities/Essential Functions:

· Assist in selecting and building Data Warehouse

· Define and Build Tabular Data Model

· Improving observability, discoverability, governance, and implementing a common data integrity and data quality testing framework.

· Constructing reliable and performant high-volume ETL or ELT pipelines for sensitive healthcare data.

· Contributing to and maintaining legacy ETL and ELT data pipelines.

· Proactively monitoring data pipelines for potential problems and debugging issues if they arise.

· Helping to model data at various stages of refinement, curation, and enrichment to best suit different downstream targets and marts.

· Partnering with leadership to identify data objectives, targets, and bringing data insights to life.

· Other duties as assigned.

Education & Qualifications:

· A Bachelor's degree in computer science, data science, or information systems.

· 3 years of proven data and performance engineering.

· Expert in SQL.

· Experience using data warehouses and databases like Azure, SQLAAS.

· Experience developing custom-built data/analytics solutions.

· Experience with Azure, Data Factory, API’s.

· A strong understanding of healthcare.

· Established project management skills.

· Advanced training certifications may be advantageous.

· Excellent verbal and written communication skills, interpersonal, and teaching skills.

· Good anticipation, analytical, and problem-solving skills.

· The ability to remain current on the latest technology and best practices in information security.

· Valid Driver’s License with acceptable driving record as determined by Motor Vehicle Report and insurance guidelines.

Job Type: Full-time

Benefits:

401(k)
401(k) 4% Match
Dental insurance
Health insurance
Health savings account
Life insurance
Paid holidays
Paid time off
Vision insurance

Compensation package:

Yearly bonus

Experience level:

3 years

Schedule:

Monday to Friday

Application Question(s):

Are you willing to travel to Nashville, TN as needed? (not frequent)
Do you require work sponsorship now or in the future? (Answer Required)

Education:

Bachelor's (Required)

Experience:

Healthcare IT: 3 years (Required)

Work Location: In person",1964,Health Care Services & Hospitals,$5 to $25 million (USD),Healthcare,1001 to 5000 Employees,Company - Private,True
Senior Data Engineer (Snowflake) - Contractor,"EY
",United States,$90.00 - $130.00 Per Hour (Employer est.),3.9,"The primary responsibility for the Sr. Data Engineer / Tech Lead is to ensure data accessibility, quality, and reliability within the client's data platform ecosystem.

RESPONSIBILITIES

Design and develop end-to-end data pipelines and ETL processes using Snowflake, Denodo, DBT Cloud, Fivetran, and AWS Glue, ensuring seamless data integration, transformation, and loading.
Collaborate with cross-functional teams to gather data requirements and implement scalable data models and schemas within Snowflake and Denodo, ensuring optimal performance and data consistency.
Implement and maintain data orchestration workflows using Stonebranch, ensuring efficient and reliable scheduling and automation of data processes.
Work with EnterpriseDataLake for ingestion and storage of data from various sources, ensuring the availability and accessibility of data for analytics and reporting purposes.
Utilize Azure DevOps and Teraform to implement and manage infrastructure as code, ensuring streamlined deployment and scalability of data engineering solutions.
Skills

snowflake

denodo

dbt cloud

fivetran

Qualifications

REQUIREMENTS

Proficiency in Snowflake and Denodo: Strong understanding and hands-on experience in working with Snowflake and Denodo for data integration, transformation, and analysis.
Knowledge of DBT Cloud: Familiarity with DBT Cloud, including experience in building and maintaining efficient data transformation workflows and deploying reliable data pipelines.
Experience with Fivetran: Demonstrated experience in utilizing Fivetran for data ingestion, source connectivity, and ensuring data accuracy and completeness.
Understanding of EnterpriseDataLake: Knowledge of EnterpriseDataLake principles and practices, including data ingestion, storage, and organization for analytics and reporting purposes.
Familiarity with Stonebranch: Proficiency in using Stonebranch for data orchestration and scheduling, ensuring efficient and reliable execution of data pipelines and workflows.
Proficiency in Azure DevOps and Teraform: Experience in leveraging Azure DevOps and Teraform for infrastructure as code, enabling streamlined deployment and scalability of data engineering solutions.

The expected pay rate range for this contract assignment is $90 to $130 per hour. The exact pay rate will vary based on skills, experience, and location. The position is approximately 65-70% remote and 30-35% travel to the client as needed.

#GigNowTechOpportunities

GigNowOpportunities

Equal Employment Opportunity Information
EY provides equal opportunities to applicants, employees, contractors, vendors, and stakeholders without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. If you are an individual with a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please email gignow.recruiting@ey.com.",-1,-1,Unknown / Non-Applicable,-1,Unknown,Unknown,False
Data Engineer II,Velocity Risk,"Nashville, TN",$87K - $116K (Glassdoor est.),-1.0,"By innovating the connection of risk and capital, Velocity Risk delivers specialty property insurance in catastrophe prone communities. Embracing Nature’s volatility and turning “problems” into potential, we are transforming old insurance practices. Our uncommon approach to business creates uncommon careers where employees are empowered to flourish.

Do you enjoy a career where you can work on routine tasks and projects using your keen attention to detail and focus? Are you someone that likes to look at a problem and analyze all the perceived outcomes to make a research-based, smart decision? Would you consider yourself steady and consistent in your work and diligence to the product you create and your ability to execute on tasks assigned? If so, we are looking for you!

As our Data Engineer I, you will be a crucial part of the data architecture of Velocity by utilizing your knowledge and detailed mind to develop reliable tools and systems of data for better business consumption and analysis.

You will thrive in this position if you have these core capabilities…

High Attention to Detail – focused and attentive to correct data and pinpointing any inaccurate information quickly and efficiently
Perpetual curiosity with a mindset of continuous improvement
Autonomy with a collaborative drive when it benefits the outcome or results
Business Acumen
Comfortable in ambiguity
7+ years’ experience using query languages within relational database management systems.
5+ years’ experience with ETL products with experience with Informatica Cloud being a plus
5+ years’ experience with scripting languages with Powershell and/or Python being pluses
3+ years’ experience with report writing and data visualization and/or business intelligence software with experience with Tableau being a plus.

The core responsibilities in this role are…

Maintaining end-to-end data pipelines.
Produce documentation related to internal data flows.
Assist internal business partners with using data to make informed decisions and improve processes.
Develop tooling to facilitate end-user consumption of company data.
Merge business knowledge with various complex data sources to produce reports on an ad hoc basis.
Act as subject matter expert on latest technology trends related to data engineering, data governance, and automation of data-related processes.

Demonstrated Experience for success in this role…

Velocity Risk provides equal opportunity to everyone, and we do not tolerate discrimination or harassment to anyone.

We strive to ensure our employees have the best experience possible! We provide comprehensive and competitive benefits packs for our full-time employees.

Medical, Dental, and Vision fully subsidized by Velocity
Health Savings Account with employer contributions
401k after 6 months of employment
Education and Certification Reimbursement and Bonus programs
Paid Time off and company Holidays with floating holidays for flexibility
Gym membership reimbursements
Volunteer rewards and “give-back” initiatives
In-office lunch provided

We are a hybrid team (2 days remote, 3 days in office).

Velocity Risk participates in E-Verify. https://e-verify.uscis.gov/web/media/resourcesContents/E-Verify_Participation_Poster.pdf",2015,Insurance Carriers,Unknown / Non-Applicable,Insurance,51 to 200 Employees,Company - Private,True
Junior Data Engineer,"Careoperative Llc
",United States,-1,4.2,"Healthcare Bluebook is an industry pioneer - one of the first to expose the true quality and cost of healthcare by making information accessible through a simple digital solution. Our founders are thought leaders who are sought after for their expertise in one of the fastest growing healthcare markets today. Now consumers can have confidence they’re making high-value healthcare choices when they use Bluebook to identify high-quality doctors and facilities that consistently deliver care at a Fair Price.


Your Job Will Be:


The Data Engineer will support our efforts to integrate, validate, enrich, and aggregate healthcare data for use by our analysts and data scientists. You’ll help find new and useful sources of information and lead the charge to go get it and make sure we can keep this data up to date over time. You will also help ensure this data is translated to the rest of the analytics teams in a useable format. You will be expected to master the intricacies of efficiently acquiring large amounts of data from various sources, designing pipelines to move that data to and from our hosted and cloud environments, and push the evolution of these processes to accommodate new types of data.


Essential Duties and Responsibilities:


Create and maintain processes to acquire, validate, and enrich data from various sources

Build and maintain data pipelines and automate existing manual processes.

Work with Data Integration to build and maintain efficient processes for loading acquired data into our relational, dimensional, and no-SQL databases

Implement data lake architecture best practices to ensure a standardized and scalable way that we store and process our data

Work with other teams to identify new sources of data, and estimate feasibility of acquiring specific data sources

Take an active role in agile processes

Work Experience and Background:


This is a junior-level role, and the ideal candidate will have several of the following.


1+ years of work experience in a hands-on data engineering role

Experience working with Data Lakehouse and / or migrating RDBMS systems to a Lakehouse.

Experience working with the most common types of healthcare data (medical claims, eligibility, provider network rosters, Rx claims, etc.) from a variety of sources.

Strong organizational skills and time management capacity to balance multiple projects with limited supervision.

Ability to build and re-evaluate a process from the ground up.

Strong investigative skills with ability to search beyond the initial results.

Have a fanatical attention to detail, with overwhelming desire to test and double-check your own results.

Comfortable working with messy data and ambiguous results

Education (Bachelor’s degree or greater, or equivalent practical experience) in a quantitative field such as statistics, mathematics, engineering, or computer science


Technical Proficiencies:


Our infrastructure consists of a hybrid solution (traditional hosting + cloud hosting) that uses the technologies below. Ideal candidates will have experience with several of these. While we use Azure for our cloud environment, experience with equivalent cloud services from AWS and/or Google is acceptable.


SQL Server

.NET Framework and C#

Databricks / Spark

Delta Data Lakehouse

Python and Jupyter Notebooks

Azure Blob Storage

Azure Data Factory

Azure Synapse Analytics

Version control systems (Git, Azure DevOps, etc)

Experience building workflows


Healthcare Bluebook Core Values:


As a member of the Bluebook team, it is expected that you will live and breathe our Core Values each and every day in everything they do striving to help us achieve our purpose of Protecting Patients by exposing the truth and empowering choice.


Substance Create Value over splash.
Humility Serve with Gratitude.
Accountability Own it no matter what.
Resourcefulness Always agile with change.
Integrity Honor the truth.",-1,Internet & Web Services,$5 to $25 million (USD),Information Technology,51 to 200 Employees,Company - Private,True
Data Engineer,"Phosphorus Cybersecurity Inc.
","Nashville, TN",$81K - $117K (Glassdoor est.),4.0,"As a Data Engineer at Phosphorus you will play a critical role in ensuring high standards of data management in the ever evolving field of xIoT cybersecurity. Your work has the opportunity to directly impact the safety and security of critical infrastructure in industrial, medical and enterprise environments around the world. This role reports directly to the Director of Device Intelligence and depending on where you live, will have some travel to the Corporate headquarters based in Nashville, TN.

What you'll do.

Architect the future of data at Phosphorus. Make significant contributions to the development of the Phosphorus Data Platform and provide input from beginning to end. Your work will support customers in making informed decisions about the security of their xIoT ecosystem.

Uphold system-wide data integrity. Ensure a high level of data integrity and availability deepening the confidence customers have when making decisions about their critical infrastructure managed by Phosphorus.

Continuously innovate and iterate. Pursue a culture of continuous improvement and excellence by challenging assumptions and driving technical direction in a data-driven manner.

Empower others. Advocate for best practices not only within your team but throughout the organization gathering feedback on the Data Platform services along the way to inform future direction.

Grow yourself and the team. Collaborate with your team to identify and fill one another's skill gaps. We are redefining a critical product category and it is unlikely we all have 100% of the skills needed to succeed.

What you're great at.

5+ years building scalable data solutions

Experience with modern programming languages such as Go and Python (Rust and Elixir a plus)

Maintained industrial-strength web scraping platforms and are familiar with the ongoing maintenance required

Established a modern datastack usings tools such as dbt, Airflow, Snowflake/Redshift, etc.

Experience in deploying OLTP, OLAP and KVS data stores where appropriate and the ETL/ELT pipelines to keep them up-to-date

Excellent communication skills and the ability to flex between technical and non-technical audiences

About us:

Phosphorus Cybersecurity is the leading xTended Security of Things platform designed to secure the rapidly growing and often unmonitored Things across the enterprise xIoT landscape. Our Enterprise xIoT Security Platform delivers Attack Surface Management, Hardening & Remediation, and Detection & Response to bring enterprise xIoT security to every cyber-physical Thing in your enterprise environment. With unrivaled xIoT discovery and posture assessment, Phosphorus automates the remediation of the biggest IoT, OT, and Network device vulnerabilities—including unknown and inaccurate asset inventory, out-of-date firmware, default credentials, risky configurations, and out-of-date certificates.

Follow Phosphorus on LinkedIn, Twitter, and YouTube. Learn more: www.phosphorus.io.",2017,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,True
DATA ENGINEER,"Dollar General
","Goodlettsville, TN",$76K - $118K (Glassdoor est.),2.7,"Company Overview:
Dollar General Corporation has been delivering value to shoppers for more than 80 years. Dollar General helps shoppers Save time. Save money. Every day.® by offering products that are frequently used and replenished, such as food, snacks, health and beauty aids, cleaning supplies, basic apparel, housewares and seasonal items at everyday low prices in convenient neighborhood locations. Dollar General operates more than 18,000 stores in 47 states, and we’re still growing. Learn more about Dollar General at www.dollargeneral.com.
Job Details:
General Summary:
Dollar General Corporation has been delivering value to shoppers for more than 80 years. Dollar General helps shoppers Save time. Save money. Every day.® by offering products that are frequently used and replenished, such as food, snacks, health and beauty aids, cleaning supplies, basic apparel, housewares and seasonal items at everyday low prices in convenient neighborhood locations. Dollar General operates more than 18,000 stores in 47 states, and we’re still growing. Learn more about Dollar General at www.dollargeneral.com.

Duties & Responsibilities:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud technologies.
Build analytics tools that utilize the data pipelines to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Qualifications:
Knowledge, Skills and Abilities:
Knowledge of programming languages (e.g. Java and Python)
Hands-on experience with SQL database design
Great numerical and analytical skills
Degree in Computer Science, IT, or similar field; a Master’s is a plus
Data engineering certification (e.g IBM Certified Data Engineer) is a plus
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with Snowflake/Azure cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc
Work Experience &/or Education:
Degree in information technology or computer science with additional vendor-specific certification.
BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients
Experience designing, building, and maintaining data processing systems
Experience working with a cloud platform such as Snowflake / Azure or Databricks
_:
#mogul#",1939,Other Retail Stores,$10+ billion (USD),Retail & Wholesale,10000+ Employees,Company - Public,False
Data Engineer,"HCA Healthcare
","Nashville, TN",$82K - $109K (Glassdoor est.),3.3,"Introduction

Do you want to join an organization that invests in you as a Data Engineer? At HCA Healthcare, you come first. HCA Healthcare has committed up to $300 million in programs to support our incredible team members over the course of three years.

Benefits

HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:

Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing

401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)

Employee Stock Purchase Plan with 10% off HCA Healthcare stock

Family support through fertility and family building benefits with Progyny and adoption assistance.

Referral services for child, elder and pet care, home and auto repair, event planning and more

Consumer discounts through Abenity and Consumer Discounts

Retirement readiness, rollover assistance services and preferred banking partnerships

Education assistance (tuition, student loan, certification support, dependent scholarships)

Colleague recognition program

Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)

Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.

Learn more about Employee Benefits

Note: Eligibility for benefits may vary by location.


You contribute to our success. Every role has an impact on our patients’ lives and you have the opportunity to make a difference. We are looking for a dedicated Data Engineer like you to be a part of our team.

Job Summary and Qualifications

What makes the Information Technology Group unique as a technology company is that our solutions ultimately impact the care of patients. Although our skills are needed in a number of industries, we in ITG apply them specifically to the noble cause of healthcare. We are ""Healthcare Inspired."" It is this guiding vision that pervades and positively influences every level of our organization. It shapes our mission, defines our values, and brings our leaders and employees together in a shared enthusiasm for their work, setting ITG apart as a uniquely purpose-driven company in the IT industry. As a part of that, we exist to Raise the bar, Unlock possibilities, and Care like family.

The Data Engineer will report directly to the Manager of Automation Delivery, and work closely with stakeholder teams and the Automation Center of Excellence. This role will collaborate with various leaders, product owners, analysts, project managers, and technical solution providers across the enterprise to deliver on data-related business needs to support the development of new end user, analytics, and operational automations and applications. The Data Engineer will work alongside engineers and subject matter experts for the planning and execution of designated work efforts, escalation of issues, and support of associated areas to assist in the development and support of tools and analysis to ensure a successful implementations and ongoing operations. The ideal candidate will be data-driven, with the ability to plan out and develop applications. The individual should be innovative and passionate about developing new automation capabilities alongside our clinical and operational product teams and Automation Center of Excellence


CORE COMPETENCIES


The following are highlighted core expectations for the job/role:


Communication and interpersonal skills
Moral Courage
Stakeholder partnership
Understanding strategic imperatives
Cross-functional knowledge
Risk management
Software Development
Technology Implementations
Process improvement/re-engineering

At HCA ITG, you WILL influence patient care. Every process, technology and decision matters.

Major Responsibilities


Automation Development

Collaboration with various teams to understand opportunities and challenges related to data implementations using automation
Perform deep data analysis to inform solution design and application optimization
Contribute to day-to-day efforts associated with building and optimizing automation tooling.
Propose recommendations, adjustments and/or process improvements to achieve success as needed.
Development of support tools to assist in effective and efficient functional implementations.
Provide assistance and support to facilitate business needs as they arise
Escalation of concerns or issues that could impact a successful project go live in a timely and detailed manner.
Attendance and participation in team and/or project meetings.
Provide detailed report outs and status updates as needed.
Some travel may be required to support business efforts.
Practice and adhere to the “Code of Conduct” philosophy and “Mission and Value Statement”
Perform other duties as assigned

Incident Response and Communications

Provide after-hours support including weekends and holidays as needed
Participate in major events and/or large problem efforts between multiple divisions, vendors, and ITG resources
Actively participate in communications needs and expectations for customers and stakeholders

What qualifications you will need:

Bachelor's Degree preferred
Three or more years relevant work experience
Three or more years in Information Technology
One or more years experience in healthcare

Knowledge, Skills, Abilities, Behaviors:

Results oriented with an eye towards business results as the objective of automations
Exceptional written and verbal communication skills
Exceptional customer service skills in a team-oriented, collaborative environment
Demonstrated excellent analytical skills and problem solving abilities
Demonstrated experience with process improvement/re-engineering
Extensive experience with relational database management systems; SQL Server preferred
Advanced SQL skills, including the ability to write, tune, and interpret SQL queries
Demonstrated experience with healthcare integration standards such as HL7 and FHIR Ability to troubleshoot, maintain, reverse engineer, and optimize existing ETL pipelines and SSIS packages
Experience with public cloud technologies such as, GCP Big Query, GCP Data Catalog and Azure Data Bricks In depth knowledge of all applicable systems as assigned
Ability to make independent decisions and work on independent tasks Ability to be adaptable and flexible with a changing environment
Knowledge of architectural and data principles
Ability to leverage technical metrics to drive effective business decisions
Ability to accomplish assignments, analyzing alternative approaches in the process of advising management on aspects of development, operations and solutions
Knowledge of IT governance and operations
Knowledge of microservices architecture and distributed systems


HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.


""Good people beget good people.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder

We are a family 270,000 dedicated professionals! Our Talent Acquisition team is reviewing applications for our Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your resume today to join our community of caring!

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",1968,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Company - Public,True
Data Engineer,"CHS Corporate
","Franklin, TN",$80K - $106K (Glassdoor est.),3.2,"Community Health Systems is one of the nation’s leading healthcare providers. Developing and operating healthcare delivery systems in 43 distinct markets across 15 states, CHS is committed to helping people get well and live healthier. CHS operates 76 acute-care hospitals and more than 1,000 other sites of care, including physician practices, urgent care centers, freestanding emergency departments, occupational medicine clinics, imaging centers, cancer centers and ambulatory surgery centers.

Summary:
This role places you at the heart of Big Data and Google Cloud Platform (GCP), central to maintaining and developing all systems connected to CHS Data Services. Your keen understanding of Managed File Transfer (MFT) will be crucial in managing and enhancing our MFT platform seamlessly integrated within GCP.

Responsibilities:

Administer GCP and MFT Systems:
Oversee and optimize Business Intelligence and data service systems within GCP, and play an active role in the MFT platform’s management.
GCP and MFT Analysis and Review:
Scrutinize GCP and MFT reporting implementations, ensuring their optimal performance and timely problem resolution.
Collaborate on GCP and MFT Initiatives:
Work synergistically with different teams to address GCP and MFT-related information processing and capacity planning.
Provide GCP and MFT User Assistance:
Offer vital support to users, ensuring the efficient and productive use of GCP and MFT applications, alongside comprehensive training and problem resolution.
Ensure GCP and MFT Compliance:
Maintain adherence to relevant policies and procedures within GCP and MFT operations.
Design GCP-Based Databases:
Develop OLAP databases within GCP for extensive multi-dimensional data analysis.
Implement GCP Data Warehousing Solutions:
Integrate data from diverse sources within GCP, underlining the efficiency and enhancing organizational performance.

Requirements:
Educational Qualification: Bachelor's in Computer Science or Electrical Engineering.
Professional Experience:

3 years in Information Technology, with experience in MFT, GCP and Big Data Processing Frameworks.
GCP and MFT Expertise: Proficient in GCP tools and services with a solid understanding and experience in MFT platforms.
Experience in designing GCP-based OLAP databases.
Familiarity with XML, JSON/JavaScript, and Hadoop ecosystem tools within GCP environments.
Additional Skills:
Clear and concise oral and written communication skills.
Previous experience in a healthcare environment is a plus.
Contribute substantially by enhancing our GCP and MFT platforms, ensuring top-tier customer experience and the evolution of our business models.

Physical Demands:

In order to successfully perform this job, with or without a reasonable accommodation, the following are outlined below:

The Employee is required to read, review, prepare and analyze written data and figures, using a PC or similar, and should possess visual acuity.
The Employee may be required to occasionally climb, push, stand, walk, reach, grasp, kneel, stoop, and/or perform repetitive motions.
The Employee is not substantially exposed to adverse environmental conditions and; therefore, job functions are typically performed under conditions such as those found within general office or administrative work.",1985,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Company - Public,True
Data Engineer,"Cadre5
","Knoxville, TN",$73K - $113K (Glassdoor est.),4.6,"Data Engineer
Founded in 1999 in the beautiful Smoky Mountains of East Tennessee, Cadre5 provides innovative technical solutions to our customers locally and nationally. Our Cadre5 Lab Partners division has partnered with The Information Technology Services Division at Oak Ridge National Laboratory (ORNL) to recruit a qualified Data Engineer.
ORNL delivers scientific discoveries and technical breakthroughs needed to realize solutions in energy and national security and provides economic benefit to the nation. This premier research institution located near Knoxville in Oak Ridge, TN, addresses national needs through impactful research and world-leading research centers.
The Data Engineer will play a pivotal role in supporting two customers at Oak Ridge National Laboratory, involving:
Primary Role:
Refactoring a substantial data extraction pipeline, exclusively crafted in TSQL, against a multi-terabyte database/warehouse. Project constraints mandate adherence to the current technology (TSQL), requiring expertise in SQL performance tuning tools and techniques, including interpreting execution plans, and optimizing read/write indexes. The role mandates the ability to secure and maintain an HSPD-12 or higher clearance.
Secondary Role:
Contributing to The Knowledge Discovery Infrastructure (KDI) program, facilitating research on data entrusted to ORNL by the U.S Department of Veteran’s Affairs (VA) and other agencies. This role offers an opportunity to engage in challenging research and development programs in healthcare informatics, bioinformatics, and computer science.


This is a full-time, permanent position that adopts a hybrid work model.
Why Cadre5?
Working with highly talented team members
Paid over-time
3 weeks’ vacation
Excellent medical insurance, up to 100% paid by employer and contributions to HSA Plans
Job Responsibilities:
Developing high-scale, robust data warehouses, and data lakes with special focus on the state-of-the-art solutions for healthcare, life sciences, and genomics
Interfacing with research teams to understand data needs, and providing subject matter expertise to research teams, and other team members about the data models, query optimizations, and schema interpretation
Designing, building, and launching new data/study marts for the major national research programs
Designing, building, and launching new data quality, data extraction, transformation and loading processes
Designing and developing architectures for intake, curation, organization, and dissemination of data in support of data science and related disciplines
Designing and development of high-performance database architectures
Researching and evaluating the state-of-the-art data and information management technologies
Working on a variety of data assignments; collaborate with scientists and engineers, and expect to produce reliable data products and systems
Collaborating with sponsors and research users to establish and maintain data pipelines, encompassing ETL and reporting workflows, data management, and data lifecycles.


Basic Qualifications:
Bachelor’s Degree or Master’s Degree in Computer Science, Engineering, Mathematics, or closely related field, or equivalent experience
4+ years of experience in database design and/or development
Proficiency in various technologies, including Linux, SQL, Python, containers, Pandas, Spark, and source control
The ability to obtain and maintain a Department of Energy ""Q"" clearance is required. This requires US Citizenship.
Preferred Qualifications:
M.S or Ph.D. degree in Computer Science, Information Systems, Engineering, or closely related field
6+ years of experience in basic and advanced SQL, database programming, and scripting languages (Python preferred)
6+ years of experience in data warehousing systems
Strong knowledge of database system administration
6+ years of experience in data driven software development
Demonstrated expertise with OLTP and data warehousing, SQL Server is preferred
Experience in designing analytics data systems
Experience working with Big Data processing frameworks such as Spark, Dask, and Pandas
Familiarity with Big Data and NoSQL architectures
Demonstrated experience with collecting, organizing, storing, and preparing data analysis
Ability to conduct tasks independently and communicate effectively to team members and stakeholders
Experience with heath care informatics is highly desired
Working experience and basic understanding of AI/ML data requirements


Benefits
Cadre5 offers excellent pay and benefits, to include full medical, dental, and vision coverage coupled with 401K match, 15 days PTO, and 10 holidays.
Cadre5 is an equal opportunity employer. All qualified applicants, including individuals with disabilities and protected veterans, are encouraged to apply. Cadre5 is an E-Verify Employer.",1999,Computer Hardware Development,$5 to $25 million (USD),Information Technology,1 to 50 Employees,Company - Private,True
Data Engineer- 5050306,"Accenture
","Nashville, TN",-1,3.9,"Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.

As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.

You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.

Utilize strong SQL Python skills to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features.

Build reporting dashboards and visualizations to design, create and track campaign program KPIs.

Perform analyses on large data sets to understand drivers of operational efficiency.

Manage end to end process of analytic tooling feature development, including request intake, requirements evaluation, cross functional team alignment, feature execution, QA testing, and stakeholder communication.

Consult with business analysts, technical data SMEs, and cross functional partners to understand their reporting and data needs, serving as the point of contact for requests, inquiries, and actions.

Interface with other data engineering, product, and data science teams to implement client needs and initiatives.




Basic Qualifications:

Minimum 2 years experience with Python.

Minimum 3 years experience SQL.

Minimum 3 years experience Big Data Analytics.

High School Diploma or GED.

Preferred Qualifications:

Experience with large enterprise data sets.

Bachelors Degree

Compensation at Accenture varies depending on a wide array of factors, which may include but are not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York, or Washington as set forth below.

Information on benefits is here.

Role Location

California: $61.53 to $71.53/hour

Colorado: $61.53 to $71.53/hour

New York: $61.53 to $71.53/hour

Washington: $61.53 to $71.53/hour


What We Believe


We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.


Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here


Equal Employment Opportunity Statement


Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.


All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.


Accenture is committed to providing veteran employment opportunities to our service men and women.


For details, view a copy of the Accenture Equal Employment Opportunity and Affirmative Action Policy Statement.


Requesting An Accommodation


Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.


If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.


Other Employment Statements


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.


Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.


Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.


The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",1989,Business Consulting,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Engineer - 3338,"National Aerospace Solutions
",United States,-1,3.5,"Title: Data Engineer- 3256
Function: Business Operations
Position Type: Regular, Full-Time
Pay Type: Exempt
Grade: 33-35
US Citizenship Required

This opportunity is being offered by National Aerospace Solutions, the team selected by the U.S. Air Force to conduct Test and Operations Sustainment at the Arnold Engineering Development Complex (AEDC), Arnold Air Force Base, Tennessee. National Aerospace Solutions is a limited liability company comprised of Bechtel National Inc. (as lead company) and Sierra Lobo Inc. with teaming Subcontractors nLogic Inc. and Chugach Federal Solutions Inc. AEDC operates more than 55 aerodynamic and propulsion wind tunnels, rocket and turbine engine test cells, space environmental chambers, arc heaters, ballistic ranges and other specialized units located in six states. Many of the complex's test units have capabilities unmatched elsewhere in the United States; some are unique in the world. AEDC is one of three installations which are part of the Air Force Test Center (AFTC), one of six subordinate commands of the Air Force Materiel Command organization and an important national resource.

AEDC’s mission is to conduct developmental test and evaluation for the Nation through modeling, simulation, ground, and flight test. Execution of the mission requires a large team of highly qualified and dedicated professionals from multiple technical disciplines to effectively accomplish the objectives of our test customers.

Job Summary:
This job is to develop and apply statistical and modern analytical methods to improve operations and maintenance of the Arnold Engineering Development Complex (AEDC) air and space ground test equipment and facilities. The successful candidate will work as a member of the Digital Enterprise group (DE) in the Mission Support Branch to lead implementation of data-centered projects to improve the AEDC ground test data infrastructure, facility operations, and business systems. The person selected for this role will work closely with multidisciplinary work teams throughout the NAS organization to identify opportunities for leveraging data to drive decisions and will help design and implement a data architecture working with the Digital Enterprise team.

Job Duties:
Design, development, sustainment, and deployment of complex Government data engineering solutions
Utilize test data sources to optimize data analytics at AEDC and suggest ways which insights obtained might be used to inform testing sustainment and operational strategies.
Automate manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Utilize machine learning tools to select features, create, and optimize classifiers.
Define & develop approaches and demonstrate abilities to mine and analyze data from databases to drive optimization and improvement of data collected at AEDC.
Perform development lifecycle aspects that includes requirements documentation, design documentation, configuration management, testing, implementation plans, etc.
Identify and assess the effectiveness of data engineering, data sources and data gathering techniques.
Utilize applicable experience in “big data,” analytics, algorithmic, custom data models, algorithms and/or machine learning approaches to help extract data that will help drive engineering decisions.
Coordinate with different multidisciplinary teams to implement models and monitor outcomes.
Define & develop processes and tools to monitor and analyze model performance and data accuracy.
Define & develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and ‘big data’ technologies.
It is a condition of employment to wear company issued PPE (Personal Protective Equipment) in accordance with supervisory direction and company policy.
Performs other related duties as required.

Basic Qualifications:
B.S. in Computer Science, Statistics, Mathematics, Engineering, or another relevant engineering field from an accredited university program plus a minimum of 1 to 4 years of progressive and relevant experience
Current U.S. Citizenship is required.
Preferred Qualifications
Experience with development lifecycle methodologies such as Agile DevSecOps
Experience with data scripting language software like Python, Java, C++, or Ruby and SQL.
Experience with data extraction tools and processes, data ingestion, ETL, data mining, API’s, and data warehousing
Experience in developing and implementing data management solutions.
Demonstrated experience in a data engineering role.
Experience working with and creating data architectures and data models.
Knowledge of a variety of machine learning techniques and their real-world advantages/drawbacks.
Coding knowledge and experience with multiple languages
Due to Air Force Security requirements, U.S. Citizenship is required for employment at AEDC.

NAS is an Equal Opportunity Employer of Minority/Women/Veterans/Disabled (AA/EOE). All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, sexual orientation, gender identity and expression, pregnancy, physical or mental disability, citizenship, genetic information, protected veteran status or any other characteristic protected by federal, state or local law. Applicants with a physical or mental disability, who require a reasonable accommodation for any part of the application or hiring process, may e-mail their request to careers@nas-llc.us. PLEASE DO NOT SUBMIT RESUMES to this address as they will not be considered for employment opportunities.",-1,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,1001 to 5000 Employees,Government,False
Data Engineer,"SVS Technologies
","Memphis, TN",$79K - $110K (Glassdoor est.),4.6,"Data Engineer, Memphis, TN: Limited domestic travel, telecommute and/or occasional relocation to client sites nationwide to work on every stage of data science projects; develop predictive models, identify key processes for improvement using advanced analytics/data science. Work on data gathering, sampling, EDA. Work in Hadoop, Hive Kafka, Maven, JUnit, MySQL, Jenkins environment. Reply to: SVS Technologies Limited, 8700 Trail Lake Drive, #228 Memphis, TN 38125",2011,Information Technology Support Services,Less than $1 million (USD),Information Technology,1 to 50 Employees,Company - Private,False
Data Engineer,"Kenco Management Services LLC
","Chattanooga, TN",$78K - $122K (Glassdoor est.),3.2,"About the Position

The Data Engineer will develop and support next generation architecture for the advanced supply chain analytics offering. The job will design, create, manage, and use of large datasets across a variety of data platforms. The position crafts, implements, and operates stable, scalable, low-cost solutions to replicate data from production systems into the BI data store.


Functions

Partner with key distribution, transportation, and material handling business managers to design and implement efficient and scalable Extract, Transform, Load (ETL) solutions
Assist in developing and improving the current ETL/BI architecture, emphasizing data security, data quality and timeliness, scalability, and extensibility
Design low latency data architectures at scale to enable data driven decision-making
Delivery of performant and scalable data products and platforms, both Online Transactional Processing (OLTP) and Online Analytical Processing (OLAP), to consume, process, analyze and present data from the data ecosystem, while driving data engineering best practices
Ensure the integrity and uninterrupted processing of batch and real-time data pipelines to ingest and process data from various internal data sources and third-party platforms
Work closely with Data Science and Business Intelligence team to develop and maintain company-level Key Performance Indicators (KPIs), accompanying core metrics and develop architecture to drive business growth

Qualifications

Bachelor’s degree in Computer Science. Master’s or PhD degrees preferred
6-8 years Data Engineering experience: proven track record working with large datasets and closely working with data analysts, software, and infrastructure engineers
Expert level skills writing/optimizing complex SQL and schema buildout with structured and unstructured data, including star schemas, constellations, and snowflake schemas
5-6 years of experience with Python
Experience with ETL tool like SSIS etc.
Strong background in working with Big Data technologies like: Spark, Kafka, Hadoop, etc. preferred
Experienced in developing and delivering on technical roadmaps and architectures for platforms or cross-functional problems that impact multiple teams
Experience in data mining, profiling, and analysis
Experience with workflow orchestration tools and rules-driven process automation engine systems
Good understanding of Continuous Integration (CI)/ Continuous Delivery (CD) principles
Demonstrated track record of dealing with ambiguity, prioritizing needs, and delivering results in a dynamic business environment
Proven ability to develop unconventional solutions; Sees opportunities to innovate and leads the way
Experienced in designing data solutions utilizing AWS cloud data platforms and tools


Competencies

Business Acumen - Knowledgeable in current and possible future policies, practices, trends, technology, and information affecting his/her business and organization.
Communicate for Impact - Proactively communicate with all stakeholders throughout the life cycle of programs and projects.
Influencing Others - Can quickly find common ground and can solve problems for the good of the organization with a minimal amount of noise. Authentically gains trust and support of peers.
Managing Transitions/ Change Management - Effectively plans, manages and communicates changes in processes with appropriate stakeholders.
Strategic Agility - Enable Kenco to remain competitive by adjusting and adapting to innovative ideas necessary to support Kenco’s long-term organizational strategy.


For California residents – please enter or copy/paste the address below into your address bar to review an important notice regarding Kenco’s privacy policy.

https://www.kencogroup.com/ccpa-notice-at-collection-for-employees-and-applicants/

Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities

The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)",1950,Shipping & Trucking,$1 to $5 billion (USD),Transportation & Logistics,1001 to 5000 Employees,Company - Private,True
Data Quality Engineer,"BayOne
","Brentwood, TN",$65K - $93K (Glassdoor est.),3.9,"Job Description :
Education and Experience


Bachelor's degree in a technical or business discipline OR additional training/certification on ETL and Data Warehouse testing.
Three years of database/warehouse experience in Information Technology with a reporting/analytics or software development focus
Demonstrated strong SQL skills in reading and writing data from a relational database for purposes of data warehousing, ETL, and data management
One year of using test management tools like Client ALM/qTest/xRay and one year of experience using any automated ETL/Dashboard/Reporting testing tool
Demonstrated analytical, problem-solving, time management skills and think out of the box.
Demonstrated experience in working with Data Quality Metrics
Knowledge, Skills, and Abilities


Works to achieve operational targets, which has a moderate impact on the overall achievement of results for the team
Work is moderately supervised
Problems faced are difficult but typically not complex and requires some depth of analysis
Communicates information typically within the immediate team on matters that involve obtaining or providing information of direct importance to the team
May provide guidance and assistance to associate and/or support professionals
Passion to Client data-driven solutions that solve business problems within a healthcare setting
Possesses data warehouse core techniques: design, ETL, query development, and optimization to move from ambiguity to a solution
Comfortable working in a team-oriented, collaborative environment
Good communication and interpersonal skills
Ability to work effectively in a fast-paced environment with tight schedules and target dates as part of a high-performing team
Nice to have


Healthcare data domain knowledge including EDI standards, authorization, claims, DRG, diagnosis, and other related taxonomies applicable in claims / clinical workflow
Agile process experience including scrum and kanban frameworks
Test automation experience supporting warehouse / ETL data flows
Exposure to big data technologies (NoSQL) and machine learning tools, including R and Python",2012,Information Technology Support Services,$25 to $100 million (USD),Information Technology,501 to 1000 Employees,Company - Private,False
Sr. Data Engineer,"Honest Medical Group
","Nashville, TN",$78K - $111K (Glassdoor est.),3.6,"Who You Are

You are devoted, compassionate, and enjoy being on the front lines in healthcare, changing the lives of your patients. You are passionate about getting to the root cause of a patient's conditions, removing social determinants of healthcare, and ensuring the highest possible quality of life for those in your care. You don't want to sacrifice quality over quantity, and you aim to provide the same level of care and commitment to your patients that you would to your own family member.

Does this sound like you? If so, we should talk.




Who We Are

We are Honest Medical Group, a groundbreaking team of health care professionals focused on making a major impact in health care. At Honest, we align every aspect of our company to support patients and providers. We are devoted to purpose and inspired by innovation. We embrace our communities and lead with kindness. We drive health improvements, create a seamless member experience, and eliminate unnecessary cost. We listen to the needs of our patients and our employees—continually working to push beyond the status quo.

For us, it's all in an Honest day's work.

Your Role

The Sr. Data Engineer will be an integral member of the IT organization at Honest which ultimately will strive to help those organizations by creating new solutions and integrating with existing solutions to improve efficiencies with the least disruption to existing workflows. This position offers the opportunity to build solutions that focus on the user needs and experience.

This is an onsite position, requiring an in-office presence 4 days/ a week.
Primary Functions of the Sr. Data Engineer Include:
Design, develop, and maintain cloud data lakes and data warehouses to support business requirements.
Create complex ELT/ETL scripts to perform data integration to data lakes and data warehouses.
Work with healthcare data sets and implement backend business logic, databases, APIs, and data workflows.
Perform data analysis on healthcare data (medical claims, Rx, CMS) to derive meaningful analysis for business needs.
Research emerging cloud-related technologies.
Work as part of a development team participating in various development-related meetings, including but not limited to daily stand-up meetings, spring planning, reviews, and commentary.
Impact the design of platforms and components.
Design and implement solutions to user submitted analysis tasks.
Test and address any issues in work and material as well as the work of others.
Implement APIs for needed application functions.
Work on backlog items as they are being prepared for development.
Perform other related responsibilities as assigned.
How You Qualify

You reviewed the Who You Are section of this job posting and immediately felt the need to read on. This makes you a match for our innovative culture. You accept things change quickly in a startup environment and are willing to pivot quickly on priorities.

Bachelor's degree in Computer Science, Engineering (with 5+ years in the data field), or related field
5+ years of data management/engineering experience
2+ years of experience in cloud data warehouses like Snowflake or Redshift
Advanced and hands-on experience with Python, JavaScript, and SQL required
3+ years of experience with AWS for developing applications that include services like S3 or Lambda
Strong knowledge and experience with healthcare data sets and implementations of backend business logic, databases, APIs, and data workflow queries
Database CI/CD knowledge is a plus
Able to perform code reviews for other developer's work
Ability to utilize technical creativity and operate independently
Ability to work as a team effectively
Ability to manage multiple priorities and demands daily
Must be able to work with users at all levels of skills and abilities
Works well and is effective in a dynamic, face-paced environment, adaptable to shifting priorities


How You are Supported
As a full-time team member, you will benefit from Honest's exceptional total rewards package, including competitive base pay with bonuses, paid time off starting at 4 weeks for full time employees, 12 paid holidays per year, reimbursement for continuing medical education, 401k with match, health, dental, and vision insurance.
As a part-time team member, you will benefit from Honest's total rewards package, including competitive base pay with bonuses, pro-rated paid time off, paid holidays, reimbursement for continuing medical education, 401k with match.
Family friendly policies that support paid parental leave and flexible work arrangements
As a team member you'll be supported by our robust commitment to training and development that starts with onboarding and continues throughout your career with Honest
You will collaborate with like-minded healthcare professionals who, like you, understand the importance and value of Honest's high-quality, value-based, care model.

Honest is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics.

Honest is committed to working with and providing reasonable accommodations to job applicants with physical or mental disabilities. Applicants with a disability who require a reasonable accommodation for any part of the application or hiring process should email careers@HonestMedicalGroup.com for assistance. Reasonable accommodation will be determined on a case-by-case basis.",2021,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,201 to 500 Employees,Company - Private,True
"Data Engineer (Associate Consultant), June 2024","UDig
","Nashville, TN",$67K - $94K (Glassdoor est.),4.4,"Can UDig It?

UDig designs, builds, and implements technology solutions that deliver on business objectives. People join our team because they are excited to have an impact on the future of our organization, passionate about delivering meaningful results, and energized by solving complex problems. Oh, and they like working with other driven, smart, and authentic people!

UDig is proud to be recognized as a ""Best Places to Work"" in Virginia and Tennessee. We're committed to fostering a transparent environment where leadership is accessible, professional development opportunities are abundant, and you are empowered to achieve your career goals. You'll collaborate, develop deep relationships with teammates, and accelerate your success while having fun!

If you're graduating in May 2024 and excited by the idea of impacting organizations by building data solutions to achieve business goals, you should consider joining our growing technology team.




How Things Go Down

As a new, entry-level teammate, you'll take part in our ""Breaking Ground"" training program designed to help you quickly get up-to-speed on UDig's delivery approach within a project team. The program covers:

UDig delivery process and methodologies such as gathering requirements and delivering projects using agile
Technical guidance and instruction on the best practices from Data leaders at UDig
Delivering executive and technical presentations
Coaching to prepare you to for success on your first client project at UDig

A typical day might entail:

Project standups and check-ins
Design and development of data pipelines, BI reports, and more
Planning and participating in project demos
Contributing to internal UDig projects
Career and job growth through UDig-provided training
Creating long-lasting friendships with teammates through fun activities as well as your projects (including social events, winning a prize for guessing the weight of pumpkin, or sharing experience on cool tech side projects)

UDig believes it is important for Associate Consultants going through our Breaking Ground program to reside in one of our major markets (Richmond, VA or Nashville, TN metro area) for at least the first year of employment.

Want to learn more? Hear directly from our teammates by checking out our 'A Day in the Life' blog series: https://www.udig.com/digging-in/breaking-ground-2023/




Sound Interesting? Here's the Technical Piece

Below are a few boxes you should be able to check if you're interested: Don't check every box? Go ahead and apply!

1+ year of experience with relational database management systems such as Microsoft SQL Server, MySQL, or Oracle
Understanding of the full lifecycle of design, development, and implementation of data solutions including architecture design, development, testing
Some experience in ETL development or reporting is a plus
Ability to present technical ideas and high-level concepts and solutions to internal and external team members with varying degrees of technical knowledge
Bachelor's Degree in in computer science, information technology, or any science or business discipline
Ability to take your work seriously but also seriously enjoy a good time with your UDig colleagues



What's in It For You?

At UDig, you will build your career alongside talented and experienced developers while gaining experience and having fun! We provide continuous challenges and professional development opportunities. Additionally, we offer:

Competitive salary, merit reviews, and career advancement paths
Flexible, hybrid environment
Individual $1500 Training Budget
Regular team building and social activities (virtual and/or in-person)
Transparent culture with strong communication and access to leadership
Great benefits like
Generous Paid Time Off, company holidays, and parental leave
Multiple Single and Family Health Insurance plans to choose from
Dental & Vision coverage
Short-Term and Long-Term disability
Optional accident and critical illness coverage
Matching 401(k)

...and more!",2001,Business Consulting,$5 to $25 million (USD),Management & Consulting,51 to 200 Employees,Private Practice / Firm,True
SiteOps Data Center Operations Engineer,"Meta
","Gallatin, TN",$67K - $99K (Employer est.),3.9,"Meta is seeking an entry level engineer to apply their technical skills in a fast-paced and complex environment. Having a working knowledge of server hardware and the desire to participate in projects at a large-scale data center is central to this role. This position will work to resolve and diagnose server issues at scale, escalate issues and work with remote engineering teams. Additionally, this role will work within the rack lifecycle processes with a focus on helping build out and enable cloud scale compute and storage environments. Solid communication skills are a requirement for this role. This person should enjoy working in a fast-paced environment where adaptability and flexibility will be key to their success. The successful candidate will be able to work independently and also within groups.



SiteOps Data Center Operations Engineer Responsibilities:

Work within Meta's ticketing system in support of the health of Meta's server fleet
First point of contact for break fix technicians
Accountable for assisting with projects (new capacity as well as retrofits) and repairs throughout the data center
Understand and initial analysis to debug hardware, and Linux OS related issues
Demonstrate personal leadership Identifying and helping to create documentation for the global data center knowledge base
Assist with process improvements and best practices in data center operations
Participate in on-call rotation (once a month on call for a week after hours, first point of contact)




Minimum Qualifications:

Currently has, or is in the process of obtaining, an Associate’s, Bachelor's, or Master's degree in technical field, or equivalent experience/certification
Knowledge of Linux and server hardware repairs
Must obtain work authorization in the country of employment at the time of hire and maintain ongoing work authorization during employment
Experience in at least one of the following core areas: Networking, Programming/Scripting, Hardware and OS repair
Working conceptual knowledge of developing in Python, SQL, and/or shell scripting
Working conceptual knowledge of technologies such as HTTP, DNS, RAID, and DHCP






About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.



Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",2004,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer - Tennessee Population Health Consortium,"University of Tennessee Health Science Center
","Memphis, TN",$50K - $80K (Glassdoor est.),3.8,"Data Engineer - Tennessee Population Health Consortium

- 22000002IJ


Salary Commensurate with Education and Experience.




THIS IS A GRANT FUNDED POSITION.




JOB SUMMARY/ESSENTIAL JOB FUNCTIONS: Under the direction of the assigned supervisor, this position will support the work of the TN-PHC initiatives and Tennessee Population Health Data Network (TN-POPnet). This position will be responsible for co-managing the EHR & claims data extraction, integration, and standardization and provide direct support to UTHSC in the development of research projects.

DUTIES AND RESPONSIBILITIES:

Assists in general management of the TN-POPnet database.
Assists in migrating electronic health records data from various clinics/hospitals and healthcare vendors across secure servers into our database.
Creates scripts and tooling to clean raw data from data providers.
Utilizes common data models like OMOP to simplify data linkages, creating data extracts and reports.
Creates data architecture for data network to enhance reporting and analysis capabilities.
Assists in onboarding new registry data providers and working closely with data providers regarding data requirements, feedback, and deliverables.
Collaborates with UT information technology and the Center for Biomedical Informatics at UTHSC to troubleshoot data-related issues.
Provides project status reports to TN-PHC management and collaborators.
Performs administrative duties related to research projects including paperwork preparation for IRB approvals.
Creates data extracts and analytical files for individual projects.
Assists in building and maintaining analytical dashboards for statistical & performance metrics using Power BI.
Develops research designs and analysis plans in collaboration with the study investigators.
Creates appropriate data visualization (tables, figures, etc.) and other research-related materials for scientific papers and grant applications.
Manages development, programming and improvement of the Heart Health Message Program and other text messaging services.
Performs other related duties as assigned.




MINIMUM REQUIREMENTS:




EDUCATION: Master’s Degree in statistics, mathematics, data analytics, management information systems, life sciences or engineering. (TRANSCRIPT REQUIRED)




EXPERIENCE: Four (4) years of experience in data analytics. Must be proficient in statistical methods (ANOVA, Regression analysis, Trees, Clustering, SVM, NLP, Ensemble methods) as well as statistical software (R, SAS, JMP). High proficiency in SQL, use of subqueries, aggregates, cursors and test scripts, use of Linux command line, REDCap and Twilio.




KNOWLEDGE, SKILLS, AND ABILITIES:

Proficient in Oracle SQL Developer, R scripting, Tableau, Shell Scripting, server administration/operation/navigation, general software interfacing, statistical analysis & data cleaning.
Ability to optimize different analyses by using multiple machine threads/cores/processors by utilizing parallel computing/high-performance computing technologies such as Spark, Hadoop, and web services from Microsoft Azure and/or Amazon Web Services.
Proficient in statistical methods (ANOVA, Regression analysis, Trees, Clustering, SVM, NLP, Ensemble methods) as well as statistical software (R, SAS, JMP).
Ability to implement OMOP Common Data Model.
Excellent communication skills, personal, written, and presentation skills are essential.
Ability to work with diverse faculty and staff of various experience levels.
Analytical and problem-solving skills.



Job Other Professional
Primary Location US-Tennessee-Memphis
Organization Medicine-Gen Internal Med
Campus/Institute Memphis
Schedule Full-time
Job Posting Oct 25, 2023, 2:23:47 PM",-1,Colleges & Universities,$1 to $5 billion (USD),Education,10000+ Employees,College / University,False
Spark + Java Engineer/Big Data Engineer,"Intellibee
","Morristown, TN",$84K - $136K (Glassdoor est.),4.5,"Required skills: (USC/GC Only)

Spark + Java
Deep Knowledge in Spark(8+years )
Must have Health care exp
Hands on exp over using the core Spark APIs and processing data on an EMR cluster.
Experience in Developing Spark applications using Spark – SQL
Spark Core APIs, Data Frames, Spark-SQL.",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,False
Principal Hadoop Data Engineer,"HCA Healthcare
","Nashville, TN",$89K - $118K (Glassdoor est.),3.3,"Introduction

Last year our HCA Healthcare colleagues invested over 156,000 hours volunteering in our communities. As a Principal Data Engineer with HCA Healthcare you can be a part of an organization that is devoted to giving back!

Benefits

HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:

Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing

401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)

Employee Stock Purchase Plan with 10% off HCA Healthcare stock

Family support through fertility and family building benefits with Progyny and adoption assistance.

Referral services for child, elder and pet care, home and auto repair, event planning and more

Consumer discounts through Abenity and Consumer Discounts

Retirement readiness, rollover assistance services and preferred banking partnerships

Education assistance (tuition, student loan, certification support, dependent scholarships)

Colleague recognition program

Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)

Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.

Learn more about Employee Benefits

Note: Eligibility for benefits may vary by location.


Would you like to unlock your potential with a leading healthcare provider dedicated to the growth and development of our colleagues? Join the HCA Healthcare family! We will give you the tools and resources you need to succeed in our organization. We are looking for an enthusiastic Principal Data Engineer to help us reach our goals. Unlock your potential!

Job Summary and Qualifications

HCA Healthcare ITG

Job Summary:

The role requires working closely with others, frequently in a matrixed environment, and with little supervision. As a Principal Data Engineer/Architect level, the role requires 'self-starters' who are proficient in problem solving and capable of bringing clarity to complex situations. It requires contributing to strategic technical direction and system architecture approaches for individual projects and platform migrations. The culture of the organization places an emphasis on teamwork, so social and interpersonal skills are equally important as technical capability. Due to the emerging and fast-evolving nature of GCP/Big Data technology and practice, the position requires that one stay well-informed of technological advancements and be proficient at putting new innovations into effective practice.

Responsible for leading GCP development efforts, driving adoption and appropriate use of technology and consulting on internal and external development efforts to ensure code quality and sound architecture. This position that assumes the responsibility for project success and the upward development of team members technical skills. They are the development team's point of contact that must interface with business partners of varying roles ranging from technical staff to executive leadership. In addition, this candidate will have a history of increasing responsibility in a multi-role team. This position requires a candidate who can analyze business requirements, perform design tasks, construct, test, and implement cutting-edge technical data solutions with minimal supervision.

As a Principal Data Engineer/Architect, you will work closely with all team members to create a modular, scalable solution that addresses current needs, but will also serve as a foundation for future success. The position will be critical in building the team’s engineering practices in test driven development, continuous integration, and automated deployment and is a hands-on team member who actively coaches the team to solve complex problems. She / he will be responsible for the design, development, performance and support of the Cloud Platform components.

This candidate will have a record of accomplishment of participation in successful projects in a fast-paced, mixed team (consultant and employee) environment. In addition, the applicant must be willing to train and mentor other developers to prepare them for assuming the responsibilities.

General Responsibilities:

Responsible for building and supporting a GCP/Hadoop-based ecosystem designed for enterprise-wide analysis of structured, semi-structured, and unstructured data.
Bring new data sources into GCP/HDFS, transform and load to databases.
Lead projects in delivering the data and projects on-time
Closely collaborates with team members to successfully execute development initiatives using Agile practices and principles
Leads efforts to design, development, deploy, and support software systems
Experience with HL7, FHIR, and Whistle mapping.
Collaborates with business analysts, project lead, management and customers on requirements
Participates in large-scale development projects involving multiple areas outside of core team
Designs fit-for-purpose products to ensure products align to the customer's strategic plans and technology road maps
Demonstrates deep understanding and coaches’ value-based decision making and Agile principles across teams
Coaches team on clinical data, existing system structure, constraints and deficiencies with product
Shares knowledge and experience to contribute to growth of overall team capabilities
Participates in the deployment, change, configuration, management, administration and maintenance of deployment process and systems
Work closely with management, architects and other teams to develop and implement the projects.
Actively participate in technical group discussions and adopt any new technologies to improve the development and operations.
Focuses on customer satisfaction
Rapidly prototypes and delivers just-in-time solutions
Gather requirements, designs, constructs and delivers solutions with minimal team interaction
Works in an environment with rapidly changing business requirements and priorities
Demonstrates deep understanding and acts as a leader in the team’s continuous integration and continuous delivery automation pipeline
Work collaboratively with Data Scientists, business, and IT leaders throughout the company to understand Cloud/Big Data needs and use cases.

Education, Experience and Certifications:

Bachelor's Degree in computer science or related field – Required
Master's Degree in computer science or related field – Preferred
3+ years of experience in Data Engineer – Required
1+ year(s) of experience in Healthcare – Preferred
10+ years of experience in Information Technology – Required
GCP Cloud Professional Data Architect certification – Preferred
GCP Cloud Professional Data Engineer certification – Preferred

Other Required Qualifications:

A successful candidate will have:




Strong understanding of best practices and standards for GCP application design and implementation.
Two Year of hands-on experience with GCP platform and experience with many of the following components:
GCS, Cloud Run, Cloud Functions
Bigtable, Cloud SQL
Kafka, Pub/Sub
Python, Golang, Spark, Scala or Java
BigQuery, Dataflow, Data Fusion
CICD process and Logging & Monitoring
OpenShift, Docker
Experience with Unstructured Data, Real-Time Streaming with GCP
Ability to multitask and to balance competing priorities.
Requires strong practical experience in agile application development, file systems management, and DevOps discipline and practice using short-cycle iterations to deliver continuous business value.
Knowledge of all facets of GCP Cloud ecosystem development including ideation, design, implementation, tuning, and operational support.
Ability to define and utilize best practice techniques and to impose order in a fast-changing environment. Must have strong problem-solving skills.
Strong verbal, written, and interpersonal skills, including a desire to work within a highly-matrixed, team-oriented environment.

A successful candidate may have:

Experience in Healthcare Domain
Experience in Patient Data
Experience with Natural Language Processing (NLP)
Azure/AWS Cloud experience
Hands-on experience with Cloudera Distributed Hadoop (CDH)

Hardware/Operating Systems:

Linux, UNIX
GCP
Distributed, highly-scalable processing environments

Databases:

NoSQL, Hbase, Cassandra, MongoDB, Cosmos, In-memory, Columnar, other emerging technologies
Build Systems – TFS, Github
Ability to integrate tools outside of the core Cloud ecosystem

Physical Demands/Working Conditions

Prolonged sitting or standing at computer workstation including use of mouse, keyboard, and monitor.
Requires ability to provide after-hours support.
Occasional Travel: The job may require travel from time- to-time, but not on a regular basis.

HCA Healthcare’s Information Technology Group (ITG) delivers healthcare IT products and services to HCA Healthcare's portfolio of business and partners, including Parallon, HealthTrust and Sarah Cannon.

For decades, ITG has been a pioneer in the industry, leading the transformation of healthcare into a new era of quality and connectivity. ITG relies on the breadth of the organization and depth of technical expertise to advance and enhance today’s healthcare and to enable our physicians and clinicians to provide world-class, innovative care for patients.

ITG employees rally around the noble cause of transforming healthcare through technology and find inspiration in the meaningful work they do—creating a culture that follows our mission statement which begins by saying “above all else we are committed to the care and improvement of human life.”

If you want a career in technology and have a heart for healthcare, apply your expertise to a mission that matters.

HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.

""There is so much good to do in the world and so many different ways to do it.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder

Be a part of an organization that invests in you! We are reviewing applications for our Principal Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your application and help us raise the bar in patient care!

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",1968,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Company - Public,True
Data Center Specialist / Senior Engineer,Network Data Source,"Memphis, TN",$69K - $104K (Glassdoor est.),-1.0,"Please forward your resume to contact@networkdatasource.com.



Job Description
Plans and Executes a Variety of Highly Complex Assignments Associated with Managing and Controlling Computer Operating Systems

Sets Up and Maintains More than One Type of Computer System

Analyzes System Faults and Troubleshoots, and Runs Diagnostic Tests on Operating Systems and Hardware to Detect Problems

Evaluates and Installs Developed Software during Various Phases of Testing

Coordinates the Remote Testing of Products in Other Areas

Reviews and Prepares Documentation for Systems, Tests, and Installation of Software

Investigates and Recommends Methods and Techniques for Obtaining Solution

Initiates Preventative Maintenance on the Operating Systems as well as Repairs System/Storage Problems

Administers and/or Oversees System/Storage Solutions for Multiple Projects with Varying Schedules which are Critical to the Success of Programs

Plans System/Storage Requirements for Individual Projects

May Participate in the Creation/Maintenance of the Overall Management Plan",-1,Information Technology Support Services,$1 to $5 million (USD),Information Technology,1 to 50 Employees,Contract,False
Senior Data Engineer (Remote Available),"Vanderbilt University Medical Center
","Nashville, TN",-1,3.7,"Discover Vanderbilt University Medical Center: Located in Nashville, Tennessee, and operating at a global crossroads of teaching, discovery, and patient care, VUMC is a community of diverse individuals who come to work each day with the simple aim of changing the world. It is a place where your expertise will be valued, your knowledge expanded, and your abilities challenged. Vanderbilt Health recognizes that diversity is essential for excellence and innovation. We are committed to an inclusive environment where everyone has the chance to thrive and where your diversity of culture, thinking, learning, and leading is sought and celebrated. It is a place where employees know they are part of something that is bigger than themselves, take exceptional pride in their work and never settle for what was good enough yesterday. Vanderbilt’s mission is to advance health and wellness through preeminent programs in patient care, education, and research.
Organization:
HealthIT Data Platform Svcs
Job Summary:
JOB SUMMARY
The Data Platform Services team is seeking an experienced Data Engineer with an inquisitive and analytical mindset to join our team. In your role, you will be responsible for developing, maintaining, and optimizing our cloud-based data infrastructure, as well as designing and implementing efficient data extraction and ingestion processes. You will also be responsible for working with stakeholders to identify data needs, investigating opportunities to improve platform scalability, building generic solutions for patterned problems, and ensuring data accuracy and integrity.
.
KEY RESPONSIBILITIES
Independently and full proficient to:
Design and develop performant data pipelines that support a variety of source system types (flat files, APIs, databases, etc.)
Troubleshoot complex issues with production pipelines and work with internal stakeholders to deploy fixes
Develop tools and services used by other teams to create, test, and deliver data-related assets
Design and develop cloud infrastructure-as-code to support the data platform
Participate in code review sessions for merge requests and assist in mentoring developers in best development practices
May assist with onboarding and training new employees as needed
TECHNICAL CAPABILITIES
Minimum Qualifications
Bachelor's Degree
4+ years C# and/or Python in an OOP paradigm experience
2+ years with SQL experience
2+ years implementing cloud solutions with Azure, AWS, or GCP
2+ years with containerization with Docker or Podman
Preferred Qualifications
2+ years with CI/CD automation in GitLab, GitHub, or Azure DevOps
Experience with REST data services, APIs, and microservices
Experience with Infrastructure as Code solutions using Terraform, Bicep, or ARM
Experience with Git
Bonus Qualifications
Experience with Databricks or Apache Spark
Experience with PowerShell and/or Bash
GitHub profile link to some personal code examples
Our professional administrative functions include critical supporting roles in information technology and informatics, finance, administration, legal and community affairs, human resources, communications and marketing, development, facilities, and many more.
At our growing health system, we support each other and encourage excellence among all who are part of our workforce. High-achieving employees stay at Vanderbilt Health for professional growth, appreciation of benefits, and a sense of community and purpose.
Core Accountabilities:
Organizational Impact: Independently delivers on objectives with understanding of how they impact the results of own area/team and other related teams. Problem Solving/ Complexity of work: Utilizes multiple sources of data to analyze and resolve complex problems; may take a new perspective on existing solution. Breadth of Knowledge: Has advanced knowledge within a professional area and basic knowledge across related areas. Team Interaction: Acts as a ""go-to"" resource for colleagues with less experience; may lead small project teams.
Core Capabilities :
Supporting Colleagues: - Develops Self and Others: Invests time, energy, and enthusiasm in developing self/others to help improve performance e and gain knowledge in new areas. - Builds and Maintains Relationships: Maintains regular contact with key colleagues and stakeholders using formal and informal opportunities to expand and strengthen relationships. - Communicates Effectively: Recognizes group interactions and modifies one's own communication style to suit different situations and audiences. Delivering Excellent Services: - Serves Others with Compassion: Seeks to understand current and future needs of relevant stakeholders and customizes services to better address them. - Solves Complex Problems: Approaches problems from different angles; Identifies new possibilities to interpret opportunities and develop concrete solutions. - Offers Meaningful Advice and Support: Provides ongoing support and coaching in a constructive manner to increase employees' effectiveness. Ensuring High Quality: - Performs Excellent Work: Engages regularly in formal and informal dialogue about quality; directly addresses quality issues promptly. - Ensures Continuous Improvement: Applies various learning experiences by looking beyond symptoms to uncover underlying causes of problems and identifies ways to resolve them. - Fulfills Safety and Regulatory Requirements: Understands all aspects of providing a safe environment and performs routine safety checks to prevent safety hazards from occurring. Managing Resources Effectively: - Demonstrates Accountability: Demonstrates a sense of ownership, focusing on and driving critical issues to closure. - Stewards Organizational Resources: Applies understanding of the departmental work to effectively manage resources for a department/area. - Makes Data Driven Decisions: Demonstrates strong understanding of the information or data to identify and elevate opportunities. Fostering Innovation: - Generates New Ideas: Proactively identifies new ideas/opportunities from multiple sources or methods to improve processes beyond conventional approaches. - Applies Technology: Demonstrates an enthusiasm for learning new technologies, tools, and procedures to address short-term challenges. - Adapts to Change: Views difficult situations and/or problems as opportunities for improvement; actively embraces change instead of emphasizing negative elements.
Position Qualifications:
Responsibilities:
Certifications:
Work Experience:
Relevant Work Experience

Experience Level:
5 years
Education:
Bachelor's
Vanderbilt Health recognizes that diversity is essential for excellence and innovation. We are committed to an inclusive environment where everyone has the chance to thrive and to the principles of equal opportunity and affirmative action. EOE/AA/Women/Minority/Vets/Disabled",1874,Health Care Services & Hospitals,$1 to $5 billion (USD),Healthcare,10000+ Employees,Nonprofit Organization,False
Sr. Data Engineer,"Ingram Content Group
","La Vergne, TN",$79K - $114K (Glassdoor est.),3.6,"Job Description


Ingram Content Group (ICG) is currently recruiting for a Senior Data Engineer join our team in LaVergne, TN (Greater Nashville area). This individual will work to deliver enterprise grade data products and solutions with high customer impact. They’ll implement the proposed architecture and contribute to development activities with a specialization in at least one of the following:, one major database platform (e.g, MySQL, Oracle, SQL Server), and Event driven data movement patterns of integration using streaming (e.g. Kafka) and transformations using applications such as NiFi. The Senior Data Engineer also performs all aspects of the development life cycle. Finally, they will deliver results through independent contributions and through mentoring and collaborating with other engineers.


Want to help explore and build new ways to deliver content to the world?

At Ingram, our Technology team is blazing a trail by providing content distribution services to thousands of publishers with key initiatives around business intelligence, machine learning, continuous integration and omnichannel. We support diverse people and technology that highlights innovation through SaaS platforms, metadata, cloud, and containerization. Our teams are agile, and emphasize authenticity, creativity, and transparency upon a fact-based foundation.

The world is reading, and it is our goal to connect as many people as possible to the content they want in the simplest ways. If you are an IT professional who strives to deliver results through collaborative partnerships, understanding what drives business, and enjoys working in a connected culture, we can’t wait to meet you!

The ideal candidate will have the following minimum qualifications:

Bachelor’s Degree in Computer Science or related field or directly related year for year experience
6 + years’ experience in designing, developing, implementing, and supporting enterprise level IT solutions

We have a preference for:

Experience with Kafka, setting up event driven architecture for data movement
Experience with database application development experience
Exposure to NiFi or data flow automation tools
Experience with writing and optimizing existing complex SQL queries
Experience with columnar databases or non-relational databases
Knowledge of Linux commands and scripting (logs, piping, redirections, grep, sed, yum)
Knowledge of scripting languages (Python, Perl, shell scripts)
Experience with architecting data models and interpreting business needs into technical requirements for data visualization or reporting
Experience with collaborating in a cross-functional capacity across teams, building consensus and executing the necessary vision for the project deliverables.
Knowledge of JIRA, agile methodologies and Confluence

The Sr Data Engineer key responsibilities are:

Serves as Designer/Architect/Engineer for a major enterprise IT Data Lake house.
Creates, develops, modifies, and maintains data pipelines and patterns for application or analytical usage across the enterprise establishing best practices.
Assembles large and complex data sets that meet business requirements.
Coordinates and communicates with users, developers, and product owners to gather and understand requirements.
Develops new design patterns, standards, documentation, etc. and works with other developers for implementation.
This list is not exhaustive



Additional Information


Perks/Benefits:

A highly competitive compensation package with generous benefits beginning first day of employment for Medical/Prescription Drug plans, HSA, Vision, Dental and Health Care FSA.
15 vacation days & 12 sick days accrued annually and 3 personal days
401K match, Life and AD&D, Employee Assistant programs, Group Legal, & more
Wellness program with access to onsite gym and basketball court for associates
Avid reader? Numerous opportunities to engage with books and authors
Free card registration at the Nashville Public Library
Discounted offers to self-publish with IngramSpark®!
Encouraged continued education with our tuition reimbursement program
Financial and in-kind opportunities to engage with non-profits in your community
Company match program for United Way donations
Volunteer opportunities and in-kind drives for non-profits throughout the year
Take breaks or brainstorm in our game room with ping pong & foosball
Casual Dress Code

The world is reading, and Ingram Content Group (“Ingram”) connects people with content in all forms. Providing comprehensive services for publishers, retailers, libraries and educators, Ingram makes these services seamless and accessible through technology, innovation and creativity. With an expansive global network of offices and facilities, Ingram’s services include digital and physical book distribution, print-on-demand, and digital learning. Ingram Content Group is a part of Ingram Industries Inc. and includes Ingram Book Group LLC, Ingram Publisher Services LLC, Lightning Source LLC, Ingram Library Services LLC, Tennessee Book Company LLC, Ingram Content Group UK Ltd. and Ingram Content Group Australia Pty Ltd.

Ingram Content Group LLC is an affirmative action/equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, work related mental or physical disability, veteran status, sexual orientation, gender identity, or genetic information.

EEO/AA Employer/Vet/Disabled
We participate in EVerify.
EEO Poster in English
EEO Poster in Spanish",1964,Publishing,Unknown / Non-Applicable,Media & Communication,1001 to 5000 Employees,Company - Private,False
Data Engineer II,"Qsource
","Memphis, TN",$75K - $101K (Glassdoor est.),3.3,"Job Summary

The Data Engineer II is responsible for the design and implementation of robust data infrastructure. This role is pivotal in transforming healthcare data into actionable insights, ultimately enhancing the quality of patient care and organizational efficiency.

Essential Duties and Responsibilities

Collaborate with interdisciplinary teams to understand healthcare data requirements and design effective data pipelines.
Develop, test, and maintain data architectures, ensuring secure and compliant handling of sensitive healthcare information.
Implement and optimize ETL processes to facilitate the seamless extraction, transformation, and loading of healthcare data.
Work closely with healthcare professionals and data analysts to understand their unique data needs and provide tailored solutions.
Monitor and troubleshoot data issues, ensuring data accuracy, compliance with regulations, and maintaining patient privacy.

Stay abreast of healthcare industry regulations, standards, and best practices to continually enhance data systems.

Knowledge, Skills & Abilities

Excellent computer skills (MS Word, Excel, PowerPoint).
Excellent oral, written, and customer service-oriented communication skills.
Excellent organizational skills with the ability to respond to and coordinate multiple activities simultaneously under short time frames.
Excellent and demonstrated critical thinking ability with keen attention to detail.
Must be able to work both collaboratively and independently and communicate/present professionally with internal and external customers.
Excellent problem-solving skills and the ability to work independently or in a team setting.

Education, Experience, & Licensing Requirements

Education

Bachelor’s degree in computer science, Health Informatics, information technology, or an equivalent combination of education and experience required.

Experience

Three to five years of experience as a Data Engineer in a healthcare or life sciences setting.
Two years of experience with healthcare information systems, EMRs, and other clinical data sources.
Two years of experience with cloud platforms (e.g., AWS, Azure, GCP) and healthcare-specific data storage solutions.
Proficiency in SQL, Python, and other relevant programming languages.
Strong understanding of healthcare data standards, interoperability, and security.

Travel Requirements

Employee will work remotely from a home-based office. Infrequent travel may be required.

Physical Requirements

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.

Employee will constantly communicate with others regarding employment related information or instruction and must be able to exchange accurate information in these situations.
This role requires constant use of standard office equipment such as computers and telephones to receive and share information.
Employee must be able to read and interpret information displayed on a computer screen.
Employee must be able to remain in a stationary position for extended periods of time.
This role occasionally requires the employee to lift light objects up to 25 pounds.",1973,Civic & Social Services,Unknown / Non-Applicable,Nonprofit & NGO,51 to 200 Employees,Nonprofit Organization,True
Risk Data Engineer,"AllianceBernstein
","Nashville, TN",$130K - $140K (Employer est.),3.7,"Who We are:
As a leading global investment management firm, AB fosters diverse perspectives and embraces innovation to help our clients navigate the uncertainty of capital markets. Through high-quality research and diversified investment services, we serve institutions, individuals, and private wealth clients in major markets worldwide. Our ambition is simple: to be our clients’ most valued asset-management partner.

With over 4,400 employees across 51 locations in 25 countries, our people are our advantage. We foster a culture of intellectual curiosity and collaboration to create an environment where everyone can thrive and do their best work. Whether you're producing thought-provoking research, identifying compelling investment opportunities, infusing new technologies into our business, or providing thoughtful advice to clients, we’re looking for unique voices to help lead us forward. If you’re ready to challenge your limits and build your future, join us.
Who You'll Work With:
We are seeking a Mid Level Data Engineer based in Nashville to join our MAS Technology department in Global Technology & Operations
The Multi-Asset Technology group supports quantitative research, model development, and portfolio management processes for Multi-Asset Solutions (MAS) unit of AB. Specifically, we directly support the Dynamic Asset Allocation (DAA) group, the Outcome-Oriented Product group, the Defined-Contribution Retirement Solutions group, the Custom Alternative Solutions group, the Index and Factor Investment group, and other quantitative investment groups.
What You'll Do:
The Risk Data Engineer is a key role for our firm providing data pipelines and data quality control between our internal data warehouse and investment reporting platform and an external investment risk engine.
Applications and business or enterprise functions the role supports
MAS actively manages over $100 billion for global institutions, high net worth individuals and retail mutual fund investors. The group’s macro and quantitative research insights are used to develop innovative investment products and drive investment decisions. We assess both short and long-term outlooks for risk and return across all major markets, including Equities, Fixed Income, Currencies, Commodities, Credit, Real Assets, and Alternatives. We use quantitative and fundamental research techniques that are highly adaptive to the current market environment. We combine these views with the specific needs of clients to develop custom portfolio solutions.
Over the past couple of years, MAS has grown rapidly and continues to add new sources of market data, new security instruments, and new quantitative tools to its investment and research process. The diversity and complexity of the investment types requires a robust data acquisition, mapping and quality control process between our internal systems and an external risk analytics engine.
Develop and enhance our investment risk platform interfaces. Perform code and design reviews ensuring adherence to architecture principles, while meeting business use case requirements. Collaborate with an offshore development and data oversight team to execute integration and regression tests prior to code release.
Develop data quality tests and related reports to identify interface failures and/or risk and performance data anomalies. Build workflow automation tools to recalculate daily or historical risk / performance numbers once problem input data has been remediated.
Manage vendor and / or upstream application functional defects and / or operational outages/incidents, ensuring timely recovery / issue resolution accompanied by a thorough root cause analysis.
Develop a new portfolio risk and performance reporting platform which aggregates security level risk exposures from the external risk engine and returns from our internal performance engine.
(if applicable)?
Risk and performance data is perhaps the most challenging data domain in any financial industry database in that it requires the accuracy of all data which can impact an investment’s future cash flow. This project will expose the candidate to the entire investment lifecycle including initial client account set up / new product launch, initial market valuation and risk calculation, ongoing risk and performance monitoring, until final investment maturity or liquidation.
Professional development value of this role (i.e., what learning and professional growth does the role offer the candidate?)
The candidate will have an opportunity to learn or leverage existing skills in SQL, Python, distributed storage and execution platforms, statistical process control, and DataOps methodologies.
The candidate will work closely with professional investment staff and get an opportunity to broaden their financial knowledge across asset classes, markets and instruments
What We're Looking For:
Degree in Computer Science/Engineering, Master’s degree preferred
5+ years experience as a developer involved in enterprise data integration, ideally in the finance industry
5+ years experience programming SQL queries and stored procedures (Microsoft SQL Server or ORACLE)
3+ years experience in Python
2+ years experience using Agile or DevOps methodologies (continuous integration / deployment)
Skills
Strong project management, analytical and quantitative skills
This is a data-centric development role. The candidate must be willing to learn the problem domain; namely, the investment / trade lifecycle, financial instruments and the terms and conditions that impact risk and return.
Candidate must be willing to take full ownership of projects, covering analysis, technical design and implementation, testing, and deployment tasks
Software engineering skills including object-oriented design, application of design patterns
Must demonstrate good communication skills and be comfortable working closely with senior quantitative analysts and business partners
A strong desire to document and share work done to aid in long term support
Candidate must be a self-starter, a dependable partner, and team player
Special Knowledge (if applicable)
Knowledge of financial instruments
Experience with Git/GitHub
Experience with risk platform or market data vendors - MSCI, BarraOne, Bloomberg, Refinitive et. al.
Experience working in the finance industry, demonstrable curiosity in quantitative research and investment
Workflow orchestration tools such as Airflow, Control-M, Autosys
Business intelligence tools such as PowerBI
In accordance with applicable law, the minimum and maximum base annual salary for this role is as follows:
Base Salary Range: $130,000 to $140,000
Actual base salaries may vary based on factors including but not limited to education, training, experience, past performance, and other job-related factors. Base salary is just one component of total compensation at AB, which may include, depending on eligibility, commissions, year-end incentive compensation, short- and long-term incentives and Department-specific awards. In addition AB provides a variety of benefits to eligible employees, including health insurance coverage, an employee wellness program, life and disability insurance, a retirement savings plan, paid holidays, sick and vacation time off
Nashville, Tennessee",1967,Investment & Asset Management,$1 to $5 billion (USD),Financial Services,1001 to 5000 Employees,Company - Public,False
Data Operations Engineer,"ITR
",Tennessee,-1,3.7,"Would need to be able to work onsite in Oak Ridge, TN
No C2C or Sponsorship
Data Operations Engineer

Major Duties/Responsibilities:
You will work independently and/or as part of a team in research, analysis, and operations of backend data flow processes, including analyzing scientific data-related problems and formulating the necessary solutions; using information technologies (i.e., Python and Bash scripting) and learning new technologies; conducting requirements analysis; developing automated workflows; using scripting languages; knowledge of Linux command-line interface; working with open source tools; database relationships and query development; configuring, deploying and executing backend processes on Linux based servers; ability to work with distributed and diversified teams on various data flow processes; ability to multitask; create documentation for developers, other operational team members, and program staff.

We are seeking a self-starter willing to develop expertise in data preparation for archiving and distribution, as well as advanced data tools development and full-stack software development. The following skills and experience are desirable:

Qualifications:

B.S. or currently pursuing B.S. in Computer Science or Information Systems or related field is preferred.
Two years of progressive Linux systems administration, including experience in monitoring and management of data workflows and standards is required.
Internship experience working in a research laboratory.
Experience in working in a Dev/Ops environment is required.
Strong software experience in building data analysis, or automating data workflows using modern technologies.
Experience working with scientific data is a plus.
Knowledge and experience in software languages such as Python and scripting languages is a must.
Knowledge and experience in database applications such as PostGreSQL and database query language.
Knowledge of any of the following is a plus: web servers (Apache, NGINX, Tomcat, etc.), DNS (bind), OpenLDAP, databases (PostGreSQL, MySQL, NoSQL), virtualization and container infrastructure (VMware, Docker, Singularity, Kubernetes), storage and communication protocols (zfs, nfs, ftp, scp, etc.), HPC/cluster technologies (Slurm), and monitoring (Nagios, Checkmk).
Good communication skills in English, both oral and written.
Desire to learn and adopt new tools and technologies as required by the projects.",-1,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,501 to 1000 Employees,Company - Private,True
Systems Engineer II Data Center,"HCA Healthcare
","Nashville, TN",$73K - $96K (Glassdoor est.),3.3,"Introduction

Are you looking for a work environment where diversity and inclusion thrive? Submit your application for our Systems Engineer II opening with HCA Healthcare today and find out what it truly means to be a part of the HCA Healthcare team.

Benefits

HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:

Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing

401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)

Employee Stock Purchase Plan with 10% off HCA Healthcare stock

Family support through fertility and family building benefits with Progyny and adoption assistance.

Referral services for child, elder and pet care, home and auto repair, event planning and more

Consumer discounts through Abenity and Consumer Discounts

Retirement readiness, rollover assistance services and preferred banking partnerships

Education assistance (tuition, student loan, certification support, dependent scholarships)

Colleague recognition program

Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)

Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.

Learn more about Employee Benefits

Note: Eligibility for benefits may vary by location.


We are seeking a Systems Engineer II for our team to ensure that we continue to provide all patients with high quality, efficient care. Did you get into our industry for these reasons? We are an amazing team that works hard to support each other and are seeking a phenomenal addition like you who feels patient care is as meaningful as we do. We want you to apply!

Job Summary and Qualifications

JOB SUMMARY

Provide technical skills that cover a broad range of data center disciplines. Responsible for installation, maintenance, upgrades, and repairs of data center infrastructure.

Must have proficient troubleshooting skills and working knowledge of Data Center practices. Must have a fundamental understanding of Data Center security including HIPAA and SOX.

GENERAL RESPONSIBILITIES

To perform the job successfully, the individual should be able to demonstrate the following skills and competencies:

Proficient working knowledge of hardware platforms – HP ProLiant, Cisco UCS, Dell PowerEdge, IBM P-Series, Cisco Network/SAN switches and routers and Nutanix Systems.
Proficient working knowledge of server hardware components – Processors, Memory, Disk Drives, RAID controllers, I/O Cards, Mainboards.
Fundamental working knowledge of Firmware, RAID configurations, Integrated Lights Out, hardware logs.
Strong working knowledge of copper and fiber optic infrastructure – Cat6, Twinax, Single-mode fiber, multi-mode fiber, rollover, serial. Good understanding of TIA 942 standard.
Working knowledge of Operating systems - Windows OS, Unix / Linux, VMWare ESX
Working knowledge of networking topologies and network protocols including LAN/WAN technologies, TCP/IP, Switches and routers.
Limited 24x7 on call troubleshooting and repair – Must be able to meet established TTR and SLA’s.
Asset Management – Manage inventory of all assets and components in the data center. Update and report on assets to ensure compliance.
Project Management - Manages assigned projects with minimal supervision. Communicates changes and progress; Completes projects on time and within budget.
Leadership - Exhibits confidence in self and others; Inspires and motivates others to perform well; effectively influences actions and opinions of others; Provides vision and inspiration to peers and subordinates. Provides training and mentoring to junior level employees as required.
Requires minimal supervision and fill in for Senior Hardware Engineer as needed.
Customer Service – Responds promptly to customer needs; Responds to requests for service and assistance; meets commitments.
Oral Communications – Speaks clearly and persuasively in positive or negative situations. Written communications – Writes clearly and informatively; Able to read and interpret written information and technical documents/maps. Leadership Skills - Carries out responsibilities in accordance with the organization's policies and applicable laws.
Ethics – Upholds and enforces organizational values and Data Center specific Standards.
Other duties as assigned.

TECHNICAL EXPERIENCE

Hardware: HP Proliant, Cisco UCS, Cisco Nexus, IBM P-Series, Dell PowerEdge

Operating Systems: Current Window OS, AIX / Linux, VMWare ESX, Cisco IOS

Applications/Software/Tools: Microsoft Office, Fluke, Remedy, Fieldview, Nlyte

Networking: LAN/WAN, DHCP, TCP/IP

Certifications: ITIL, Server +, Network +

EDUCATION

College graduate preferred

EXPERIENCE

3-7 years of relevant work experience required

HCA Healthcare has been recognized as one of the Worldâ€™s Most Ethical CompaniesÂ® by the Ethisphere Institute more than ten times. Â In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.


""Across HCA Healthcare’s more than 2,000 sites of care, our nurses and colleagues have a positive impact on patients, communities and healthcare.
Together, we uplift and elevate our purpose to give people a healthier tomorrow.""- Jane Englebright, PhD, RN CENP, FAAN
Senior Vice President and Chief Nursing Executive

If you find this opportunity compelling, we encourage you to apply for our Systems Engineer II opening. We promptly review all applications. Highly qualified candidates will be directly contacted by a member of our team. We are interviewing apply today!

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",1968,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Company - Public,True
Azure Data Engineer,Monogram Health Renal Services,"Brentwood, TN",-1,-1.0,"Position: Azure Data Engineer

The Azure Data Engineer will work with our business operations and technology teams to build out an enterprise-wide Data Warehouse and related systems in the cloud. Will collaborate with our internal teams and 3rd party vendor in building our future state, business process, system interfaces, governance and technology platforms needed to enable a single source of truth for product and customer data, drive a more sophisticated data environment and be positioned to scale for future business growth.

Roles and Responsibilities

In collaboration with our 3rd party vendor, implement strategic roadmap and operational framework for Enterprise Data Management, in partnership with key stakeholders
Collaborate on the strategy on new cloud data stores and migration of existing data in Azure
Work collaboratively with teams to design, document, and ensure continuous improvement of SDLC best practices for data in the cloud
Be an advocate for quality and security through data quality and accuracy validation and auditing of security best practices
Focus on understanding business problems and determine what aspects require optimization; articulate those aspects in a clear and concise manner
Work collaboratively with cross-functional teams to support Data Models in alignment with business needs
Partner with IT, on design and oversight of APIs and other data sharing capabilities in collaboration with short / long term business needs
Partner with IT to integrate new data management technologies and software engineering tools (automation projects, process improvements, etc.) into existing systems to enable single source of truth for product and customer data
Adhere to identified key performance indicators for quality and compliance metrics to ensure data related policies and standards are followed
Acts as a SME to explain all facets of EDM data exchange and processing, business user involvement, and overall architecture
Support Monogram as necessary with any tasks required to deliver excellent personalized kidney care and perform all other duties as assigned
Uphold the mission and values of Monogram Health in all aspects of your role and activities

Position Requirements

BS or equivalent experience in crucial duties and responsibilities
3-5 years’ experience in cloud computing
Solid understanding of enterprise data management in Healthcare Data
Solid understanding of data, databases, data tools (e.g. SQL) and data processing experience
Solid understanding of standard ETL tools and techniques, sourcing, maintaining, and updating data, data warehousing, data cleansing, and other analytical techniques required for data usage.
Experience with database systems, Azure cloud storage, and significant exposure to or experience with modern data and BI platforms (such as Databricks, MSSQL Data Warehouse (Synapse), Snowflake, and Tableau).
Previous experience with data migration to cloud-based environment
Interest and passion in designing and implementing data management, querying, and storage, with a particular focus on purpose-built data stores.
Functional knowledge of data visualization tools such as PowerBI and Tableau.
Strong intuition for business and analytical skills
Team player with excellent communication skills
This role is eligible for telecommuting in accordance with the policy.

Benefits

Opportunity to work in a dynamic, fast-paced and innovative value-based provider organization that is transforming the delivery of kidney care
Competitive salary
Comprehensive medical, dental, vision and life insurance
Flexible paid leave and vacation policy
401(k) plan with matching contributions

About Monogram Health

Monogram Health is a next-generation, value-based chronic condition risk provider serving patients living with chronic kidney and end-stage renal disease and their related metabolic disorders. Monogram seeks to fill systemic gaps and transform the way nephrology, primary care and chronic condition treatment are delivered. Monogram’s innovative, in-home approach utilizes a national nephrology practice powered by a suite of technology-enabled clinical services, including case and disease management, utilization management and review, and medication therapy management services that improve health outcomes while lowering medical costs across the healthcare continuum. By focusing on increasing access to evidence-based care pathways and addressing social determinants of health, Monogram has emerged as an industry leader in championing greater health equity and improving health outcomes for individuals with chronic kidney and end-stage renal disease.

At Monogram Health we believe in fostering an inclusive environment in which employees feel encouraged to share their unique perspectives, leverage their strengths, and act authentically. We know that diverse teams are strong teams, and welcome those from all backgrounds and varying experiences.

#IND123",-1,-1,-1,-1,-1,-1,True
Data Engineer IV - Max Digital (Data Operations),"ACV Auctions
",Tennessee,-1,3.7,"If you are looking for a career at a dynamic company with a people-first mindset and a deep culture of growth and autonomy, ACV is the right place for you! Competitive compensation packages and learning and development opportunities, ACV has what you need to advance to the next level in your career. We will continue to raise the bar every day by investing in our people and technology to help our customers succeed. We hire people who share our passion, bring innovative ideas to the table, and enjoy a collaborative atmosphere.

Who we are:
ACV is a technology company that has revolutionized how dealers buy and sell cars online. We are transforming the automotive industry. ACV Auctions Inc. (ACV), has applied innovation and user-designed, data driven applications and solutions. We are building the most trusted and efficient digital marketplace with data solutions for sourcing, selling and managing used vehicles with transparency and comprehensive insights that were once unimaginable. We are disruptors of the industry and we want you to join us on our journey. ACV’s network of brands includes ACV Auctions, ACV Transportation, ClearCar, MAX Digital and ACV Capital within its Marketplace Products, as well as, True360 and Data Services.
At ACV we focus on the Health, Physical, Financial, Social and Emotional Wellness of our Teammates and to support this we offer:

Multiple medical plans including a high deductible health plan that costs $0 out of your paycheck
Company-sponsored (paid) Short-Term Disability, Long-Term Disability, and Life Insurance
Comprehensive optional benefits such as Dental, Vision, Supplemental Life/AD&D, Legal/ID Protection, and Accident and Critical Illness Insurance
Generous paid time off options, including vacation time, sick days, Company holidays, floating holidays, parental leave, bereavement leave, jury duty leave, voting leave, and other forms of paid leave as required by applicable law or regulation
Employee Stock Purchase Program with additional opportunities to earn stock in the Company
Retirement planning through the Company’s 401(k)
Who we are looking for:
We are seeking a highly skilled Engineer IV in Data Engineering with a strong foundation in computer science and excellent problem-solving skills. You will be responsible for maintaining and extending our database operations, optimizing SQL queries, and designing scalable data services.

What you will do:

Actively and consistently support all efforts to simplify and enhance the customer experience.
Maintain and extend (as required) existing database operations solution for backups, index defragmentation, data retention, etc.
Troubleshoot any SQL Server or ETL stack (SSIS, C#, Web APIs) outages during our operational support window.
Leverage monitoring tools to ensure high performance and availability; work with operations and engineering to improve as required.
Leverage DMVs and monitoring tools to ensure system performance; work with data operations and engineering to improve as required.
Ensure existing HADR (availability groups) solution is functional and meets requirements.
Support development, integration, and stage SQL Server environments for application development and data science teams.
Ensure that new database development meets company standards for readability, reliability, and performance. Work with internal teams on transactional and analytical schema design.
Collaborate with software and DevOps engineers to design scalable services, plan feature roll-out, and ensure high reliability and performance of our products.
Conduct code reviews, develop high-quality documentation, and build robust test suites.
Own the overall performance of products and services within a defined area of focus.
Respond-to and troubleshoot highly complex problems quickly, efficiently, and effectively. This may include being part of the emergency after-hours on-call rotation.
Mentor junior data engineers.
Perform additional duties as assigned.
What you will need:

Bachelor's degree in Computer Science, Information Technology, Computer Information Systems, Management Information Systems, or similar
5 years' building & supporting the database-tier of SaaS web applications.
Ability to read, write, speak, and understand English.
Expert in SQL Query optimization
ETL workflow implementation (SSIS, Airflow, C#, Python)
Experience working with Cloud Services (AWS RDS, S3, SQS, SNS)
Experience working with NoSQL data stores (e.g., MongoDB)
Experience developing Windows services in C#
Experience writing unit and integration testing
Expert SQL and data-layer development experience; OLTP schema design.
Experience using and integrating with cloud services, specifically: AWS RDS, S3, SQS, SNS.
Nice to Have
Experience with Airflow
Experience with DBT
Our Values
Trust & Transparency | People First | Positive Experiences | Calm Persistence | Never Settling

At ACV, we are committed to an inclusive culture in which every individual is welcomed and empowered to celebrate their true selves. We achieve this by fostering a work environment of acceptance and understanding that is free from discrimination. ACV is committed to being an equal opportunity employer regardless of sex, race, creed, color, religion, marital status, national origin, age, pregnancy, sexual orientation, gender, gender identity, gender expression, genetic information, disability, military status, status as a veteran, or any other protected characteristic. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires reasonable accommodation, please let us know.

For information on our collection and use of your personal information, please see our Privacy Notice.",2014,Wholesale,Unknown / Non-Applicable,Retail & Wholesale,1001 to 5000 Employees,Company - Public,True
Senior - Data Engineer,"Shelby County Schools
","Memphis, TN",$79K - $116K (Glassdoor est.),3.9,"Purpose and Scope:
To lead the data engineering team and guides members in best practices for data movement, data quality, master data management (MDM), data masking, data sub-setting, data security, data management and data virtualization development (collectively referred to as data integration and data management activities).
Essential Job Functions:
Leads the data engineering team and guides team members in best practices for data movement, data quality, master data management (MDM), data masking, data sub-setting, data security, data management and data virtualization development (collectively referred to as data integration and data management activities).
Drives the technical design, installation & configuration, development, optimization, error handling and support of data management initiatives.
Leads team in code reviews and ensures technical documentation, quality assurance and performance testing of data replication pipelines and data models to help with the reporting and data visualization requirements to support business operations and district sr. leadership stakeholders.
Develop efficient data policies, processes, and procedures to support data quality, access, and integrity of data.
Creates and implements scheduling and automation strategies for data management processes.
Identifies, designs, and implements internal process improvements including re-designing current data flows, infrastructure for greater scalability, optimizing extraction data delivery, and automating manual processes.
Develops and reviews and ownership of execution of test plans/cases to ensure high-quality data and smooth deployments and releases.
Apply test driven development using industry best practices such as Gherkin, Cucumber or using similar technology stacks / tools.
Collaborates with the business to understand and interpret data through stakeholder interviews and by defining, analyzing, and validating data
Provides appropriate training, mentoring and support for developers and junior data engineers. Leads code reviews.
Performs other related duties as assigned or directed.
Minimum Qualifications:
Bachelor's Degree in Information Systems, Data Science, Computer Science, Business Analytics, Engineering, Mathematics, Statistics, Economics, or other relevant STEM degree plus an additional five (5) years of related experience as a data engineer; OR a combination or related education and experience totaling nine (9) years.

(PROOF OF EDUCATION, TRAINING, AND/OR EXPERIENCE IS REQUIRED)

Degree Equivalency Formula:

Bachelor’s Degree= 4 years plus required years of experience.

Master’s Degree=6 years plus required years of experience.

Knowledge, Skills, and Abilities:

Experience with snowflake and playing the role of technical lead of data engineering, ETL or data warehouse team.
Outstanding critical, out-of-the-box thinker and exceptional diagnostician with a positive collaborator approach and a passion for solving complex problems
Professional with excellent initiative, able to work in fast-pace continuously evolving environment, and ready to take on uphill challenges
Strong understanding of devOps and DataOps methodologies with practical experience designing and implementing large-scale data processing pipelines
Deep understanding of cloud-native architecture and practical development experience in optimization and performance tuning of ETL workloads
Highly proficient in Python, writing complex SQL statements, and interpreting results for accuracy and performance
Strong experience with architecture and cost optimization in modern cloud-based data platforms Snowflake and Azure (preferred), or other platforms
Working knowledge of Agile Methodology
Ability and desire to quickly learn new technologies, as required.
Experience with CI/CD and version control frameworks such as Gitlab or Git preferred
Exposure to scheduling solutions (Airﬂow), Kubernetes (EKS at scale)
Experience deploying applications through serverless services (functions, tasks, etc.) preferred –Azure, Snowflake, and Snowpipe a plus
Experience in Data Integration, Data engineering, Master Data Management, Business and Data Analysis, and Modeling
Experience with fundamentals of signal processing and good exposure to ML algorithms preferred
Experience with process improvement practices (LEAN, Six Sigma, etc.)- Certification a plus.


Physical Requirements and Working Environment:
Physical Demands: Requires sedentary work involving standing or walking for brief periods, exerting up to 10 pounds of force on a regular basis; and some dexterity in operating office equipment.

Unavoidable Hazards: The position is exposed to no unusual environmental hazards.

Sensory (ADA) Requirements: The position requires normal visual acuity and field of vision, hearing and speaking abilities.

Additional Job Details: AMERICANS WITH DISABILITIES ACT COMPLIANCE MSCS is an Equal Opportunity Employer. MSCS provides reasonable accommodations to qualified persons with disabilities. Prospective and current employees are encouraged to discuss ADA accommodations with management.",-1,Primary & Secondary Schools,$5 to $25 million (USD),Education,5001 to 10000 Employees,School / School District,False
Lead-Data Engineer,"St. Jude Children's Research Hospital
","Memphis, TN",$68K - $98K (Glassdoor est.),4.6,"Overview

The department of Cancer Center Administration at St. Jude Children's Research Hospital is seeking a Lead-Data Engineer. This role is responsible for creating detailed designs and specifications based on data extract requirements and turning the requirements into a solution using standard development tools and processes. This position is responsible for ensuring the solution meets the functional requirements and follows St. Jude development standards and specifications. The lead assists in the monitoring of implemented databases, objects, ETL programs and ETL scheduler to ensure they complete normally and are performing optimally. This is an opportunity to develop out a new group at St. Jude Children's research hospital and provide solutions between various research groups.

Responsibilities

Work closely with Data Architects to drive the design of data models based on analytics requirements
Work closely with Solutions Architects, Business SMEs and other stakeholders throughout the analytics development lifecycle to ensure the delivery of robust and reusable data models.
Gather, document, and build business logic of metrics into a dataset for ad hoc use to improve self-sufficiency in data access
Translate business requirements into technical specifications, including data streams, integrations, transformations, databases, and data warehouses
Review design with team members to ensure institutional data management framework is being understood, followed, and matured
Develop data integration pipelines from data sources to the Enterprise Data Warehouse
Collaborate with analytics training staff to develop job aids and other training documents for solutions built
Develop a dashboard design and review it with key stakeholders – following institutional standards for data visualization
Develop standardized dashboard design templates for use across St. Jude
Map data sources, data movement, interfaces, and analytics, with the goal of ensuring data quality.
Track data quality, completeness, redundancy, compliance and improvement.
Understanding Common data model frameworks and implementing them as needed.
Collaborate with clinical and clinical research stakeholders, end users, leadership, and subject matter experts to understand current and future goals
Ability to confidently demo applications developed to multiple committees, leadership, and stakeholders
Excellent communication and presentation skills
Mentor data analysts across St. Jude business areas
Performs other related duties as assigned or directed in order to meet the goals and objectives of the department
Maintains regular and predictable attendance

Minimum Education

Bachelor's or Master's degree in computer science, data science, information science, business, or related field.

Minimum Experience

Minimum requirement: Six (6) progressive years of IT experience including strong database design, data architecture and data transform processes.
Experience in data architecture and design.
Some experience with data governance including implementation of a data governance framework.
Experience with leading industrial tools for data lake, big data, or ETL.
Experience with enterprise reporting tools for the development of reports as applicable.
Experience creating dashboards using data visualization tools (e.g. PBI, Tableau, Qlik, and data warehousing applications) and source control systems (e.g., Epic, Workday) as applicable.
Some experience and knowledge in Master Data Management and Data Dictionary Standards.
Some experience with regulatory requirements and standards as applicable.
Experience providing technical guidance and mentorship within Data Engineering.
Proven performance in earlier role/comparable role.
Epic Reporting tools (Cogito) experience preferred
Expertise in designing Common Data models preferred

Other Credentials


Other Information

St. Jude is an Equal Opportunity Employer
No Search Firms:
St. Jude Children's Research Hospital does not accept unsolicited assistance from search firms for employment opportunities. Please do not call or email. All resumes submitted by search firms to any employee or other representative at St. Jude via email, the internet or in any form and/or method without a valid written search agreement in place and approved by HR will result in no fee being paid in the event the candidate is hired by St. Jude.
COVID-19 vaccine:
St. Jude Children’s Research Hospital has mandated the COVID-19 vaccine for all employees, excluding those with an approved medical or religious accommodation, as a condition of employment.",1962,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,5001 to 10000 Employees,Nonprofit Organization,False
Marketing Data Engineer - Opry Entertainment,"Ryman Hospitality Properties
","Nashville, TN",$47K - $72K (Glassdoor est.),3.9,"The Marketing Data Engineer will play a key role in shaping Opry Entertainment Group's (OEG) Marketing strategy and uncovering opportunities for audience growth and application through analytics-driven recommendations and informed decision-making. This role is focused on data integration and analysis and is critical to driving audience acquisition, customer data capture and growth by developing and maintaining reporting and delivering insightful analyses across all aspects of acquisition funnel metrics, customer trends and behaviors and CRM management. This individual has a strong background in and passion for statistics and data analysis while also possessing a keen understanding of digital marketing, funnel metrics, and KPIs. This individual will also need to understand data modeling and regression modeling using multiple analytics tools and applications of those models on existing data sets. Reports to Director of Customer Engagement, Analytics and Engineering.

Manage data pipelines and architecture, including CRM and other databases, through data hygiene and creation of new data elements and calculated measures. Move, process, and monitor data systems.
Create and manage cloud environments such as Big Query and Snowflake, including data pipelines, views, and integrations. Define and implement cloud-based infrastructure for data lakes, analytics and machine learning initiatives.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management. Conduct data audits for quality, efficiency, and speed. Design and improve ETL processes for large complex data sets.
Build analytics tools that utilize data pipelines to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Create and maintain data modeling for audience segmentation, product recommendation, predictive scoring, and customer affinities. Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Create and manage SQL code and Salesforce Marketing Cloud automations for campaign-specific needs, journey automations, CRM updates, and ingesting new data into CRM databases.
Collaborate with analytics teams to define requirements, mine and analyze data, and integrate data from various sources.
Participate in implementation of BI visualizations. Serve as the technical resource to identify input and output requirements for campaigns, projects, and other development needs.
Create advanced analyses of customer and transactional data to create predictive and propensity models to inform segmentation and customer behavior studies. Conduct analysis to uncover insights about our products and users through cohort analysis, A/B tests, funnel analysis, user segmentation, etc.
Evaluate marketing initiatives to determine profitability and success rate, then make recommendations and adjustments to improve performance or shifts in direction.
Perform other duties as assigned.
Requirements:
Education
Bachelor's degree required, in a quantitative, analytical discipline preferred
Experience
3+ years of experience working with statistics, analyzing large data sets, modeling and analysis using SQL or similar language
3+ years of data management experience
Diverse platforms experience and work with a customer data platform or CRM system required
Digital marketing tools experience (Google Analytics, Adobe, etc.) required
Experience with cloud platforms (Google Cloud Platform, Snowflake, etc.) required
Background in Salesforce Marketing Cloud, specifically automation studio preferred
Experience with BI visualization tools (PowerBI, Looker, Tableau, etc.) preferred
Knowledge, Skills and Abilities
Excellent written and verbal communication skills
Demonstrated focus on driving growth
Keen understanding of digital marketing, funnel metrics and KPIs
Passion for statistics and data analysis
Continuous learner driven to succeed and achieve significant results
Advanced Excel skills desired",1955,Culture & Entertainment,$1 to $5 billion (USD),"Arts, Entertainment & Recreation",501 to 1000 Employees,Company - Public,True
Senior Data Engineer,"Cellular Sales
","Knoxville, TN",$102K - $141K (Glassdoor est.),3.8,"Cellular Sales:
Sr Data Engineer - ETL

About Us
At Cellular Sales, we connect our customers with Verizon, the network more people rely on. We strive to bring people together through technology and work towards great accessibility today and every day. As a trusted partner of Verizon, we share their mission: to give humans the ability to do more in this world. We create the connections that turn innovative ideas into reality.

Do you have experience working with relational databases using ETL tools? Can you design and load data patterns? Do you thrive working in a collaborative environment helping to influence company strategy?
If so, we would love to talk with you!

Summary/Objective
The Sr Data Engineer will be responsible for designing and implementing enterprise level ETL processes in order to consume data from various sources. This position will be responsible for collaboration with the rest of the ETL team to facilitate the growth of the enterprise data warehouse as well as developing ETL solutions for various applications. This position also serves to mentor other team members on ETL best practices.


What we need from you:

Experience effectively using ETL tools (Informatica or other tools).
Develop, Design, and communicate practical enterprise level ETL solutions.
Ability to translate requirements and technical design to an automated ETL solution.
Understanding of data concepts to accommodate both operational and reporting design elements.
Ability to translate requirements and technical design to an automated ETL solution.
Mentor team members in SQL/Query performance tuning as well as ETL design.
Familiarity with Cloud technologies as they relate to Data Engineering
Full knowledge of storage and consumer database best practices.
Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

What we provide:
A collaborative working environment encouraging input from team members.
Strong commitment to the success of the employees and the business.
Support from the team, tools and systems.
Ability to build strong relationships throughout the organization.


Additional Benefits
Health and Dental Benefits
401K with matching
On site gym
Great Culture and an inviting atmosphere


Other Duties
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.",1993,"Cable, Internet & Telephone Providers",$1 to $5 billion (USD),Telecommunications,5001 to 10000 Employees,Company - Private,False
Data Engineer,"Double Line, Inc.
","Nashville, TN",$67K - $98K (Glassdoor est.),4.2,"(This is a remote position open to candidates residing near Austin, TX, Raleigh, NC, or Nashville, TN. We have an office location in Austin, TX for use at our employees' convenience. We have no plans to return to the office on a mandatory basis.)


Feeling underappreciated? Underutilized? Want to be a part of a specialized team with exposure to a wide variety of data puzzles to solve, while using your skills to improve education? Come join a team where you can Fly the Airplane, not just be a passenger in the back. We're a growing company focused on expanding our Operations team with a solutions-focused Data Engineer. Sound interesting?


If so, we're looking for a motivated and driven person like you who has:

Strength in thinking creatively and collaborating with other data experts in figuring out solutions to really tough data loads or transformation problems
Experience leveraging SQL and/or ETL development, data mapping, and data modeling to manage and organize client data
A passion for continuous improvement in refining the approach and doing it better and faster the next time


Bonus points if you're bringing knowledge of or really want to learn the following:

Consultancy experience with a focus on Agile practices
AWS and Azure Cloud
Python or similar scripting languages
AWS Quicksight, Tableau, Power BI, or other visualization tools


In return, we offer:

A mission-driven company with a long-term focus on helping the world by untangling the technical knots that challenge state and local governments, particularly in education, healthcare, and similar fields
A home where your voice matters and you can affect real change
An employer who cares about you, makes sure you're engaged with exciting work, and offers robust benefits, 401k with employer match, and a great culture


We do not want you to make the leap without knowing what we need, so here is how we define success for this position:

Soak up knowledge from the existing team of experts in the first 30 days
Bring fresh eyes to our processes and techniques and bring new ideas to the table in the first 2 months
Mentor a new data engineering hire in your first 90 days


We need to know - can you make this happen? If so, we definitely need to talk to you.


Double Line understands the importance of creating a safe and comfortable work environment and encourages individualism and authenticity in every member of our team. We provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment.


Double Line does not currently offer relocation assistance.




o7APWT65D0",2009,Business Consulting,$5 to $25 million (USD),Management & Consulting,51 to 200 Employees,Company - Private,True
Senior Data Engineer,"Mars
","Franklin, TN",$107K - $143K (Glassdoor est.),4.3,"Job Description:

What are we looking for?
Mars Petcare consists of five Divisions: Pet Nutrition, Royal Canin, Mars Veterinary Health & Diagnostics and Kinship. The Pet Nutrition division is currently embarking on a 3-year Digital Transformational program that aims to irreversibly digitise Mars.
Our purpose in the R&D Digital Transformation of Pet Nutrition Is to create step-change value creation for pets and pet parents by digitalising R&D to accelerate innovation, deliver superior propositions and fuel an integrated supply chain, with Increased agility and reduced cost. Some of the key deliverables we will look to unlock are:
From siloed, small-scale product performance evaluation to a fully Integrated, data driven performance assessment through real-time predictive solutions; maximising capability and reducing evaluation time & cost by building confidence to drive superior propositions across the portfolio.
From traditional Innovation and scale-up protocols to innovative digital modelling which enables rapid scenario evaluation, accelerated development and scale-up, with increased agility and reduced costs/resources.
From dispersed physical quality records to digitalised quality standards, capturing of data and trend predictions, which can be leveraged in order to proactively mitigate emerging risks and avoid non-quality Impacts.
From fragmented legacy IT systems holding unreliable data to an integrated R&D digital & data ecosystem with the purpose of enacting step-change operational efficiency and maximising business value by confidently utilising trustworthy data.
What will be your key responsibilities?
As a Data Engineer in the R&D team, your key responsibilities are as follows:
1. Technical Proficiency:
Collaborate in hands-on development using Python, PySpark, and other relevant technologies to create and maintain data assets and reports for business insights.
Assist in engineering and managing data models and pipelines within a cloud environment, utilizing technologies like Databricks, Spark, Delta Lake, and SQL.
Contribute to the maintenance and enhancement of our progressive tech stack, which includes Python, PySpark, Logic Apps, Azure Functions, ADLS, Django, and ReactJs.
Support the implementation of DevOps and CI/CD methodologies to foster agile collaboration and contribute to building robust data solutions.
Develop code that adheres to high-quality standards, promoting a scalable and maintainable data platform.
2. Learning and Growth; Contribution to Solutions:
Collaborate with the team to learn and apply the best practices in data engineering.
Actively participate in engineering projects, gaining experience in developing high-quality, scalable, and sustainable data solutions.
Stay updated with emerging technologies and trends in data engineering, contributing to the team's knowledge base by sharing insights and ideas.
Assist in the development of data solutions within the Pet Nutrition data platform, working on challenging aspects under the guidance of senior team members.
Contribute to the management of data from various divisions to generate valuable data assets related to pets and pet owners.
Support the maintenance of a semantic and intelligent data layer to contribute to the comprehensive leadership of the data solution within the environment.
3. Collaboration and Communication:
Collaborate closely with analysts, data scientists, and team members to understand their requirements and assist in translating them into actionable data solutions.
Maintain effective communication with the Data Engineering Lead, actively participating in team discussions and sharing ideas to improve platform excellence
Education & Professional Qualifications
5+ years’ experience as a Data Engineer.
Knowledge / Experience
Experience with Spark, Databricks, or similar data processing tools.
Proficiency in working with the cloud environment and various software's including SQL Server, Hadoop, and NoSQL databases.
Proficiency in Python (or similar), SQL and Spark.
Proven ability to develop data pipelines (ETL/ELT).
Strong inclination to learn and adapt to new technologies and languages.
Expertise in designing and building Big Data databases, analytics, and BI platforms.
Strong understanding and experience in working with Databricks Delta Lake.
Keen interest in the latest trends and tools in data engineering and analytics.
Familiarity with graph databases (e.g., Neo4J/Cypher).
Experience with data visualization tools (e.g., PowerBI).
Proficiency in Microsoft Azure cloud technologies would be a bonus.
What can you expect from Mars?
Work with over 130,000 diverse and talented Associates, all guided by the Five Principles.
Join a purpose driven company, where we’re striving to build the world we want tomorrow, today.
Best-in-class learning and development support from day one, including access to our in-house Mars University.
An industry competitive salary and benefits package, including company bonus.

Mars is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. If you need assistance or an accommodation during the application process because of a disability, it is available upon request. The company is pleased to provide such assistance, and no applicant will be penalized as a result of such a request.",1911,Food & Beverage Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Private,False
Data Engineer,"CHS Corporate
","Franklin, TN",$80K - $106K (Glassdoor est.),3.2,"Community Health Systems is one of the nation’s leading healthcare providers. Developing and operating healthcare delivery systems in 43 distinct markets across 15 states, CHS is committed to helping people get well and live healthier. CHS operates 76 acute-care hospitals and more than 1,000 other sites of care, including physician practices, urgent care centers, freestanding emergency departments, occupational medicine clinics, imaging centers, cancer centers and ambulatory surgery centers.

Summary:
This role places you at the heart of Big Data and Google Cloud Platform (GCP), central to maintaining and developing all systems connected to CHS Data Services. Your keen understanding of Managed File Transfer (MFT) will be crucial in managing and enhancing our MFT platform seamlessly integrated within GCP.

Responsibilities:

Administer GCP and MFT Systems:
Oversee and optimize Business Intelligence and data service systems within GCP, and play an active role in the MFT platform’s management.
GCP and MFT Analysis and Review:
Scrutinize GCP and MFT reporting implementations, ensuring their optimal performance and timely problem resolution.
Collaborate on GCP and MFT Initiatives:
Work synergistically with different teams to address GCP and MFT-related information processing and capacity planning.
Provide GCP and MFT User Assistance:
Offer vital support to users, ensuring the efficient and productive use of GCP and MFT applications, alongside comprehensive training and problem resolution.
Ensure GCP and MFT Compliance:
Maintain adherence to relevant policies and procedures within GCP and MFT operations.
Design GCP-Based Databases:
Develop OLAP databases within GCP for extensive multi-dimensional data analysis.
Implement GCP Data Warehousing Solutions:
Integrate data from diverse sources within GCP, underlining the efficiency and enhancing organizational performance.

Requirements:
Educational Qualification: Bachelor's in Computer Science or Electrical Engineering.
Professional Experience:

3 years in Information Technology, with experience in MFT, GCP and Big Data Processing Frameworks.
GCP and MFT Expertise: Proficient in GCP tools and services with a solid understanding and experience in MFT platforms.
Experience in designing GCP-based OLAP databases.
Familiarity with XML, JSON/JavaScript, and Hadoop ecosystem tools within GCP environments.
Additional Skills:
Clear and concise oral and written communication skills.
Previous experience in a healthcare environment is a plus.
Contribute substantially by enhancing our GCP and MFT platforms, ensuring top-tier customer experience and the evolution of our business models.

Physical Demands:

In order to successfully perform this job, with or without a reasonable accommodation, the following are outlined below:

The Employee is required to read, review, prepare and analyze written data and figures, using a PC or similar, and should possess visual acuity.
The Employee may be required to occasionally climb, push, stand, walk, reach, grasp, kneel, stoop, and/or perform repetitive motions.
The Employee is not substantially exposed to adverse environmental conditions and; therefore, job functions are typically performed under conditions such as those found within general office or administrative work.",1985,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Company - Public,True
Data Engineer - GCP,"emids
","Franklin, TN",$86K - $113K (Glassdoor est.),3.6,"This is us, your new colleagues!
Our organization is based on people and great teamwork.

We work at the intersection of design, engineering and domain expertise, our passionate team of problem solvers work closely with customers to blaze new trails that will positively impact the future of health. We are a truly global company, we rely on diversity and together we create a workplace that brings the best out of everyone. Using technology and insights, we move nimbly and provide trusted advice, seeking ways to amplify results.




We're committed to bettering healthcare and empowering wellness.


Do you want to be a part of this journey?


The role


As a team we are together responsible for providing a modern, efficient and secured environment supporting our employees as we believe that our employees are our greatest strength. We are looking for someone with strong understanding of the management, soft and people's skills, excellent communication, leadership and planning skills.

Emids is a leading provider of digital transformation solutions to the healthcare industry, serving payers, providers, life sciences, and technology firms. Headquartered in Nashville, Emids helps bridge critical gaps in providing accessible, affordable, and high-quality healthcare by providing digital transformation services, custom application development, data engineering, business intelligence solutions, and specialized consulting services to all parts of the healthcare ecosystem. With nearly 3,500 professionals globally, Emids leverages strong domain expertise in healthcare-specific platforms, regulations, and standards to provide tailored, cutting-edge solutions and services to its clients.

Responsibilities:
Design and implement ETL workflows to extract, transform, and load data from various sources into GCP platforms.
Build and maintain data pipelines to ensure data quality, accuracy, and consistency.
Develop and maintain data models that enable efficient and effective data analysis.
Work with other team members to identify and troubleshoot data quality issues.
Collaborate with data analysts, data scientists, and other stakeholders to understand their data requirements and provide data support.
Monitor and optimize data workflows to ensure efficient and reliable performance.
Document data processes, including data lineage and data definitions, for future reference.
Required Qualification:
Possess excellent knowledge of SQL along with its variation for popular database like BigQuery etc.
Experience writing Python & Pyspark scripts.
Strong experience in data analytics and business intelligence.
Development experience building ETL pipelines using cloud tools like dataflow, lambda.
Experience in tuning SQL queries to maximize performance.
Working knowledge on implementing Data quality checks.
Experience with Airflow or Tidal to orchestrate the data pipelines.
Excellent critical reasoning, problem-solving skills and teamwork skills.
Solid written and verbal communication skills and able to articulate complex solutions to technical and non-technical personnel.
Experience with VCS such as git and build tools such as Jenkins or Maven.
Experience working for clients in healthcare space.
Must to Have' Experience:
Experienced in healthcare domain
Hands-on with Google Cloud services for data engineering- Data Proc, Big Query, Cloud storage,
Manage end to end data pipeline from extraction from source, landing on google platform and transformation
Implemented data management best practices – Data quality, Capture of metadata
Experience with DevOps and GKE patterns



Emids is an Equal Opportunity Employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, alienage or national origin, ancestry, citizenship status, age, disability or handicap, sex, marital status, veteran status, sexual orientation, or any other characteristic protected by applicable federal, state or local laws. Our management team is dedicated to this policy with respect to recruitment, hiring, placement, promotion, transfer, training, compensation, benefits, employee activities and general treatment during employment.


What can we offer you?


You will be part of a team that offers you a fulfilling career, great results through amazing team, strong relationships and a high performance culture. We are using the latest technologies, high security mediums, and service platforms top market providers. We strongly promote agile mind-set and ways of working, followed by agile methods used in practice. We offer proper guidance and take care of our people and offer top notch services including flexible work timings and training required.




We also offer:

Benefits and leave management
A great learning platform
A challenging environment where 2 days never look the same
A high performing team and a positive atmosphere where mistakes are welcome as part of the learning

About Us


Emids is healthcare's digital transformation leader, delivering business and tech solutions that help payers, providers and tech-enablers maximize technology to deliver care better since 1999

As a global partner headquartered in Nashville, TN, emids helps bridge the critical gaps in accessible, affordable, high-quality healthcare by providing advisory consulting services, custom application development, and data solutions. Services include EHR application deployment and management, analytics, data integration and governance, software development and testing, and business intelligence.




Emids specialises in Healthcare Expertise, Mobile Health Solutions, Healthcare Reform & Benefits Exchange, Regulatory Compliance, HIE & HIS Implementation, Clinical Systems Engineering, Care Analytics, Testing & QA, Implementation & Integration, and Cloud Enablement




Website: http://www.emids.com",1999,Information Technology Support Services,$100 to $500 million (USD),Information Technology,1001 to 5000 Employees,Company - Private,True
Software Engineer 3 - Customer Data Domain,"Asurion
","Nashville, TN",$81K - $116K (Glassdoor est.),3.3,"Who’s a great match for us?

Developers who are passionate about developing great software, have a love for solving hard problems, and enjoy learning new technology

Developers who enjoy collaboration with other engineers, product and design teams

As a Software Engineer, here’s what you can expect to do:

Work very closely with our product and design teams
Take on an opportunity that offers variety, innovation, and unique challenges, where you can learn something new every day
Think through hard problems, and work with a team to make them reality and provide very tangible benefits to the corporation
Work in a dynamic, collaborative, transparent, non-hierarchal, and inclusive culture
Ensure the performance, quality, and responsiveness of applications and services
Identify and correct bottlenecks and fix bugs
Help maintain code quality, organization, and automation
Participate in on-call rotation, including weekends and holidays

Here’s what you’ll bring to the team:

Bachelor’s degree in Computer Science, Software Engineering, Computer Engineering, Electrical Engineering, Electronics Engineering, or a related field
3+ years of software development experience building modern web services or applications.
Strong experience with some combination of full-stack modern technologies (i.e., React, Node, Java, Amazon Web Services (AWS)
Experience with Kafka, Kotlin, GraphQL, or Restful APIs are a plus
Understanding and application of Security fundamentals
A passion for keeping applications lean and fast, while ensuring that all features are a pleasure to use
A relaxed yet enthusiastic attitude",1994,Information Technology Support Services,Unknown / Non-Applicable,Information Technology,10000+ Employees,Company - Private,True
Case Management Clinical Data Performance Engineer,"CHS Corporate
","Franklin, TN",$67K - $90K (Glassdoor est.),3.2,"Community Health Systems is one of the nation’s leading healthcare providers. Developing and operating healthcare delivery systems in 43 distinct markets across 15 states, CHS is committed to helping people get well and live healthier. CHS operates 76 acute-care hospitals and more than 1,000 other sites of care, including physician practices, urgent care centers, freestanding emergency departments, occupational medicine clinics, imaging centers, cancer centers and ambulatory surgery centers.

Summary:

The CHS Care Management team’s vision is to leverage data to provide evidence based, safe, quality healthcare to the communities we serve. The CM team is looking to add a Clinical Data Engineer, who will be responsible for implementing and maintaining the data processes and pipelines that underpin the functions of the CM team.

This role has responsibility for the development, ongoing quality assessment, deployment and maintenance of architectures for the 2 applied CM/UR solutions in use at CHS – including bringing these within the CHS Google Cloud environment, manipulating the data within, and enhancing these with additional clinical, operational and financial data to create high value solutions for the CM team.

This role will also be involved in partnering with business owners to create project-specific data sets and visualizations, automating existing manual data tasks, and troubleshooting data anomalies and data quality issues within the CM data ecosystems.

The position is remote – but travel to Franklin, TN 4 to 8 times per year is required for in person meetings with CM leadership and associated team members.

Required Qualifications

Bachelor’s degree in technical field, including: Healthcare Analytics, Business Analytics, Computer Science, Engineering, Data Science, or related field from an accredited university or college.
One year of experience using Cloud Based Platforms (e.g. Azure, AWS, GCP) to complete advanced data processing, including implementing data pipelines for structured and unstructured data
One year of applied experience using Python & SQL to develop, test and deploy data resources for business owners (Data Science, Business Intelligence, Analytics)

Desired Qualifications

Master’s Degree
Applied experience using big data, statistics and/or data science principles and processes.
Experience working with large healthcare data (Clinical, Claims, Survey).

Physical Demands:

In order to successfully perform this job, with or without a reasonable accommodation, the following are outlined below:

The Employee is required to read, review, prepare and analyze written data and figures, using a PC or similar, and should possess visual acuity.
The Employee may be required to occasionally climb, push, stand, walk, reach, grasp, kneel, stoop, and/or perform repetitive motions.
The Employee is not substantially exposed to adverse environmental conditions and; therefore, job functions are typically performed under conditions such as those found within general office or administrative work.",1985,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Company - Public,True
Azure Data Engineer,"Wipro Limited
","Nashville, TN",$79K - $111K (Glassdoor est.),3.1,"Overview:
About Wipro:
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.
A PROUD HISTORY OF OVER 75 YEARS
FY22 REVENUE 10.4 BN USD
WE’RE PRESENT IN 66 COUNTRIES
OVER 1,400 ACTIVE GLOBAL CLIENTS

Role: Data Engineer
Location - USA (Remote)

Job Description:


Undergraduate degree or equivalent work experience
8+ years’ experience in Development, design, test and implementation of complex database programs using Oracle and third-party tools. within a distributed, service-based enterprise environment
4+ years Hands-on development using Oracle PL/SQL.
Demonstrates expertise in a variety of data warehousing and business intelligence concepts, practices, and procedures.
Strong experience with oracle functions, procedures, triggers, packages & performance tuning,
Significant experience and comfortable with production support (and willing to take on slots within our 24/7 support rotation).Providing technical assistance, problem resolution and troubleshooting support issues.
Analytical approach to problem solving
At least 2+ year practical experience of developing solutions hosting within key major cloud providers such as OpenShift, Kubernetes, AWS, Google Cloud and Azure
Experience in using modern software engineering and product development tools including Agile / SAFE, Continuous Integration, Continuous Delivery, DevOps etc.
Demonstrate being an avid supporter of the Open-Source software community
Excellent time management, communication, decision making, and presentation skills
Display a strong desire to achieve and attain high levels of both internal and external customer satisfaction
Strong experience of operating in a quickly changing environment and driving technological innovation to meet business requirement
Proven track record of building relationships across cross-functional teams
Positive attitude and easy to work with
Initiative-taker. Has grit and can solve problems without management oversight.
Takes ownership for work. When something goes wrong, stance is introspective rather than blaming.
Engineering mindset(automate manual process) when it comes to ETL processes.
Accustomed to developing code in Git and using CI/CD practices.
Preferred: development experience using Java or open-source technologies, developing Restful APIs

We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, caste, creed, religion, gender, marital status, age, ethnic and national origin, gender identity, gender express.

#LI-SJ3",1945,Information Technology Support Services,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Engineer III, Big Data","Pilot Company
","Knoxville, TN",-1,3.3,"Company Description


Pilot Company is an industry-leading network of travel centers with more than 30,000 team members and over 750 retail and fueling locations in 44 states and six Canadian provinces. Our energy and logistics division serves as a top supplier of fuel, employing one of the largest tanker fleets and providing critical services to oil operations in our nation's busiest basins. Pilot Company supports a growing portfolio of brands with expertise in supply chain and retail operations, logistics and transportation, technology and digital innovation, construction, maintenance, human resources, finance, sales and marketing.

Founded in 1958 by Jim A. Haslam II and currently led by CEO Adam Wright, our founding values, people-first culture and commitment to giving back remains true to us today. Whether we are serving guests, a fellow team member, or a trucking company, we are dedicated to fueling people and keeping North America moving.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status or any other characteristic protected under applicable federal, state or local law.



Job Description


Looking for an opportunity with a growing company? This exciting full time position is located in Knoxville, TN, please see the job description below and if interested, please apply!

The purpose of this job is to provide technical expertise for research, development and modification of data engineering processes and jobs in support of a Big Data infrastructure for PFJ Energy in the commodities and energy space.

Research, develop, document, and modify Data Engineering processes and jobs per data architecture and modeling requirements; collaborate with Data Analytics team members such as Data Strategists and Data Scientists
Collaborate with business stakeholders to understand data needs including data velocity, veracity, and access patterns
Provide technical expertise to implement Data and Analytics specifications
Serve on cross-functional project teams and provide perspective for the Data Analytics team on executing key deliverables
Troubleshoot complex, escalated issues including connection, failed jobs, application errors, server alerts and space thresholds within predefined service level agreements (SLAs)
Proactively maintain and tune all code according to internally documented Data Engineering standards and best practices
Review and ensure appropriate documentation for all new development and modifications of the Data Lake processes and jobs
Perform code and process reviews and oversee testing for solutions developed, and ensure integrity and security of institutional data
Educate business stakeholders on the usage and benefits of the

Data Lake/Lakehouse and related technologies

Mentor and guide less experienced team members and provide feedback on project work
Model behaviors that support the company’s common purpose; ensure guests and team members are supported at the highest level
Ensure all activities are in compliance with rules, regulations, policies, and procedures
Complete other duties as assigned


Qualifications

Bachelor’s degree in computer science, engineering, information technology, or related field, required.
Minimum five years of technology operations experience required.
Strong SQL knowledge and skills required
Strong knowledge of Relational Databases like Oracle, Postgres or SQL Server required
String knowledge of relational modeling and features including triggers, stored procedures, and constraints required
Experience with Apache Spark or Spark-streaming, Message Queue technologies and Python required
Strong knowledge of enterprise data warehouse (EDW) data models with a focus on Star Schema data modeling
techniques required
Strong knowledge of Amazon Web Services (AWS) or similar Cloud Big Data platform preferred
Excellent analytical skills and the ability to identify solutions to complex data problems
Ability to provide excellent customer service
Excellent written and verbal communication skills
Willingness to learn and embrace new technologies
Ability to mentor and motivate a diverse team; ensure team and individual accountability and performance standards are met
Ability to prioritize, multitask and manage multiple projects successfully in a fast-paced and dynamic environment
Strong organizational skills with attention to detail
Ability to communicate and interact effectively with different levels of the organization to negotiate, problem solve, complete projects and influence decision making
Self-motivated with ability to work both independently and within teams in order to establish and meet deadlines, goals, and objectives
Travel required less than 10%
General office work requiring sitting or standing for long periods of time
Able to lift up to 30 lbs.
Able to work evenings, weekends and odd hours as needed

Additional Information

Nation-wide Medical Plan/Dental/Vision
401(k)
Spending Accounts
Adoption Assistance
Tuition Reimbursement
Weekly Pay
Team Member Fuel Discount
All your information will be kept confidential according to EEO guidelines",1958,Convenience Stores,$10+ billion (USD),Retail & Wholesale,10000+ Employees,Subsidiary or Business Segment,False
Machine Learning Data Engineer,"Oak Ridge National Laboratory
",United States,-1,3.8,"Requisition Id 11602


Our Organization:

As a U.S. Department of Energy (DOE) Office of Science national laboratory, ORNL has an extraordinary 80-year history of solving the nation’s biggest problems. We have a dedicated and creative staff of over 6,000 people! Our vision for diversity, equity, inclusion, and accessibility (DEIA) is to cultivate an environment and practices that foster diversity in ideas and in the people across the organization, as well as to ensure ORNL is recognized as a workplace of choice. These elements are critical for enabling the execution of ORNL’s broader mission to accelerate scientific discoveries and their translation into energy, environment, and security solutions for the nation.


ORNL is home to Frontier, the world’s fastest and first exascale supercomputer—providing an open science environment to develop solutions that touch us all. With direct access to Frontier, we can simulate and engineer solutions that only exascale computing can enable.




The Analytics and AI Methods at Scale Group (AAIMS) at the Oak Ridge National Laboratory is seeking qualified and driven applicants for a Machine Learning Data Engineer position for the broad area of AI for science projects. The research and development activities include but not limited to: scientific data collection, transformation, feature engineering, large-scale natural language modeling and understanding etc. In this role, you will have the opportunity to work on some of the most challenging and impactful research and development, and collaborate with both computer scientists and domain scientists to build end-to-end data and ML pipeline/services to facilitate and expedite the ML-assisted scientific discovery process.


As a Machine Learning Data Engineer, you should be comfortable around Linux, SQL, Python, containers, Pandas, Spark, and source control in a highly collaborative environment.


Major Duties and Responsibilities:

Mobilizing and leading data analysis activities on projects with a focus on common deliverables, goals and timelines, including data preparation, transformation, feature engineering etc. in collaboration with scientists and engineers.
Research and evaluate emerging technologies and approaches from the broader ML community.
Evaluate and deploy scalable AI frameworks, tools, and execute them on high-performance computing (HPC) resources, in close collaboration with research staff and computing technical staff.
Troubleshoot data analysis issues, including implementation issues, hyperparameter choices, and modeling decisions.
Quickly and clearly summarize analyses, following best practices in documentation, data visualization, and provenance tracking for reproducibility.
Assist in preparation of manuscripts and dissemination of research results in publications and conferences.
Develop high-quality Python code following best practices in the community; manage code and data through version control systems and community hub such as HuggingFace.


Basic Qualifications:

B.S. and 2+ years of relevant experience or an M.S. and 1+ year of relevant experience.
Degree concentration should be in Computer Science/Engineering or closely related field.
Experience with Python for data science.
Experience with PyTorch and/or Tensorflow.


Preferred Qualifications:

Understanding of supervised and unsupervised learning, reinforcement learning, and deep learning.
Experience of CUDA programming.
Experience of MPI programming, and collective communication primitives.
Applied research experience in at least one machine learning discipline such as natural language processing, image processing and classification or related areas.
Excellent communication skills for conveying technical material to both scientists and non-scientists in both written and oral presentations.
Self-disciplined work ethic and eagerness to tackle challenging research problems.
Ability to communicate and work on diverse and interdisciplinary teams.


Benefits at ORNL:

ORNL offers competitive pay and benefits programs to attract and retain talented people. The laboratory offers many employee benefits, including medical and retirement plans and flexible work hours, to help you and your family live happy and healthy. Employee amenities such as on-site fitness, banking, and cafeteria facilities are also provided for convenience.


In addition, we offer a flexible work environment that supports both the organization and the employee. A hybrid/onsite working arrangement may be available with this position.

Other benefits include: Prescription Drug Plan, Dental Plan, Vision Plan, 401(k) Retirement Plan, Contributory Pension Plan, Life Insurance, Disability Benefits, Generous Vacation and Holidays, Parental Leave, Legal Insurance with Identity Theft Protection, Employee Assistance Plan, Flexible

If you have difficulty using the online application system or need an accommodation to apply due to a disability, please email: ORNLRecruiting@ornl.gov or call 1.866.963.9545.


#LI-KC1


This position will remain open for a minimum of 5 days after which it will close when a qualified candidate is identified and/or hired.

We accept Word (.doc, .docx), Adobe (unsecured .pdf), Rich Text Format (.rtf), and HTML (.htm, .html) up to 5MB in size. Resumes from third party vendors will not be accepted; these resumes will be deleted and the candidates submitted will not be considered for employment.


If you have trouble applying for a position, please email ORNLRecruiting@ornl.gov.


ORNL is an equal opportunity employer. All qualified applicants, including individuals with disabilities and protected veterans, are encouraged to apply. UT-Battelle is an E-Verify employer.",1943,National Agencies,Unknown / Non-Applicable,Government & Public Administration,5001 to 10000 Employees,Government,False
Data Engineer,"Denso
","Maryville, TN",$74K - $113K (Glassdoor est.),3.3,"Purpose:

Develop tools utilizing Artificial Intelligence (AI) that are backed with high confidence data analytics that supports Manufacturing Improvement

Scope of Work:

Generate Tools that point to true root cause (Deep Learning Root Cause Analysis)
Evaluate data collection systems & Complete data analytics looking for data accuracy (Clean & Prepare Data)
Understand root cause & develop count-measures to eliminate missing or inaccurate data
Develop Tools utilizing Machine Learning for Production Forecasting, Process Optimization, Predicative Maintenance & Quality Control


Key Projects:

Internal Supply Chain Optimization (Production schedule adjustment: based on available components, Current WIP Levels, Statistical data of how parts flow through the plant, Suggestive WIP levels)
Predictive Quality & Productivity Focused Action (Indicators of areas that need attention before a defect or OEE loss occurs)


Required Qualifications:

Bachelor’s Degree or Higher in Computer Engineering, Computer Science or Data Analytic related degree or equivalent professional work experience.
Hands-on technical/Engineering manufacturing experience.
Strong verbal and written communication skills
Ability to work effectively with a multi-disciplined cross-functional team: Strong Teamwork Skills
Skilled at setting priorities and completing tasks: able to accept and take direction
Willingness to travel domestically and internationally, up to 10%
Willingness to work periodic overtime, as required: typically at critical project deadline timing
Possess and demonstrate excellent analytical, communication, and interpersonal skills: welcome different ideas and viewpoints
Demonstrate initiative by investigating outside own areas for given tasks and by helping others: Team Player
Demonstrate ownership of responsible areas through committed actions and responses
Ability to develop and closely follow schedules and due dates
Willingness to contribute opinion and feedback in various meetings and situations
Possess and demonstrate a positive attitude and outlook
Desire to learn and master new technology: Self-motivated to learn new methods and technology

Preferred Qualifications:

Previous analytical model and algorithm development experience
Knowledge of Database Structure
Working Knowledge of coding/scripting
3+ Years work experience in data science related field

Bachelor's Degree",1949,Transportation Equipment Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Public,False
AWS Certified Data Engineer,"CGI Group, Inc.
","Knoxville, TN",$80K - $114K (Glassdoor est.),3.8,"AWS Certified Data Engineer

Position Description
Want to leverage your experience and development skills in the Financial Industry as an AWS Data Engineer?

CGI is seeking a AWS Data Engineer who can bring in expertise and industry best practices define better development and Engineering approaches. The position will be located in Knoxville, TN.

This is an exciting opportunity to augment your current skills, as well as learn new technologies.

If you are looking for a new challenge and want to make a difference in the Financial Industry, this role is for you.

Your future duties and responsibilities
Our AWS Data Engineer will be a key contributor with the below responsibilities:

Work with the technical development team and team leader to understand desired application capabilities.

Continuously improve software engineering practices.

Work within and across Agile teams to test and support technical solutions across a full stack of development tools and technologies.

Develop applications in AWS - data and analytics technologies including but not limited to Glue, EMR, Lambda, Step Functions, CloudTrail, CloudWatch, SNS, SQS, S3, VPC, EC2, RDS, IAM.

Application development by lifecycles, & continuous integration/deployment practices.

Work to integrate open-source components into data-analytic solutions.

Working with vendors to enhance tool capabilities to meet enterprise needs.

Willingness to continuously learn & share learnings with others.

Required qualifications to be successful in this role
Any Applicants should have hands on experience with AWS services such as Glue, EMR, Lambda, Step Functions, CloudTrail, CloudWatch, SNS, SQS, S3, VPC, EC2, RDS, IAM.

Proficient in at least one programming language (Python, Scala, Java etc)

Experience in ETL / Data application development and version control systems such as Git.

Knowledge of application development lifecycles, & continuous integration/deployment practices.

6-10 years' experience delivering and operating large scale, highly visible distributed systems.

Knowledge of IAC using terraform is preferred.

Snowflake MPP and graph database experience is preferred but not mandatory.

CGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to: skill set level; experience and training; and licensure and certifications. CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $74,600 - 143,700.

At CGI we call our professionals ""members"" to reinforce that all who join our team are, as owners, empowered to participate in the challenges and rewards that come from building a world-class company. CGI's benefits include:

Competitive base salaries
Eligibility to participate in an attractive Share Purchase Plan (SPP) in which the company matches dollar-for-dollar contributions made by eligible employees, up to a maximum, for their job category
401(k) Plan and Profit Participation for eligible members
Generous holidays, vacation, and sick leave plans
Comprehensive insurance plans that include, among other benefits, medical, dental, vision, life, disability, out-of-county emergency coverage in all countries of employment;
Back-up child care, Pet insurance, a Member Assistance Program, a 529 college savings program, a personal financial management tool, lifestyle management programs and more

#DICE
#LI-JG1

Insights you can act on

While technology is at the heart of our clients' digital transformation, we understand that people are at the heart of business success.

When you join CGI, you become a trusted advisor, collaborating with colleagues and clients to bring forward actionable insights that deliver meaningful and sustainable outcomes. We call our employees ""members"" because they are CGI shareholders and owners and owners who enjoy working and growing together to build a company we are proud of. This has been our Dream since 1976, and it has brought us to where we are today - one of the world's largest independent providers of IT and business consulting services.

At CGI, we recognize the richness that diversity brings. We strive to create a work culture where all belong and collaborate with clients in building more inclusive communities. As an equal-opportunity employer, we want to empower all our members to succeed and grow. If you require an accommodation at any point during the recruitment process, please let us know. We will be happy to assist.

Ready to become part of our success story? Join CGI - where your ideas and actions make a difference.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, height, weight, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the Position ID of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a Position ID will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI's legal duty to furnish information.",1976,Business Consulting,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Engineer,"Contact Government Services, LLC
","Nashville, TN",$80K - $120K (Glassdoor est.),4.7,"Data Engineer
Employment Type: Full-Time, Mid-level
Department: Business Intelligence
CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.
Skills and attributes for success:
Complete development efforts across data pipeline to store, manage, store, and provision to data consumers.
Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices.
Write code to ensure the performance and reliability of data extraction and processing.
Support continuous process automation for data ingest.
Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing.
Work with program management and engineers to implement and document complex and evolving requirements.
Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork.
Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists.

Qualifications:
Must be a US Citizen.
Must be able to obtain a Public Trust Clearance.
7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.
Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats.
Proficiency in developing ETL processes, and performing test and validation steps.
Proficiency to manipulate data (Python, R, SQL, SAS).
Strong knowledge of big data analysis and storage tools and technologies.
Strong understanding of the agile principles and ability to apply them.
Strong understanding of the CI/CD pipelines and ability to apply them.
Experience with relational database, such as, PostgreSQL.
Work comfortably in version control systems, such as, Git Repositories.

Ideally, you will also have:
Experience creating and consuming APIs.
Experience with DHS and knowledge of DHS standards a plus.
Candidates will be given special consideration for extensive experience with Python.
Ability to develop visualizations utilizing Tableau or PowerBI.
Experience in developing Shell scripts on Linux.
Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions.
Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences.
Our Commitment:
Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:
Health, Dental, and Vision
Life Insurance
401k
Flexible Spending Account (Health, Dependent Care, and Commuter)
Paid Time Off and Observance of State/Federal Holidays

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:
https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:
Email: info@cgsfederal.com",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,True
Scalable Data and Simulation Engineer (Hybrid Eligible),"Oak Ridge National Laboratory
",United States,-1,3.8,"Requisition Id 11990


Overview:
We are seeking a Scalable Data and Simulation Engineer to build state of the art software technologies for use in a wide variety of engineering disciplines, ranging from networked controls to unique modeling and simulation technologies for national security applications. Oak Ridge National Laboratory supports unique research needs for the Department of Energy and other Government agencies with goals ranging from improvements to energy efficiency, transitioning to renewable energy, improving the resiliency of the national electric infrastructure, and growing national defense. Applications will focus on discrete event simulation and utilization of machine learning approaches for scalable simulation. The Software systems engineer will play an integral role in prototyping, demonstrating, and transitioning to production complex systems to meet these diverse objectives. This position resides in Systems Engineering and Cybernetics Group in the Computational Sciences & Engineering Division of the Computing & Computational Sciences Directorate at Oak Ridge National Laboratory (ORNL).


As a U.S. Department of Energy (DOE) Office of Science national laboratory, ORNL has an extraordinary 80-year history of solving the nation’s biggest problems. We have a dedicated and creative staff of over 6,000 people! Our vision for diversity, equity, inclusion, and accessibility (DEIA) is to cultivate an environment and practices that foster diversity in ideas and in the people across the organization, as well as to ensure ORNL is recognized as a workplace of choice. These elements are critical for enabling the execution of ORNL’s broader mission to accelerate scientific discoveries and their translation into energy, environment, and security solutions for the nation.


Major Duties/Responsibilities:

Work with a team to move research concepts from exploratory prototype to delivered systems.
Research, develop and implement machine learning-driven algorithms for improved computational efficiency and scalability.
Apply sophisticated computing and machine learning capabilities to solve scientific challenges within ORNL.
Build, test, and maintain software elements of these systems.
Support modeling and simulation activities to exercise software elements.
Support field exercises to demonstrate system capabilities.
Provide technical leadership for software development teams.
Mentor new and junior technical staff.


Basic Qualifications:

A master’s degree in computer science, electrical or computer engineering, or other field relevant to the job duties.
4+ years of systems software experience.
Experience developing machine learning approaches for scalable simulation and discrete event simulation.
Experience programming in Python and C++.


Preferred Qualifications:

6 or more years of experience relevant to the job duties.
Experience with modelling and simulation of complex, interdisciplinary systems.
Extensive experience working with PyTorch and TensorFlow.
Knowledge of computer architecture, computer networking, and experience with the development of virtualization technologies and/or computer system simulations.
Experience in software architecture and enterprise-scale application development for sophisticated scientific projects.
Extensive experience in Internet of Things (IOT) applications, machine learning, cloud-based software deployment, and embedded systems.
Experience in leading and working in Agile software development environments.
Excellent interpersonal skills for working within a highly diverse team, as well as strong oral and written communications skills, good organizational habits, and a high degree of personal motivation.
A commitment to lifelong learning.


Special Requirement:

Q Clearance: This position requires the ability to obtain and maintain a clearance from the Department of Energy. As such, this position is a Workplace Substance Abuse (WSAP) testing designated position. WSAP positions require passing a pre-placement drug test and participation in an ongoing random drug testing program.


Benefits at ORNL:
ORNL offers competitive pay and benefits programs to attract and retain talented people. The laboratory offers many employee benefits, including medical and retirement plans and flexible work hours, to help you and your family live happy and healthy. Employee amenities such as on-site fitness, banking, and cafeteria facilities are also provided for convenience.


Other benefits include the following: Prescription Drug Plan, Dental Plan, Vision Plan, 401(k) Retirement Plan, Contributory Pension Plan, Life Insurance, Disability Benefits, Generous Vacation and Holidays, Parental Leave, Legal Insurance with Identity Theft Protection, Employee Assistance Plan, Flexible Spending Accounts, Health Savings Accounts, Wellness Programs, Educational Assistance, Relocation Assistance, and Employee Discounts.


If you have difficulty using the online application system or need an accommodation to apply due to a disability, please email: ORNLRecruiting@ornl.gov or call 1.866.963.9545.


In addition, we offer a flexible work environment that supports both the organization and the employee. A hybrid/onsite working arrangement may be available with this position.


#li-kc1


This position will remain open for a minimum of 5 days after which it will close when a qualified candidate is identified and/or hired.

We accept Word (.doc, .docx), Adobe (unsecured .pdf), Rich Text Format (.rtf), and HTML (.htm, .html) up to 5MB in size. Resumes from third party vendors will not be accepted; these resumes will be deleted and the candidates submitted will not be considered for employment.


If you have trouble applying for a position, please email ORNLRecruiting@ornl.gov.


ORNL is an equal opportunity employer. All qualified applicants, including individuals with disabilities and protected veterans, are encouraged to apply. UT-Battelle is an E-Verify employer.",1943,National Agencies,Unknown / Non-Applicable,Government & Public Administration,5001 to 10000 Employees,Government,False
Data Integration Engineer - Remote,"CareHarmony
","Nashville, TN",$77K - $119K (Glassdoor est.),2.7,"We’re looking for a founding data integration engineer who loves building repeatable, scalable approaches to exchanging EMR and patient eligibility data with our clients (large health systems).
Our ideal candidate is well-versed with patient eligibility and demographic data ingestion, EMR/EHR data integration using HL7 standard transactions, and building RESTful APIs to exchange data with internal and external systems.
Requirements
Responsibilities

Map, extract, transform and load data from source to target through multiple stages.
Own ETL pipelines that exchange data in HL7 Standard transactions like FHIR, 2.x, CCDA, XML, JSON, RESTful APIs, as well as flat files, SFTP and other modalities.
Partner with client-facing teams to engage with clients to explain and enforce data requirements, standardize data file templates, and establish/maintain required data source feeds.
Provide technical support to integrate EMR/EHR and patient eligibility data with internal systems and operational teams.
Understand and translate business needs into data models to support long-term, scalable, and reliable solutions
Build out new APIs and functionality for data ingress/egress with external systems

Requirements

5+ years building healthcare data integrations with at least 2 or more EHR systems (EPIC, Allscripts, Athena, eClinicalWorks, NextGen, Cerner, Greenway, Meditech).
Experience with healthcare data workflows and with using Healthcare data standards like HL7 FHIR, HL7 CDA, HL7 2.x EDI X12, FHIR, LOINC, ICD10, SNOMED, CPT
Experience with data quality processes, checks, validations, metrics definition and measurement
Demonstrated track record working with data warehouse and ETL architectures and concepts
Experience creating new APIs from scratch and automating data pipelines

Bonus Points

Passion for improving healthcare and the patient experience.
Enthusiasm for building foundational API and data integration capabilities for a fast-growing startup.
Early-stage start-up experience

Benefits
Why Apply:

Opportunity to get in the early stage at a high-growth HealthTech company with extreme product market fit and exponential growth (we’re deployed at 80+ health systems across &gt;25 states!).
You are trusted to take complete autonomy over data ingestion, data integration, and data-related API development.
Actively transform healthcare outcomes by solving real-world problems for millions of patients.",2015,Health Care Services & Hospitals,Unknown / Non-Applicable,Healthcare,51 to 200 Employees,Company - Private,True
Senior Software Engineer-Large Scale Data Management,"ITR
","Oak Ridge, TN",$67K - $120K (Glassdoor est.),3.7,"Senior Software Engineer, Large-Scale Data Management

Overview:
East Tennessee company is seeking a senior software engineer focused on large-scale data management and storage. Position can be remote and candidates need to be able to obtain a federal security clearance.

Company operates several simulation and experimental facilities that produce large volumes of data. There is the immediate need to manage these petabytes of data efficiently and provide user-facing tools for organizing, cataloging, curating, publishing, and searching the data assets. We are seeking an expert software developer/engineer who excels in developing scalable data management software systems, and at solving interdisciplinary problems. Successful candidate(s) will possess the necessary technical skills to take on existing and new challenges, particularly in large-scale data management and storage.

Major Duties and Responsibilities:

Architect and develop scalable data management systems to manage petabytes of data.
Lead a team of research and technical professionals to develop new capabilities that execute on ORNL’s leading data and compute infrastructures.
Principle Investigator / project manager for OLCF/ORNL public data portal, Constellation.
Develop storage microservices.
Develop software for the scalable cataloging of billions of datasets.
Develop software for capturing and extracting metadata from scientific datasets.
Develop software for creating scalable indexes of the captured metadata to facilitate efficient searches.
Develop software for the scalable upload and download of datasets.
Evaluate hardware and software that might be deployed in the future.
Basic Qualifications:

Bachelor’s degree in Computer Science, Computer Engineering, or related field and 8+ years of relevant experience.
5+ years of experience leading data management development.
Experience in writing production code in programming languages such as C++ or Python.
Experience with container technologies such as Docker, Kubernetes and OpenShift.
Experience with web platforms (e.g., Drupal/WordPress).
Experience with REST APIs, HTTP.
Experience with large-scale storage solutions.
Preferred Qualifications:

10+ years of experience leading data management development.
Knowledge of large, open-data repositories.
Experience with Globus integration
Experience with CD/CI practices, test methodologies.
Knowledge of distributed file systems used for large-scale cluster computing (Lustre, GPFS, etc.)
Familiarity with open-source development tools and large-scale collaborations.
Knowledge of Agile development methodologies and tools.
Knowledge of metadata, graph databases, etc.
Architectural knowledge of scalable distributed system architectures.
Passion for data management and data technologies.
Excellent written and oral communication skills.
Ability to think critically.
Strong problem-solving skills.
Highly skilled in people management/development, strong communication skills, and an impeccable attention to detail.
Team oriented, collaborative.",-1,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,501 to 1000 Employees,Company - Private,True
Case Management Clinical Data Performance Engineer,"CHS Corporate
","Franklin, TN",$67K - $90K (Glassdoor est.),3.2,"Community Health Systems is one of the nation’s leading healthcare providers. Developing and operating healthcare delivery systems in 43 distinct markets across 15 states, CHS is committed to helping people get well and live healthier. CHS operates 76 acute-care hospitals and more than 1,000 other sites of care, including physician practices, urgent care centers, freestanding emergency departments, occupational medicine clinics, imaging centers, cancer centers and ambulatory surgery centers.

Summary:

The CHS Care Management team’s vision is to leverage data to provide evidence based, safe, quality healthcare to the communities we serve. The CM team is looking to add a Clinical Data Engineer, who will be responsible for implementing and maintaining the data processes and pipelines that underpin the functions of the CM team.

This role has responsibility for the development, ongoing quality assessment, deployment and maintenance of architectures for the 2 applied CM/UR solutions in use at CHS – including bringing these within the CHS Google Cloud environment, manipulating the data within, and enhancing these with additional clinical, operational and financial data to create high value solutions for the CM team.

This role will also be involved in partnering with business owners to create project-specific data sets and visualizations, automating existing manual data tasks, and troubleshooting data anomalies and data quality issues within the CM data ecosystems.

The position is remote – but travel to Franklin, TN 4 to 8 times per year is required for in person meetings with CM leadership and associated team members.

Required Qualifications

Bachelor’s degree in technical field, including: Healthcare Analytics, Business Analytics, Computer Science, Engineering, Data Science, or related field from an accredited university or college.
One year of experience using Cloud Based Platforms (e.g. Azure, AWS, GCP) to complete advanced data processing, including implementing data pipelines for structured and unstructured data
One year of applied experience using Python & SQL to develop, test and deploy data resources for business owners (Data Science, Business Intelligence, Analytics)

Desired Qualifications

Master’s Degree
Applied experience using big data, statistics and/or data science principles and processes.
Experience working with large healthcare data (Clinical, Claims, Survey).

Physical Demands:

In order to successfully perform this job, with or without a reasonable accommodation, the following are outlined below:

The Employee is required to read, review, prepare and analyze written data and figures, using a PC or similar, and should possess visual acuity.
The Employee may be required to occasionally climb, push, stand, walk, reach, grasp, kneel, stoop, and/or perform repetitive motions.
The Employee is not substantially exposed to adverse environmental conditions and; therefore, job functions are typically performed under conditions such as those found within general office or administrative work.",1985,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,10000+ Employees,Company - Public,True
"Lead Software Engineer, Data Engineering","S&P Global
","Antioch, TN",$85K - $170K (Employer est.),4.1,"The Role: Data Engineer
Location: Team is in Boston, but is available for remote or on-site throughout CST and EST Time zones
GL (for internal use only): 11

Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.
Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy!
Job Description
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.

You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets.
You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use.
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.

Responsibilities
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers
Optimizing slow-running database queries and data pipelines
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency

Qualifications
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience
7+ years of experience working with data-at-scale in a production environment
Experience designing and implementing large-scale, distributed systems
Experience in multi-threaded software development (or some form of parallelism)
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale
Strong understanding of relational databases and proficiency with SQL
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript)
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go)
Experience developing software on Linux-based operating systems
Experience with distributed version control systems
Nice-to-Haves
Familiarity with relational database internals (especially PostgreSQL)
Proficiency with cloud computing platforms, specifically AWS
Working knowledge of probability & statistics
Contributions to open-source software
Experience building customer-centric products

Compensation/Benefits Information (US Applicants Only):
S&P Global states that the anticipated base salary range for this position is $85,300 - $170,000 . Base salary ranges may vary by geographic location.
In addition to base compensation, this role is eligible for an annual incentive bonus plan.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires .
About S&P Global
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 277527
Posted On: 2023-09-21
Location: Cambridge, Massachusetts, United States",1860,Research & Development,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
"Senior Data Engineer, Public Company","Recruiting From Scratch
","Nashville, TN",$100K - $200K (Employer est.),4.0,"This is for a client of Recruiting from Scratch.
Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Our Client:

Our next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we’re blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.

With a track record of strong financial performance and plans for continued headcount growth, we’re looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us.

What’s so interesting about this role?

Our client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .

In this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.

What’s the job?

Design, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.
Moving implementation to ownership of real-time and batch processing and data governance and policies.
Maintain and enforce the business contracts on how data should be represented and stored.
Stay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users
Implementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.
Work closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.

What we’ll love about you

5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.
7+ years experience using Python,
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )
Significant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.
Experience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Experience with dimensional data modeling and schema design in Data Warehouses
Familiar with ETL (managing high-quality reliable ETL pipelines)
Be familiar with legal compliance (with data management tools) data classification, and retention.

Salary Range: $165,000-$210,000 USD base. Equity. Medical, Dental, Vision.
https://www.recruitingfromscratch.com/",2019,Staffing & Subcontracting,$1 to $5 million (USD),Human Resources & Staffing,1 to 50 Employees,Company - Private,True
Sr. Electrical Engineer - Data Center,"Barge Design Solutions
","Chattanooga, TN",$79K - $118K (Glassdoor est.),4.5,"Sr. Electrical Engineer - Data Center

Career Area: Engineering - Electrical

What We're Looking For:
Barge Design Solutions is seeking an experienced Electrical Engineer with expertise in designing distribution and controls for low, medium, and high voltage systems associated with mission-critical infrastructure for data centers, industrial, and healthcare facilities. The selected candidate will be part of our growing Mission-Critical team and will be responsible for electrical designs to achieve enhanced efficiency, reliability, and safety.

Responsibilities:

Collaborates with project team members, client representatives, and review agencies to provide a comprehensive project design.
Develops design criteria for protective device coordination, relay applications, medium voltage transformers, switchgear, medium and low voltage distribution.
Leads technical electrical design portions of a projects in a multi-discipline environment.
Develops concepts, studies, and narratives to help clients understand options available to meet project requirements.
Selects equipment and designs code compliant electrical systems to achieve client objectives related to uptime and reliability of mission-critical facilities.
Conducts fault current analysis, short circuit analysis, and protective device coordination studies.
Oversees installation of systems to ensure functionality and compliance with design intent.
Participates in project site visits.
Mentors, directs, and oversees work of junior staff and designers.
Participates in the strategy, growth, and development of Barge's Mission-Critical sector.



Education & Experience Qualifications:
Bachelor's degree in Electrical Engineering from an ABET-accredited university.
Professional Engineering license (PE)
10 years of progressive experience in the electrical engineering field with emphasis on design of power distribution systems for data centers or other mission-critical facilities.
Strong knowledge of electrical codes and standards (NEC, IECC, IEC, etc.)
Strong knowledge of electrical equipment design ANSI and IEEE standards.
Ability to communicate technical information clearly and effectively with a wide range of audiences.
Experience with Revit a plus.
Familiarity with sustainable design practices and energy-efficient systems a plus
RCCD, DCDC, CDCDP, and DCEP certifications all considered a plus



Why join us?

Barge Design Solutions, Inc., is an engineering and architecture firm with diverse in-house multidisciplinary practice areas. The employee-owned company is more than 400-people strong and serves clients nationwide from multiple U.S. locations. Barge is ranked No. 171 on Engineering News-Record (ENR)'s 2021 Top 500 Design Firms list, is No. 177 on Architectural Record's Top 300 Architecture Firms and is a certified Great Place To Work®.

Our primary purpose for being in business is ultimately to create a better life by unleashing the potential of our people, clients and communities. This purpose is supported by our company's core values because at the end of the day, Barge CARES:


Collaborate - Help and expect help. Teamwork is essential in what we do.
Authentic - Honesty, integrity and trust are at the heart of everything we do. We are who we say we are.
Responsible - We are accountable for our work, our attitude, and our actions. We make Barge better.
Excellence - We go all in and expect more of ourselves than others expect of us.
Service - We are humble. We use our gifts in service of others.

We believe that if we are living out our purpose for being in business and integrating our values into everything we do, we will ultimately achieve our vision to be the firm best known for being selected when it matters most.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status or on the basis of disability. Equal Opportunity Employer/Veterans/Disabled",1955,Architectural & Engineering Services,$25 to $100 million (USD),"Construction, Repair & Maintenance Services",201 to 500 Employees,Company - Private,False
Senior Staff AI Data Engineer,"Recruiting From Scratch
","Nashville, TN",$160K (Employer est.),4.0,"Who is Recruiting from Scratch :
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
https://www.recruitingfromscratch.com/

This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays.

What’s so interesting about this role?

We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety.

What’s the job?

We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.

In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.

Responsibilities:

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn’t always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams
Build data processing streams for cleaning and modeling text data for LLMs
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure

What we’ll love about you

Bachelors in Computer Science, Mathematics, Physics, or a related fields
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Experience in statistical analysis & visualization on datasets using Pandas or R
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines)

We’ll really swoon if you have

2+ years of experience of technical leadership in building data engineering pipelines for AI
Previous experience in building data pipeline for conversational AI APIs and recommender systems
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Strong understanding of applied machine learning topics
Be familiar with legal compliance (with data management tools) data classification, and retention
Consistent track record of managing and implementing complex data projects

What you'll love about us

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events
Base Pay Range
$160,000—$280,000 USD
https://www.recruitingfromscratch.com/",2019,Staffing & Subcontracting,$1 to $5 million (USD),Human Resources & Staffing,1 to 50 Employees,Company - Private,True
