Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply
Data Engineer III,"Farm Credit Financial Partners
","Springfield, MA",$99K - $134K (Glassdoor est.),3.4,"For over 25 years, Farm Credit Financial Partners, Inc. (FPI) has provided technology products and services to the Farm Credit System. We care deeply about the agricultural credit associations (ACAs) we serve through our mission of delivering trusted technology solutions to help American agriculture thrive. As a customer-owned service organization, we support ACAs from Maine to California with over 62,000 customer-members and over $40 billion in loan volume . Everyone here contributes to the success of our customers, and to the vibrant culture that makes FPI a great place to work. Throughout the year, you will find us having fun and jamming out to FPI’s band, coming together to support local charities, and celebrating our wins together.

We offer a robust benefits package that includes competitive earnings, hybrid and remote work options, tuition reimbursement, generous 401(k) matching, and development opportunities through company-sponsored trainings and certifications.

Come grow with us: financialpartners.com .

Farm Credit Financial Partners, Inc. is an Equal Opportunity Employer, and all qualified applicants will receive consideration for employment without regard to age, race, color, national origin, sex or gender, religion, pregnancy, marital status, status as a veteran, sexual orientation, gender identity, disability, or any other characteristic protected by law. EEO / AA / Minorities / Female / Disabilities / Veterans

#FPI




JOB SUMMARY: The Data Engineer III is responsible for transforming data that can be easily analyzed. The position will be responsible for expanding and optimizing our data and data pipeline for our Association partners. The Data Engineer III primarily works with project teams on developing new data platforms to support strategic initiatives in alignment with business and/or enterprise strategies.

ESSENTIAL FUNCTIONS:

Work with architects, modelers, and other data engineers to implement design and assemble large, complex data sets that meet end user business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Participate in technical design and code reviews to ensure quality and best practices are maintained.
Perform as technical lead on smaller projects and be a collaborative member on larger projects.
Contribute to the effective data governance of the organization’s business data. This includes data quality, data management, data policies, business process management, and risk management surrounding the handling of organizational data.

ADDITIONAL FUNCTIONS:

Coach and mentor junior engineers
Communicate effectively with stakeholders regarding project status and delivery time frames
Fosters innovative team culture and process improvement during development phase

OTHER DUTIES : This job description is not designed to cover or contain a full listing of activities, duties or responsibilities required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.




QUALIFICATIONS:

Bachelor's degree in computer science or MIS, and 5+ years’ experience in data modeling and cloud technologies. Strong working experience with the Azure technology stack including:
Databricks
Data Factory
SQL
Python
Power BI (Business Intelligence)
Experience with Agile and Waterfall methodologies
Strong organization, analytical, and communication skills
Proficiency in the following technologies: R, Microsoft Office Suite
Strong customer service focus (data consumers as customers)
Familiar with software development best practices

WORK ENVIRONMENT: Typical noise levels for an open, cubicle-styled environment.

PHYSICAL DEMANDS : This position requires periods of standing, walking, and the use of computer equipment. Additional physical demands include, but may not be limited to, talking or hearing, push/pull, stooping, kneeling, reaching w/hands and arms, and lifting at least 10 pounds.

WORK AUTHORIZATION: Authorization to work in the United States is required.

REASONABLE ACCOMMODATION : Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.",1995,Information Technology Support Services,$25 to $100 million (USD),Information Technology,201 to 500 Employees,Company - Private,False
Data Center Engineer,"Mimecast
","Boston, MA",$40.00 - $50.00 Per Hour (Employer est.),3.8,"This contract role is located at our two US Boston data centre colocations in Andover and Waltham. The team is based within our Global Technical Operations department here at Mimecast.

The ideal candidate must be a self-motivated and a strong team player. Successful candidates will thrive in a fast paced and agile environment that is regularly evolving.

Key Responsibilities

Help to develop global standards and promote best practices in data center operations.
Introduce process improvements and encourage best practices in datacentre operations.
Racking of quarterly server deliveries and network equipment.
Decommission of aging equipment
Track server/network assets through deployment lifecycle.
Maintain accurate reporting and auditing of all assets within the data centers.
Regular JIRA ticket management.
Diagnose server component faults and perform replacements.
Provide cross-functional communication with other technical operations groups.
Upkeep of data centre equipment records
Work with monitoring systems to identify problems.
Maintenance and configuration of data rack PDUs
Participate in conference calls/meetings with team members on a regular basis.
Handle incoming and outgoing shipments worldwide.
Work closely with other 3rd party datacenter remote hands engineers worldwide.
RMA Management with multiple vendors
Assist with tracking data center issues and keeping Mimecast servers in production.
Send weekly task progression reports.

Essential Skills and Experience

Basic knowledge of Linux, and Windows Operating Systems.
Good knowledge of Microsoft Outlook, Word and Excel.
Good knowledge of data centre cabling standards
Good knowledge of data centre buildings & critical infrastructure
Excellent knowledge of server hardware and troubleshooting.
Able to lift and or move equipment up to 22.5 Kgs daily, group lifts for 22.5 Kgs or more.
Candidate must be flexible in visiting either of our US Boston datacentres where needed.
Strong verbal and written communication skills.
Ability to prioritize in a complex, fast-paced environment.
Able to work in noisy environments such as datacenters.

Desirable Skills

Experience working in a multi-vendor datacentre environment.
Understanding of out-of-band server communication methods
Experience in datacentre hardware deployments and building scaling infrastructure.
Basic knowledge of Atlassian JIRA/Confluence and Microsoft Sharepoint.

Job Type: Contract

Salary: $40.00 - $50.00 per hour

Schedule:

8 hour shift

Ability to commute/relocate:

Boston, MA: Reliably commute or planning to relocate before starting work (Required)

Experience:

Data center (Required)

Work Location: In person",2003,Enterprise Software & Network Solutions,$500 million to $1 billion (USD),Information Technology,1001 to 5000 Employees,Company - Private,True
Lead Data Engineer - FinTech - Hybrid,"Michael Page
","Boston, MA",$130K - $150K (Employer est.),4.4,"Lead the development and maintenance of Business Intelligence and Safeguarding solutions.
Assume complete responsibility for BI and Data Engineering projects, from requirements gathering and design to development, implementation, and ongoing maintenance.
Innovate and explore strategies to enhance data quality, reliability, and performance.
Analyze and structure raw and structured data from diverse sources.
Evaluate and align data solutions with business needs and objectives.
Prepare data for prescriptive and predictive modeling.
Develop algorithms and prototypes to drive data-driven insights.
Create and maintain analytical tools and programs.
Collaborate closely with BI Engineers and Finance team members on various projects.
Participate in on-call duty responsibilities.


MPI does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, disability, veteran status, marital status, or based on an individual's status in any group or class protected by applicable federal, state or local law. MPI encourages applications from minorities, women, the disabled, protected veterans and all other qualified applicants.

Strong technical expertise in data modeling, data mining, and segmentation techniques.
Proven track record with ETL and Data Integration tools.
Proficiency in Groovy and SQL.
Excellent analytical skills.
Ability to troubleshoot independently.
Strong teamwork and interpersonal skills, fostering collaboration among diverse team members.
Effective oral and written communication skills, with the ability to simplify complex ideas.
Experience with Oracle's BI and EPM product suites is advantageous.
Knowledge of database maintenance is a plus.

Join an innovative and rapidly expanding FinTech company. They are a prominent player in the payments industry, committed to creating a cutting-edge payments orchestration platform that empowers our clients with advanced payment solutions.

As a valued full-time team member, you'll enjoy a competitive salary and an exceptional benefits package, including comprehensive medical and dental insurance, FSA, HRA, vision coverage, life insurance, disability coverage, and more. You'll also have the opportunity to save for retirement through our 401K plan, which features a generous company match. We highly value employee referrals and offer substantial referral bonuses. Additionally, we provide our team members with a comprehensive PTO plan to support a healthy work-life balance. These are just a few of the outstanding benefits we offer, and we look forward to discussing them further during the interview process. Join us and be part of an exciting journey in the FinTech industry!",-1,Security & Protective,Unknown / Non-Applicable,Management & Consulting,201 to 500 Employees,Company - Private,False
Principal Data Engineer Snowflake AWS,"Motion Recruitment
","Boston, MA",$165K - $190K (Employer est.),3.4,"Job Title: Principal Data Engineer

Location: Downtown Boston, MA

Company Overview: Join a prestigious asset management firm in the heart of Boston, boasting over $1 trillion in assets under management. Our firm is renowned for its innovative investment strategies and commitment to excellence in financial management. We are at the forefront of integrating technology and finance, continually enhancing our capabilities to maintain a competitive edge in the global market.

Job Description: As a Principal Data Engineer, you will play a crucial role in our strategic initiative to migrate over 100 on-premise SQL instances to the cloud. Your expertise in Snowflake and AWS will be instrumental in this transformation, directly impacting the efficiency and effectiveness of our top quantitative analysts.

Key Responsibilities:

Lead and execute the migration of SQL databases to Snowflake on AWS.
Collaborate closely with quantitative analysts to understand their data needs and optimize cloud solutions accordingly.
Design and implement robust, scalable data architectures in the cloud, ensuring high availability and performance.
Develop and enforce best practices for data management, security, and compliance within the cloud environment.
Provide technical leadership and mentorship to junior data engineers and other team members.
Stay abreast of emerging cloud technologies and data management trends, recommending improvements to our cloud strategy.

Qualifications:

Bachelor’s or Master’s degree in Computer Science, Engineering, or a related field.
Minimum of 8 years of experience in data engineering with a focus on cloud technologies.
Expertise in Snowflake and AWS services (e.g., EC2, RDS, S3, Lambda).
Proven track record of successfully migrating large-scale databases to the cloud.
Strong understanding of SQL and experience with on-premise SQL databases.
Excellent problem-solving skills and ability to work in fast-paced environments.
Strong communication and leadership skills, with the ability to collaborate effectively across teams.

We Offer:

Competitive salary and benefits package.
Opportunity to work in a dynamic, collaborative environment.
Exposure to cutting-edge technologies and innovative projects.
Career growth opportunities in a top-tier asset management firm.",1989,HR Consulting,Unknown / Non-Applicable,Human Resources & Staffing,51 to 200 Employees,Company - Private,False
Data Engineer,"Hydrow, Inc.
","Boston, MA",$84K - $116K (Glassdoor est.),4.3,"Boston, MA or Remote
Engineering /
Full-Time
/ Hybrid
WHO WE ARE

If you ask us, we’re the perfect mix of athletes, entrepreneurs, engineers, and creatives. Our diverse backgrounds and shared values are what help make Hydrow great. Our mission is not just to create an amazing fitness experience, but a beautiful human experience - one that’s honest, inclusive, and positive.. Hydrow is the Live Outdoor Reality (LOR)™ rowing machine that delivers on-water experiences at home with workouts led by world-class athletes. At Hydrow, you’ll have the chance to shape a company that is disrupting the fitness industry while creating engaging content unmatched in the marketplace today. Sound exciting? That’s because it is!



JOB OVERVIEW

We seek a Data Engineer who will serve as a cornerstone in our expanding Data and Analytics team. Your role is pivotal in providing ongoing analytics and insights across multiple departments, emphasizing a data-first approach to accelerate our strategies and decision making.
You will serve as a critical member of the Data and Analytics team, focusing on integrating disparate sets of data on our Domo platform. Your work will support Marketing, Customer Engagement, Finance, and Hardware - really, the whole company. You will work closely across the analytics team and be deeply integrated with specific functional departments. You will field a mix of ad hoc reporting and drive longer strategic projects. You will employ your curiosity, creativity, and analysis skills to make a significant impact in a fast-paced and engaging culture.
CORE COMPETENCIES
Ability to design, construct, test, and maintain data architectures and platforms, including AWS and Google Cloud (BigQuery)
Proficiency in using various approaches for data integration for comprehensive analysis using business intelligence tools (Domo, Tableau, PowerBI)
Exercise strong quantitative and research skills to interpret findings
Ability to clearly communicate findings and business impacts
Advanced critical thinking skills to scope and frame problems
Effective interpersonal and relationship building skills to establish critical partnerships with cross- functional teams
Use of product analytics tools: Google Analytics, Amplitude etc
Analytics Coding Proficiency: SQL (required) , R, Python (preferred)
YOUR EXPERIENCE
Preferred to have a Bachelor’s degree in a technical field
Minimum of 3 years relevant experience in an analytics role preferred
Demonstrated ability to collaborate effectively with cross-functional teams.
Excellent problem-solving skills and meticulous attention to detail.
Strong communication skills, capable of conveying complex data concepts in a clear and concise manner.
We are currently not accepting resumes from external recruiters.



HOW WE WORK

Authentic and Inclusive: We embrace each and every one of our differences and celebrate our diversity. We commit to fostering a space where everyone belongs and is heard.

Nimble with Purpose: We are a fleet of speedy boats, instead of a barge. As pathfinders of positive change, we adapt our focus with ease when our purpose points us in a new direction

Resilient Teammates: We support our Hydrow teammates and members through challenges: technical, personal, or unexpected waves. We overcome the present obstacle and persevere together.

Hydrow is a community of innovators, risk-takers, and trailblazers who celebrate individual differences and recognize that unique perspectives make us stronger, smarter, and more successful. Hydrow actively seeks applicants who can bring a variety of experiences, perspectives, and backgrounds to the team. Hydrow provides equal employment opportunities to all employees and applicants for employment without regard to race, color, ancestry, national origin, gender, sex, pregnancy, pregnancy-related condition, sexual orientation, marital status, religion, age, disability, qualified handicap, gender identity, results of genetic testing, military status, veteran status, or any other characteristic protected by applicable law.

Our team values diversity in experience and backgrounds—we do our best work when we create space for different voices and perspectives. Whatever unique experiences or skill sets you bring, we look forward to learning from each other.

BENEFITS AND PERKS (Full Time Permanent Hydrownauts)

Medical, Dental, and Vision Insurance Premiums 100% Paid For By Hydrow
6 Months Fully Paid Primary and Secondary Parental Leave
Unlimited PTO Policy
$150/week Reimbursable for Childcare
401k
Free Membership to the Hydrow App and access to a free Hydrow
➕ MORE!

By submitting your application, you agree that Hydrow may collect your personal data for recruiting, global organization planning, and related purposes. Hydrow's Privacy Notice explains what personal information we may process, where we may process your personal information, our purposes for processing your personal information, and the rights you can exercise over Hydrow's use of your personal information.",2017,Beauty & Wellness,Unknown / Non-Applicable,Personal Consumer Services,51 to 200 Employees,Company - Private,False
Data Engineer 3,"Kagr Llc
","Foxborough, MA",$92K - $127K (Glassdoor est.),3.3,"SUMMARY: The Data Engineer 3 will drive the planning, design, and development of integration processes to build and improve the data warehouse. The Data Engineer will be responsible for building data integrations, data pipelines and other processes the data warehouse and KAGR product. This role will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build our product to enable our clients to use data to drive their business.
DUTIES AND RESPONSIBILITIES
Building data integrations and data pipelines within the KAGR tech stack
Translate business requirements into data pipelines
Extract and load many disparate systems into a centralized data warehouse
Assist in gathering requirements for new pipelines
Implement data auditing strategies and processes to ensure data integrity
Document complex integration pipelines into easy-to-understand technical specifications
Perform data modeling to document existing and new tables in the data warehouse
Monitor and successfully troubleshoot data problems
Handle multiple projects effectively and meet deadlines
Special projects and assignments as business dictates
Responsible for the maintenance, creation and control of all personally identifiable information or any other information protected by any Confidentiality or Privacy Standards or Company policies that you have access or knowledge of, including but not limited to any state or federal regulations including HIPAA
SUPERVISORY RESPONSIBILITIES
This position has no supervisory responsibilities.
SKILLS AND QUALIFICATIONS
Bachelor's Degree in Computer Science, Information Systems, or related field
4-7 years of experience working with data using SQL or similar technology
3+ years of experience using cloud data warehouses such as Snowflake, Amazon Redshift, Google BigQuery, Azure Synapse
Experience with languages like Python, Ruby, Java, or similar language
3+ years of experience using a data integration platform, such as Talend, Snaplogic, or Informatica
Experience working in a cloud native environment
Strong understanding of data warehousing principles and methodologies
Ability to manage multiple projects in a fast-paced environment
Strong communication skills to all levels of technical expertise
Very high attention to detail
Familiarity with BI Visualization tools
PHYSICAL DEMANDS
Sitting for extended periods of time
Dexterity of hands and fingers to operate a computer keyboard, mouse, and other computing equipment
The employee frequently is required to talk or hear
The employee is occasionally required to reach with hands and arms
Specific vision abilities required by this job include close vision, distance vision, color vision, peripheral vision, depth perception, and ability to adjust focus
Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
WORK ENVIRONMENT
The noise level in the work environment is usually moderate
Fast paced office environment
Ability to work nights and weekends as business dictates
CERTIFICATES, LICENSES, REGISTRATIONS
None required
OTHER DUTIES
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.
This company is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics.",2016,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,True
Data Engineer - 5050304,"Accenture
","Boston, MA",-1,3.9,"Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.

As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.

You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.

Utilize strong SQL Python skills to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features.

Build reporting dashboards and visualizations to design, create and track campaign program KPIs.

Perform analyses on large data sets to understand drivers of operational efficiency.

Manage end to end process of analytic tooling feature development, including request intake, requirements evaluation, cross functional team alignment, feature execution, QA testing, and stakeholder communication.

Consult with business analysts, technical data SMEs, and cross functional partners to understand their reporting and data needs, serving as the point of contact for requests, inquiries, and actions.

Interface with other data engineering, product, and data science teams to implement client needs and initiatives.




Basic Qualifications:

Minimum 2 years experience with Python.

Minimum 3 years experience SQL.

Minimum 3 years experience Big Data Analytics.

High School Diploma or GED.

Preferred Qualifications:

Experience with large enterprise data sets.

Bachelors Degree

Compensation at Accenture varies depending on a wide array of factors, which may include but are not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York, or Washington as set forth below.

Information on benefits is here.

Role Location

California: $61.53 to $71.53/hour

Colorado: $61.53 to $71.53/hour

New York: $61.53 to $71.53/hour

Washington: $61.53 to $71.53/hour


What We Believe


We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.


Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here


Equal Employment Opportunity Statement


Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.


All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.


Accenture is committed to providing veteran employment opportunities to our service men and women.


For details, view a copy of the Accenture Equal Employment Opportunity and Affirmative Action Policy Statement.


Requesting An Accommodation


Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.


If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.


Other Employment Statements


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.


Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.


Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.


The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",1989,Business Consulting,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Engineer,Synovix,"Bedford, MA",$174K - $184K (Employer est.),-1.0,"Responsibilities:
Provide expertise on all data concepts for the broader advanced analytics group, and inspire the adoption of advanced analytics, data engineering and data science across the organization. This will include Installing continuous pipelines of large pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses .

Must have familiarity with the manipulation of unstructured data in a data analytics environment, and the use of open-source tools, cloud computing, machine learning and data visualization. Familiar with specialized languages relevant to the technologies employed such as Apache, Hadoop, etc.

Requirements:

Must have a DoD Secret clearance or higher (interim is okay).
A bachelor's degree in the requisite relevant field. A Master's degree in a relevant field may be substituted for 3 years of general experience.
7 years or more of experience in the data engineering field, at least three of which must have been in a data analytics environment, preferably in DoD or the intelligence community.
Must be willing to work on-site.

Very competitive compensation and benefit package, as well as relocation assistance.

Job Type: Full-time

Pay: $174,000.00 - $184,000.00 per year

Benefits:

401(k) matching
Dental insurance
Health insurance
Life insurance
Paid time off
Relocation assistance
Vision insurance

Compensation package:

Yearly pay

Experience level:

7 years

Schedule:

8 hour shift

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Data Engineer,"Dana-Farber Cancer Institute
","Boston, MA",$88K - $123K (Glassdoor est.),4.0,"Job ID:
37134

Location:
20 Overland Street, Boston, MA 02215

Category:
IT/Informatics

Employment Type:
Full time

Work Location:
Remote: 100% off site

Overview

Located in Boston and the surrounding communities, Dana-Farber Cancer Institute is a leader in life changing breakthroughs in cancer research and patient care. We are united in our mission of conquering cancer, HIV/AIDS and related diseases. We strive to create an inclusive, diverse, and equitable environment where we provide compassionate and comprehensive care to patients of all backgrounds, and design programs to promote public health particularly among high-risk and underserved populations. We conduct groundbreaking research that advances treatment, we educate tomorrow's physician/researchers, and we work with amazing partners, including other Harvard Medical School-affiliated hospitals.

We are seeking a Data Engineer with a strong background in developing technical solutions for Cloud data warehouses to join our team. You will be a critical member of the Informatics & Analytics team supporting the Enterprise Data Systems (EDS) in support of the overall DFCI mission to improve quality and manage healthcare expense trends.

Responsibilities

PRIMARY DUTIES AND RESPONSIBILITIES:
Develops and delivers data & analytics solutions and projects to meet organizational priorities and timelines
Design, Development, and unit testing of data pipelines in Informatica IICS
Utilize Snowflake cloud database to write SnowSQL and utilize advanced features such as micro partitions and time travel
Works with offshore and external partner resources and owns delivery of work items

Qualifications

Minimum Education: Bachelor's degree in Computer Science, Software Engineering or a related field. Master’s degree may substitute for experience.

Minimum Experience: Two years; experience may substitute for degree.

2 years experience in IICS (Informatica Cloud)
Experience with Snowflake cloud database and SnowSQL
Understanding of data warehousing and ETL concepts

KNOWLEDGE, SKILLS, AND ABILITIES REQUIRED:
Should have advanced SQL skills
Gitlab experience is a plus
Good experience with scripting in Python
Should have prior experience working with Dimensional model and understand data warehousing concepts
Demonstrates potential for technical proficiency, creativity, collaboration with others, and independent thought
Excellent communication, problem-solving, and organizational skills
Must be able to build and manage relationships with all involved, managing expectations at all levels
Must be capable of working independently with limited to no supervision

At Dana-Farber Cancer Institute, we work every day to create an innovative, caring, and inclusive environment where every patient, family, and staff member feels they belong. As relentless as we are in our mission to reduce the burden of cancer for all, we are equally committed to diversifying our faculty and staff. Cancer knows no boundaries and when it comes to hiring the most dedicated and diverse professionals, neither do we. If working in this kind of organization inspires you, we encourage you to apply.

EEOC Poster",1947,Health Care Services & Hospitals,$500 million to $1 billion (USD),Healthcare,1001 to 5000 Employees,Nonprofit Organization,False
Data Engineer,"Catalytic Data Science
","Boston, MA",$96K - $136K (Glassdoor est.),4.2,"Data Engineer

Engineering

REMOTE OPPORTUNITY




About Catalytic Data Science (CDS):

Catalytic Data Science is a groundbreaking cloud R&D platform designed to integrate the volumes of scientific resources, data, and analytic tools while providing the ability to network with colleagues in one secure and scalable environment. By enabling R&D teams to work more collaboratively and improving productivity company-wide, the Catalytic platform helps teams achieve key R&D milestones faster and with greater accuracy. Our customers are passionate about making the world a better place, and we are inspired by the opportunity to help them.


The Role:

You are a Data Engineer with experience in processing terabytes of data. You have experience in creating and automating scalable, fault-tolerant and reproducible data pipelines using Amazon AWS technologies. You are interested in helping to create a platform completely built on top of AWS. You are eager to join a team of Life Scientists and Software Engineers that believe the brightest minds in research should have the best tools to drive innovation.




What You’ll Do:




Build & operate automated ETL pipelines that process terabytes of text data nightly
Develop service frontends around our various backend datastores (AWS Aurora MySQL, Elasticsearch, S3)
Perform technical analyses and requirements specification with our product team on data service integrations
Help customers bring their data to the platform



What You Know:




Must Haves:




Python 3 or Java programming experience, preferably both
Day-to-day experience using AWS technologies such as Lambda, ECS Fargate, SQS, & SNS
Experience building and operating cloud-native data pipelines
Experience extracting, processing, storing, and querying of petabyte-scale datasets
Familiarity with building and using containers
Familiarity with event-based microservices



Nice-to-Haves:




Prior experience with Elasticsearch (custom development and/or administration) is a huge plus
Prior work with text and natural-language processing
Knowledge of Graph databases



What do we love in team members?




Your specialization is less important than your ability to learn fast and adapt to shifting technologies. We’re especially fond of people who:




Focus on customer’s needs and our company’s goals, not just writing code
Iterate until customers love what you’ve built
Self-start and initiate
Self-organize
Strive to grow personally and professionally, beyond just expanding technical abilities
Love to experiment with new technology and share knowledge with the team



In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",-1,Computer Hardware Development,$1 to $5 million (USD),Information Technology,1 to 50 Employees,Company - Private,True
Data Engineer,Walmart Advanced Systems and Robotics,"Andover, MA",-1,-1.0,"Walmart Advanced Systems & Robotics is a rapidly expanding initiative with the objective of revolutionizing the retail landscape through robotics. Our development and implementation of the cutting-edge Alphabot® technology are currently underway, with deployment in stores across North America.

As a Data Engineer on the Service & Support Team, you will play a hands-on-role in the development of the data pipelines, setting up data warehouse, and create dashboards for visualization with a goal to make data accessible, and enable the team and the organization to effectively use data to identify bottle necks and make decisions to optimize site performance. The ideal candidate possess strong aptitude for Data, enjoys problem solving, able to multitasks and effectively manage priorities on the incoming data requests.

WHAT YOU'LL WORK ON:

Create data models, reports & analyses to support business needs and convert raw data into meaningful insights through interactive and easy-to-understand dashboards and reports.
Translate team's needs into data solutions using visualization tools like Power BI and Tableau.
Recommend technical approach to data pipeline development and understand the correct schemas to future-proof data pipelines.
Develop queries and reports for internal and external stakeholders.
Review, improve and optimize existing ETL/SQL queries, dashboard views, and procedures while implementing best practices for data extraction and storage.
Work on implementation of technology needed to facilitate the transfer of data and integrations with internal and third-party applications.
Propose, define, review and test data warehouse modifications to fill identified data gaps and improve report design efficiency, including custom tables and views.

WHAT WE'RE LOOKING FOR:

Data Warehousing and Data Mining Experience.
Hands-on experience in extracting data from various data sources and building data models (Star Schema/Snowflake).
Experience in requirement analysis, design, and prototyping.
Experience resolving complex issues in creative, efficient, and effective ways.
Have strong working knowledge of SQL and relational databases.
Experience with cloud data platforms (experience with Azure is a plus).
Demonstrated proficiency transferring data between cross-platform applications.
Ability to write clean, readable, and maintainable code and documentation in Java and/or Python (experience with both not required).
Excellent written & oral communication skills, and strong organizational & planning skills.
B.S. in Computer Science, Data Engineering, or related field. MS is a plus.
3+ years of experience with data visualization tools like Power BI or Tableau.
1+ year of experience within machine learning, computer vision and/or artificial intelligence is a must. Equivalent Master's-level course work is acceptable.
Walmart Advanced Systems and Robotics' recent awards include:
EXCLUSIVE BENEFITS FOR OUR FULL-TIME TEAM MEMBERS:
Comprehensive Health Care Options: Choose from a range of health plans tailored for you, and extend those benefits to your dependents.
Unlimited PTO: Salaried employees receive unlimited paid time off for vacation, holidays, and personal days.
Eye & Dental Care: We've got you and your family covered with top-notch vision and dental insurance.
Secure Your Future: Take advantage of our competitive 401(k) matching, stock purchase plans, and equity opportunities.
Peace of Mind: Comprehensive life and disability insurance options.
Parental Leave: Embrace the joys of parenthood with up to 12 weeks of fully paid maternity/paternity leave.
Exclusive Discounts: Shop and save with special Walmart discounts, both in-store and online.
Dine & Energize On Us: Enjoy daily complimentary lunches, beverages, and a variety of snacks to keep you fueled throughout the day.
Join us and experience the best in employee care and benefits!

Learn more about why we were named a 2022 Best Place to Work at walmartasr/careers.

Walmart Advanced Systems and Robotics is proud to be an Equal Employment Opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",-1,-1,-1,-1,-1,-1,True
Amazon Robotics - Data Engineer (DE) Co-op - Spring 2024,"Amazon.com Services LLC
","Westborough, MA",$90K - $139K (Glassdoor est.),3.7,"Enrolled in a Bachelor's degree in a quantitative/technical discipline such as Computer Science, Engineering, Statistics
Completion of at least junior year of degree program is required with a graduation date of September 2024 or later
Must be eligible and available for a full-time (40h / week) 6-month co-op between January to June 2024
At least 1 year database/data warehouse experience or relevant Graduate/Undergraduate courses
Are you inspired by invention? Is problem solving through teamwork in your DNA? Do you like the idea of seeing how your work impacts the bigger picture? Answer yes to any of these and you’ll fit right in here at Amazon Robotics. We are a smart team of doers who work passionately to apply cutting edge advances in robotics and software to solve real-world challenges that will transform our customers’ experiences. We invent new improvements every day. We are Amazon Robotics and we will give you the tools and support you need to invent with us in ways that are rewarding, fulfilling, and fun.

Amazon.com empowers a smarter, faster, more consistent customer experience through automation. Amazon Robotics automates fulfillment center operations using various methods of robotic technology including autonomous mobile robots, sophisticated control software, language perception, power management, computer vision, depth sensing, machine learning, object recognition, and semantic understanding of commands. Amazon Robotics has a dedicated focus on research and development to continuously explore new opportunities to extend its product lines into new areas.

This role is a 6-month Co-Op to join AR full-time (40 hours/week) from January 16, 2024 to June 28, 2024. This Spring Amazon Robotics Co-op opportunity is be based out of the Greater Boston Area. The campus provides a unique opportunity to have direct access to robotics testing labs and manufacturing facilities.

Key job responsibilities
As a Data Engineer Co-Op, you will be responsible for developing data architecture components that scale for growing data needs. You will solve big data warehousing problems on a massive scale. You will apply cloud-based AWS services to solve challenging problems around: big data processing, data warehouse design, and enabling self-service. You will focus on automation and optimization for all areas of DW/ETL maintenance and deployment. You will work closely with the business intelligence engineers, data scientists and the software development teams on many non-standard and unique business problems and use creative problem solving to deliver actionable output. The role of a Data Engineer in Amazon requires excellent technical skills in order to develop systems and tools to process data as well as, but not limited to, the ability to analyze data. A qualified candidate must have a demonstrated ability to manage large-scale data modeling projects, identify requirements and tools, and build data warehousing solutions that are scalable. Strong written and verbal communication skills with the ability to learn new concepts/frameworks.

We are open to hiring candidates to work out of one of the following locations:

North Reading, MA, USA | Westborough, MA, USA


Experience as a Data Engineer or in a similar role
Experience in working and delivering end-to-end projects independently
AWS experience, building dashboards and BIE reporting tools
Knowledge of distributed systems as it pertains to data storage and computing
If you are not sure that every qualification on the list above describes you exactly, we'd still love to hear from you! At Amazon, we value people with unique backgrounds, experiences, and skillsets. If you’re passionate about this role and want to make an impact on a global scale, please apply!
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",1994,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Junior Data Engineer,"Decision Point Healthcare
","Boston, MA",$86K - $120K (Glassdoor est.),5.0,"Boston, MA

Full-Time


We need your help.

We’re looking for a self-motivated and detail-oriented data engineer to join our DataOps team. This opportunity will enable you contribute to the operation, support, and enhancement of our mission critical data operations platform and the development of data pipelines. Our data operations platform supports high volume, high velocity data ingestion and curation to support our existing, and rapidly expanding, health plan client base.

What you’ll do:

As a junior data engineer, you will be part of a team that is responsible for the execution and management of inbound client and internal service-based data pipelines. This encompasses the development, management, and operation of our client data hubs, including data intake, data quality assessment/evaluation, data curation and enrichment processes. Our client data hubs consist of various health related data sources supporting Decision Point services including our AI/ML platform, analytics platform, and OPUS application suite. If this interests you, read on.

The position:
Develop and apply scalable data integration (ETL/ELT) processes (including ingestion, cleansing, curation, unification, etc.)
Support various components of the data pipelines, including ingestion, validation, cleansing and curation
Manage and ensure the success of ongoing data pipeline routines
Collaborate with our implementation team to assist with the identification and reconciliation of data anomalies
Create and maintain documentation on data pipelines
Engage with our software engineering team to ensure precise data points per application specifications
Provide periodic support to our customer success team
Skills & experience:
BS / MS in Computer Science, Engineering, or applicable experience
Expertise with SQL, database design and data manipulation methodologies
Expertise with ETL/ELT and the development of automated validation and data pipelines
Strong data profiling and analytic skills; Ability to discover and highlight unique patterns/trends within data to identify and solve complex problems
Keen understanding of EDW, master data management and other database design principles
Comfortable working with high volume data in a variety of formats
Excellent verbal and written communication
Self-motivated
Passionate at learning
Familiarity with healthcare data is a plus
Experience with CI/CD and version control tools is a plus
Experience working within hybrid cloud environment such as AWS is a plus
Why Decision Point?:

We’re as passionate about our people as we are about making our mark on healthcare. Fostering a fun and challenging environment that’s centered around personal and professional growth has brought us to where we are today. We are constantly seeking out new ways to reinvest in our team members because let’s face it, we all do our best work when we feel valued.

Meaningful work
Remote friendly environment
We encourage outside the box ideas
Great healthcare coverage
Competitive compensation
Social outings",2013,-1,Less than $1 million (USD),-1,1 to 50 Employees,Company - Public,False
Data Engineer,"EFFECT Photonics
","Maynard, MA",$87K - $130K (Glassdoor est.),3.7,"EFFECT Photonics is looking for an experienced – Data Engineer


The Data Engineer will be responsible for data visualization, architecting, developing, and maintaining databases tied to Manufacturing results. They will work closely with Operations, Contract Manufacturing Partners, Engineering and R&D stake holders to create unique data infrastructure in support of Operations Results.




Role responsibilities




The ideal candidate will have 5 years of experience in data engineering and possess expertise in the following areas:


PostgreSQL: Proficiency in working with PostgreSQL, including designing, and optimizing database schemas.
Azure Cloud: Experience working with Azure Cloud services, such as Azure Data Factory, Azure Data Lake Analytics, and Azure Stream Analytics.
Data Visualization: Familiarity with data visualization tools like Power BI to create visualizations of data for analysis.
Data Architecture: Experience in developing data architectures for manufacturing results, ensuring efficient data storage, retrieval, and processing.
Quality Management Systems: Experience aggregating data in support of product build histories, field failure history, product flow control, correct actions, traceability, and genealogy
Manufacturing Execution Systems: Understand of MES systems
CRM: Exposure to customer management systems

Tasks and projects:

Assembling large, complex sets of data that capture manufacturing results and product performance.
Building required infrastructure for optimal extraction, transformation, and loading of data from various data sources using Azure, AWS and SQL technologies.
Building visualization and analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including build history, yields, operational efficiency, and product history.
Identifying, designing, and implementing internal process improvements, including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Working with stakeholders including the Executive, Product, Data, and Design teams to support their data infrastructure needs while assisting with data-related technical issues.
Work with Contract Manufacturing Partners to define the processes to extract near real time data from their proprietary MES implementations.
Work with Sales Operations, owners of Salesforce CRM, to provide Unit history for warranty needs.
Work with internal owners at Effect Photonics to provide unit history into overall QMS implementation.


About You




We want you to bring your Data Engineering skills and deep knowledge of managing manufacturing information on various platforms to the forefront of our organisation, helping us set the standard for Data management allowing EFFECT Photonics to become a leader in this field.

Required / Desired knowledge, skills, and abilities

Bachelor’s degree in Data Science, Business Intelligence, Computer Science or related fields or equivalent combination of education, professional training, and work experience.
5 years of experience working with one or more languages commonly used for data operations including SQL (e.g., PostgreSQL), Python, Scala, and R.
Experience with Salesforce, Arena, MES and\or QMS systems highly desirable
Experience with Power BI, Tableau or other visualization tools
Exposure to Manufacturing Results data streams
Ideally would like candidates to be in Maynard, or able to travel to site as required

About Us

Where Light Meets Digital - EFFECT Photonics is a highly vertically integrated, independent photonic semiconductor company addressing the need for high-performance, affordable optic solutions driven by the ever-increasing demand for bandwidth and faster data transfer capabilities. Our teams are made up of professional, highly skilled, energized, and enthusiastic people who share a passion for developing and creating high-volume, world-class solutions. We operate globally, and our teams work collaboratively to make EFFECT Photonics a very dynamic and rewarding place to work.

We are a collaborative Global Technology Company, and we’re building a truly dynamic and rewarding place to work.

Reward and Benefits

Benefits are a critical component to consider when taking on a new challenge, but because we are a global company, benefits may vary by location.

Here’s what you can expect from us regardless:

An exciting working culture where everyone’s point of view has real value
An environment that embraces collaboration
A competitive salary that reflects our ambition
A flexible benefits scheme with health, dental and pension scheme (401 k – for US based roles)
Paid time off (vacation days) plus statutory annual holidays
Stock Appreciation Rights (SAR – stock program)

We look forward to receiving your application, if you have any questions, please get in touch with our recruitment team.

Email: recruitment@effectphotonics.com - No agencies please!

Effect Photonics is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. Effect Photonics complies with all applicable state and local laws governing non-discrimination in employment.

Ref: SCJD008",2010,Electronics Manufacturing,Unknown / Non-Applicable,Manufacturing,51 to 200 Employees,Company - Private,True
Data Engineer (On-Site),"PrismHR
","Hopkinton, MA",$77K - $108K (Glassdoor est.),3.9,"Do you have a passion for building data architectures that enable smooth and seamless product experiences? Are you an all-around data enthusiast with a knack for ETL? We're hiring Data Engineers to help build and optimize the foundational architecture of our product's data.

We’ve built a strong data engineering team to date, but have a lot of work ahead of us, including:

Migrating from relational databases to a streaming and big data architecture, including a complete overhaul of our data feeds
Defining streaming event data feeds required for real-time analytics and reporting
Leveling up our platform, including enhancing our automation, test coverage, observability, alerting, and performance

As a Data Engineer, you will work with the development team to construct a data streaming platform and data warehouse that serves as the data foundations for our product.

Help us scale our business to meet the needs of our growing customer base and develop new products on our platform. You'll be a critical part of our growing company, working on a cross-functional team to implement best practices in technology, architecture, and process. You’ll have the chance to work in an open and collaborative environment, receive hands-on mentorship and have ample opportunities to grow and accelerate your career!

Responsibilities:

Build our next generation data warehouse
Build our event stream platform
Translate user requirements for reporting and analysis into actionable deliverables
Enhance automation, operation, and expansion of real-time and batch data environment
Manage numerous projects in an ever-changing work environment
Extract, transform, and load complex data into the data warehouse using cutting-edge technologies
Build processes for topnotch security, performance, reliability, and accuracy
Provide mentorship and collaborate with fellow team members

Qualifications:

Bachelor’s or Master’s degree in Computer Science, Information Systems, Operations Research, or related field required
3+ years of experience building data pipelines
3+ years of experience building data frameworks for unit testing, data lineage tracking, and automation
Fluency in Scala is required
Working knowledge of Apache Spark
Familiarity with streaming technologies (e.g., Kafka, Kinesis, Flink)

Nice-to-Haves:

Experience with Machine Learning
Familiarity with Looker a plus
Knowledge of additional server-side programming languages (e.g. Golang, C#, Ruby)

PrismHR is a fast-paced SaaS company which provides customers with a cloud-based payroll process software application. PrismHR also provides professional services including system implementation consulting, custom configurations, and training. Lastly, via the Company’s Marketplace platform customers and end users access other human resources and employee benefits applications from PrismHR’s Marketplace Partners.

Diversity, Equity and Inclusion Program/Affirmative Action Plan:
We have transformed our company into an inclusive environment where individuals are valued for their talents and empowered to reach their fullest potential. At PrismHR, we strive to continually lead with our values and beliefs that enable our employees to develop their potential, bring their full self to work, and engage in a world of inclusion.

Ensuring an inclusive environment for our employees is an integral part of the PrismHR culture. We aren't just checking a box, we are truly committed to creating a workplace that celebrates the diversity of our employees and fosters a sense of belonging for everyone. This is essential to our success. We are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about our roles but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for these open roles or other open roles. We particularly encourage applicants from traditionally under-represented groups as we seek to increase the diversity of our workforce and provide fair opportunities for all.

As a proud Equal Opportunity and Affirmative Action Employer, PrismHR encourages talent from all backgrounds to join our team. Employment decisions are based on an individual’s qualifications as they relate to the job under consideration. The Company’s policy prohibits unlawful discrimination based on sex (which includes pregnancy, childbirth, breastfeeding, or related medical conditions, the actual sex of the individual, or the gender identity or gender expression), race, color, religion, including religious dress practices and religious grooming practices, sexual orientation, national origin, ancestry, citizenship, marital status, familial status, age, physical disability, mental disability, medical condition, genetic information, protected veteran or military status, or any other consideration made unlawful by federal, state or local laws, ordinances, or regulations.

The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company and prohibits unlawful discrimination by any employee of the Company, including supervisors and co-workers.

Privacy Policy: For information about how we collect and use your personal information, please see our privacy statement available at https://www.prismhr.com/about/privacy-policy.

PrismHR provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need a reasonable accommodation due to a disability, you may use the following alternative email address to contact us about your interest in employment at PrismHR: taglobal@prismhr.com. Please indicate in the subject line of your email that you are requesting accommodation. Only candidates being considered for a position who require an accommodation will receive a follow-up response.

#LI-ML1

TeUlu1eovl",1985,Software Development,$500 million to $1 billion (USD),Information Technology,501 to 1000 Employees,Company - Private,True
Data Engineer,"Harvard University
","Boston, MA",-1,4.3,"Position Description

The Center for Computational Biomedicine (CCB) is a new center within the Blavatnik Institute at Harvard Medical School. Our mission is to provide cutting-edge computational capabilities, data analysis, and data integration technologies to support medical and biological research within the Medical School. Based at the Harvard Medical School Longwood Campus, we are part of a vibrant community of scientists, physicians, and engineers whose goal is to advance the boundaries of knowledge and improve patient care. The working environment combines the best features of a startup (fast pace, flexibility, flat hierarchies) with those of one of the leading medical schools (excellent benefits, outstanding opportunities for learning, great resources, name recognition).


CCB is looking for an individual to join the Data and Analytic Platforms Group, a group of engineers and scientists developing data warehousing and analytic solutions in support of epidemiology, healthcare economics, machine learning, and basic science research.


The Group works to reduce the burden on faculty by developing centrally managed and shareable data solutions to be used across research silos. We curate very large public and private healthcare utilization (insurance claims, electronic health record), multi-omics, environmental exposure, and social determinants data sets, provision access to those curated data sets, and develop analytic frameworks to accelerate reproducible academic research on top of them. Collectively these data sets contain information relating to hundreds of millions of patients.


This position reports to the Director of the CCB Data and Analytic Platforms Group. Primary responsibilities will include designing and implementing relational database architecture (schema, indexing, stored procedures, ETL processes, etc.) to warehouse multi-terabyte data sets in Microsoft SQL Server. This will include periodically evaluating various query performance metrics to ensure real-time availability to the research community and recommending modifications to the underlying database platform to resolve any identified issues. The bulk of this design work will be left up with the candidate, while a small portion will involve refactoring (or strategically deciding to abandon) existing ETL / indexing strategies. The data sets will be staged into a combination of proprietary schemas as well as the open-source i2b2 data model.


Additional opportunities will be available for the candidate to interact with individual scientific research teams to help improve their workflows.

Basic Qualifications

Minimum of seven years’ post-secondary education or relevant work experience

Additional Qualifications and Skills

Bachelor’s Degree in Computer Science or related degree preferred. At least 5 years experience as a software systems architect, including experience developing solutions with both relational database systems and at least one of the following languages: Java, Python, R.
Master’s Degree in a related field (Computer Science / Electrical Engineering, Bioinformatics, Statistics, Data Science, etc.) preferred.
Excellent communication skills, both written and oral
Experience with Microsoft SQL Server or cloud-based data warehousing technologies
Experience designing and maintaining multi-terabyte analytic relational databases, including index and query optimization
Experience orchestrating and optimizing Extract-Transform-Load (ETL) processes for multi- terabyte data warehouses
Comfort doing basic system administration in a Linux environment Comfort doing basic system administration in a Windows environment Experience with relational database index optimization
Experience with containerized (Docker or Singularity) workflows/paradigms
Experience with non-relational database systems (graph, key/value, document, array data stores) Experience with the R statistical computing platform
Experience with Java Experience with Python
Experience with high-performance computing
Comfort independently exploring distributed computing and database technologies and generating executive reports
Experience with public cloud platforms (AWS, Azure, Google Cloud)

Additional Information

This is a 12-month term appointment with the possibility of renewal contingent on funding.

The health of our workforce is a priority for Harvard University. With that in mind, we strongly encourage all employees to be up-to-date on CDC-recommended vaccines.

Please note that we are currently conducting a majority of interviews and onboarding remotely and virtually. We appreciate your understanding.

Harvard University offers an outstanding benefits package including:
Time Off: 3 - 4 weeks paid vacation, paid holiday break, 12 paid sick days, 12.5 paid holidays, and 3 paid personal days per year.
Medical/Dental/Vision: We offer a variety of excellent medical plans, dental & vision plans, all coverage begins as of your start date.
Retirement: University-funded retirement plan with full vesting after 3 years of service.
Tuition Assistance Program: Competitive tuition assistance program, incredibly affordable classes directly at the Harvard Extension School, and discounted options through participating Harvard grad schools.
Transportation: Harvard offers a 50% discounted MBTA pass as well as additional options to assist employees in their daily commute.
Wellness options: Harvard offers programs and classes at little or no cost, including stress management, massages, nutrition, meditation, and complementary health services.
Harvard access to athletic facilities, libraries, campus events, and many discounts throughout metro Boston.
The Harvard Medical School is not able to provide visa sponsorship for this position.

Not ready to apply? Join our Talent community to keep in touch and learn about future opportunities!
(https://www.gem.com/form?formID=16341e35-cbc6-4904-88a3-09b35763307e)



Job Function

Information Technology, Research

Department Office Location

USA - MA - Boston

Job Code

I1359P IT Data Architect Prof V

Work Format

Remote

Sub-Unit

-

Salary Grade

059

Department

Center for Computational Biomedicine

Union

00 - Non Union, Exempt or Temporary

Time Status

Full-time

Pre-Employment Screening

Criminal, Identity

Schedule

35 hrs. per week | Monday - Friday | 9:00 am - 5:00 pm

Commitment to Equity, Diversity, Inclusion, and Belonging

We are committed to cultivating an inclusive workplace culture of faculty, staff, and students with diverse backgrounds, styles, abilities, and motivations. We appreciate and leverage the capabilities, insights, and ideas of all individuals. Harvard Medical School Mission and Community Values



EEO Statement

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation, pregnancy and pregnancy-related conditions, or any other characteristic protected by law.",1636,Colleges & Universities,$10+ billion (USD),Education,10000+ Employees,College / University,False
Data Engineer MongoDB,Digital Plus Solutions,"Waltham, MA",$55.00 - $60.00 Per Hour (Employer est.),-1.0,"Title: MongoDB Data Engineer

Location: Waltham MA (Onsite)

Contract: Long Term

Visa: Any

Description:

· Post process submitted data & records handling.

· Schedule and monitor the Triggers and Cron tasks.

· Monitor database performance and optimize queries for efficiency.

· Stay up-to-date with MongoDB best practices and emerging trends.

· Develop and enforce database policies and procedures for data governance.

Skills:MongoDB, JavaScript, Crons

Job Types: Contract, Full-time

Pay: $55.00 - $60.00 per hour

Work Location: In person",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,True
Senior Data Engineer,"TriMark USA
","Mansfield, MA",$93K - $123K (Glassdoor est.),3.1,"TriMark USA is the country’s largest provider of design services, equipment, and supplies to the foodservice industry. We proudly serve our customers by providing design services, commercial equipment, and foodservice supplies across a wide range of industries and business sectors. Headquartered in Massachusetts, with a history dating back to 1896, we have locations across the country that offer foodservice operators an unparalleled level of service by combining our unique design capabilities and our expert market knowledge with the purchasing strength, delivery, installation, and after-sales service capabilities of a national company. Our employees are focused on creating customized solutions for our clients to ensure they achieve their culinary goals while upholding our I.C.A.R.E. values: Integrity, Customer Service, Accountability, Respect, and Excellence. For more information, please visit: www.trimarkusa.com

Why you’ll love it here!
+ Benefits include Medical, Dental, Vision, Tuition Reimbursement, Pet, and Legal Insurance.

POSITION SUMMARY:

The Senior Data Engineer reports to the Vice President of Data Analytics.
Located in Mansfield, Ma.
Full-Time
Hybrid
ESSENTIAL FUNCTIONS & RESPONSIBILITIES:

Design, build, and deploy business intelligence solutions with Microsoft's BI stack and other BI tools.
Perform ETL development utilizing SQL queries, stored procedures, functions, views, SSIS packages and other tools as necessary to meet all customer requirements.
Plan, design, develop and implement robust ETL processes between internal systems and to external systems.
Develop integrations and support a large enterprise data warehouse integrated to several disparate database platforms.
Build reporting solutions for diverse business functions utilizing various reporting tools such as Microsoft SSRS, Tableau and Power BI.
Develop an in-depth understanding of our data environment and leverage knowledge to build robust, user-friendly reports and visualizations by utilizing diverse reporting tools.
Primarily work within MS-SQL, but access Oracle, DB2 and other database platforms, as well as import/export to a variety of file formats.
Job duties will include all phases of the SDLC process for database development, including problem definition, requirements gathering, design, build, test, implement and ongoing support. Follow design and development standards and guidelines as defined by the IT development team.
Assist in the designing, planning, and implementation of disaster recovery policies and procedures. Work with business analysts and application development staff to develop and enforce database architectures, coding standards and quality assurance policies and procedures.
Proactively contribute, offer recommendations, and identify risks and solutions associated with proposed or existing database solutions and strategies.
Work cooperatively with business analysts to define business needs, translating those needs into system requirements and clearly defining the scope of the solution.
Consult and coordinate with business analysts and other programmers to design and develop automated business systems.
Understand the data elements, database structures, and data flows within an enterprise system. Assist with new software/hardware implementation including initial training, follow-up support, and on-going continuous application improvement.
Track and document changes to functional and business specifications. Create or assist others in the writing of user documentation, instructions, and procedures.
Monitor and document post-implementation problems and revision requests.
QUALIFICATIONS & EXPERIENCE:

Requires a Master's degree in Computer Science, Information Systems, Business Analytics, or a related field plus 2 years of experience with SSRS reports developing Business Intelligence and Business Analytics reports, or equivalent Military or practical experience.
2 years of experience working with business requirements for projects, including designing and building reports.
2 years of experience creating dashboard-style reports with Tableau.
2 years of experience with Server Integration Services (SSIS), or other ETL protocols.
2 years of experience with Microsoft SQL. Ability to successfully pass a background check post offer acceptance.
The range provided represents the national average pay range for this position and is considered to be a general guideline. Pay for this position will reflect the candidate’s unique qualifications and may be higher or lower than the range provided based on employee geographic location. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other local, state, and federal law.

In addition to base salary, this role will be eligible for participation in TriMark’s’ benefits programs, including medical, dental, vision, 401K (with employer match), etc. Leadership positions may also qualify for participation in bonus programs commensurate with role and scope of responsibility.

TriMark’s commitment to diversity, equity, and inclusion is a purposeful mission of strengthening our organization and those we serve by uniting the unique differences of our employees. This mission is instilled in who we are as a company. We are committed to promoting diversity, equity and inclusion through sharing, education, and experiences. We are greater together through unity in diversity.

TriMark USA provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to accommodations@trimarkusa.com.",-1,Wholesale,$1 to $5 billion (USD),Retail & Wholesale,1001 to 5000 Employees,Company - Private,True
Data Support Engineer,"Hashmap
","Brighton, MA",$67K - $98K (Glassdoor est.),3.4,"Req ID: 261278

NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.

We are currently seeking a Data Support Engineer to join our team in Brighton, Massachusetts (US-MA), United States (US).


Work hours between 2 – 11 PM EST. This position can be remote with PST time zone ideal.


Responsibilities:

at staging/QA environments and help deploying them at production.

- Work with business, product and technical stakeholders on data or report issues.

- Create and manage Incident and Change Requests as needed for data pipelines.

- Assist with data architecture, pipeline development, automation and planning

- Develop and maintain documentation, departmental technical procedures, and user guides

- Maintain best practices to facilitate optimized software development and continuous improvement/continuous delivery (CI/CD)

- Triage problems across the data platform to help address development, test, and production issues.

- Testing Data pipelines


Basic Qualifications:

- 4+ years of software development

- Software engineering best practices (system design for scale, modularity, version control, unit testing, documentation etc.) on real-world projects

- Code in multiple languages ( Python and SQL ; R, Java , or others as well)

- Foundation/certification in the AWS Cloud Services: S3, Redshift Spectrum, EC2

- Gitlab, JIRA and Confluence


Education:

- Undergraduate degree in computer science, engineering, or a related discipline preferred.


#INDFSINS

#L1-NAM


About NTT DATA Services

NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients’ long-term success. Visit nttdata.com or LinkedIn to learn more.

NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.",1967,Information Technology Support Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer,"MIT
","Cambridge, MA",$103K - $140K (Glassdoor est.),4.4,"DATA ENGINEER, Political Science, to be part of an innovative computational social science project at the forefront of leveraging advanced computational techniques to deepen our understanding of politics. Will spearhead the development of an ETL (extract, transform, load) pipeline, working closely with the MIT Institute for Data, Systems, and Society (IDSS) and the Schwarzman College of Computing; collaborate with Professor In Song Kim (principal investigator) as well as with a team of postdoctoral, graduate, and undergraduate researchers to design and improve the LobbyView database, a comprehensive repository on lobbying and political donations; and help researchers to solve the most challenging computational problems in social science research and establish pipelines for queries and analysis.

The position offers career development and the opportunity to engage with a vibrant academic community in a nimble, start-up like setting that provides a unique opportunity to make immediate impacts on various research initiatives at MIT.




Job Requirements


REQUIRED: B.A./B.S. in computer science or related technical domain; at least three years’ professional experience; experience with SQL databases, especially PostgreSQL, encompassing advanced query writing and server management; proficiency with Python; familiarity with standard web scraping and data science libraries and Bash shell scripting; experience using Git or analogous version control systems; comfort connecting to and utilizing Linux-based servers, preferably administrative experience; and excellent communication skills. PREFERRED: experience with modern web development frameworks; grasp of cloud server deployments, particularly on AWS; interest in social science/political science, preferably trade, lobbying, or American politics; and experience writing documentation, including writing and recording video tutorials. Job #23328

This is an ongoing position and is local to the Boston/Cambridge area. Remote or hybrid work schedules will be considered.

Hiring for this position will involve a take-home skills test and oral interview.

A complete application should include: a) a cover letter (Please indicate your earliest preferred start date in your cover letter.), b) a resume, and c) a project portfolio (if any, that is relevant to the position) as a single PDF file.",1861,Colleges & Universities,$1 to $5 billion (USD),Education,10000+ Employees,College / University,False
Data center technician/Customer Engineer,"Vortalsoft
","Grafton, MA",$60K - $65K (Employer est.),3.4,"Job Title: Data center technician/Customer Engineer

Location: Westborough/Grafton, MA

Maintech provides computer system and LAN/WAN services to mission critical, multi-vendor, multi-site applications in the Financial, Telecommunications and Research and Development markets. Maintech's broad spectrum of IT design, procurement, project management and maintenance services, includes 24/7 managed network and systems support.

We are looking for 5 self-motivated, dedicated individuals who are ready to put their technical skills to work in a fast-paced, customer focused environment. Utilizing their technical knowledge, they will have the responsibility of responding to customer calls in a timely and efficient manner to troubleshoot, analyze and diagnose servers in a critical environment. They will provide problem resolution or refer more complex issues to a Sr. Support Engineer. Maintenance of inventory and documentation of activity will demonstrate strong organizational skills. Must be available and on-call 24x7x365.

Responsibilities

Analyzes, diagnoses, and troubleshoots hardware/server issues with focus on responsiveness; provides issue resolution
Maintains inventory and documentation of activity
Creates own service tickets, updates, and closes
Communicates before and after repair work windows via ticket and email to client
Break/Fix

Qualifications

Previous experience working on on HPE, DELL, Oracle (SUN), or Lenovo Servers
Strong problem solving and self-management skills with attention to detail
Ability to prioritize tasks and effectively communicate verbally and in writing
5+ years’ experience servicing hardware as specified or utilized in customer environment
Familiarity with ticket-tracking software (ServiceNow preferred)

Job Type: Full-time

Salary: $60,000.00 - $65,000.00 per year

Schedule:

8 hour shift

Work setting:

In-person
Office

Ability to commute/relocate:

Grafton, MA 01519: Reliably commute or planning to relocate before starting work (Required)

Work Location: In person",-1,Computer Hardware Development,$5 to $25 million (USD),Information Technology,1 to 50 Employees,Company - Private,True
"Research Software Engineer, Data Science","Dana-Farber Cancer Institute
","Boston, MA",$110K - $137K (Glassdoor est.),4.0,"Job ID:
29995

Location:
450 Brookline Ave, Boston, MA 02215

Category:
IT/Informatics

Employment Type:
Full time

Work Location:
Remote: 100% off site

Overview

The Department of Data Science at the Dana Farber Cancer Institute (DFCI) seeks candidates with a strong R programming background. As part of the department's mission to collaborate with basic biologists and clinical researchers to better understand cancer and improve treatment, our department develops new statistical methods and data analysis pipelines and implements these as R packages or shiny dashboards. We need help extending and improving these, as well as training our students, postdoctoral faculty and collaborators in best practices and new developments related to R. We are seeking a software engineer to help with these challenges. The department chair will help prioritizing projects and compartmentalize them into manageable units.

The successful candidate will have a unique opportunity to work in an exceptional collaborative environment with experts in a wide range of areas including clinical trials, cancer genetics, immunology, epigenetics, machine learning, Bayesian methods, and alignment algorithms. There is room for growth in this position as the career ladder permits promotion to levels that lead groups of other software engineers. We offer salaries that are competitive with the biotech industry. Remote work is a possibility.

Located in Boston and the surrounding communities, Dana-Farber Cancer Institute is a leader in life changing breakthroughs in cancer research and patient care. We are united in our mission of conquering cancer, HIV/AIDS and related diseases. We strive to create an inclusive, diverse, and equitable environment where we provide compassionate and comprehensive care to patients of all backgrounds, and design programs to promote public health particularly among high-risk and underserved populations. We conduct groundbreaking research that advances treatment, we educate tomorrow's physician/researchers, and we work with amazing partners, including other Harvard Medical School-affiliated hospitals.

Responsibilities

As this is part of multiple ongoing collaborations, the nature of the work will depend on your strengths and experiences; this is an exciting opportunity to be involved in work with direct real-world impact and leverage our department’s expertise to build skills in a number of areas from high-performance computing/GPU acceleration, implementation of machine learning algorithms, computational biology pipelines, matrix operations on sparse data, among others. Examples of tasks you may be asked to perform are listed below.

Work with center technical and research staff to develop tools that directly help researchers put their ideas into production.
Maintain and improve shiny apps
Train SAS users to use dplyr or data.table
Iteratively develop software in collaboration with a world-leading team of researchers
Use test-driven-development and continuous integration to ensure that the new code is reliable
Document the software from a user and developer perspective

Qualifications

Minimum Education:
Successful completion of a coding training/coursework, software certificate program, or similar; or current enrollment in a bachelor’s degree program in Computer Science, Software Engineering, or a related field.

You should hold demonstrable experience in R, shiny, C++, Python, and Unix.
You will be familiar with version control (e.g. git) and standard development practice tools and be able to write modular, maintainable and testable code.
A high level of communication skills is essential to be able to elicit complex requirements from, and convey complex requirements to, groups with differing technical backgrounds.

Please contact chair@ds.dfci.harvard.edu with questions about this role.

At Dana-Farber Cancer Institute, we work every day to create an innovative, caring, and inclusive environment where every patient, family, and staff member feels they belong. As relentless as we are in our mission to reduce the burden of cancer for all, we are equally committed to diversifying our faculty and staff. Cancer knows no boundaries and when it comes to hiring the most dedicated and diverse professionals, neither do we. If working in this kind of organization inspires you, we encourage you to apply.

EEOC Poster",1947,Health Care Services & Hospitals,$500 million to $1 billion (USD),Healthcare,1001 to 5000 Employees,Nonprofit Organization,False
Workday HR Data & Integration Engineer,"DraftKings
","Boston, MA",$63K - $93K (Employer est.),4.0,"We’re defining what it means to build and deliver the most extraordinary sports and entertainment experiences. Our global team is trailblazing new markets, developing cutting-edge products, and shaping the future of responsible gaming.

Here, “impossible” isn’t part of our vocabulary. You’ll face some of the toughest but most rewarding challenges of your career. They’re worth it. Channeling your inner grit will accelerate your growth, help us win as a team, and create unforgettable moments for our customers.

The Crown Is Yours

We have an incredible team working together to build innovative people experiences for everyone at DraftKings. As a member of the People Technology Team, the People Technology Data and Integrations Engineer, you will play a pivotal role in enhancing our HR and technology systems. Your primary responsibilities will include designing, developing, and managing integrations within the Workday platform, optimizing SQL databases, and learning to work with Workday Extend to customize our HR systems further.

Key Responsibilities:

Design, develop, and maintain integrations within the Workday platform to streamline data flows and enhance automation.

Collaborate with cross-functional teams to understand integration requirements and create efficient solutions.

Troubleshoot and resolve integration-related issues in a timely manner.

Manage and optimize MySQL databases, ensuring data integrity, performance, and security.

Write and optimize MySQL queries and scripts for data extraction, transformation, and loading (ETL) processes.

Monitor database performance and implement performance tuning strategies as needed.

Learn and master the Workday Extend platform to create custom solutions and extensions for our HR systems.

Collaborate with HR and IT teams to gather requirements and develop customized solutions using Workday Extend.

Maintain detailed documentation for integrations, database configurations, and Workday Extend customizations.

Create user guides and training materials for HR and IT teams.

May assist Workday Systems Leads with roadmap initiatives, Workday configuration updates, security assignments and/or Tier 2 inquiries.

Required Skills/Abilities:

Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience).

Proven experience in designing and developing integrations within the Workday platform.

Strong proficiency in MySQL database management, including data modeling, performance tuning, and scripting.

Ability and willingness to quickly learn and adapt to new technologies, particularly Workday Extend.

Excellent problem-solving skills with a keen attention to detail.

Strong communication and collaboration skills for working with cross-functional teams.

Familiarity with HR systems and processes is a plus.

Join Our Team

We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston. As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment. Don’t worry, we’ll guide you through the process if this is relevant to your role.

The US base salary range for this full-time position is $63,495.00 - $93,375.00, plus bonus, equity, and benefits as applicable. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range and how that was determined during the hiring process.",2012,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Public,False
Data Engineer - Linguistics,"Babel Street
","Somerville, MA",$120K - $150K (Employer est.),4.3,"About Babel Street and the Role:


Babel Street illuminates identity and information for a safer, more productive world. Engineered for mission-critical applications, our proven AI-powered products transform data into knowledge, build a more complete picture around identity, and discover digital evidence. Our advanced data analytics and intelligence platform, combined with a robust text analytics engine, helps teams rapidly transform massive amounts of global, multilingual data into actionable and contextual insights so they can act with confidence. Every day, we work with our customers in highly-regulated, high-stakes industries such as financial services, healthcare, legal and law enforcement, and the global public sector. The actionable insights we deliver safeguard lives and protect critical assets around the world. Learn more at babelstreet.com.


In this role you will have the opportunity to work with multiple, discrete engineering teams providing annotated, reliable data to train, develop, and evaluate natural language processing systems as well as consult on the language specific aspects of multilingual text. Join us and help us create the next wave of software for Natural Language Processing and Text Analytics.




What you will do:




Manage large-scale text mining, data acquisition and annotation projects
Train and supervise contractors as they perform manual annotation tasks
Measure reliability of parallel, manual annotations
Survey and catalogue new data releases and best practices in data maintenance, conversion, and analytics



What you will bring:




Strong scripting abilities, especially Python
Data cleaning, conversion, organization
Parsing XML, JSON, tabular data sets
Scraping and collecting text from online resources including web sites and APIs
Ability to write and revise annotation guidelines
Ability to translate product requirements into annotation guidelines
Ability to synthesize clear instructions and instructive examples
Knowledge of Linguistics and NLP applications including
Language identification
Tokenization
Part of speech tagging
Morphological analysis
Entity extraction, disambiguation, and linking
Syntactic parsing
Sentiment analysis
Experience working with manual annotation tools and platforms such as brat, WebAnno, Prodigy, Mechanical Turk, etc.



Nice to have:




Experience with databases such as SQL and Mongo
Experience with SPARQL query language
Proficiency in at least one natural language in addition to English
Experience with conversion, storage, version control and maintenance tasks for large multilingual text collections
Familiarity with prominent linguistic annotation guidelines (e.g., Penn Treebank)
Familiarity with linguistic community resources and data providers such as
Universal Dependencies treebank project
ClueWeb
CommonCrawl
Linguistic Data Consortium






Benefits at Babel Street (just to name a few...)




Health Benefits: Babel Street covers 90-100% monthly premium costs for Medical, Dental, Vision, Life & Disability insurances – for you and your family!
Retirement Plans: Babel Street offers both a Traditional and Roth 401(K) with a very competitive match.
Unlimited Flexible Leave: We trust our employees to manage their own time and balance their personal and work lives. At a minimum, employees need to take a least 15 to 25 days per year.
Holidays: Babel Street provides employees with 12 paid Federal Holidays
Tuition Reimbursement: We are committed to investing in our employees. One way we do that is with our Tuition Reimbursement Program for continuing education.



Babel Street is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. Further, Babel Street will not discriminate against applicants for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co‐worker, Pay Transparency Nondiscrimination. In addition, Babel Street's policy is to provide reasonable accommodation to qualified employees who have protected disabilities to the extent required by applicable laws, regulations and ordinances where a particular employee works. Upon request, we will provide you with more information about such accommodations.


#LI-Hybrid",2012,Computer Hardware Development,$25 to $100 million (USD),Information Technology,51 to 200 Employees,Company - Private,True
Data Engineer,"Intone Networks
","Marlborough, MA",$88K - $124K (Glassdoor est.),4.3,"Title: Data Engineer Location: 400 Value Way, Marlborough, MA 01752 – 100% remotE Visa : USC,GC • Fully remote role • 5-10 in data engineering • Min 3 years hands on exp with Alteryx; not only design • Min 3 years hands on exp with Snowflake; not only design Skills Strong working experience with Excel, Power BI, Snowflake, & Alteryx. Some experience in data bricks and Azure Data Lake Services Strong experience (5-10 years) in a technical data or analytics role, specifically in the technical design, development and implementation or support of business systems",-1,Information Technology Support Services,$5 to $25 million (USD),Information Technology,201 to 500 Employees,Company - Private,False
Solutions Engineer/ Systems Data Management Consultant,"Trianz
","Springfield, MA",$87K - $122K (Glassdoor est.),4.3,"About Trianz

Trianz is a digital transformation technology and services firm that helps clients transform their value proposition and business value chains. We deliver end-to-end digital transformation services from strategy and roadmaps to experience design, technology implementations, and managed services. With a multi-disciplinary, collaborative model, we help clients understand their competitive digital maturity, develop effective strategies, and transform using our IP-led platforms and technology services. We lead with data and IP that accelerates digital transformations, optimizes investments, and delivers measurable results. We have been rated #1 for 'transformational impact' and 'predictability of execution' by a Fortune 1000 client base- 5 years straight.

At Trianz, we offer you an open and learning-oriented culture essential to emerge as a leader. Completely focused on the Digital Evolution philosophy and phenomenon, we view delivering our value proposition consistently as a non-negotiable commitment. Our enablers include Intelligent Team Formations, a Client-Centric Approach, Predictability in Execution, and establishing a Unique Relationship Experience. A culture of innovation, encouraging our people to create, and belief in the importance of training and development set us apart.

Role: Solutions Engineer/ Systems Data Management Consultant

Employment Type: Contract for 6 months (can be extended depending on the scope of the project)

Location: Springfield, MA - (3days in a week at onsite /Hybrid Model)

POSITION SUMMARY

The Solutions Engineer is a key member of the Investment Delivery Services (IDS) Team responsible for application administration and technical support for technology platforms and systems supporting Investment Management (IM). This role supports and maintains numerous large and complex applications to manage work queues for project delivery and daily operations.

The Solutions Engineer is responsible for the testing and introduction of application configuration changes, applying upgrades, setup and maintenance of user security roles, and monitoring and troubleshooting issues concerning the health of the application and/or the environment. Additionally, this position will provide technology support for onshore and offshore teams including user provisioning/de-provisioning, designing and implementing application customizations, and managing and tracking desktop and connectivity related issues. This position requires a broad technical knowledge with the ability to perform very specific technical tasks within the various solutions.

KEY RELATIONSHIPS

Reports to: Delivery Lead, Investments

Other Relationships: Investment Management (IM), Corporate Finance, Investment Data Ecosystem (IDE) Teams, Enterprise Experience and Technology (ETX) Teams, Project Management Office for Investments (PMOfi), Data and Solution Vendors
OVERALL RESPONSIBILITIES


Support business stakeholders during production operations
Support IDS and project development teams
Influences and implements the IDS technology strategy
Technology support for end-users and development teams
Assist in defining, documenting, and implementing best practices
Administer the IDS technology solutions including Eagle, Infogix Reconciliation, Web Servers, AD security, SFTP sites, and Network file shares
Application Support and Maintenance functions include:
System and/or server administration including change management, patches, and product upgrades
User provisioning and de-provisioning
Security role setup and management
Troubleshooting: jobs, access, application issues
Annual DR testing
Environment health management
Schedule and lead working sessions that will align stakeholder requests with application features/capabilities

CANDIDATE QUALIFICATIONS

Bachelors Degree in Computer Science
Minimum of between 3-5 years of application administration experience with large, multi-tiered applications
Comfortable taking initiative and working independently but knows when to involve others
Comfortable working with stakeholders from a wide range of functions and seniority levels
Strong collaboration skills and the ability to work in a team-based environment
Excellent communication skills with ability to address and resolve conflicts diplomatically
Ability to work through complexity with ease, identifying themes across complicated issues in time-critical situations
Experience in agile and DevOps tools and delivery is a plus
Experience in cloud administration and maintenance (e.g. IAAS) is a plus, AWS preferred
Experience in the investments and/or finance data domain is a plus.
CANDIDATE COMPETENCIES
· Ability to apply technical knowledge across multiple business functions and technology platforms
Ability to work in close collaboration with project/program managers, architects, developers, and testers to define and implement standards and best practices
Ability to leverage technical skills across multiple departments and domains
Skilled in interacting between internal business partners, internal IT teams, and offshore partners
Ability to communicate clearly and to simplify complex topics for a wide range of audiences (both written and verbal)
Ability to work through complex issues, identify themes, and develop solutions, in time-critical situations
Ability to quickly learn new technologies and platforms
Ability to adhere to project schedules and meet deadlines in the execution of job responsibilities
Ability to identify improvements in personal efficiency by seeking counsel from more experienced peers/partners

Trianz is growing at a faster pace than the industry for the last five years. Read through some of the key industry recognitions we have received for our innovative execution and strategic client initiatives here.

Equal Employment Opportunity

Trianz is an Equal Opportunity Employer and does not discriminate on the basis of race, color, creed, national or ethnic origin, gender, religion, disability, age, political affiliation or belief, disabled veteran, veteran of the Vietnam Era, or citizenship status (except in those special circumstances permitted or mandated by law).",2001,Information Technology Support Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,True
Data Engineer,"Mass General Brigham
","Somerville, MA",$84K - $117K (Glassdoor est.),3.8,"Data Engineer

- (3260562)


As a not-for-profit organization, Mass General Brigham is committed to supporting patient care, research, teaching, and service to the community by leading innovation across our system. Founded by Brigham and Women’s Hospital and Massachusetts General Hospital, Mass General Brigham supports a complete continuum of care including community and specialty hospitals, a managed care organization, a physician network, community health centers, home care, and other health-related entities. Several of our hospitals are teaching affiliates of Harvard Medical School, and our system is a national leader in biomedical research.

We’re focused on a people-first culture for our system’s patients and our professional family. That’s why we provide our employees with more ways to achieve their potential. Mass General Brigham is committed to aligning our employees’ personal aspirations with projects that match their capabilities and creating a culture that empowers our managers to become trusted mentors. We support each member of our team to own their personal development—and we recognize success at every step.

Our employees use the Mass General Brigham values to govern decisions, actions, and behaviors. These values guide how we get our work done: Patients, Affordability, Accountability & Service Commitment, Decisiveness, Innovation & Thoughtful Risk; and how we treat each other: Diversity & Inclusion, Integrity & Respect, Learning, Continuous Improvement & Personal Growth, Teamwork & Collaboration.

General Summary:

As a not-for-profit organization, Mass General Brigham is committed to supporting patient care, research, teaching, and service to our community by leading innovation across our system. Founded by Brigham and Women’s Hospital and Massachusetts General Hospital, Mass General Brigham supports a complete continuum of care including community and specialty hospitals, a managed care organization, a physician network, community health centers, home care and other health-related entities. Several of our hospitals are teaching affiliates of Harvard Medical School, and our system is a national leader in biomedical research.


We seek employees who bring passion, are highly collaborative, and thrive in a dynamic, diverse, and inclusive team. We work in a highly agile environment with a focus on quality and achieving real impact with our work. We are excited to have a team with a rich mix of experiences, with people who bring innovative approaches to their work, an excitement for looking at things from new angles, and a spirit of continuous improvement. Finally, we seek employees who embrace and live our core values of respect, recognition, communication, commitment, trust, innovation, and service. If this sounds like you, we invite you to apply.

Mass General Brigham’s main office is in Somerville, MA. We are currently working as a fully remote team due to COVID-19 and encourage applications from across the US as telecommuting becomes part of our new normal. We are committed to building an engaged, inclusive community and offer a variety of opportunities to come together virtually and facilitate learning and collaboration.

Overview

Mass General Brigham’s board and system-wide executive leadership are making significant investments in enterprise data and digital health, enabling innovation and transformation in the delivery of health care, research and discovery. By building out core digital and data capabilities, we are supporting the achievement of Mass General Brigham’s mission to drive growth and innovation in inpatient, ambulatory, and digital care. We are at the start of this journey, and we are looking for talented individuals from across the nation to join us in transforming healthcare and in achieving the expected outcomes of this strategy: improved patient care, quality of care, patient engagement, and efficiency in the delivery of healthcare with excellence.

In the achievement of these goals, Mass General Brigham’s data and analytic teams are working together to build a system-wide data ecosystem. We are both leveraging current assets and building new, integrated solutions to provide a holistic set of industry-leading data and analytic capabilities, supporting Artificial Intelligence (AI), Machine Learning (ML), and real-time insights. Teams from Data and Analytics, Research Analytics, Clinical Data Science, and Information Systems are collaborating to build this new data and analytic ecosystem. To ensure success of this effort, Mass General Brigham is standing up a new Data and Analytics operating model with a goal of driving a level of standardization for data and analytic operations across the teams involved.

The value of investments in data and analytics were proven out during our response to COVID-19 as these investments were leveraged to stand up new reporting and analytic capabilities to support executive and clinical leadership on managing the pandemic. Our broad data and analytic community have come together across Mass General Brigham ’s 14 healthcare sites with shared urgency, delivering analytic tools to our system that drove timely insights in both clinical and operational domains, resulting in effective delivery of critical care and in organizational efficiencies during a time of reduced resources.

Team Overview

EDW data engineering team supports various data source ingestion and builds analytics data layer in the cloud. The team also manages ETL/ELT operation, performance, and site -specific security for our broad data and analytics community.

Position Overview

We are looking for a self-motivated EDW Data Engineer to join our data engineering team to perform design, build, test and maintain architectures such as EDW, data lake and large -scale data processing systems. Join a team of data engineers to build, monitor and support EDW ingestions, data marts and extracts to meet various SLAs for our broad data and analytic community. The ideal candidate also performs on-going operation performance and security activities to support EDW access and optimization of user queries. The right candidate will be excited by the prospect of optimizing and/or redesigning our data landscape to support the next generation of products and data initiatives.

PRINCIPAL DUTIES AND RESPONSIBILITIE

Develop and implement data pipelines and ETL/ELT code to support business requirements.
Work on cross-functional teams delivering enterprise solutions for internal and external clients.
Maintain and optimize various components of the data pipeline architecture.
Build scalability into design solutions to meet growth and performance benchmarks.
Deliver high quality, efficient solutions to meet technical standards and industry best practices.
Deliver optimal technical solutions for business and operational requirements.
Participate in team design sessions and contribute options and solutions.
Produce and support product documentation.
Conduct code review sessions to validate technical solutions and facilitate knowledge sharing.
Participate in ETL Quality circle discussions to explore, discuss, and arrive at efficient solutions and best practices.
Perform research and troubleshooting on user reported data problems and issues.

WORKING CONDITION

It is currently expected that this position will work remotely (e.g., from home) full time.

If onsite:

Possible local travel to Partners sites, vendors, and conferences.
Normal office working conditions. The noise level in the work environment is quiet to moderate.
While performing the duties of this job, the employee is frequently required to sit; talk; or hear; use hands to finger; handle; or feel; reach with hands and arms. The employee is occasionally required to stand; walk; and stoop; kneel; or crouch. The employee must frequently lift and/or move up to 5 pounds and occasionally lift and/or move up to 20 pounds. Specific vision abilities required by this job include close vision, distance vision and depth perception.
The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job.


2+ years of data warehousing development in large reporting environment(s)
Experience with developing data pipelines using on Snowflake features (Snowpipe, SnowSQL, Snow Sight, Data Streams)
Hands-on development experience with ETL/ELT tools, such as dbt, Fivetran, or Informatica
Working knowledge of cloud computing platforms such as AWS, GCP, or Azure
Experience working in Agile software development environment
Familiarity with enterprise data warehousing systems a plus

PREFERRED SKILLS/ABILITIES/COMPETENCIES

Experience with DBT development is preferred
Proficient in SQL and at least one scripting language
Ability to juggle multiple projects in a high volume, fast-paced Production environment
Familiarity with current healthcare industry practices a plus
Familiarity with Agile development methodologies
Experience with Epic data a plus


EEO Statement


Mass General Brigham is an Equal Opportunity Employer. By embracing diverse skills, perspectives, and ideas, we choose to lead. All qualified applicants will receive consideration for employment without regard to race, color, religious creed, national origin, sex, age, gender identity, disability, sexual orientation, military service, genetic information, and/or other status protected under the law. We will ensure that all individuals with a disability are provided a reasonable accommodation to participate in the job application or interview process, perform essential job functions, and receive other benefits and privileges of employment.



Primary Location MA-Somerville-MGB Assembly Row
Work Locations MGB Assembly Row 399 Revolution Drive Somerville 02145
Job Business and Systems Analyst
Organization Mass General Brigham
Schedule Full-time
Standard Hours 40
Shift Day Job
Employee Status Regular
Recruiting Department MGB Digital
Job Posting Sep 22, 2023",1994,Health Care Services & Hospitals,$10+ billion (USD),Healthcare,1001 to 5000 Employees,Nonprofit Organization,False
Data Integration Engineer,"Encore Fire Protection
","Needham, MA",$88K - $128K (Glassdoor est.),4.6,"Encore is an industry leading, full-service fire protection company serving the Northeast with offices from Maine to New Jersey. Encore’s mission is to save lives and protect property with innovative fire suppression, fire sprinkler and fire alarm solutions. We are dedicated to providing sole source, customer centric fire protection services throughout all of the Northeast.

Our continued growth and success have created the need for an Data Integration Engineer supporting our fast-growing services business. The Data Integration Engineer will work cross functionally across our M&A Integration and Business Intelligence teams. The role will primarily work with our Data Implementation Project Manager and will be responsible for scoping, extracting, transforming, and loading large scale data sets. You will work on multiple projects at a time in a variety of integration stages.

As an Data Integration Engineer, you will be responsible for leading and effectively transferring data sets from our new partners to our existing service platform. This position will require prior experience with ETL processes to facilitate partner onboarding. Prior Experience spearheading data migrations is preferred.

You will be utilizing your passion for our mission and ability to connect with people to:

Collaborate with new partners to identify data sources.
Design, develop, and document ETL processes, customized for each partner integration.
Develop integration process data flows and data mapping analyses.
Collaborate with M&A team, business intelligence and data integrity to ensure loaded data is following most recent SOPs and guidelines.
Monitor partner feedback post-integration to quickly identify and remediate discrepancies.

Requirements

The only limits to where someone in this position can rise are the ones that they put on themselves. Requirements are simple:




Up to 25% Travel within the Northeast
Proficiency in SQL, Excel, Access, and REST APIs. Prior experience with QuickBooks is desirable.
Aptitude and willingness to learn new skills as needed
Experience performing data mapping
Strong problem-solving skills, and the ability to troubleshoot and resolve issues
Excellent communication skills, both written and verbal, with the ability to effectively convey technical concepts to non-technical stakeholders
Ability to work under pressure and quickly pivot focus to meet moving deadlines

Benefits

As a company, Encore is hyper-focused on developing a culture that thrives on success and is energized by the fact that we get to make peoples' lives better and safer each day. One of the ways we do this is by generously rewarding all those who contribute to our continued growth. But we also believe that not all rewards are monetary. Here are just a few a few perks that a successful individual in this role can expect:

Salary commensurate with experience with opportunity for a results-driven bonus based on personal output and effectiveness in role
Flexible work environment that allows travel between CT, MA, and RI office locations
Real-time performance feedback and coaching
We dress for the objective which means most days we wear jeans but occasionally we wear suits. As long as you know which situations require which (or aren't afraid to ask), you'll be all set!
Speaking of attire, we offer all employees Encore when they join the team
401(k) with employer match
Medical, Dental and Vision coverage
Flexible vacation policy
Snacks and coffee everyday and weekly office lunches
Company-paid life insurance policy of $50,000

Encore Fire Protection is an Equal Opportunity Employer.

Encore Fire Protection is an E-Verify Employer

As an EEO/AA employer, Encore Fire Protection considers applicants for employment without regard to, and does not discriminate on the basis of, gender, sex, sexual orientation, gender identity, national origin, age, race, protected veteran status, disability, or any other legally protected status.",2009,Commercial Equipment Services,$25 to $100 million (USD),"Construction, Repair & Maintenance Services",201 to 500 Employees,Company - Private,True
Data Scientist / Engineer,"Shift Technology
","Boston, MA",$70K - $100K (Employer est.),4.1,"Did you know that about 10% of all insurance payouts are flowing directly into the pockets of fraudsters? The future of insurance starts with Decisions Made Better.

Shift Technology harnesses the power of AI to enable the world's leading insurance organizations to make better decisions. Our products automate and optimize decisions from underwriting to claims, resulting in increased operational efficiency, reduced costs, and superior customer experiences for millions of people around the globe.

Our culture is built on innovation, trust, and a drive to transform the insurance industry by imagining and innovating solutions that impact insurers and their customers - like you! We come from more than 50 different countries and cultures and together we are creating the future of insurance.




About the Team

This role is part of our Data Science team which is the largest team in our organization consisting of over 140+ Data Scientists throughout the world.
Our Data Scientists work in a full lifecycle role and on a broad range of subjects acquiring extensive technical and professional experience in data science, data engineering, coding, business understanding and client engagement.
Our company is small enough that each person's achievements has an impact on our overall performance, yet big enough to be a world leader and innovator in our domain.
As a member of the data science team, you will be working alongside our technical experts and your role will be key to rolling out our enterprise level solutions to our clients.
Job Responsibilities
Your role will be to actively contribute to the US Subrogation roadmap and clients, and working on various data types such as structured data, free text, documents and images.
Implementation of the data engineering, usually from client extracts to the insertion of the data in our data stores (SQL, ElasticSearch)
Developing, testing, tuning models and putting them in production for tasks such as fraud detection and automation detection in complex environments.
Automate key business tasks by implementing them in our production process framework in C#
Conduct meetings with clients and interact with external stakeholders, whether it is for direct user feedback, presenting business cases or defining the roadmap of evolutions

WHAT WE ARE LOOKING FOR

We are looking for candidates with 1-2 years of experience with diverse skills to help us build excellent technology solutions for our clients and be proficient in the following skills:

Code-savvy, either by having a degree in computer science and/or having developed some apps with actual users- writing scripts for models and notebooks is not enough at Shift, we thrive on people who can write maintainable, production-quality code that will run everyday without breaking.
AI-savvy, either by having a degree in machine learning and/or statistics. Having a clear understanding of statistics and machine learning problems, tasks and common resolutions is important to communicate internally and explain to the client how the product is working.
Client facing. You will need to be comfortable and open to communicating to our clients on a regular basis
Business smart. We don't expect candidates to know the insurance sector, but we want applicants who are interested in learning and mastering the business aspects of our products

#LI-MG1

#LI-HYBRID




The range listed is for base compensation. Your actual base salary will vary based on factors including location and individual qualifications objectively assessed during the interview process.

In addition to base salary, your total rewards package will include additional components such as incentive pay, equity, and benefits. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the specific details for this position.

US Base Salary Pay Range

$70,000—$100,000 USD

To support our employees at every stage of their careers and lives, we provide a competitive total rewards and benefits package. Here are the global benefits we'd like to highlight:

Flexible remote and hybrid working options
Competitive Salary and a variable component tied to personal and company performance
Company equity
Focus Fridays, a half-day each month to focus on learning and personal growth
Generous PTO and paid holidays
Mental health benefits
2 MAD Days per year (Make A Difference Days for paid volunteering)

Additional benefits may be offered by country - ask your recruiter for more information.

At Shift we strive to be a diverse and inclusive workforce. We hire and trust people without regard to race, color, religion, marital status, age, national or ethnic origin, physical or mental disability, medical condition, pregnancy, genetic information, gender identity or expression, sexual orientation, or other non-merit criteria.

Shift Technology is committed to providing reasonable accommodations for qualified individuals with disabilities in our application and employment process. Should you require accommodation, please email accommodation@shift-technology.com and we will work with you to meet your accessibility needs.

Shift Technology does not accept unsolicited CVs from recruiters or employment agencies in response to the Shift Technology Careers page or a Shift Technology social media post. Any unsolicited CVs, including those submitted directly to hiring managers, are deemed to be the property of Shift Technology.",2014,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,201 to 500 Employees,Company - Private,True
Data Engineer,"HarbourVest Partners
","Boston, MA",$93K - $135K (Glassdoor est.),4.2,"Job Description Summary
For over forty years, HarbourVest has been home to a committed team of professionals with an entrepreneurial spirit and a desire to deliver impactful solutions to our clients and investing partners. As our global firm grows, we continue to add individuals who seek a collaborative, open-door culture that values diversity and innovative thinking.
In our collegial environment that’s marked by low turnover and high energy, you’ll be inspired to grow and thrive. Here, you will be encouraged to build on your strengths and acquire new skills and experiences.
We are committed to fostering an environment of inclusion that promotes mutual respect among all employees. Understanding and valuing these differences optimizes the potential of both the individual and the firm.
HarbourVest is an equal opportunity employer.
This position will be a hybrid work arrangement, which translates to 2-3 days minimum per week in the office.
The data engineer will work toward the transformation of our firm’s core data infrastructure, using the Microsoft data stack on prem and in Azure. Hired staff will design and build data validations, transformations, normalizations, reports and extracts, and integration processes that strengthen internal business analytics as well as external client reporting functions. The staff will partner with business users, analysts, senior architect and development lead, product owner, and infrastructure engineers to form complete end-to end-solutions. They enjoy working in an evolving fast-paced environment, and bring a work style marked by high energy, flexibility, quick learning, and collaboration.
The ideal candidate is someone who has:
Mix of education and experience with SQL Server, SQL Server Integration Services, and Azure Data Services (Data Factory, Databricks), MicroStrategy, and PowerBI
In-depth SQL
Data modeling and design understanding, including conceptual, logical, and physical modeling
Understanding of DevOps and CI/CD practices and tools
High energy and team-oriented style; flexibility and motivation to take on a broad range of engineering and support assignments
Track record and skills demonstrated on high-intensity, high-complexity projects
Confidence interacting with business users
Ability to use analytical skills to translate business ideas into technology solutions
Experience in Agile delivery framework
Clear communicator of technical details both verbally and in writing
What you will do:
Design and build of data validations, transformations, normalizations, reports and extracts, and integration processes
Design and implementation of schemas and access views
Issue resolution
Version control, release planning, and deployment preparation
Contribution to logical and physical data models
Creation and updates to project artifacts and tools such as task boards, problem lists, user stories, and technical documentation
Examine & evaluate technical tools
Prototype solutions
Attend trainings to sharpen technical and business skills
Education
Bachelor of Science/Bachelor of Arts or equivalent experience
Experience
5+ years of relevant experience
#LI-Hybrid",1982,Investment & Asset Management,Unknown / Non-Applicable,Financial Services,501 to 1000 Employees,Company - Private,False
Data Center Engineer,"Aqueduct
","Canton, MA",$65K - $91K (Glassdoor est.),3.3,"We are looking for a Data Center Engineer who will be responsible for providing design, implementation, and operational support to our customer base using advanced Data Center Technologies. This is a full-time role working with our Data Center Practice and external customer base here at Aqueduct Technologies!


In this customer-facing role, the successful candidate must have strong written and verbal communication skills, be client-focused, service-driven, and able to simultaneously manage multiple projects and implementations. Aqueduct is committed to learning, teaching, and your career advancement. You’ll be provided with mentorship from passionate technology professionals; certification opportunities leveraging our exclusive vendor partnerships; and hands-on access to cutting-edge technology as it hits the market.


Essential Job Responsibilities:

Understand customers’ business processes to assess and identify best practices for hardware and software configurations which meet industry standards
Design and deploy technology using reference architecture and industry best practices
Lead deployment and support for solutions which can be new, integrated with legacy systems, or upgrades of current systems
Perform services such as consultation, assessment, and education to customers
Develop deep technical skillset in several cloud and data center technologies
Engage in continuous learning to stay abreast of new and emerging data center technologies
Obtain vendor-related certifications
Work in a dynamic team environment following Aqueduct project methodologies and deliverables as outlined by the Statement of Work to ensure customer satisfaction

Traditional Product Portfolio for Deployments:

Virtualization platforms such as vCenter, vSphere, Horizon, vRealize
Storage systems such as PURE, PowerScale, PowerStore, PowerVault
Hyperconverged solutions including Cisco Hyperflex and VxRail
Data Protection solutions including Veaam, Rubrik, and Cohesity
Replication solutions, for example: Site Recovery Manager, Zerto, RecoverPoint
Cisco UCS (UCS manager, B-Series and C-Series server)

Qualifications/Requirements:

Minimum of 4 years of deployments of relevant technologies
Possess advanced troubleshooting skills for finding solutions to customer problems
Comfortable, adaptable, and flexible working with diverse customer environments and regulatory requirements
Knowledge of traditional and next-generation compute, network, storage and virtualization theory, design, and architecture
A positive team player who enjoys learning from and teaching others

Preferred Skills:

Industry certifications with Microsoft, Cisco, DELL/EMC, and VMware
Experience with public cloud providers such as Amazon, Microsoft, and Google
Experience with MFA solutions such as Okta and Duo

Aqueduct Technologies is committed to developing a diverse and talented team. We celebrate and support diversity and are committed to making an inclusive environment for all employees and applicants. In that spirit, we are particularly interested in receiving applications from a broad spectrum of individuals including women, minorities, individuals with disabilities, members of the LGBTQIA community, veterans, and any other legally protected group. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant on the basis of any status protected by federal, state, or local laws.


Aqueduct Technologies is one of the largest IT solutions providers in the US, recognized for our relentless pursuit of customer satisfaction, our corporate culture, technology leadership, and our commitment to the local community. We pride ourselves on our world-class engineering, the investments we make in our employees and our systems, and on our loyal base of customers and manufacturers. Recognized as one of the fastest-growing, private companies in Massachusetts—and awarded the Best Place to Work in Boston for seven, consecutive years—there is no better time to join Aqueduct than now!",2010,Information Technology Support Services,$25 to $100 million (USD),Information Technology,51 to 200 Employees,Company - Private,False
Data Engineer,Boston Dynamics AI Institute,"Cambridge, MA",$88K - $122K (Glassdoor est.),-1.0,"Our Mission
Our mission is to solve the most important and fundamental challenges in AI and Robotics to enable future generations of intelligent machines that will help us all live better lives.

Data Engineers will work cross-functionally, creating new technology to improve software development for robots. If you have a passion for developing technology for robots and use it to advance their capabilities and usefulness, you will want to join us! We are onsite in our new Cambridge, MA office where we are building a collaborative and exciting new organization.
Responsibilities
Work collaboratively with research scientists and software engineers on software development for a range of different robotic platforms
Develop and maintain our data warehouses and data pipelines in cloud and on-premise infrastructureBuild event and batch driven ingestion systems for machine learning and R&D as needed
Develop and administer databases, knowledge bases, and distributed data stores
Create and use systems to clean, integrate, or fuse datasets to produce data products
Establish and monitor data integrity and value through visualization, profiling, and statistical tools
Perform updates, migrations, and administration tasks for data systems
Develop and implement a data governance, data retention strategyUse Python and SQL to develop, maintain and scale our data stores
Requirements
BS/MS in computer science, robotics, or a related field
10+ years of experience in a data engineering or similar role
Demonstrated experience with a variety of relational database and data warehousing technology such as AWS Redshift, Athena, RDS, BigQuery
Demonstrated experience with big data processing systems and distributed computing technology such as Databricks, Spark, Sagemaker, Kafka, etc
Strong experience with ETL design and implementations in the context of large, multimodal, and distributed datasets
Bonus (Not Required)
5+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
5+ year experience working on real-time data and streaming applications
5+ years of experience with NoSQL implementation (Mongo, Cassandra)2+ years of experience with Airflow
5+ years of data warehousing experience (Redshift or Snowflake)
5+ years of experience with UNIX/Linux including basic commands and shell scripting
We provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",-1,-1,Unknown / Non-Applicable,-1,51 to 200 Employees,Company - Private,False
Data Engineer,"Olmstead Associates
","Boston, MA",$90K - $128K (Glassdoor est.),4.0,"Opportunity:

Olmstead drives business success by helping clients build and leverage a strong data foundation. The right data strategy can reduce risk, increase productivity, improve decision making, and fuel innovation.

We are seeking a hands-on detail-oriented data engineer with investment management industry experience. Candidates will have experience with writing Extract Transform Load (ETL) processes, SQL, DevOps/DataOps, job orchestration, data modeling, data profiling, database design, and data governance. They are not afraid to roll up their sleeves, challenge the status quo, leverage best practices, and grow beyond their comfort zone. They are an excellent communicator that uses precise language and frames messaging in business terms.

As a valued member of our expert data management consulting team, you will engage clients to document and analyze their data landscape. Analysis will help the client grow, develop new capabilities, and optimize data management. You will deliver a wide range of data engineering solutions, such as data integrations, data migrations, data warehousing, query optimizations, and advanced analytics.

Responsibilities:

Aid current state assessments by collecting information on data sources, data flows, data transformations, and data delivery timelines
Proactively analyze data flows to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance, investigating and communicating areas for improvement in efficiency and productivity
Collaborate with team members and client stakeholders to understand data engineering needs and deliver solutions
Produce project deliverables that may include ETL processes, stored procedures, data integration solutions, documentation, and job orchestration
Trace data requirements, data sources, and data flows for data engineering processes
Apply best practices
Qualifications:
Possess strong business knowledge of the investment management industry and common data management operations
Data modeling expertise for investment data domains, such as security master, accounts, holdings, transactions, etc.
Experience creating ETL solutions using a leading ETL tool or data management platform
Strong hands-on SQL and programming skills with the ability to learn other tools
Expertise with relational databases, Snowflake, data lakes, JSON, XML, document stores, and REST web services
Familiarity with data management best practices and patterns
Experience with building cloud solutions, preferably on Azure
DevOps and agile delivery experience, preferably DataOps
Experience with DBT, Power BI, PowerShell, and Python is desired
Experience with Bloomberg, FactSet, Salesforce, Seismic, and Vermillion is desired
Bachelor’s degree required
If you are interested in joining Olmstead, please send an email to recruiting@olmst.com",1994,Business Consulting,$5 to $25 million (USD),Management & Consulting,1 to 50 Employees,Company - Private,False
Data Engineer Co-Op,"Werfen
","Bedford, MA",$90K - $132K (Glassdoor est.),4.1,"Job Overview
Post Date
January 8, 2024
Number
ICIMS-2023-6736
Job Function
R&D
Location
Bedford - 180 Hartwell Road Bedford, Massachusetts 01730 United States
Country
United States
Shift
About the Position
Overview

Werfen


Werfen, founded in 1966, is a worldwide developer, manufacturer and distributor of specialized diagnostic instruments, related reagents, automation workcells, and data management solutions for use primarily in hospitals and independent clinical laboratories. The Company’s business lines include Hemostasis, Acute Care, and Autoimmunity diagnostics, as well as Original Equipment Manufacturing. Our success comes from a specific focus in these rapidly evolving diagnostic areas, our commitment to customers, and our dedication to innovation and quality. We’re passionate about providing healthcare professionals the most valuable and complete solutions to improve hospital efficiency and enhance patient care.


Our North American Commercial Operations, as well as our Headquarters and Technology Center for Hemostasis and Acute Care Diagnostics, are based in Bedford, MA. Our Headquarters and Technology Center for Autoimmunity Diagnostics is based in San Diego, CA. Additionally, our Technology Center for Hemostasis and Blood Gas Reagents is in Orangeburg, NY, and our Technology Center for Whole Blood Hemostasis is in San Diego, CA.


Summary:


The purpose of the cooperative experience is to provide a semester long hands-on experience. Werfen hires students with leadership potential and proven academic success. Ideal candidates will combine technical and business knowledge with analytical strength and creative problem-solving abilities.

Responsibilities

Key Accountabilities

To perform entry level work of a routine nature requiring application of standard techniques, procedures and criteria in carrying out a sequence of related tasks.
Responsible for process and production support of a product or product line. Provides support for continuous improvement team efforts focused on process improvement and optimization. Provides design, procedures and implementation of assembly methods, test methods, equipment operation, including specification and optimization.
Ability to lead and influence at various levels and functions of the organization through strong interpersonal and communication (oral and written) skills
Competency in conducting desk research and competitive intelligence, distilling down vast amounts of data into concise summaries focused on the key strategic & financial implications to IL

Essential Functions:

Performs experiments, analyzes and interprets numerical data from experiments.
Summarizes findings by computer readouts, statistical summaries, graphs and other methods.
Requires confidence in using Microsoft Word and Excel tools.
Requires Enthusiasm, motivation, initiative and ability to work within an interactive and energetic workplace.
Review process procedures, change orders, equipment specifications, validation plans, and reports.
Performs market research on
Qualifications

Minimum Knowledge & Experience Required for the Position:

Currently pursuing B.S. in Engineering, Finance, Business, Marketing with a minimum of 2 college semesters complete.
Ability to multitask




If you are interested in constantly learning and being challenged on a daily basis we encourage you to submit your resume or CV.


Werfen appreciates and values diversity. We are an Equal Opportunity/Affirmative Action Employer M/F/D/V.


We operate directly in over 30 countries, and in more than 100 territories through distributors. Annual revenue is approximately $2 billion and more than 5,000 employees around the world comprise our Werfen team.


www.werfen.com",1966,Medical Testing & Clinical Laboratories,$1 to $5 billion (USD),Healthcare,5001 to 10000 Employees,Company - Private,False
Data Engineer,"GEI Consultants Inc
","Woburn, MA",$33.65 - $72.11 Per Hour (Employer est.),4.3,"Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties

ETL of data from a wide variety of sources
Database and Data Warehouse design/expansion/backup & recovery
Index management and optimization
Support data sources for Tableau Server, Power BI, and ArcGIS
Stored procedure development and maintenance
Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
SQL Agent Job development and monitoring
Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
Develop test plans, implementation plans, and project timelines for various data engineering projects
Define, prioritize, communicate, and foster shared understanding of project objectives and scope
Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
Team with all staff necessary to complete assignments
Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
Other duties as assigned

Minimum Qualifications

3+ years of experience in a position performing similar data engineering tasks
Proven record of ability to design, manage, and support MS SQL Server and Azure databases
Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
Bachelor's Degree, from an accredited college or university
MS SQL Server/Azure certification preferred
Ability to develop project plans and meet deadlines
Self-starter with attention to detail and stakeholder needs
Able to critically analyze and solve problems of a complex nature
Excellent Communication skills
Able to work on multiple projects of moderate complexity simultaneously and independently
Proficient in organization and time management skills
Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
Able to work effectively in GEI s partnership model, including a team environment, building rapport and relationships.

We are GEI.

Some of the world s most pressing problems – from climate change to sustainable development, to critical infrastructure and the future of our energy supply – need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients most complex challenges.

With more than 40 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs – we are Client-Centered, Curious, Collaborative, and Community Minded – which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI s career site here.

GEI s Total Rewards Package

Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
Pay Range For This Position: $33.65-72.11/hour
Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
Well-Being Program and Paid Parental Leave
Commuter Benefits
Hybrid Work Schedules and Home Office and Cell Phone Stipends
GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
Paid Holidays and Generous Paid Time Off Program
Rewards and Recognition
GEI-Funded Profit Sharing and 401(k)
Opportunity to be an Owner and Shareholder (Learn more here)
A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
And More…

Physical Job Requirements




Sedentary




X




Light




Medium




Other






Activity Level Throughout Workday




Physical Activity Requirements




Occasional

(0-35% of day)




Frequent

(33-66% of day)




Continuous

(67-100% of day)




Not Applicable




Sitting




X





Standing




X







Walking




X







Climbing




X




Lifting (floor to waist level) (in pounds)




X







Lifting (waist level and above) (in pounds)




X







Carrying objects




X







Push/pull




X







Twisting




X







Bending




X







Reaching forward




X







Reaching overhead




X







Squat/kneel/crawl




X







Wrist position deviation




X







Pinching/fine motor skills




X







Keyboard use/repetitive motion




X







Taste or smell (taste=never)




X




Talk or hear




X







Accurate 20/40




Very Accurate 20/20




Not Applicable






Near Vision




X






Far Vision




X








Yes




No




Not Applicable






Color Vision (ability to identify and distinguish colors)




X






Sensory Requirements




Minimal




Moderate




Accurate




Not Applicable




Depth perception




X





Hearing




X








Environmental Requirements




Occupational Exposure Risk Potential




Reasonably Anticipated




Not Anticipated




Blood borne pathogens




X




Chemical




X





Airborne communicable diseases




X




Extreme temperatures




X





Radiation




X




Uneven surfaces or elevations




X




Extreme noise levels




X





Dust/particular matter




X




Other (exposure risks):







Usual workday hours:




X


8




10




12




Other work hours






GEI is an AA/equal opportunity employer, including disabled and veterans.",1970,Architectural & Engineering Services,$100 to $500 million (USD),"Construction, Repair & Maintenance Services",1001 to 5000 Employees,Company - Private,False
System Engineer – Global Data Operations | India,"OnProcess Technology
","Boston, MA",$70K - $111K (Glassdoor est.),3.9,"Job Overview

We’re looking for a System Engineer specializing in L1/L2 support for Global Data Operations. The incumbent will play a key role in managing feed processes, ensuring seamless operations and handling exception handling in real-time. This role will primarily involve Azure database management, pipeline handling, and leveraging Power Automate to streamline data workflows.




Responsibilities and Duties

Responsibilities and Duties

1.Feed Processing

Manage and monitoring of automated feeds/Azure pipelines.
End-to-end management of real time API based data imports along with exception handling.
Trouble shoot and fix in real-time any feed alerts/failures – both file based, and API driven
Escalate exceptions having business impacts, to higherups/senior levels.
Maintain and review feed reconciliation.
2. Job-Automation & Reporting

Monitor automated jobs for import processes in Azure.
Develop process to track/monitor data push from Azure to Salesforce
Reconciliation of data updates in different platform touch points.
Produce data driven reports in Azure – ad-hoc, manually generated or automated.
Develop and support maintenance of extensive process and technical documentation.
3. Implementation Activities

Work on new implementations hand-offs from project teams/other DB teams.
Create tasks and reconciliation routines.
Validation and testing.
Essential Skills

Advanced database/SQL skills
Development of stored procedures.
Programming concepts including application development exposure.
Understanding of Micro Service/API
Working experience in Azure (CI/CD)
Working experience in Power Automate platform.
Advanced knowledge of Office tools
Strong verbal and written English communication skills.
Documentation/presentation capabilities
Team player, fast learner, go-getter.
Ability to meet deadlines and manage stress effectively in high demand situations.
Exposure with remote work model.
Flexibility towards work schedules – 5-day work week but requires 24×7 availability.
Be self-motivated, innovative, highly accountable and carry integrity.
Desired Skills (Not Mandatory):

Familiarity with any reporting tool, like crystal reports or SSRS.
Having worked on MS Access, MS SQL and/or Oracle.
Programming concepts including application development exposure
Advanced knowledge of Office tools, Documentation/presentation skills
Qualifications:

B.E./B. Tech/ BCA, preferably in Computer Science/IT.
3-5 years of experience in:
o Databases
o Azure Pipeline
o Power Automate



Education Requirements

Bachelor’s Degree




Experience Requirements

3+ years




About OnProcess

OnProcess is on a mission – to transform and drive the world’s circular service supply chains – for brilliant customer experiences, efficiencies at the speed of digital, and more sustainable ‘circular economy’ processes.
At OnProcess, we encourage a collective sense of engagement, affirmation and belonging, where everyone is proud to be a member of our company. As a global business, we recognize our ability to understand, embrace and operate in a multicultural world – both in the marketplace and in the workplace – is critical to our long-term sustainability. That’s why we are committed to a company-wide culture that understands that diversity, equity, and inclusion is essential.",1998,Business Consulting,$25 to $100 million (USD),Management & Consulting,1001 to 5000 Employees,Company - Private,False
Data Engineer,"OneSource Regulatory
","Boston, MA",$95K - $129K (Glassdoor est.),4.2,"Company Introduction

OneSource Regulatory Technology hosts a number of innovative solutions to enhance job performance in the Pharmaceutical space. OSR Technology is looking for an experienced and dedicated data engineer to join our product solutions team!




Job Description

OneSource Regulatory is trying to identify a full-time contractor with at least 4+ years of experience to assist us with ongoing R&D projects.

We are looking for a data engineer to pull data from various sources and do all the necessary steps to clean, normalize, possibly annotate, and finally load the data into databases. The candidate should be able to develop and implement a strategy for testing the data integrity of the collected data. This role requires extreme attention to detail to ensure data quality is top priority.


Responsibilities

Well versed in parsing and synthesizing of XML and/or JSON documents.
Curating of data that can involve some intermediate to advanced web scraping. (data may need to be fetched via SFTP, FTP, Wget, Curl, REST APIs, GraphQL queries from spots on the Internet)
Proficiency with Linux command line and various simple tools, such as grep, wc, sed, awk, find, ls, cat, piped commands and possibly some very light Bash shell scripting, setting up crontab schedules and programs
Must have basic knowledge of SQL with the following databases: PostGres, MySQL, Google BigQuery
Must have basic knowledge of No-SQL database knowledge such as MongoDB or similar
Familiarity with basic Cloud technology such as storage buckets, cloud serverless functions
Must have experience extracting text and images from PDF files
Knowledge of Puppeteer or other automatable web client technologies
Understanding JavaScript, HTML/CSS and HTTP methods (for understanding page structure for web scraping)



Skills

Solid experience with Python and Python Libraries such as Pandas, requests, etc
Skill set should match up with required responsibilities listed above
Strong English skills (e.g. grammatical analysis and rhetorical structure)
Team Player
Great communication skills



Bonus Skills

Experience within the Pharmaceutical Space
Ability to expose data via C# NETCore and/or GraphQL
Google Cloud Platform (Cloud Buckets, Google Cloud Functions (.NET, Python, Node.JS))
Ability to parallelize data manipulation and scraping via Python multi-threading, etc.
Python BeautifulSoup
Scrapy
Docker (setting up Kubernetes style processing if warranted for data scraping/data ingestion/normalization)
Multithreading concepts",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,True
Data Pipeline Engineer,"Decision Point Healthcare
","Boston, MA",$78K - $108K (Glassdoor est.),5.0,"Boston, MA

Full-Time


We need your help.

We’re looking for a self-motivated and detail-oriented data engineer to join our DataOps team. This opportunity will enable you contribute to the operation, support, and enhancement of our mission critical data operations platform and the development of data pipelines. Our data operations platform supports high volume, high velocity data ingestion and curation to support our existing, and rapidly expanding, health plan client base.

The position:
Design and develop scalable data pipeline processes (including ingestion, cleansing, curation, unification, etc.)
Automate the processing of inbound client data feeds
Design and develop tools and processes to support automated data profiling and data quality methodologies
Work with our data science team to assist with the development of feature store data including data prep, enrichment, and feature engineering for AI/ML
Write and maintain documentation on data pipelines
Provide periodic support to our customer success team Skills & Experience
BS / MS in Computer Science, Engineering, or applicable experience
3+ Year using Python (Pandas/NumPy) in a production environment
3+ Year using PowerShell in a production environment
Expertise with ETL/ELT and the development of automated validation and data pipelines
Understand database design and data manipulation and transformation methodologies
Keen understanding of EDW, master data management and other database design principles
Experience designing solutions using a range of AWS Services
Experience with data engineering and workflow management frameworks such as Airflow and dbt
Comfortable working with high volume data in a variety of formats
Experience with CI/CD such as Jenkins
Experience with version control tools: Git preferred
Excellent verbal and written communication
Familiarity with healthcare data is a plus
Familiarity with ML pipelines, principles and libraries is a plus
Experience with REST API is a plus
Why Decision Point?:

We’re as passionate about our people as we are about making our mark on healthcare. Fostering a fun and challenging environment that’s centered around personal and professional growth has brought us to where we are today. We are constantly seeking out new ways to reinvest in our team members because let’s face it, we all do our best work when we feel valued.

Meaningful work
Remote friendly environment
We encourage outside the box ideas
Great healthcare coverage
Competitive compensation",2013,-1,Less than $1 million (USD),-1,1 to 50 Employees,Company - Public,False
Data Engineer,"iSeeCars.com
","Woburn, MA",$90K - $129K (Glassdoor est.),5.0,"iSeeCars.com, a Boston-based company, is an award-winning car search engine that helps consumers find great deals on cars. Founded in 2012 by TripAdvisor and SAP veterans, it is turning car shopping on its head by using big data analytics, AI, and proprietary algorithms to objectively analyze, score and rank millions of cars and formulate insights that give consumers the upper hand. iSeeCars has been featured extensively in the media, including The Wall Street Journal, New York Times, CNN, Consumer Reports, Forbes, Fortune, USA TODAY, and Bloomberg.

What you’ll do

As a Data Engineer, you’ll be responsible for acquiring data using API, feeds, scraping, scripting, automation and software development experience to design and build high-performance automated systems, create ETL data pipelines and enhance the data aggregation systems.

Work with data feeds and data APIs
Design and develop web crawling and scraping solutions with a focus on performance and accuracy
Build scalable tools that automate web crawling, scraping, and data aggregation to populate databases
Own the creation process of the crawling and scraping tools, services and workflows to improve crawl and scrape analysis, reports and data management
Test the acquired data to insure accuracy and quality and rectify any issues with breaks as well as performance as needed
Requirements
Experience conducting large scale web crawling and scraping
Experience working with data APIs and data feeds
Strong troubleshooting and debugging skills
Solid python experience
Solid SQL experience
Experience with shell scripting
Experience working with Data APIs
Familiarity with statistical concept
Familiarity with Linux/UNIX, HTTP, HTML, Javascript and Networking
Familiarity with techniques and tools for crawling, extracting and processing data (e.g. Scrapy, pandas, mapreduce, SQL, Selenium, BeautifulSoup, etc
Experience in building systematic data quality processes and checks
Experience with using data profiling tools to query the data, identify anomalies, gaps and issue
Experience with version control, open source practices, and code review is a plus
Experience in working with data in various forms (data warehouses/SQL, unstructured data environments/PIG,HIVE, Impala) is a plus
Experience working with ETL / Data warehousing
Excellent communication skills (written and spoken English)
Excellent analytical and reasoning skills; able to decompose complex problems and projects into manageable pieces; comfortable suggesting and presenting solution
Working knowledge of AWS / S3 / RDS / Lambda",-1,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1 to 50 Employees,Company - Private,False
Senior Data Engineer - HYBRID,"Inclusively
","Boston, MA",$88K - $129K (Glassdoor est.),5.0,"Inclusively is partnering with a multinational financial services company to hire a Senior Data Engineer - HYBRID.

ABOUT INCLUSIVELY:

Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD). Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability.

Position Description:

***Applicants are permitted to work remotely from an at-home work site anywhere in the United States.***

Develops and implements Proof of Concepts (PoCs), generic frameworks, and real time pipelines, using SQL, Amazon Web Services (AWS), Snowflake, and Python. Introduces automation into software application development using Continuous Integration/Continuous Delivery (CI/CD) methodologies. Programs software applications and databases using programming languages -- Python and Shell Scripting.

Primary Responsibilities

Designs and develops technical solutions.
Reports data and data sets.
Performs object or component oriented software development.
Establishes project plans for projects of moderate scope.
Develops technical modules in support of complex assignments and multi-phase projects.
Performs independent and complex technical and functional analysis for multiple simultaneous projects.
Develops original and creative technical solutions to on-going development efforts
Designs applications for multiple projects supporting several division initiatives.
Supports and performs all phases of testing leading to implementation.
Develops comprehensive documentation for multiple applications supporting several corporate initiatives.

Total Number of employees that you directly supervise: None

Titles of employees that you directly supervise: None

Education and Experience

Bachelor’s degree (or foreign education equivalent) in Computer Science, Engineering, Information Technology, Information Systems, Mathematics, Physics, or a closely related field and three (3) years of experience as a Senior Data Engineer (or closely related occupation) performing application development, deployment, maintenance, and support in a data centric/driven environment.

Or, alternatively, Master’s degree (or foreign education equivalent) in Computer Science, Engineering, Information Technology, Information Systems, Mathematics, Physics, or a closely related field and one (1) year of experience as a Senior Data Engineer (or closely related occupation) performing application development, deployment, maintenance, and support in a data centric/driven environment.

Skills and Knowledge

Candidate must also possess:

Demonstrated Expertise (“DE”) developing and implementing POCs, generic frameworks, and surrounding real time pipelines using Python, Shell Script, SQL Databases (Oracle, DB2,MySQL, and SQL Server) and Cloud technologies (AWS and Snowflake) on diverse platforms crossing multiple businesses according to Agile methodologies.
DE performing application development, deployment, maintenance, and support using Python, Shell Script, SQL, AWS, and Snowflake in a data centric/driven environment; troubleshooting technical issues and identifying existing or potential issues on applications running on Python, Snowflake, and AWS services -- EC2; and resolving issues by performing root cause analysis using Visual Studio Code, Putty, SQL Server Management Studio, SQL Developer, and DBeaver.
DE contributing to performance improvement of processes/applications and automating manual tasks using Python; developing automated deployment tasks to deploy infrastructure related components in AWS Cloud using CI/CD pipelines; and developing Web Services and surrounding eco-systems for frameworks/pipelines using NGINX, SupervisorD, Celery, and Spark.
DE participating in the Software Development Lifecycle (SDLC) -- analyzing, designing, implementing, and performing version control, automation, disaster recovery, and post-installation validation using Azure DevOps and Jenkins according to Agile methodologies and CI/CD best practices.

Job Type: Full-time

Schedule:

Monday to Friday

Work Location: Remote",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Private,False
Software Engineer - Data,"Intentsify LLC
",Massachusetts,-1,4.6,"Description:


At Intentsify, we build software to make intent data actionable for marketing and sales teams. Our services digest millions of web pages every day, extracting deep semantic information that helps our customers make sense of what their buyers are interested in, how competitors position their messaging, and what the main market trends are.

Intentsify is looking for a Software Engineer - Data ready to contribute to our growing software engineering team and our monstrous data processing pipelines, terabyte-sized databases, APIs, and cloud infrastructure. You will be an early member of our rapidly growing software team, guiding the evolution of our software infrastructure to support both internal and external products.


Responsibilities
Design, develop, and maintain large-scale distributed data-heavy backend services in Python that directly impact Intentsify’s bottom line.
Improve tooling, testing, and automation to ensure production-quality backend deployments
Productionize machine learning models
Develop best-in-class services by ensuring that they are well-defined and modularized, secure, reliable, reusable, diagnosable, and actively monitored
Investigate issues with our support team and develop fixes where appropriate.
Contribute to team's adoption of state of the art technologies where appropriate


Requirements:
You have 2+ years of experience and enjoy writing and maintaining scalable backend services using Python, AWS (SQS, SNS, EKS, EC2, Codebuild), Kubernetes, and relational databases / data warehouses.
You have worked cross-functionally and interfaced with product managers, designers, front end developers, customers, vendors
You hold yourself and others to a high bar when working with production systems, and take pride in owning and driving projects to business impact
You are comfortable with Linux / Unix environments
You might have experience with: Snowflake
[Bonus] You might have experience with bringing machine learning models to production",2018,Software Development,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,True
Lead Data Engineer,"Blue Cross Blue Shield of Massachusetts
","Boston, MA",$143K - $175K (Employer est.),3.8,"Ready to help us transform healthcare? Bring your true colors to blue.

What We Need

The Data Engineering Lead is a staff member of Data, Analytics and BI Transformation team. This role will lead solutioning and implementation of data and integration needs of digital & analytical platforms at BCBSMA This role will work closely with other technology partners to build highly available, scalable and distributed data platforms using open-source frameworks to process high volume, high velocity, and wide variety of structured and unstructured data. Strong focus on defining and executing data solutions with cloud (AWS) first strategy to deliver unparalleled consumer experience.

Other responsibilities include designing and delivering data engineering solutions, ETL/ELT pipelines on multi-terabyte SQL/NoSQL databases, data warehouse environments. Strong communication skills with an ability to help business define requirements, articulate business requirements as technical architecture is also essential to this role.

Your Day to Day
Leads end to end implementation of data & analytics solutions as per BCBSMA business needs.
Delivers solutions & integrations across on-prem & multi-cloud data & analytics platforms.
Designs & builds frameworks for various common data engineering processes like ingestions, mastering, data cleansing, and data masking.
Change agent for implementing data engineering best practices to BCBSMA environment.
Collaborates with vendors, architects, scrum masters, product managers/owners, peers, QA engineering in scoping out & delivering data & analytics solutions.
Helps grow and mentors team members on the fine art of data engineering and software abstractions.
Deliver data architecture and solutions for critical strategic portfolio projects in collaboration with business and IT stakeholders.
Ability to collaborate and partner with business domain leads, data scientists, product owners, enterprise architects and other functional leads to deliver world class data solutions.
Build and manage a team of data engineers supporting different applications.
Manage technical delivery for projects, designs processes, manage and drive execution with help of consultants and associates.
Define and deliver consistent data engineering standards, methodologies, guidelines & techniques.
Diagnose and address complex problems, including performance issues, scale and drive to resolution to meet business initiatives.
Assist data analysts and end users across all functional areas in identifying long-term, strategic data needs for the enterprise, defining how the data is related to the business processes and developing a conceptual and functional model of the data.
Assist and advocate for bringing new technologies for data management, governance, and usage.
Work hands on with emerging technologies during software evaluations, PoCs and pilots.

We’re Looking for:
Bachelor’s degree in computer science, technology, or related field.
8+ years of data engineering experience.
6+ years of experience with SQL or NoSQL databases like Snowflake, Postgres, Oracle, MongoDB
4+ years of experience with cloud platforms like AWS
Certification in cloud platforms and/or data/analytics technology is required.
Healthcare experience preferred.
Minimum 5 years of experience with ETL/ELT design and development using tools like IICS, AWS Glue, Talend, Databricks, Oracle Data Integrator (ODI) or equivalent.
Minimum 3 years of experience with programming languages such as Node.js, Python, Java or Scala.
Minimum 2 years of experience with building applicating with serverless architecture on AWS platforms using Athena, Glue, Kafka, EC2, Lamda, Kenesis.
Minimum 2 years of experience with large-scale data processing platforms such as Spark, EMR, and/or HPC computing experience with e.g. Apache Aurora, Slurm.
Experience working with RESTful API and general service-oriented architectures.
Experience with DevOps, Continuous Integration and Continuous Delivery technologies is desirable.
AWS Solution Architect certification (associate & above) is highly desirable.
Excellent verbal and written communication skills.

What You Bring:
Bachelor’s degree or higher in Computer Science or related field.
8+ years of data engineering experience
6+ years of experience with SQL or NoSQL databases like Snowflake, Postgres, Oracle, MongoDB
4+ years of experience with cloud platforms like AWS, Azure, Google
Healthcare experience preferred.

It is our mission at Blue Cross Blue Shield of Massachusetts to foster a culture that enables associates to do their best work while living happy and healthy lives. That's why we offer you a variety of ways to support your best physical, emotional, financial, and social well-being. For more information on our benefit offerings, visit https://careers.bluecrossma.org/us/en/benefits

#LI-Remote

Minimum Education Requirements:
High school degree or equivalent required unless otherwise noted above

Location Boston Time Type Full time

Salary Range: $143,370.00 - $175,230.00

The job posting range is the lowest to highest salary we in good faith believe we would pay for this role at the time of this posting. We may ultimately pay more or less than the posted range, and the range may be modified in the future. An employee’s pay position within the salary range will be based on several factors including, but limited to, relevant education, qualifications, certifications, experience, skills, performance, shift, travel requirements, sales or revenue-based metrics, and business or organizational needs and affordability.

This job is also eligible for variable pay.

We offer comprehensive package of benefits including paid time off, medical/dental/vision insurance, 401(k), and a suite of well-being benefits to eligible employees.

Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, or any other form of compensation that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.

WHY Blue Cross Blue Shield of MA?
We understand that the confidence gap and imposter syndrome can prevent amazing candidates coming our way, so please don’t hesitate to apply. We’d love to hear from you. You might be just what we need for this role or possibly another one at Blue Cross Blue Shield of MA. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be brilliant. We encourage you to bring us your true colors, , your perspectives, and your experiences. It’s in our differences that we will remain relentless in our pursuit to transform healthcare for ALL.

As an employer, we are committed to investing in your development and providing the necessary resources to enable your success. Learn how we are dedicated to creating an inclusive and rewarding workplace that promotes excellence and provides opportunities for employees to forge their unique career path by visiting our Company Culture page. If this sounds like something you’d like to be a part of, we’d love to hear from you. You can also join our Talent Community to stay “in the know” on all things Blue.

At Blue Cross Blue Shield of Massachusetts, we believe in wellness and that work/life balance is a key part of associate wellbeing. We provide a flexible hybrid work model in which roles are designated as resident (on site 4-5 days/week), mobile (on site 1-3 days/week), or eworker (on site 0-3 days/month).",1937,Insurance Carriers,$100 to $500 million (USD),Insurance,1001 to 5000 Employees,Nonprofit Organization,False
Data Engineer,"Azurity Pharmaceuticals, Inc.
","Boston, MA",$102K - $146K (Glassdoor est.),3.2,"Azurity Pharmaceuticals, Inc. is a fast-growing pharmaceutical company focusing on the needs of patients requiring customized, user-friendly drug formulations, especially children and the elderly. Azurity’s products have benefited millions of patients whose needs are not served by other commercially available therapies. For more information, visit www.azurity.com.
Azurity's success is attributable to our incredibly talented, dedicated team that focuses on benefiting the lives of patients by bringing the best science and commitment to quality into everything that we do.

Mission:
Implement the data models and data structures needed for each use case as defined by the Data Architect, in the most convenient format to be used by the Data Scientist
Own the structural elements of data, e.g., data storage, data piping, interfacing with analytics platforms
Participate in data requirements, modelling and testing
Tasks & responsibilities:
Provide technical support related to data structures, data models and meta data management to relevant stakeholders
Creates data models, providing the right format and structure for the use case solutions
Participate in early data modeling and testing for use case development, provide input on how to improve proposed solutions and implement necessary changes
Extract relevant data to solve analytical problems; ensure development teams have the required data
Interact with the business ([function]) to understand all data requirements to develop business insights and translates them into data structures and data models, in close collaboration with Data Architect
Work closely with IT/IM teams on internal data acquisition (e.g., CRM, ERP) and with Data Architect for external data acquisition
Knowledge & experience:
5+ years’ experience with advanced data management systems (e.g., PostgreSQL, etc.)
Deep expertise in data modeling and structuring
Experience in high volume data environments
Ability to quickly learn new technologies
Developing and maintaining formal documentation that describes data and data structures including data modelling
Strong attention to detail and an ability to think critically and conceptually
Team oriented and flexible with proven track record in collaborating with multiple stakeholders
Strong verbal and written",1999,Biotech & Pharmaceuticals,$100 to $500 million (USD),Pharmaceutical & Biotechnology,201 to 500 Employees,Company - Private,True
Data Engineer only W2,"IDC
","Boston, MA",$96K - $125K (Glassdoor est.),4.3,"Experience with engineering data flow pipelines on Google Cloud Platform (GCP) including data transformation, data modeling, storage, indexing, and version management.
Experience coding in Python and SQL for manipulating both structured and unstructured data
Experience and familiarity with web technologies such as JavaScript, React, or Angular
Familiarity with DevOps ways of working (git, Safe Agile, CI/CD, etc.) to be able to participate in sprint planning, project management meetings, documentation, and delivery activities
Experience in extracting data from web, PDF, Word, Excel, etc. with Natural language processing techniques (NLP)
Should be familiar with extracting data from unstructured sources into formatted data & data cleaning (e.g. packages such as beautifulsoup, NLTK, huggingface)
Familiarity with Generative AI is a plus (Google Bard, OpenAI Service, or language models such as HuggingFace)

Job Type: Contract

Ability to commute/relocate:

Boston, MA 02108: Reliably commute or planning to relocate before starting work (Preferred)

Experience:

data engineer: 6 years (Preferred)
GCP: 4 years (Preferred)

Work Location: In person",1972,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,True
Data Lake Engineer,CIMCON Digital,"Westford, MA",$63K - $100K (Glassdoor est.),-1.0,"Data Lake Engineer (1-2 years) (Job Code: DL-01)

Cassandra & PostgreSQL installation, administration and tuning.
Server-side software development skills in any language – C / C++ / C# / Java / Python / Node.JS, Bash Scripting, ETL Tools.
Good to have - Knowledge of SFTP, WebDAV and SMB protocols.",-1,-1,Unknown / Non-Applicable,-1,201 to 500 Employees,Company - Private,False
Hospitality Data Systems Engineer,Pyramid Global Hospitality Corporate Offices - Boston,"Boston, MA",$75K - $105K (Employer est.),-1.0,"About Us:
At Pyramid Global Hospitality, people come first. As a company that values its employees, Pyramid Global Hospitality is dedicated to creating a supportive and inclusive work environment that fosters diversity, growth, development, and wellbeing. Our commitment to a People First culture is reflected in our approach to employee development, employee benefits and our dedication to building meaningful relationships.

Pyramid Global Hospitality offers a range of employment benefits, including comprehensive health insurance, retirement plans, and paid time off, as well as unique perks such as on-site wellness programs, local discounts, and employee rates on hotel stays. In addition, Pyramid Global Hospitality is committed to providing ongoing training and development opportunities to help our people build the skills and knowledge they need to advance their careers.

Whether you are just starting out in the hospitality industry or are a seasoned professional, Pyramid Global Hospitality offers a supportive and collaborative work environment that encourages growth and fosters success, in over 230 properties worldwide. Join their team and experience the benefits of working for a company that values its employees and is committed to creating exceptional guest experiences.

Check out this video for more information on our great company!
Location Description:

Pyramid Global Hospitality (“Pyramid”) is a leading hotel management company, operating in the US, Caribbean, and Western Europe. With portfolio revenues exceeding $3 billion, Pyramid manages 230 hotels, resorts, and conference centers, both branded and independent. The firm maintains offices in Boston (Headquarters), Cincinnati, Houston, and London. Additional information about Pyramid can be found at www.pyramidglobal.com

In 2021, Pyramid and Benchmark Resorts and Hotels merged to add an additional 59 Managed or Asset Managed Resorts and over 10,000 additional team members. The two companies share the same company culture, values and philosophies. We are growing and opportunities abound!

What really sets Pyramid apart from our competitors is our reputation as an employer. Professional growth is not just possible throughout the company but planned and encouraged. The Leadership Team at Pyramid consider team member development its first priority, understanding that success is only achieved in a workplace where every contributor is respected and recognized. This is why we deliver superior results.

There is opportunity to work directly with senior leaders, experience stretch assignments and learn hospitality management from industry giants. You will come to know a distinctive people centric culture that is at the core of all we do. The decisions we make and the paths we take are bound by a commitment to our Owners, Associates, Customers and the Communities where we work. We attract the most talented associates in the industry, and actively encourage candidates with a “hospitality spirit” who may be thinking about a career change to join our team.


Overview:
We are looking for a skilled Hotel Systems Expert who will play a pivotal role in extracting, analyzing, and optimizing data from multiple Property Management Systems (PMS) and Point of Sale (POS) systems. The ideal candidate is a proven leader with hotel operational knowledge, strong technical proficiency, and extensive knowledge on how to extract data from multiple systems and formats. Experience with hotel & restaurant systems is a plus.

Responsibilities:
Data Extraction: Extract data from various PMS, POS, and sales systems used across the organization with a focus on our European platform.
Data Integration: Collaborate with other members of our analytics team to ensure seamless integration of data sources and maintain data integrity. Design and manage necessary ETL tools to move the data into various systems (PowerBI, Azure SQL, etc..).
Training: Once extraction systems are deployed train on-property personnel to monitor the extraction process.
Reporting & Tracking: Develop a system to track incoming data and alert stakeholders of possible issues and failures.
System Maintenance: Monitor system performance, troubleshoot issues, and coordinate with vendors for system updates.
Continuous Improvement: Stay updated on industry trends and best practices to recommend improvements in hotel systems.
Qualifications:
Degree in Information Technology, Computer Science, Hotel Management, Data Management or a related field.
Proven data management experience. Experience with PMS and POS systems in the hospitality industry is a plus.
Experience using various ETL techniques and tools (SSRS, Azure Data Factory, Synapse Analytics, etc…).
Proficiency in database management systems (SQL, Oracle, etc.) as well as common sales platforms (Salesforce, CI, etc…).
Strong analytical and problem-solving skills with an attention to detail.
Excellent communication and teamwork abilities.
Knowledge of hotel operations, revenue management, and industry-specific software is a plus.
Experience with scripting languages (Python, R, etc. TSQL, Dax).
Compensation Range: The compensation for this position is $75,000.00/Yr. - $105,000.00/Yr. based on qualifications and experience.",-1,-1,-1,-1,-1,-1,False
Data Analyst & Machine Learning Engineer,"Dassault Systèmes
","Waltham, MA",$92K - $130K (Glassdoor est.),3.9,"Title: Data Analyst & Machine Learning Engineer

Here at Dassault Systèmes, we empower people with passion to change the world. Let’s open new horizons together with the power of 3DEXPERIENCE virtual universes!

ENOVIA, powered by the 3DEXPERIENCE platform, enables you to plan your definition of success with a broad portfolio of technical and business applications for all users across your enterprise. With ENOVIA, teams collaborate and innovate together to build and execute a successful plan - one that is flexible, allowing continuous optimization, real-time progress tracking and compliance with industry standards and regulations. ENOVIA enables you to plan your definition of success with a broad portfolio of technical and business applications for all users across your enterprise.

Are you passionate about delivering Data Science based applications?

ENOVIA has an immediate opening in Waltham, MA for a highly skilled developer with a strong background in Data Science & web applications development

Roles & Responsibilities:

Build business insights using data visualization & machine learning in applications that are used by fortune 500 companies
Analyzing large datasets, building data pipelines, building ontology, creating insightful visualization
Developing and optimizing machine learning algorithms, deploying models into production environments, integrating models into existing systems
Build and validate scalable Cloud solutions end to end (UX, Webservice APIs, ETL)
Promote and enable the adoption of technical advances in Data Science
Drive projects to completion independently
Work with cross-functional teams to generate Data Science-based solutions that meets the company's emerging standards

Qualifications & Experience:

Master's Degree in Engineering, Mathematics, or Computer Science- with a focus in Process Mining, Machine Learning, Data Science, and Artificial Intelligence
2+ years of relevant work experience
Proficient with data platform architecture, design, data dictionaries, multi-dimensional models, and structures for data science
Deep expertise in Python and SQL
Experience with Tableau or other data visualization platforms
Familiarity with data platform architecture, data lake, ETL development, data dictionaries, metadata management and data quality
Preferred full-stack developer with familiarity with Java and Javascript
Exposure to Prompt Engineering, Large Language Models (LLM) & fine-tuning
Independent self-starter with time management and prioritization skills in a dynamic environment
Strong team player with the ability to successfully collaborate remotely with geographically distributed teams


Diversity statement
As a game-changer in sustainable technology and innovation, Dassault Systèmes is striving to build more inclusive and diverse teams across the globe. We believe that our people are our number one asset and we want all employees to feel empowered to bring their whole selves to work every day. It is our goal that our people feel a sense of pride and a passion for belonging. As a company leading change, it’s our responsibility to foster opportunities for all people to participate in a harmonized Workforce of the Future.
Compensation & Benefits
Dassault Systèmes offers an excellent salary with potential for bonus, commensurate with experience. Benefits include a choice of plans providing comprehensive coverage for medical, dental, vision care for employee & dependents as well as employee life, short & long term disability, tuition reimbursement, immediate 401K enrollment, 401K match (50 cents on the dollar, up to the first 8% of your eligible compensation that you contribute based on match eligibility criteria), flexible time off policy, and 10 paid holidays.
Equal opportunity
In order to provide equal employment and advancement opportunities to all individuals, employment decisions at 3DS are based on merit, qualifications and abilities. 3DS is committed to a policy of non-discrimination and equal opportunity for all employees and qualified applicants without regard to race, color, religion, gender, sex (including pregnancy, childbirth or medical or common conditions related to pregnancy or childbirth), sexual orientation, gender identity, gender expression, marital status, familial status, national origin, ancestry, age (40 and above), disability, veteran status, military service, application for military service, genetic information, receipt of free medical care, or any other characteristic protected under applicable law. 3DS will make reasonable accommodations for qualified individuals with known disabilities, in accordance with applicable law.",1981,Software Development,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Engineer I,"Nuvera Fuel Cells
","Billerica, MA",$77K - $102K (Glassdoor est.),3.2,"Job Title
Data Engineer I
Job Family
Job Description
Nuvera Fuel Cells, LLC is a manufacturer of heavy-duty, zero-emissions hydrogen fuel cell stacks and engines for mobility applications. With facilities located in the U.S. and Europe, Nuvera provides clean, safe, and efficient products designed to meet the rigorous needs of industrial vehicles and other transportation markets.
Nuvera is a subsidiary of Hyster-Yale Group, Inc., which designs, engineers, manufactures, sells, and services a comprehensive line of lift trucks and aftermarket parts marketed globally primarily under the Hyster® and Yale® brand names. Hyster-Yale Group is a wholly owned subsidiary of Hyster-Yale Materials Handling, Inc. (NYSE:HY). Hyster-Yale Materials Handling, Inc. and its subsidiaries, headquartered in Cleveland, Ohio, employ approximately 7,600 people worldwide.
We are seeking a Data Engineer I. This role will improve Nuvera’s methods and systems for data management and analysis; expand usage of databases and develop custom front-end visualizations for product performance insights; ensure data systems are optimized for efficiency and aligned with latest industry developments and best practices.
Essential Job Responsibilities:
Create and maintain well-structured relational databases for efficient storage of Nuvera product performance data.
Develop and support automation scripts which populate product databases directly via Nuvera test stands
Establish interface to monitor for proper functionality of automated processes and quickly alert engineers to breakdowns
Create front-end visualizations (ie. dashboards) for engineers to interact with system data for both standardized analyses and ad-hoc investigations
Stay up to date with new software packages and technologies which can facilitate more rapid front-end development; participate in trainings and/or continued learning as appropriate
Work with Senior Software Engineers to ensure data systems are properly architected for enterprise deployment with a focus on data security according to industry best practices.
Support Systems and Test Engineers to develop and debug Python code for a variety of applications.
Required Job Qualifications (unless otherwise noted):
Educational Background
Bachelor’s in Computer Science or Computer Engineering
or Bachelor’s in Relevant Engineering Discipline (Mechanical/Chemical/Electrical) plus Master’s in Data Engineering/Data Analytics
Previous Work Experience
0-2 years demonstrated success developing and implementing advanced data systems in either a professional or co-op role.
Special Skills, Experience and Abilities
Solid grounding in data systems fundamentals: relational databases, tables and data types, normalization, indexes, query optimization.
Preference for broader knowledge of engineering fundamentals: thermodynamics, fluid dynamics, heat & mass transfer.
Strong knowledge of coding best practices and Python programming language
Familiarity with query and statement commands for a variety of DBMS including MySQL and PostgreSQL.
Facility with Microsoft Office suite (Excel, PowerPoint, Word)
Strong and proactive problem solving, debugging, and troubleshooting abilities
Ability to work both independently and in team contexts, Comfort with a rapid development pace and ability to multitask, Strong interpersonal and communication skills
Physical requirements/Work environment
Laboratory and office work environments. This position has an emphasis on analytics of information which originates from physical systems and will therefore require occasional interaction with hardware in a laboratory or pilot plant setting.
Ability to lift components weighing up to 35 lbs. is required.
Travel Required
Up to 5% domestic travel may be required.
Nuvera Fuel Cells, LLC. is an Equal Opportunity Employer. Veterans/Disabled and other protected categories. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Nuvera participates in e-Verify.
Job ID
JC1001
Employment Type
Full time
Work Hours
40
Travel Required
Primary Location
Nuvera US Billerica, MA
Address
129 Concord Road Building 1
Zip Code
01821
Field-Based
No
Relocation Assistance Available
No
We are an equal opportunity employer with an excellent benefit package including medical, dental and life insurance, 401(k) and profit sharing.
EOE/Minorities/Females/Veterans/Disabled",2000,Chemical Manufacturing,$25 to $100 million (USD),Manufacturing,51 to 200 Employees,Subsidiary or Business Segment,False
Senior Data Engineer,"Cirkul Inc
","Watertown, MA",$111K - $148K (Glassdoor est.),3.5,"About Cirkul, Inc.
Cirkul is a venture backed, direct-to-consumer startup company that develops transformational hydration products that reimagine how flavored beverages are created, personalized, and enjoyed at home and on-the-go. You may have read about us going viral on TikTok (https://www.bizjournals.com/tampabay/inno/stories/news/2021/06/15/tampa-startup-hires-100-after-going-viral-on-tikto.html) or partnering with some great investors here (https://www.bevnet.com/news/2021/cirkul-closes-30m-series-b-led-by-af-ventures/).

Overview

Cirkul is a rapidly growing beverage technology company (Avg. Revenue CAGR of >150% over the past 4 years).

We are looking for a Senior Data Engineer to join our growing data team. Our new team member will manage Cirkul’s data pipeline architecture and optimize data flow and collection. The ideal candidate has a background in site reliability and devops, configuring tooling to ensure health, uptime and reliability of our cloud infrastructure.

The Senior Data Engineer will support our data initiatives and will ensure an optimal data delivery architecture that is consistent throughout ongoing projects. They must be a self-starter, and comfortable supporting the data needs of multiple teams, systems and products. The right candidate should be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities

Manage infrastructure and configuration of data platform in the Cloud, ensuring health, reliability and uptime

Create and maintain optimal data pipeline architecture

Integrate DevOps/SRE practices on the data team by solving for performance, monitoring, and alerting

Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python and/or Node.js, SQL (using dbt for transformation), commercial SaaS and OSS offerings, and AWS ‘big data’ technologies

Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs

Qualifications


4+ years of experience in a Data Engineer role at a fast-paced organization

3+ years of production experience with AWS, including EC2, EMR, RDS

3+ years of experience in devops or site reliability engineering (SRE), directly responsible for automated configuration, management and scalability of Cloud and infrastructure processes

Hands-on experience in Infrastructure-as-Code and Configuration management tools and technologies: Terraform, Kubernetes, and Docker

Advanced working knowledge of Python or similar scripting language

Exceptional fluency with SQL; you conquered the join venn diagram long ago and have moved on to explaining cost based optimization to your peers on the engineering team

Experience with orchestration tools such as Airflow, Dagster, or Prefect, with big data tools such as Kafka & Spark, and with dbt

Experience with modern columnar data warehouses such as Snowflake, Redshift, BigQuery

Experience ingesting, processing, and visualizing data sources of varying types - structured/relational and unstructured

Experience developing, managing, and manipulating large, complex datasets

Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement

Strong project management and organizational skills

Experience supporting and working with cross-functional teams in a dynamic environment

A Little More About Cirkul

Cirkul is a rapidly growing beverage technology company on a mission to make a healthier world by helping people enjoy drinking more water. The company has developed an innovative beverage delivery system that makes drinking more water delicious, fun, and personalized. The technology reduces the shipping weight of bottled beverages by 99% and uses 84% less plastic. Cirkul offers its customers over 50 unique flavors, all with no sugar, zero calories, zero carbs, no artificial colors or flavors, and a range of functional enhancements. Hundreds of thousands of consumers are using Cirkul to transition away from single-use plastics and sugar-filled beverages to healthier, better-for-you alternatives. The company is growing at a tremendous pace, is consistently profitable, and is backed by world class investors.

Cirkul, Inc. is an Equal Opportunity Employer. We believe in hiring a diverse workforce and are committed to sustaining an equitable and inclusive, people-first environment. We do not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status. If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents.",2016,Food & Beverage Manufacturing,Unknown / Non-Applicable,Manufacturing,1001 to 5000 Employees,Company - Private,True
Principal Data Engineer,"MathWorks
","Natick, MA",$133K - $179K (Glassdoor est.),4.3,"MathWorks has a hybrid work model that enables staff members to split their time between office and home. The hybrid model provides the advantage of having both in-person time with colleagues and flexible at-home life optimizations. Learn More: https://www.mathworks.com/company/jobs/resources/applying-and-interviewing.html#onboarding.

We are seeking a self-motivated and self-directed data engineer / software engineer to develop and maintain our license usage data system.

This position plays a key role in a business-critical initiative and requires excellent hands-on software development skills as well as a big-picture perspective. You will develop requirements, implement features, and analyze data to further our understanding of customers and their usage of MathWorks products. Strong interpersonal and communication skills are a must as this is a highly visible position that involves collaboration with teams across the organization.

MathWorks nurtures growth, appreciates diversity, encourages initiative, values teamwork, shares success, and rewards excellence.




As part of this team, you will...

Evaluate and employ appropriate state of the art solutions from Amazon Web Services / EC2 and other providers.
Extract and analyze customer provided data to accurately determine usage and identify patterns.
Gather business use cases, develop requirements, enhance our data pipeline, and build reports in support of Sales, Marketing, and Development teams tasked with utilizing usage data to better understand our customers and their use of our products.
Manage the workflow and on-time delivery of requests for enhancements, reports, ad hoc analysis, and modeling for targeting and segmentation strategies.
Establish and maintain the data pipeline and infrastructure. Collaborate with Quality Engineers to develop data validation strategies.
Develop a strong working knowledge of MathWorks development practices, business processes, and enterprise data warehouse and reporting environment.


Excellent problem-solving and communication skills
Expert level of proficiency in SQL, Excel, and at least one of the following (MATLAB, SAS, SPSS or R).
Experience with scripting in one or more of the following (Perl, Python, Ruby, PHP)
Proficient with reporting tools such as; PowerBI or Tableau is a plus.
Experience with enterprise system applications
Ability to clearly explain technical and analytical information (verbally, written & in presentation format) and apply/summarize for business use.
Excellent project management skills with attention to detail
Ability to handle multiple projects simultaneously


A bachelor's degree and 10 years of professional work experience (or equivalent experience) is required.
Expertise with SQL
Experience with data security
Experience with scripting",1984,Software Development,$1 to $5 billion (USD),Information Technology,5001 to 10000 Employees,Company - Private,False
Senior Data Engineer,Behavioral Health NewCo LLC,"Boston, MA",-1,-1.0,"At Author Health, we are a new company offering technology-enabled health care services for

seniors with complex mental health conditions. We are seeking a passionate technical leader to

join our growing team.


Responsibilities

Design, develop, and maintain highly scalable data pipelines and systems using

technologies like Dagster, dbt, Airbyte, Spark, etc.

Build processes to ensure high quality, timely data is available to stakeholders across

the organization

Monitor and troubleshoot data pipelines; perform root cause analysis on issues
Work closely with product managers, analytic engineers, software engineers, and data

scientists to understand analytics and reporting requirements

Improve the performance, scalability, and reliability of our data infrastructure
Implement data modeling, warehouse design, and metadata management
Automate and optimize ETL/ELT jobs, workflows, and data integration



Requirements

High level of empathy and humility
5+ years experience in a data engineer or similar role
Expert knowledge of data pipelines, data architecture, and warehousing technologies
Proficiency with Python, SQL, and at least one data orchestration technology such as

Dagster, Airflow, Prefect, etc.

Experience with data loading tools such as Airbyte, Fivetran, Stitch, etc.
Experience with cloud data platforms like GCP, AWS, or Azure
Strong analytic, problem solving, and troubleshooting abilities
Excellent communication and collaboration skills
Passion for data and emerging technologies

Nice to have:

Experience working with healthcare datasets and domain knowledge of common

healthcare data types such as clinical, claims, EHR, genomic, etc.

Understanding of healthcare data privacy regulations such as HIPAA
Experience implementing secure and compliant data pipelines for sensitive healthcare

data

Knowledge of tools and technologies commonly used in healthcare such as FHIR, HL7,

etc. is a plus




Benefits

Medical, dental, and vision coverage
401(k) retirement plan
Annual performance bonus
Flexible vacation policy
Remote-first team



Author Health is committed to a diverse and inclusive workplace. It is the company’s policy to

comply with all applicable equal employment opportunity laws by making all employment

decisions without unlawful regard or consideration of any individual’s race, religion, ethnicity,

color, sex, sexual orientation, gender identity or expressions, transgender status, sexual and

other reproductive health decisions, marital status, age, national origin, genetic information,

ancestry, citizenship, physical or mental disability, veteran or family status or any other basis

protected by applicable national, federal, state, provincial or local law. The company’s policy

prohibits unlawful discrimination based on any of these impermissible bases, as well as any

bases or grounds protected by applicable law in each jurisdiction. If you need assistance or a

reasonable accommodation during the application process because of a disability, it is available

upon request. The company is pleased to provide such assistance and no applicant will be

penalized as a result of such a request. In accordance with applicable legal requirements such

as the San Francisco Fair Chance Ordinance Newco will consider for employment qualified

applicants with arrest and conviction records",-1,-1,-1,-1,-1,-1,True
Senior Data Engineer,Digital Biology,"Watertown, MA",$112K - $147K (Glassdoor est.),-1.0,"Digital Biology is building a precision measurement platform to accelerate the development of precision therapies. We focus on integrating technologies that enable mapping biological interactions in their native tissue context, and deploying these at the scale needed to understand and impact human disease. Our platform has broad applicability, from elucidating mechanism of action and biomarkers, to screening of genetically encoded systems at scale.

Digital Biology is a rapidly growing Seed stage company backed by top VCs and partnering with the world's top pharmaceutical companies. Our interdisciplinary team of biologists and engineers are passionate about bringing the future of biological measurements to life; we are looking for someone to work alongside us to make that a reality.

Role overview

Digital Biology is growing rapidly, and we are looking for a senior-level data/backend engineer who is excited about contributing to cutting-edge biological research. Our core technology is related to spatial biology - we collect paired molecular sequencing and image data from intact biological tissues, and use these data to deliver key insights in areas like drug discovery, vaccine research, and cancer therapies.

In order to transform our raw data into actionable biological insights that we can deliver to partners, we rely on our Data Team to write, test, validate and deploy complex data ingestion, analysis, and reporting pipelines. You would join a team of experienced Software Engineers, Biologists, and Mathematicians dedicated not just to building out new data analysis capabilities, but also to developing the data governance strategy that will guide the types of analyses that are possible in the future. In this role, you will develop data warehousing solutions and design new analytical query platforms that will unblock analysis of never-before seen types of biological data containing both rich ""spatial"" mapping information as well as sequence-based genetic information.

In addition to our core data products, our Data Team is also responsible for developing several real-time analytical tools for use in the lab. Because of the dynamic nature of the types of experiments we specialize in, these internal tools are not just ""fire-and-forget"" data pipelines attached to real-time dashboards. Instead, we aim to provide our computationally-savvy team of lab scientists with a flexible programming interface to allow them to write code that helps them optimize their workflows on a per-experiment basis. We are looking for highly collaborative individuals who would be excited to partner closely with our Scientists to help develop high-impact tooling that can interface directly with our existing LIMS (lab information management system).

Core Responsibilities

Develop, test, and maintain data warehousing solutions to ingest imaging, sequencing, and other complex data types.
Design, deploy, and maintain custom query engines for analyzing spatially-resolved sequencing data.
Collaborate directly with scientists to build real-time, interactive data analysis pipelines for use during experiments.
Design, write, test and deploy code to extract raw data from the extremely heterogeneous hardware and software environments associated with our lab equipment.
Continuously improve the reliability and scalability of both the on-premises and cloud infrastructure backing our data storage and processing pipelines.
Help establish a culture of writing clean, efficient, and maintainable code, both leading by example and by providing mentorship to junior engineers in code review.

Additional Responsibilities

Depending on your background and experience, additional projects may be available, including:

Implement and optimize new, multi-modal statistical analyses.
Develop tooling for real-time data visualization, both internally and client-facing.

Required Qualifications

MS in Computer Science or related field, or comparable industry experience.
Strong software engineering experience, with a thorough grasp of IT concepts, design and development tools, system architecture and technical standards, shared software concepts.
Experience designing, deploying, and managing relational database systems.
Experience writing best-effort data pipelines, establishing data governance plans, and enforcing constraints on storage and compute utilization.
Proven understanding of database modeling concepts: entities/tables, relations/constraints, attribute data types, and column data times, with proficiency in SQL.
Experience with both cloud and on-premises (especially real time) data processing pipelines.
Fluency in Python and SQL.
Fluency with Git and DevOps best-practices.

Preferred Qualifications

PhD in a quantitative field.
Experience with both AI-based and ""traditional"" image analysis techniques.
Molecular biology research experience is highly desirable.
Experience dealing with bioinformatics data is a plus.
Experience with spatial databases is a plus.

Company Benefits: Health, vision, and dental insurance + 401K plan

If you don't meet all of the requirements listed here, we still encourage you to apply or reach out to us. No job description is perfect – we may find an even more suitable opportunity that is a better fit for you.",-1,Software Development,Unknown / Non-Applicable,Information Technology,Unknown,Company - Private,False
Associate Staff- Data Engineer,"MIT Lincoln Laboratory
","Lexington, MA",$84K - $118K (Glassdoor est.),4.4,"The Biological & Chemical Technologies Group is in search of an innovative and highly motivated data architect to execute on our efforts in developing platforms and key enabling technologies for large-scale data. As an associate staff in this area, you will work hand in hand with software engineers, data scientists, and domain experts in biology, chemistry, and signal processing to address key national stakeholder needs and further the Group’s mission by developing and delivering the next generation software and information architectures to enable biomedical solutions. You will drive architecture solutions and innovations to support data processing pipelines and delivering national large-scale curated and harmonized data resources.




Requirements:

Masters in Computer Science, Data Science, or related scientific field or equivalent experience in technical analysis. In lieu of a Master’s degree, a bachelor’s degree with 5+ years of directly related experience will be considered.
Champion of data technologies in areas of data integration, data curation and harmonization
Experience with data science and machine learning techniques to help with automation
Functional expertise in building microservice architectures and methodologies
Data modeling and database design experience, both SQL and NoSQL
Knowledge of DevSecOps and agile software development methodologies
Demonstrable experience in deploying software prototypes using languages such as R, Python, Javascript
Ability to work collaboratively and lead small to medium team of software developers and data scientists to execute your vision and software architecture
Demonstrated skills in scientific writing, as well as development and clear presentation of technical materials to a wide spectrum of technical and non-technical audiences.
Occasional travel (<10%) with optional opportunities for travel.
Job Description

For Benefits Information, click http://hrweb.mit.edu/benefits

Selected candidate will be subject to a pre-employment background investigation and must be able to obtain and maintain a Secret level DoD security clearance.

MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, veteran status, disability status, or genetic information; U.S. citizenship is required.




Requisition ID: 40375",1951,Aerospace & Defense,Unknown / Non-Applicable,Aerospace & Defense,1001 to 5000 Employees,Nonprofit Organization,False
"Data Engineer, Remote","CorEvitas
","Waltham, MA",$87K - $125K (Glassdoor est.),3.0,"POSITION SUMMARY:

The Data Engineer will be responsible for designing and developing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure that optimal data delivery architecture is consistent throughout projects. The successful candidate will be self-motivated and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

This is an important, visible, roll-up-your-sleeves position that enables our biostatisticians, pharmacovigilance experts and epidemiologists to gain insights and critical knowledge, enabling them to make better decisions faster.

PRINCIPLE DUTIES AND RESPONSIBILITIES:

Work together with the Director, Data Engineering and the software development team to realize the data architecture and data processing pipelines on AWS.
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our life sciences offerings.
Promote data best-practices across the organization and help build a “culture of data”.

MINIMUM QUALIFICATIONS:

Skills/Knowledge:

Must have Strong SQL Server Database development, maintenance experience.

Must have working knowledge SSRS reporting.

Must have proficiency with SQL Server functions and stored procedures.

Must be able to debug, profile, tune SQL queries, functions and stored procedures.

NoSQL Database experience is a big plus.

Proficiency in at least one high-level programming language, e.g., Python or Java.

Demonstrated experience developing data pipelines/ETL/ELT processes.

Excellent communication and organizational skills.

Also, Cloud platform experience that include:

AWS data storage and retrieval experience highly preferred
AWS data services, e.g., AWS Glue
AWS data processing and analytics services

Big Plus:

Familiarity working with sensitive data and with CFR Part 11, HIPAA, GDPR compliance.
Working knowledge of clinical and pharma data
Working knowledge of Clinical Data Standards such as CDISC

Experience:

5+ yeas overall experience, at least 3 in data management and/or data-centric software development. Life sciences background preferred.

Experience in writing production-level SQL and working with various databases and reporting systems.

Education/training:

BS/MS degree in Computer Science, Computer Engineering, or other technical discipline.

SPECIAL REQUIREMENTS:

Fully Remote, though some Travel may be required for this role

This description is not intended to be a complete statement of the job, but rather to act as a guide

About CorEvitas

CorEvitas, now part of Thermo Fisher Scientific, is a science-led, real-world data intelligence company. Using syndicated registry data and analytic services to understand the post-approval comparative effectiveness and safety of approved therapies, CorEvitas provides biopharmaceutical companies with objective data and clinical insights to demonstrate the value of their products to clinicians, patients, payers, and regulators. The company operates nine major autoimmune and inflammatory registries across the U.S., Canada, and Japan, collecting data from over 400 participating investigator sites, including collection of biosamples linked to the deep clinical data. CorEvitas recently expanded its services to include Pregnancy Registries, through the acquisition of Pregistry. CorEvitas also conducts client-sponsored registries through its Patient Powered Registries business, employing a transformative patient-focused registry model to support research needs for patient-centered outcomes across all therapeutic areas. The company’s regulatory-grade registry data is complemented by its Patient Experience business, supporting evidence-based patient engagement initiatives across the product lifecycle, as well as its Specialty EMR Data business and retinal data set. CorEvitas is headquartered in Waltham, MA and is a portfolio company of Audax Private Equity. www.corevitas.com

CorEvitas is proud to provide equal employment opportunities to all qualified individuals without regard to race, color, religion, sex, gender identity, sexual orientation, pregnancy, age, national origin, physical or mental disability, military or veteran status, genetic information, or any other protected classification. Minorities, women, LGBTQ candidates, Veterans, and individuals with disabilities are encouraged to apply.

CorEvitas participate with E-Verify",2001,Biotech & Pharmaceuticals,$100 to $500 million (USD),Pharmaceutical & Biotechnology,201 to 500 Employees,Company - Private,False
"Senior Data Science Engineer, Risk & Fraud","DraftKings
","Boston, MA",$121K - $181K (Employer est.),4.0,"We’re defining what it means to build and deliver the most extraordinary sports and entertainment experiences. Our global team is trailblazing new markets, developing cutting-edge products, and shaping the future of responsible gaming.

Here, “impossible” isn’t part of our vocabulary. You’ll face some of the toughest but most rewarding challenges of your career. They’re worth it. Channeling your inner grit will accelerate your growth, help us win as a team, and create unforgettable moments for our customers.

The Crown Is Yours

Our team comprises algorithm experts and data science technologists, coming together to develop innovative data products that solve analytically challenging problems at DraftKings. As a Senior Data Science Engineer, you will be a creative thinker, utilizing data, machine learning, and software development skills to craft high-impact solutions that mitigate risk and protect and grow the business.


What you'll do as a Senior Data Science Engineer

Work within complex systems to lead the development of advanced algorithms leveraging statistical modeling, machine learning, and quantitative techniques to produce models and systems that effectively identify and mitigate risk and fraud.

Take ownership of engineering design, development, deployment, and operations of data science technical infrastructure.

Collaborate with business stakeholders across the company to plan and execute valuable data science projects.

Guide design sessions and ensure your team delivers high-quality work that aligns with DraftKings engineering strategy.


What you'll bring

Experience as a core contributor on a data science team, specifically in the risk and fraud domain, where you were responsible for all aspects of data science technical projects, including development and deployment, and then monitoring of how those applications perform in production.

Expertise in a programming language like Python, Java, C#, or C++.

Deep understanding of quantitative methods, notably writing code to navigate machine learning and data analysis.

Ability to effectively communicate technical concepts to non-experts.
You will also need an intuitive sense of how quantitative work aligns with business priorities.

Join Our Team

We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston. As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment. Don’t worry, we’ll guide you through the process if this is relevant to your role.

The US base salary range for this full-time position is $120,800.00 - $181,200.00, plus bonus, equity, and benefits as applicable. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range and how that was determined during the hiring process.",2012,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Public,False
Data Engineer,"PA Consulting
","Boston, MA",$90K - $110K (Employer est.),3.7,"Company Description


We believe in the power of ingenuity to build a positive human future.

As strategies, technologies and innovation collide, we create opportunity from complexity.

Our diverse teams of experts combine innovative thinking and breakthrough use of technologies to progress further, faster. Our clients adapt and transform, and together we achieve enduring results.

An innovation and transformation consultancy, we are over 4000 specialists in consumer and manufacturing, defence and security, energy and utilities, financial services, government and public services, health and life sciences, and transport. Our people are strategists, innovators, designers, consultants, digital experts, scientists, engineers and technologists. We operate globally from offices across the UK, US, Netherlands and Nordics.

PA. Bringing Ingenuity to Life



Job Description


Your day to day

We’re an innovation and transformation consultancy that believes in the power of ingenuity to build a positive-human future in a technology-driven world. Our diverse teams of experts combine innovative thinking with breakthrough-technologies to progress further, faster.

Are you ready to harness the power of data to drive advancements in healthcare? Are you passionate about designing, building, and maintaining data infrastructure that plays a pivotal role in improving patient outcomes and shaping the future of medicine? If you're seeking a rewarding career at the intersection of healthcare and technology, we invite you to be part of our dynamic team. This is a unique, multi-year, project-based opportunity to build and grow a clinical data registry platform over many years working with a dedicated team of collaborators and customers. As a Data Engineer for our cutting-edge medical data registry, you'll be at the forefront of managing, optimizing, and expanding our data infrastructure, enabling critical insights that can positively impact patient outcomes. If you're excited about leveraging your data engineering skills to make a difference in the world of healthcare, we want to hear from you.



Qualifications


Minimum qualifications:

Advanced SQL and Python
Expertise in the design and construction of Big Data Lakes and Data Warehouses capable of ingesting, standardizing, and serving billions of data rows spanning diverse datasets ranging from tens to hundreds
Experience building dynamic, metadata driven pipelines and analyses
Building and managing fully automated data pipelines (ETL, ELT, ELTL) including:
Designing and building data interfaces to source systems
Combining and transforming data into the appropriate format for storage
Developing data sets for analytics purposes
Developing pipelines that can handle common issues/errors in a robust and automated way
Cloud experience in Azure, AWS or GCP

Preferred qualifications:

Spark / PySpark experience highly preferable
Working in Agile and DevOps environments
Basic Python, Bash, or PowerShell for automation
Data modelling – Kimball, Data Vault, Star/Snowflake schema, Query-first etc.
Data visualisation in Power BI, Tableau, Qlik or similar
Architecting Data Platforms - designing BI/MI/Analytics solutions using Big Data, Relational or Streaming technologies
One or more of the following certifications:
Microsoft Certified: Azure Data Engineer Associate
AWS Certified Data Analytics - Specialty
GCP Professional Data Engineers

Additional Information


Life At PA encompasses our peoples' experience at PA. It's about how we enrich peoples’ working lives by giving them access to unique people and growth opportunities and purpose led meaningful work.

We believe diversity fuels ingenuity. Diversity of thought brings exciting perspectives; diversity of experience brings a wealth of knowledge, and diversity of skills brings the tools we need. When we bring people together with diverse backgrounds, identities, and minds, embracing that difference through an inclusive culture where our people thrive; we unleash the power of diversity – bringing ingenuity to life. We are dedicated to supporting the physical, emotional, social and financial well-being of our people.

The Salary for this role is between $90,000 - $110,000",1943,Business Consulting,$500 million to $1 billion (USD),Management & Consulting,1001 to 5000 Employees,Company - Private,True
Data Engineer,"KeyLogic Systems
","Boston, MA",$90K - $135K (Glassdoor est.),4.1,"KeyLogic is actively seeking Data Engineer for designing, building, and maintaining the infrastructure that supports data storage, processing, and retrieval. They work with large data sets and develop data pipelines that move data from source systems to data warehouses, data lakes, and other data storage and processing systems. Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs during the development, maintenance and sustainment of the KR data architecture and data- driven solutions.

Responsibilities:

Develop, optimize, and maintain data ingest flows using Apache Kafka, Apache Nifi and MySQL/PostGreSQL
Develop within the components in the AWS cloud platform using services such as RedShift, SageMaker, API Gateway, QuickSight, and Athena
Communicate with data owners to set up and ensure configuration parameters
Document SOP related to streaming configuration, batch configuration or API management depending on role requirement
Document details of each data ingest activity to ensure they can be understood by the rest of the team
Develop and maintain best practices in data engineering and data analytics while following Agile DevSecOps methodology

Desired Skills:

Strong analytical skills, including statistical analysis, data visualization, and machine learning techniques
Good understanding of programming languages like Python, R, and Java
Expertise in building modern data pipelines and ETL (extract, transform, load) processes using tools such as Apache Kafka and Apache Nifi
Proficient in programming languages like Java, Scala, or Python
Experience or expertise using, managing, and/or testing API Gateway tools and Rest APIs
Experience in traditional database and data warehouse products such as Oracle, MySQL, etc.
Experience in modern data management technologies such as datalake, data fabric, and data mesh
Experience with creating DevSecOps pipeline using CI CD CT tools and GitLab
Excellent written and oral communication skills, including strong technical documentation skills
Strong interpersonal skills and ability to work collaboratively in dynamic team environment
Proven track record in demanding, customer service-oriented environment
Ability to communicate clearly with all levels within an organization
Excellent analytical skills, organizational abilities and problem-solving skills
Experience in instituting data observability solutions using tools such as Grafana, Splunk, AWS CloudWatch, Kibana, etc.
Experience in container technologies such as Docker, Kubernetes, and Amazon EKS

Qualifications:

Active Secret Clearance
Bachelor's Degree in Computer Science, Engineering, or other technical discipline required, OR a minimum of 8 years equivalent work experience
8+ years of experience of IT system administration experience
AWS Cloud certifications are a plus

At KeyLogic we recognize that our employees are our most valuable resources. We hire talented, qualified professionals and provide each of our employees with every resource and opportunity to excel in their day-to-day activities as well as advance their career.

KeyLogic is a highly successful provider of professional and engineering services. We specialize in solutions that enable our customers to make better decisions for their organization. KeyLogic’s performance has earned the company a solid reputation for high standards, proactive solutions, and an outstanding commitment to the customer, best exemplified by the fact we have never had a one-time federal customer — all of our customers have provided repeat business. This has led us to achieve significant growth every year since our founding in 1999.

At KeyLogic, we're known for our extraordinary commitment to the success of the organizations we serve. Our client list includes the Department of Defense (DoD), Environmental Protection Agency (EPA), Energy (DOE), Transportation (DOT) and Treasury (including the Internal Revenue Service (IRS)), General Services Administration (GSA), and the National Aeronautics and Space Administration (NASA).

All qualified applicants will receive consideration for employment at KeyLogic without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital; or any other status protected by law. KeyLogic is proud to be an affirmative action and equal opportunity employer.

NOTE: KeyLogic is an Equal Employment/Affirmative Action employer. We do not discriminate in hiring on the basis of sex, gender identity, sexual orientation, race, color, religious creed, national origin, physical or mental disability, protected Veteran status, or any other characteristic protected by federal, state, or local law.

If you need a reasonable accommodation for any part of the employment process, please contact us by email at Recruiting@KeyLogic.com and let us know the nature of your request and your contact information. Request for accommodation will be considered on a case-by-case basis.

Job Code:
2009",1999,Energy & Utilities,$100 to $500 million (USD),"Energy, Mining & Utilities",501 to 1000 Employees,Company - Private,False
Senior Data Engineer,"Veterinary Practice Partners
","Boston, MA",$106K - $143K (Glassdoor est.),4.6,"The Company

Veterinary Practice Partners LLC (VPP) forms partnerships with veterinarians to own and manage veterinary hospitals, offering a unique model that allows veterinarians to stay in the driver's seat of their profession. Once a partnership is formed, the Company provides support and leadership for the marketing, financial, operations and human resources functions, while the veterinarian leads the clinical and client services functions. The Company was founded in 2011, has grown to more than 130 partner hospitals and over 2,200 employees across 26 states. VPP expects to accelerate growth in 2023 and beyond. The Company has partnered with a top-tier private equity firm to support this growth.

Position Summary:

Veterinary Practice Partners' (""VPP"") Data & Analytics team brings quantitative, analytical support to decision-making for our fast-growing business. Members serve as partners to business leaders in linking strategic, operational, and financial planning to execution. As a leader within the Data & Analytics team, the Senior Data Engineer will contribute significantly to the performance of our business by developing the data architecture that enables insight delivery to an ever-growing portfolio of hospitals. The ideal candidate will possess strong technical expertise, leaderships skills, and strategic thinking to drive the design, development, and maintenance of our data infrastructure. In this role, you will play a pivotal role in shaping the way we collect, store, process, and analyze data to support business objectives and innovation.

Your responsibilities will include:

Strategy Creation: Collaborate with cross-functional teams to define the data engineering strategy aligned to business objectives, including data modeling that unifies data assets across a range of source systems used to manage the operations of our partnering hospitals.
Pipeline Development: Define and execute processes needed to develop, test, deploy, and maintain high quality data pipelines. Oversee the end-to-end development of data pipelines from source data extraction through to production-grade analytical dataset delivery, ensuring data quality and security throughout the pipeline.
Performance Optimization: Continuously monitor and optimize data processing performance and efficiency. Identify and address bottlenecks, optimize query performance, and improve overall system stability.
Data Governance: Establish and enforce data quality management policies, data access controls, and data privacy standards.
Technical Leadership: Stay abreast of the latest developments in engineering tools and best practices. Provide guidance to the team about technical challenges.
Documentation: Maintain clear and comprehensive documentation of data pipelines, architecture, and processes to ensure knowledge sharing and team continuity.
Third-party Management: Evaluate and manage relationships with third-party vendors and tools, making informed decisions about when to leverage external solutions.

What you need to be considered:

6+ years in data engineering roles with progressively increasing responsibilities.
Deep understanding of data modeling, data architecture, and data integration best practices.
Strong hands-on experience with Apache Spark and cloud computing technologies.
Advanced proficiency in Python and SQL.
Familiarity with data governance, security, and privacy principles.
Comfort using collaboration tools such as GitHub or equivalent to manage development life cycle.
Excellent data modeling and engineering skills, and a talent for translating business objectives into technical solutions.
High energy, humble team player with ""get it done"" attitude, seeking collaboration with colleagues.
Ability to manage multiple projects simultaneously.

Preferred Qualifications

Experience engineering in Databricks strongly preferred.
3+ years of software engineering with python in a production environment.
Experience with the Azure cloud ecosystem.
Experience developing production-ready, real-time machine learning model serving pipelines.
Comfort developing in the Apache Spark Structured Streaming paradigm.
Experience working in the veterinary services industry, or a private equity-backed services company.
Working knowledge of Microsoft Excel and Office 365.

What's in it for the right candidate:

Competitive salary and benefits, including medical and 401(k) plan with a company match
Unlimited PTO
Growth opportunities
A fun, casual environment that values independent thought and an ownership approach to working
Ability to make a significant impact on the growth of the company in a newly created role

Equal Employment Opportunity:

Veterinary Practice Partners (VPP) provides equal employment opportunities to all applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any legally protected characteristic.",2011,Pet Care & Veterinary,$100 to $500 million (USD),Personal Consumer Services,10000+ Employees,Company - Private,True
"Data Engineer, Digital Transformation","Harvard University
","Boston, MA",-1,4.3,"Position Description

Be a pioneer in business, education, and global impact by joining the Harvard Business School Digital Transformation team - a “startup with assets,” where you will have the chance to deploy cutting-edge digital- and emerging-technology education solutions. Where else can you make a difference at the intersection of technology, world-class education, noble purpose, and timeless legacy?

As a Data Engineer, you will bring to life and implement architecture blueprints, perform data analyses, and help our team by mapping out solutions to some of our complex technical challenges. You'll provide technical expertise, analyses, mitigate risk and offer solutions tailored for our needs. From migrations of existing workloads to building advanced cloud solutions, you'll help shape and build systems to increase agility, improve security, reduce costs and meet utilization targets. You will work closely with the Data Science and Infrastructure Architecture & Platform teams and will focus on creating blueprints and finding insights to nourish a culture of engineering excellence. You will report to the Managing Director, Managing Director, Data, Analytics and AI, Digital Transformation.

Duties and Responsibilities:
Support data engineering needs across HBS by providing technical support and training in data frameworks and ways of working. Also, assist with reviewing, refactoring and integrating source code for quality control, in addition to data analyses.
Design and build production-ready applications to reliably process batch and streaming data in a multi-tenancy cloud data platform and provide insights back to business systems based on their needs.
Design and implement core platform functions, tools, and processes using Agile methodology to integrate data from multiple sources and support use cases, ensuring standardization and reusability of work products.
Collaborate with the Group Architecture team to enhance the data platform capabilities, proposing updates to the solution architecture that utilize cloud platform best practices.
Determine the tools and technologies to be used on the Data Platform and investigate new technologies to identify potential benefits and improvements.
Partner with technology teams within HBS, Harvard, and vendors as needed to implement solutions.
Complete other responsibilities as assigned.

Basic Qualifications

Minimum of five years’ post-secondary education or relevant work experience

Additional Qualifications and Skills

Other Required Qualifications:
Bachelor's degree in mathematics, physics, computer science, engineering, statistics, or an equivalent technical discipline.
Three-five years’ experience working in cloud and on-premise environments with common data processing tools, writing unit tests, performing integration testing, functional and performance testing, automating workflows, and CI/CD using agile best practices.
Minimum of three years’ experience with building data security frameworks in compliance with GDPR and CCPA guidelines.
Minimum of five years’ hands-on experience with distributed data processing tools such as MapReduce, Hadoop, Hive, EMR, Kafka, Spark, etc.
Minimum of five years’ experience working with relational databases (SQL) and non-relational databases such as MongoDB, Redis, Cassandra, etc. with an ability to choose the right database for a use case.

Other Preferred Qualifications:
Extensive experience with performance tuning applications on cloud systems to maximize performance or other data frameworks.
Experience building systems to perform real-time data processing using scalable data streaming frameworks.
Expert level experience with cloud ecosystems (AWS, GCP, Azure).
Experience with descriptive statistics and data analysis.
Strong software development experience in popular object-oriented programming languages (C/C++, Java, Python, Scala, etc.)
Experience with Unix-based systems, including bash scripting.
Strives to learn new skills, test the limits, and stretch capabilities maximizing opportunities to innovate and harness new ideas, emerging technologies and toolsets.

Additional Information

This role has the possibility of being a remote or hybrid position. You must reside in one of the following states: CA, CT, GA, IL, MA, MD, ME, NH, NJ, NY, RI, VA, VT or WA. There may be periodic visits to our Boston, MA based campus. In a hybrid role, you are required to be onsite at our Boston, MA based campus a determined number of days per month. Specific days and schedule will be determined between you and your manager.

We may conduct candidate interviews virtually (phone and/or via Zoom) and/or in-person for this role.

A cover letter is required to be considered for this opportunity.

Harvard Business School will not offer visa sponsorship for this opportunity.

Culture of Inclusion: The work and well-being of HBS is profoundly strengthened by the diversity of our network and our differences in background, culture, national origin, religion, sexual orientation, and life experiences. Explore more about HBS work culture here https://www.hbs.edu/employment.

Work Format Details

This is a hybrid position that is based in Massachusetts. Additional details will be discussed during the interview process. All remote work must be performed within one of the Harvard Registered Payroll States, which currently includes Massachusetts, Connecticut, Maine, New Hampshire, Rhode Island, Vermont, Georgia, Illinois, Maryland, New Jersey, New York, Virginia, Washington, and California (CA for exempt positions only). Certain visa types and funding sources may limit work location. Individuals must meet work location sponsorship requirements prior to employment.

Benefits

We invite you to visit Harvard’s Total Rewards website to learn more about our outstanding benefits package, which may include:

Paid Time Off: 3-4 weeks of accrued vacation time per year (3 weeks for support staff and 4 weeks for administrative/professional staff), 12 accrued sick days per year, 12.5 holidays plus a Winter Recess in December/January, 3 personal days per year (prorated based on date of hire), and up to 12 weeks of paid leave for new parents who are primary care givers.
Health and Welfare: Comprehensive medical, dental, and vision benefits, disability and life insurance programs, along with voluntary benefits. Most coverage begins as of your start date.
Work/Life and Wellness: Child and elder/adult care resources including on campus childcare centers, Employee Assistance Program, and wellness programs related to stress management, nutrition, meditation, and more.
Retirement: University-funded retirement plan with contributions from 5% to 15% of eligible compensation, based on age and earnings with full vesting after 3 years of service.
Tuition Assistance Program: Competitive program including $40 per class at the Harvard Extension School and reduced tuition through other participating Harvard graduate schools.
Tuition Reimbursement: Program that provides 75% to 90% reimbursement up to $5,250 per calendar year for eligible courses taken at other accredited institutions.
Professional Development: Programs and classes at little or no cost, including through the Harvard Center for Workplace Development and LinkedIn Learning.
Commuting and Transportation: Various commuter options handled through the Parking Office, including discounted parking, half-priced public transportation passes and pre-tax transit passes, biking benefits, and more.
Harvard Facilities Access, Discounts and Perks: Access to Harvard athletic and fitness facilities, libraries, campus events, credit union, and more, as well as discounts to various types of services (legal, financial, etc.) and cultural and leisure activities throughout metro-Boston.

Job Function

Information Technology

Department Office Location

USA - MA - Boston

Job Code

I1458P IT Rprting and Analyt Prof IV

Work Format

Hybrid (partially on-site, partially remote)

Sub-Unit

-

Salary Grade

058

Department

Digital Transformation

Union

00 - Non Union, Exempt or Temporary

Time Status

Full-time

Pre-Employment Screening

Criminal, Education, Identity

Commitment to Equity, Diversity, Inclusion, and Belonging

Harvard University views equity, diversity, inclusion, and belonging as the pathway to achieving inclusive excellence and fostering a campus culture where everyone can thrive. We strive to create a community that draws upon the widest possible pool of talent to unify excellence and diversity while fully embracing individuals from varied backgrounds, cultures, races, identities, life experiences, perspectives, beliefs, and values.

EEO Statement

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation, pregnancy and pregnancy-related conditions, or any other characteristic protected by law.",1636,Colleges & Universities,$10+ billion (USD),Education,10000+ Employees,College / University,False
Senior Data Engineer (Snowflake + Informatica),Hire IT People Inc,"Boston, MA",$88K - $187K (Employer est.),-1.0,"Position: Senior Data Engineer (Snowflake + Informatica)

Location: Boston, MA (Onsite)

Duration: Long Term Contract

Skills: Snowflake & Informatica Implementation exp.

Need local only

The Senior Data Engineer (SDE) will lead the new Snowflake & Informatica implementation of the agency.
The individual in this role will collaborate with business users and other engineers to build a new data warehouse solution using Snowflake.
The SDE will help with the overall Data Strategy, including infrastructure, software, utilities/tools, Public Cloud Solutions, and Business Intelligence Solutions for the organization.

DETAILED LIST OF JOB DUTIES AND RESPONSIBILITIES:

Provide an understanding of Snowflake Data Warehouse, Data Movement, Data Curation, Data Staging, and Transformation best practices.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Create and contribute to the automation of essential processes related to infrastructure solution deployment, creating repeatable and robust deployments.
Perform advanced data transformation activities using Informatica, PL/SQL, Oracle Database tuning, SQL tuning, and Informatica Server administration.
Provide hands-on solutions, including platform ownership and supporting essential platform capabilities.
Responsible for Performance and performance tuning, Data Quality, Protection, and Availability
Responsible for developing and implementing solutions related to Snowflake and preparing data for Business Intelligence
Fully document all solution work, including designs and configurations
Play an essential role in troubleshooting data system problems and providing viable solution options

QUALIFICATIONS:

Minimum eight years of experience in IT with a focus on Enterprise Data Solutions
5 years of experience in:

o Snowflake Data Solutions, hands-on Data warehousing methodologies and modelling techniques

o Data migration methods of on-prem to cloud data solutions, including ELT/ETL Tools and concepts

o Working with Batch and Stream data SQL, preferable Snowflake SQL Massively Parallel Processing (MPP) Analytical Datastores Education Requirements

Bachelor’s degree in computer science, engineering, or Management Information Systems, or related IT field.

Job Type: Full-time

Salary: $88,124.54 - $187,472.83 per year

Experience level:

6 years

Schedule:

8 hour shift

Ability to commute/relocate:

Boston, MA 02108: Reliably commute or planning to relocate before starting work (Required)

Experience:

Informatica: 4 years (Required)
SQL: 4 years (Required)
Data warehouse: 3 years (Required)
IT: 6 years (Required)

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Software Engineer - Data Center Networking,"Facebook App
","Boston, MA",$144K - $193K (Glassdoor est.),3.9,"The DC Networking team is responsible for developing, deploying, and operating Meta's global data center networks. Our work covers the entire network lifecycle, including hardware development, capacity planning, distributed and centralized control systems, modeling/provisioning/automation, monitoring/troubleshooting/analytics, and simulation/design/failure analysis. We are actively seeking Software Engineers to help build and scale our rapidly evolving network infrastructure. We are looking for Software Engineers with a passion for networking and aptitude for building scalable distributed systems. Do you want to work on one of the most dynamic, fast-paced networks in the world? Do you want to develop innovative solutions to our challenges and ship them into production? Then a role on one of our network engineering teams is for you!



Software Engineer - Data Center Networking Responsibilities:

Design and implement drivers (and/or Firmware) for (network) ethernet adapter functions, Transport stack for RDMA, control functions with the host/accelerators.
Design and implement Platform services such as programming, monitoring, and controlling system components (Optics, PHY, FPGAs, sensors, fan control, power etc).
Develop and enhance HPC collective communication and parallel computing libraries such as NCCL, RCCL, OneCCL, and MPI
Debug complex, system-level, multi-component issues that typically span across multiple layers from Kernel, and user-mode applications.




Minimum Qualifications:

Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
Proficient in programming in C/C++/Python
Hands on experience with debugging large scale systems




Preferred Qualifications:

Experience in one of the following areas -
Experience with Linux Kernel, especially drivers and network stack
Working knowledge of transport stack particularly RDMA (RoCEv2)
Experience with parallel computing platforms such as CUDA, RoCM and OpenCL
Platform services (program, control, and monitor Optics, PHY, FPGAs, sensors, fan control, power etc), BSP/Board Support Package, Operating Systems, Kernel, Bootloader, Power Management, RTOS, Linux.
Experience with Qemu, FPGA Emulation environment is a plus




About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.



Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",2004,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Principal Data Engineer,"Rapid7
","Boston, MA",$119K - $161K (Glassdoor est.),3.9,"Principal Data Engineer


Rapid7 seeks an experienced, highly driven, and dynamic Principal Data Engineer to take our data engineering function to the next level. Come and join our efforts in unlocking the value of data through industry-leading innovation, cutting edge modern tooling, democratization at scale and building exceptional and trusted data products for the company!

About the Team


As we spearhead a cultural shift to a data-driven business, Data Engineering serves as the Hub for all teams at Rapid7 from ML Ops, to Sales and Operations to Platform and Engineering. Our team is a highly skilled yet egoless group of data magicians (and humorists) with a penchant for innovation and a knack for problem solving.

About the Role

As a Principal Data Engineer, you will be responsible for the technical advancement of our data engineering function tackling our most complex challenges, mentoring our highly motivated core of data engineers and senior data engineers, and building strong partnerships with data consumers across the organization. You’ll have the liberty to drive business value through thought leadership and innovation as we continue to work towards the high standard we’ve set for ourselves - a best-in-class data platform.

In this role, you will:

Scope and stage larger scale initiatives into well-defined milestones to avoid a monolithic deliverables

Provide thought leadership and contribute to the vision of our data engineering function

Lead team processes such as on-call rotations, bug triage, technical direction, standards, and execution

Own delivery architecture/execution of major component(s) from conception to release

Looked up to for technical mentorship within the data engineering team. Make others better through code reviews, focus on documentation, and technical guidance

Act as a resource sought for technical advice and weigh in on technical decisions that impact other teams as well

Understand the tradeoffs between technical and business needs, interact and negotiate with key stakeholders, and deliver solutions that take all of these needs into account

Regularly take complex designs / codebases and simplify them without being asked

Regularly contribute improvements to team’s existing SDLC (ie: CICD) or other methods, programs, etc

The skills you’ll bring include:

8+ years of hands on data engineering experience and at least 4 years in a senior-level data engineering role

8+ years of experience in at least one programming language such as Python, Java, Scala is required (Python is our most commonly used language); Advanced SQL expertise is required

Experience working in a modern lakehouse is required (Snowflake is preferred); Modern warehousing best practices should be second nature

Cloud experience is required (AWS is strongly preferred); Terraform is highly preferred

Knowledge and ideally hands on experience working with container services is required (ECS, Kubernetes, etc)

Experience working in a mature SDLC environment (ie: CICD) is required

Modern tech stack experience is a plus (dbt, Fivetran, Snowflake. Airflow)

Experience as a leader within a data engineering team and ability to mentor teammates

Strong work ethic, resiliency, persistence, and urgency; Data Engineering holds itself to a high standard so you’ll need to keep up!

Sharp business and interpersonal skills; ability to influence at senior levels across business units to drive change and achieve common goals

BS or MS in Computer Science, Analytics, Statistics, Informatics, Information Systems or
another quantitative field or equivalent experience



We know that the best ideas and solutions come from multi-dimensional teams. That’s because these teams reflect a variety of backgrounds and professional experiences. If you are excited about this role and feel your experience can make an impact, please don’t be shy - apply today.


About Rapid7

At Rapid7, we are on a mission to create a secure digital world for our customers, our industry, and our communities. We do this by embracing tenacity, passion, and collaboration to challenge what’s possible and drive extraordinary impact.


Here, we’re building a dynamic workplace where everyone can have the career experience of a lifetime. We challenge ourselves to grow to our full potential. We learn from our missteps and celebrate our victories. We come to work every day to push boundaries in cybersecurity and keep our 10,000 global customers ahead of whatever’s next.


Join us and bring your unique experiences and perspectives to tackle some of the world’s biggest security challenges.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, protected veteran status or any other status protected by applicable national, federal, state or local law.",2000,Computer Hardware Development,$100 to $500 million (USD),Information Technology,1001 to 5000 Employees,Company - Public,False
Data Operations Engineer,"Global Atlantic Financial Group Opportunities
","Boston, MA",$65K - $125K (Employer est.),4.0,"All offices are currently open, and our employees are back 4 or 5 days a week in Hudson Yards, NY and 3 days a week in all other offices. If you have questions on this policy or the application process, please contact recruiting@gafg.com.

COMPANY OVERVIEW

Global Atlantic Financial Group is a leader in the U.S. life insurance and annuity industry, serving the needs of individuals and institutions. Global Atlantic is a majority-owned subsidiary of KKR, a leading global investment firm that offers alternative asset management across multiple strategies and capital markets solutions.

Global Atlantic is looking for a diverse team of talented individuals who reinforce our culture of collaboration and innovation. We are dedicated to the career development of our people because we know they are critical to our long-term success. Join our team and come grow with us.

We use Greenhouse as our scheduling tool and communicate through their systems. At times, your email may block our communications. Please be sure to check your SPAM so that you do not miss critical information about our process, including scheduling.

Job Summary:

In this role, you will be responsible for expanding and evolving the cloud-based enterprise data platform. You will ensure the technology components of the platform are correctly configured and optimized to meet the functional, non-functional, and operational requirements. This role requires a highly motivated individual with strong technical ability, data capability, excellent communication and collaboration skills including the ability to develop and troubleshoot a diverse range of problems. Support end-to-end ML workflow pipeline. The candidate must be self-directed with the ability to own and execute the platform improvement activities while collaborating with other team members and stakeholders.

Be willing to work non-standard business hours on an on-call basis in a 24x7 environment few days a month.

This role must sit in New York City, Boston or Des Moines.

Responsibilities:

Triage problems across the data platform to help address development, test, and production issues.
Assist in evaluating the reliability, accuracy, and cost-effectiveness of machine learning models and work with Business IT Teams to identify areas of improvement
Testing Data pipelines at staging/QA environments and help deploying them at production.
Work with business, product and technical stakeholders on data or report issues.
Create and manage Incident and Change Requests as needed for data pipelines.
Assist with data architecture, pipeline development, automation and planning
Develop and maintain documentation, departmental technical procedures, and user guides
Maintain best practices to facilitate optimized software development and continuous improvement/continuous delivery (CI/CD)

Qualifications:

Degree in computer science, engineering, or a related discipline preferred.
Must have 4-5 years of software development experience or must demonstrate significant experience of applying software engineering best practices (system design for scale, modularity, version control, unit testing, documentation etc.) on real-world projects
2+ MLOps experience automating processes, using data to make better decisions, using software to make processes more efficient, improving the quality of the product or service.
2+ years of Tableau or similar BI dashboards build debugging.
Ability to code in multiple languages (Python and SQL; R, Java, or others as well)
Strong foundation in the AWS Cloud Services: S3, Redshift Spectrum, EC2
Solid understanding and experience working with Gitlab, JIRA and Confluence

Various jurisdictions have passed pay transparency laws that require companies provide salary ranges for any positions for which they are accepting applications. Global Atlantic has offices in Atlanta, Batesville, Bermuda, Berwyn, Boston, Des Moines, Hartford, Indianapolis, and New York City. The base salary range posted below is inclusive of the lowest cost of living geography to the highest in which we have a Global Atlantic office.

Global Atlantic's base salary range is determined through an analysis of similar positions in the external labor market. Base pay is just one component of Global Atlantic's total compensation package for employees and at times we hire outside the boundaries of the salary range. Other rewards may include annual cash bonuses, long-term incentives (equity), generous benefits (including immediate vesting on employee contributions to a 401(k)), as well as a company match on your contributions), and sales incentives. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Compensation for our more senior positions have a larger component of short-term cash bonus and long-term incentives. The base salary range for this role is $65,000 to $125,000

#LI-AO1

#LI-Hybrid


TOTAL REWARDS STATEMENT

Global Atlantic's total rewards package is reflective of our corporate values, particularly diversity, excellence and innovation, with a focus on inclusion, pay equity, and flexibility. We are proud to support your personal and professional growth and well-being through programs such as educational assistance, virtual physical therapy, remote/onsite fitness reimbursement, a medical second opinion program, pet insurance, military leave, parental leave, adoption assistance, fertility and family planning coverage. We strive to foster a culture of total well-being through community outreach and charitable giving programs.

We are active in our communities:

New York: Red Hook Conservancy, Girls Who Invest, Outward Bound, Teach for America, StreetWise Partners,
Boston: Catie's Closet, Project Bread, Thompson Island Outward Bound Education Center, Cradles to Crayons, and many others
Hartford: Braids and Company, Junior Achievement
Indianapolis: Elevate Indianapolis, Gleaners Food Bank and the Juvenile Diabetes Research Foundation
Batesville: So Loved Ripley County Foster Closet, Southeastern Indiana YMCA, Batesville Community Education Foundation, Southeastern Indiana Voices for Children, local area youth sports, as well as many others
Des Moines: United Way of Central Iowa, Meals from the Heartland, Oakridge Neighborhood, Community Support Advocates, and many others
Wayne: For Pete's Sake, Chester County Food Bank, Habitat for Humanity Chester County, Brandywine SPCA, as well as others
Bermuda: Transformational Living Centre for Families

Social platforms provide an environment to collaborate with others and participate in friendly competitions towards achieving physical, emotional and financial well-being. Our highly competitive health, retirement, life and disability plans can be tailored to best suit your needs and those of your whole family.

Global Atlantic is committed to creating an inclusive environment where everyone can meaningfully contribute to our success. We are proud to be an equal opportunity employer and we do not discriminate in employment on any basis that is prohibited by federal, state or local laws. More than that, we strive to be inclusive of all backgrounds and experiences, which we feel gives us a competitive advantage in the market and within our firm. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status.

Employees who require an accommodation to perform the essential functions of their job will participate in an interactive process which may include providing documentation. If you are hired and require an accommodation for any protected status, please email benefits@gafg.com.

Please click on the below links to learn more about Global Atlantic.

Global Atlantic Privacy Statement",2004,Insurance Carriers,Unknown / Non-Applicable,Insurance,1001 to 5000 Employees,Company - Private,False
"Software Engineer, Data","Berkshire Grey
","Bedford, MA",$85K - $129K (Glassdoor est.),3.0,"Software Engineer - Data


Data Team Mission

Our mission on the data team is to bring value with data. We do everything from helping design schemas, providing key insights, and building the dashboards that enable world class operations and monitoring of our Robotic systems. We work with teams across the organization, from internal Machine Learning teams to customer facing groups to bring our knowledge and experience to bear in order to help them achieve their goals.


Role Description

The data software engineer will work on BG’s Data Team, to improve, manage, and own data systems that are used across the company. You will be working with various internal customer teams to help them use their data - from initial help defining schemas, to transforming and making that data available for customer-facing applications.


Your work will include:

Building software to handle data backup and management for on-prem robotic systems
Designing and building data pipelines to transform and ship data to our data warehouse
Working directly with various internal customers and product teams to help advise them on schema design, data apis, and query/analysis needs
Building and maintaining data apis for internal customers to use to both generate data and access our various data systems
Helping our internal customers design and build dashboards to enable insights and operational excellence


Background and Experience Required

3+ Years of experience working with databases and/or data streaming platforms
3 Years experience with an Object Oriented programming language - preferably Python
Experience developing in a Linux environment, using Git and Github, and using a work tracking system like Jira
A demonstrated understanding of Data Schema and basic schema design
Proficiency in one or more databases, including: MongoDB, Elasticsearch, SQL databases
An understanding of the differences and tradeoffs between SQL and NoSQL databases


Preferred

Experience using Snowflake as a data warehouse
Familiarity with Apache Kafka
3 years of experience with Python
Familiarity with Docker and building docker images
An understanding of Kubernetes concepts, with experience deploying applications to kubernetes
Experience building systems with AWS and/or GCP


6110-2309ZR",2013,Taxi & Car Services,Unknown / Non-Applicable,Transportation & Logistics,201 to 500 Employees,Company - Public,False
Lead Data Engineer,"National Grid
","Waltham, MA",$139K - $156K (Employer est.),4.0,"Lead Data Engineer

Location: Waltham, MA, US, 02451
Division: IT Global Solution Development
Job Type:
Requisition Number: 45717
Department:
Job Function: Information Technology
About us


Join National Grid’s digital transformation! We are digital creators, continuous learners and daring innovators. We leverage digital innovative ways to create products and catalyze the transformation of National Grid's business units into more agile and digitally native organizations in our shared purpose of bringing energy to life. Come and join us on this incredible journey, We need you!


We want to find a collaborative, hands-on Lead Data Engineer for our Digital Platform Data Engineering Team who will be responsible for designing sound, scalable, and performant solutions that meet the requirements in a large data volume enterprise, and leading the teams responsible for implementation. Solutions and design trade-offs are communicated to business and technical stakeholders for effective decision-making.


If you yearn to be innovative, contribute new ideas, and play a critical part in the US IT Global Solutions Delivery organization, we want to hear from you!
What you'll do


As a Lead Data Engineer, you'll work on a major IT initiative to enable National Grid Business Partners by improving how our employees serve our customers today and by creating the platform for tomorrow’s growth. Key responsibilities include the following:


Perform and collaborate on system designs, data solution development including data migration and extracts from multiple legacy systems
Provide day-to-day supervision and leadership of engineering team(s) responsible for implementation.
Update data mappings and data catalogs
Participate in, and/or lead, design and pre-deployment reviews
Data profiling
Design and development of data synchronization processes
Participate in the design/development of SaaS solutions, including data modeling
Assist in determining the cross-application data standards, data distribution standards and promote data-driven design
Create database deliverables ensuring quality and traceability to requirements and adherence to all quality management plans and governance standards
Work with the team to ensure that all components work together to meet objectives and performance goals as defined in the requirements. Identify and communicate any cross-area or cross-release issues that may affect other areas of the project
Participate in go-live preparation activities such as QA, dress rehearsals, issue remediation, cutover and go-live aftercare
Participate in data management maturity assessments to identify gaps and pain points for capabilities including data quality, governance, analytics, metadata management, master data management
Seek opportunities for continuous improvement in processes, procedures and systems with regards to data
What you'll need


5+ years’ experience in database development (Snowflake, SQLServer, Oracle, etc)
Experience in data mapping, modeling and working with teams to define data models
Experience in a dynamic work environment
Proven ability to work well in a team environment, and be capable of building and maintaining positive relationships with other staff, departments, and customers
Strong communication skills
It would be awesome if you had


Experience with cloud database architecture
Experience with Snowflake
Experience with Matillion
Experience with real-time data loads
Experience with Agile/Lean software development process and practices
Experience in with SaaS solutions such as Salesforce, ESRI and Workforce
Good team leadership and influencing skills for colleagues, partners / vendors; project sponsors
Ability to work with cross-functional teams, subject matter experts, and architects
What you'll get


Consistent growth potential through company leadership programs
Competitive compensation package including robust benefits with a yearly bonus
Numerous wellness programs
A multitude of company-endorsed community programs to participate in
More Information


Are you the right fit for this exciting role? You want to learn more about the position and National Grid's ambitious Digital Transformation? Then let's chat!


Our organization follows a hybrid work structure in our service territory (NY & MA and adjacent states) where employees can work remotely or from the office, as needed. Working from the office is encouraged when working on tasks that require a high degree of collaboration. We work with our employees to foster a work schedule that fits your flexible schedule.
#LI-CL1 #LI-HYBRID


At National Grid, we keep the lights on and homes warm. But it’s so much more than that. We keep people connected and society moving. This is no easy feat, and it takes all of us. But National Grid supplies us with the environment to make it happen. As we generate momentum in the energy transition for all, we don’t plan on leaving any of our customers in the dark. But we aren’t looking for external recognition – we already what we do is vital. We’re building a clean, fair and affordable energy future.
Salary
$139,000 - $156,000 a year
Please be advised that due to the nature of this position, incumbents are subject to federal Drug & Alcohol safety regulations governing US Department of Transportation (""DOT"") covered positions, including the Federal Motor Carrier Safety Administration (FMCSA) and Pipeline Hazardous Material Safety Administration (PHMSA). As such, the Company’s testing programs and policies regarding the use of federally prohibited drugs or alcohol, for recreational or medical purposes, will remain in effect for these safety-sensitive, DOT covered positions.
This position has a career path which provides for advancement opportunities within and across bands as you develop and evolve in the position; gaining experience, expertise and acquiring and applying technical skills. Candidates will be assessed and provided offers against the minimum qualifications of this role and their individual experience.
National Grid is an equal opportunity employer that values a broad diversity of talent, knowledge, experience and expertise. We foster a culture of inclusion that drives employee engagement to deliver superior performance to the communities we serve. National Grid is proud to be an affirmative action employer. We encourage minorities, women, individuals with disabilities and protected veterans to join the National Grid team.



Nearest Major Market: Waltham
Nearest Secondary Market: Boston

Recruitment Advisory",1990,Energy & Utilities,$5 to $10 billion (USD),"Energy, Mining & Utilities",10000+ Employees,Company - Public,False
Senior Data Engineer,"Velir
","Somerville, MA",$150K (Employer est.),3.3,"Overview:
Senior Data Engineers play a crucial role in helping our client organizations manage and leverage their data effectively. Their responsibilities include: Data Architecture Design; Data Warehousing; Data Quality Assurance; Scalability and Performance Optimization; and Data Security. As senior-level individual contributors, SDEs are also responsible for recommending and implementing data engineering tools and technologies that best suit the client’s needs.

Because our clients are mostly US-based organizations, we look for the ability to communicate with professional proficiency in English, verbally and in writing.
Responsibilities:
Data Engineering Expertise: You are responsible for building the infrastructure to support the storing and movement of data, so that it can be prepared by analytics engineers to eventually be interpreted by analysts. Your job is informing, developing, and implementing data accessibility solutions, enabling our clients to utilize data for performance evaluation and optimization. As a senior member of the Data Engineering function, you serve as a mentor to other engineers, both individually and in group settings.
Consistently seeks out and delivers on engagement level vision, tasks and problems
Actively assists in scoping and executing most impactful work for the team
Regularly delivers large features and product improvements that have a meaningful impact on clients’ data infrastructure and capabilities
Autonomous in approach and may direct or coach other less experienced Engineers
Actively mentors other Engineers in the team on individual basis or in group settings
Helps others grow through technical guidance, code reviews, documentation, etc.
Cross-Team Collaboration: You are responsible for collaborating with peers and other functional departments to develop and implement data engineering strategies and approaches that support engagement goals and understanding client needs.
Promotes a positive culture within and across different teams, collaborating with analytics engineers and data analysts on end-to-end client requirements
Collaborate with clients and functional managers to plan for data engineering needs for a product or feature launch
Pair with a teammate or with someone at a client on strategies for solving a data engineering problem
Create a process or reporting template that helps cross-functional teams solve for common data engineering problems
Regularly engages with other teams to make the organization more effective
Take initiative to identify and solve important problems. Coordinates with others on cross-cutting technical issues
Drives data solutions improvements that impacts the client experience or empowers internal stakeholders (teams like Operations, Growth / Partnerships, Finance, etc.) to do their job effectively

Project Delivery: You are responsible for ensuring that large and/or more complex data engineering projects are delivered on time, within scope, and within budget.
Architects and designs services/systems using design patterns that allow for iterative delivery and future scaling
Proactively identifies and tackles technical debt becoming too big through planning work and aligning the team. Does this with careful evaluation of additional cost on development
Optimizes for the predictability and regular cadence of deliverables
Keeps reliability, maintainability and scalability of our clients’ systems top of mind
Embraces long-term ownership of projects while training others to reduce the bus factor or becoming a blocker
Prioritizes and values undesirable/unowned work that enables the team to move faster
Skills & Qualifications:
Tools & Technologies
Programming languages (e.g. SQL, Python)
Data Processing (e.g. Apache Spark, dbt)
Cloud-based data warehouses (e.g., Snowflake, Google BigQuery)
Data orchestration (e.g., Apache Airflow, Azure Data Factory, Prefect)
Technical Skills (Hard Skills)
See the latest Data Engineering framework.
Data Movement: You can reduce latency of end-to-end pipelines through data orchestration in addition to incrementalization or streaming. You have strong knowledge of common data integration patterns (CDC, ELT, etc.).
Data Warehousing: You have a high proficiency in warehousing, including working knowledge of common ingestion SaaS platforms (e.g., Fivetran) and / or frameworks (e.g., Meltano, Airbyte), an ability to configure warehouse ingestion tools (e.g., Snowpipe) and can provision, maintain and optimize at least one cloud data warehouse (e.g., Snowflake).
Programming: You are considered a highly proficient programmer, approaching your code holistically, achieving a high standard routinely. You can optimize performance for large workloads and are able to troubleshoot complex queries / functions. Proficiency in Python required.
Domain Expertise: You have a strong foundation of knowledge in domains in which you’re working. You are able to relate how the business works with the goals of the immediate team.
Technical Management: Is able to display a clear technical confidence and understanding. For the most part, can use organizational- and team-specific tools independently.

Bonus points for:
Data Modeling & Transformation: You have high proficiency with data transformation tools such as dbt and expert proficiency in data modeling approaches and philosophies (Kimball, OBT).
Data Orchestration. You’re familiar with at least one data orchestration platform (Azure Data Factory, Apache Airflow, Prefect, etc.).
Data Infrastructure: You understand more complex infrastructure approaches, including the implications and suitability of different deployment options and how to deploy self-hosted applications for clients with high security requirements.
Essential Skills (Intangible Skills)
Curiosity & Versatility: You help your immediate peers to make decisions based on what projects need, not what they feel most comfortable doing. You have taken the initiative to seek out new ways to apply existing skills and knowledge.
Collaboration & Partnership: You can facilitate collaborative group activities and/or workshops with colleagues or external stakeholders. You are considered a role model for collaboration and creating alignment across teams because of your consistency and predictability.
Effective Communication: You reliably foster a culture of clear, concise, effective, audience-oriented communication for your team, other departments, and external stakeholders, ensuring those around you are actively listening as well as are understood.
Developing Others: You understand your team's domain, share knowledge frequently with your teammates and contribute to the team's documentation. You proactively watch for opportunities to share knowledge and encourage others to do the same.
Culture & Togetherness: You've openly stated your expectations of how your team works and acts, then demonstrated those expectations yourself. You help to coordinate and activate efforts towards a fairer, more diverse and safer workplace, using your position of influence to get things done.
Qualifications (Must Haves)
Proven experience as a Data Engineer or related role, with a focus on designing and developing data pipelines.
Strong programming skills in Python and SQL. Experience with Scala and Rust is a plus but not required.
Deep knowledge of data warehousing and ETL/ELT processes.
Intermediate / expert proficiency with common data integration / orchestration platforms (e.g., Fivetran, Azure Data Factory, Apache Airflow)
Hands-on experience with data warehouses like Snowflake, BigQuery, Databricks, or similar.
Experience with streaming solutions such as Spark Streaming, Kafka, or Flink is desirable but not required.
Familiarity with cloud platforms such as AWS, Azure, or Google Cloud.
Familiarity with machine learning operations (MLOps) techniques and platforms is a plus but not required.
Experience mentoring and advising other engineers
Strong analytical and problem-solving skills.
Excellent communication and collaboration skills.

Physical Requirements
Frequent sitting at a desk performing work on a computer
Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions

Compensation
We believe all team members should be rewarded competitively, using practices that are equitable and transparent. This philosophy ensures we’re able to find, grow, and retain exceptional talent from a variety of backgrounds.


The pay range for this role is up to $150,000 if based in the USA and up to $76,000 if based in El Salvador.

Please note that compensation packages are finalized after the interview process is concluded. We use a competency-based approach to base pay, which means it is based on the competencies and skills demonstrated for this role.

Core Company Values
Velir is an established mid-sized agency with a top-tier portfolio of clients, ranging from the world’s largest non-profits to Fortune 500 brands. We pride ourselves on our people-first culture and a low-ego workplace that embraces experimentation, collaboration and continuous improvement. We have a fun office environment located in Davis Square (Somerville, MA) and offer competitive pay and excellent benefits.
Take the Long View - Ensure the company is built to last
Be Courageous - Make the right decisions even when they aren't the easiest decisions
Be Genuine - Bring honesty and authenticity to all that you do
Work with Focus + Passion - Display purpose and pride in your work and never stop learning

As an equal opportunity employer, we are firmly committing to diversity, equity, and inclusion in our hiring efforts. We recognize that we need team members from all backgrounds and experiences to successfully shape a positive employee experience as well as deliver our product and service solutions. To that end, we actively seek candidates who can bring diverse experiences and backgrounds to our team. We know that complex factors and systemic bias can get in the way of us meeting strong candidates, so please don't hesitate to apply even if you're not 100% sure.

At this time, Velir does not sponsor candidates and unfortunately cannot accept those on OPT or CPT.

#LI-Remote",2000,Advertising & Public Relations,Unknown / Non-Applicable,Media & Communication,51 to 200 Employees,Company - Private,False
Principal Data Engineer,"Harvard University
","Boston, MA",-1,4.3,"Position Description

The Center for Computational Biomedicine (CCB) is a new center within the Blavatnik Institute at Harvard Medical School. Our mission is to provide cutting edge computational capabilities, data analysis, and data integration technologies to support medical and biological research within the Medical School.


We seek a highly motivated, collaborative individual with excellent communication skills to join our team of technologists and scientists as a Principal Data Engineer. You will help build out the necessary data warehousing infrastructure to support the downstream machine learning analysis and integration of large, complex data sets that will provide a nuanced longitudinal perspective on population- and individual-level health outcomes and disease trajectories. These data sets include healthcare insurance claims, electronic health records, genomics, environmental exposure, and other data modalities. The integration of these data will allow our research teams to make ground-breaking advances in the areas of precision medicine, healthcare AI, healthcare policy / economics, and basic science, all with the goal of improving patient outcomes.


In this role, you will work to develop innovative solutions for warehousing and integrating these large data resources. You will have frequent opportunities to dive deep to troubleshoot complex technical issues in large data management systems, working hand-in-hand with our world-class Information Technology and Research Computing teams. Your work will involve a wide variety of technologies including analytic relational data warehouses (column and row stores), graph databases, array databases, object stores, key/value stores, scale-up and scale-out storage platforms, containerized services, and others. Solutions will be deployed both on-premises and in private and public cloud environments.

Basic Qualifications

Minimum of seven years’ post-secondary education or relevant work experience

Additional Qualifications and Skills

MS in Computer Science or related field, with expertise in relational database technologies and 2+ years experience in enterprise data management and data warehousing, or an undergraduate degree in Computer Science with 5+ years experience preferred
Proven understanding of database modeling concepts: entities/tables, relations/constraints, attribute data types, and column data times, with proficiency in SQL
Strong software engineering experience, with a thorough grasp of IT concepts, design and development tools, system architecture and technical standards, shared software concepts, and layered solution and designs
Proven understanding of database modeling concepts: entities/tables, relations/constraints, attribute data types, and column data times, with proficiency in SQL
Strong software engineering experience, with a thorough grasp of IT concepts, design and development tools, system architecture and technical standards, shared software concepts, and layered solution and designs
Experience designing and maintaining multi-terabyte analytic relational databases, including index and query optimization
Experience collaborating with information security teams and working within compliance and data governance constraints
Experience with Microsoft SQL Server or cloud-based data warehousing technologies
Experience with non-relational database systems (graph, key/value, document, array data stores)

Additional Information

This is a one-year term position from the date of hire, with the possibility of extension, contingent upon work performance and continued funding to support the position.

This position is based in Boston, but the work may be done fully or primarily remote. Any remote work must be performed in a state in which Harvard is registered to do business (CA*, CT, GA, IL, MA, MD, ME, NH, NJ, NY, RI, VA, VT, and WA). Individual flexible and remote work options for this role will be discussed during the interview process. *Note: Harvard employees working in California must be exempt.

The University requires all Harvard community members to be fully vaccinated against COVID-19 and remain up to date with COVID-19 vaccine boosters, as detailed in Harvard’s Vaccine & Booster Requirements. Individuals may claim exemption from the vaccine requirement for medical or religious reasons. More information regarding the University’s COVID vaccination requirement, exemptions, and verification of vaccination status may be found at the University’s “COVID-19 Vaccine Information” webpage: http://www.harvard.edu/coronavirus/covid-19-vaccine-information/.

Please note that we are currently conducting a majority of interviews and onboarding remotely and virtually. We appreciate your understanding.

Harvard University offers an outstanding benefits package including:
Time Off: 3 - 4 weeks paid vacation, paid holiday break, 12 paid sick days, 12.5 paid holidays, and 3 paid personal days per year.
Medical/Dental/Vision: We offer a variety of excellent medical plans, dental & vision plans, all coverage begins as of your start date.
Retirement: University-funded retirement plan with full vesting after 3 years of service.
Tuition Assistance Program: Competitive tuition assistance program, incredibly affordable classes directly at the Harvard Extension School, and discounted options through participating Harvard grad schools.
Transportation: Harvard offers a 50% discounted MBTA pass as well as additional options to assist employees in their daily commute.
Wellness options: Harvard offers programs and classes at little or no cost, including stress management, massages, nutrition, meditation, and complementary health services.
Harvard access to athletic facilities, libraries, campus events, and many discounts throughout metro Boston.
The Harvard Medical School is not able to provide visa sponsorship for this position.

Not ready to apply? Join our talent community to keep in touch and learn about future opportunities! (https://www.gem.com/form?formID=16341e35-cbc6-4904-88a3-09b35763307e)



Job Function

Information Technology

Department Office Location

USA - MA - Boston

Job Code

I0759P Applications Professional V

Work Format

Remote

Sub-Unit

-

Salary Grade

059

Department

Biomedical Informatics (DBMI)

Union

00 - Non Union, Exempt or Temporary

Time Status

Full-time

Pre-Employment Screening

Criminal, Education, Identity

Schedule

Fulltime | Monday - Friday

Commitment to Equity, Diversity, Inclusion, and Belonging

We are committed to cultivating an inclusive workplace culture of faculty, staff, and students with diverse backgrounds, styles, abilities, and motivations. We appreciate and leverage the capabilities, insights, and ideas of all individuals. Harvard Medical School Mission and Community Value

EEO Statement

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation, pregnancy and pregnancy-related conditions, or any other characteristic protected by law.",1636,Colleges & Universities,$10+ billion (USD),Education,10000+ Employees,College / University,False
"Data Scientist, Data Quality Engineer","InsideTracker
","Cambridge, MA",$95K - $133K (Glassdoor est.),3.9,"Apr 26, 2022


InsideTracker is seeking a full-time Data Scientist whose main focus will be on data management and quality control of research-related data for downstream analytics, to join our Data Science team.

Requirements
Bachelor's degree in quantitative discipline (e.g. Bioinformatics, Computer Science, Statistics, Mathematics) and 4+ years of related experience, or a Master's degree and 2+ years of experience
Experience with SQL, NoSQL, and either R or Python, demonstrated through either work experience, coursework (university courses, bootcamps) or a portfolio (e.g. Github)
Excellent verbal and written communication skills with the ability to effectively articulate the scientific and business value contributed by properly managed data
Responsibilities
Implement processes that validate data, as well as monitor for and prevent future data quality issues
Take ownership of data documentation that describes the qualities of the data and how it can be used for downstream analytics. This will include reviewing documentation provided by engineering and authoring a supplemental code book
Collaborate across teams such as engineering, data science, and QA to test and monitor data platforms
Participate in implementation and maintenance of a data warehouse/data integration infrastructure
Build and maintain data formatting and processing pipelines for standardized analytical workflows for both research and business intelligence analyses
Be the guardian and purveyor of the “source of truth” for the InsideTracker data asset
You may be asked to perform analyses or build analytics dashboards for scientific research or research-related business intelligence tasks
Skills
Direct experience with any or all of the following: data quality, data management, data governance, data science, and/or data-intensive software development projects
Familiarity or experience with navigating data ecosystems (data warehouses, data lakes, structured and unstructured data, varied file types, BI systems)
Exposure to, and ability to work with, a variety of data formats and storage mechanisms (e.g. JSON, CSV, XML, BigQuery, etc.)
Aptitude for and willingness to learn new tools and technologies as driven by business needs
Ability to collaborate with engineers to dissect complex problems as they drive toward simple, effective solutions
Ability to work independently in a remote, team environment
Excruciating attention to detail - you love spotting inconsistencies and moving towards a sensible source of truth
Details

Reports to: Lead Data Scientist

Location: Cambridge, MA or remote

Hours: Full time

Candidates must be authorized to work in the U.S without sponsorship


About InsideTracker

InsideTracker is the leading personalized nutrition platform which generates ultra-customized recommendations to optimize an individual’s health by tracking and analyzing blood and genetic biomarkers using a patented algorithm.

Our expert system matches the most relevant, science-based recommendations to each individual based on blood data, DNA data and demographics, as well as self-reported preferences and goals. InsideTracker was founded in 2009 by leading scientists in aging, genetics and biometric data from MIT, Tufts and Harvard.

We are a seasoned and high performance team in a period of rapid growth. Relentlessly dedicated to what we do and why we do it, InsideTracker is fueled by our mission to transform the way every human being eats, sleeps and moves to live a longer, better life.

For more information please email jobs@insidetracker.com",2009,Biotech & Pharmaceuticals,Unknown / Non-Applicable,Pharmaceutical & Biotechnology,1 to 50 Employees,Company - Private,False
Lead Data Engineer,"ISO New England Inc.
","Holyoke, MA",$107K - $143K (Glassdoor est.),3.8,"We have an important role to play in securing the region’s clean and reliable energy future and seek folks from a variety of disciplines to join us! In this role you will play a pivotal role in designing, building, and maintaining data infrastructure and pipelines that empower data-driven decision-making. Your expertise will drive the optimization of data flows, ensure data reliability, and enable our organization to leverage the power of data effectively.

What we offer you:

Hybrid work schedule with 2 days/week onsite
ISO-NE offers a flexible and hybrid work, a base salary plus bonus program, professional development and tuition reimbursement, enhanced 401k and financial planning, wellness programs with onsite gym, eligibility for Public Service Loan Forgiveness (PSLF), access to business networks & more, all in a stable and supportive work environment!
How you will make an impact:

Data Infrastructure Excellence: You will design and implement data solutions, manage ETL processes, and optimize data pipelines.
Collaborative Partnership: Collaborating closely with business units, you will strategize the operationalization of complex business flows. Your guidance will ensure data solutions align with organizational goals, and your expertise will be key to success.
Data-Driven Innovation: Your contributions will enable our organization to capitalize on its growing data assets. By automating tasks, optimizing performance, and enhancing data quality, you will empower teams to derive deeper insights and drive innovation.
What you need to be successful in this role:

Bachelor’s Degree in Data Science, Computer Science, Engineering, Physics, or Mathematics
Database Expertise: Proficiency in SQL and experience working with relational databases is a must
ETL and Data Processing: Demonstrated ability to design and implement ETL processes to bridge data from transactional systems to analytical systems
Programming Skills: Proficiency in programming languages such as Python, R, and Shell
Data Quality and Security: Knowledge of data quality assurance techniques, data security principles, and compliance/governance practices.
Problem-Solving: Strong problem-solving and troubleshooting skills to identify and resolve data-related issues.
Collaboration: Effective communication skills to collaborate with cross-functional teams and stakeholders.
Documentation: Commitment to maintaining clear and concise documentation for data processes and pipelines.
Desired but not required:
Data-interchange formats such as JSON or XML
Machine Learning
Predictive Analytics
Linux operational system
Dashboards and Data Visualization
#LI-HYBRID

---------------------------------------------------------------
From Holyoke, MA, ISO New England oversees the 24/7 operation of the power grid that covers the six-states of New England and administers the region’s $15+ billion “stock exchange” for the buying and selling of wholesale electricity. The power system is constantly evolving as new technologies emerge and energy policies evolve. There is a lot happening at our organization behind the scenes to make sure the grid continuously yields reliable electricity at competitive prices while addressing the clean energy transition here in New England. COME JOIN US in making an impact within the region!

To learn more about what we offer our employees visit:
Mission, Vision, and Values
Living in Western New England
What we Offer
Diversity and Inclusion
Careers

Follow us on:
LinkedIn
Twitter
YouTube

Equal Opportunity: We are proud to be an EEO/AA employer. Applicants for employment are considered without regard to race, creed, color, citizenship, religion, sex, sexual orientation, marital status, national origin, age, disability, status as a veteran, Vietnam Era Veteran, or being a member of the Reserves or National Guard.

Drug Free Environment:
We maintain a drug-free workplace and perform pre-employment substance abuse testing.

Social Networking Notice:
ISO New England reserves the right to review the candidate's postings on any social networking site accessible in the public domain as part of the candidate assessment process.",1997,Energy & Utilities,Unknown / Non-Applicable,"Energy, Mining & Utilities",501 to 1000 Employees,Nonprofit Organization,False
Investment Data Engineer - Lead,"MFS Investment Management
","Boston, MA",$100K - $146K (Glassdoor est.),4.0,"At MFS, you will find a culture that supports you in doing what you do best. Our employees work together to reach better outcomes, favoring the strongest idea over the strongest individual. We put people first and demonstrate care and compassion for our community and each other. Because what we do matters – to us as valued professionals and to the millions of people and institutions who rely on us to help them build more secure and prosperous futures.
In conjunction with the Investment Data Management Office, the Lead Data Engineer contributes to a long-term strategic initiative to unify and harmonize our investment data. This initiative enables enhanced investment decision making, risk management and client reporting for our multi-asset platform by delivering consistent, timely, accurate and user-friendly data to investors, risk teams and clients.
Are you a hands-on and detailed-oriented individual working on the cutting edge of financial instruments, investment data, and analytics? Are you interested in investment data strategies across a wide variety of traditional and alternative asset classes? Are you a thinker who enjoys devising innovative and flexible business solutions to meet emerging business needs?
The MFS Investment Data Management Office is actively searching for a Lead Data Engineer to implement data engineering and analytics solutions . Primary responsibilities include full implementation and maintenance of data ingestion, data maintenance, data validation and data delivery of investment data. We are looking for someone who thrives in an agile, collaborative, team-based environment, working closely with technology peers across MFS, investment professionals and key vendor partners. This position offers the opportunity to shape the future of investment data at MFS.
PRINCIPAL RESPONSIBILITIES:
Design, develop, and implement data pipelines to maintain unified data platform for the Investment Data Management Office(IDMO)
Lead and participate in all development activities, develop and implement solutions to meet business requirements that align with program strategic objectives
Responsible for new and on-going development of data pipelines sourcing from internal and external sources
Drive continuous improvement of data quality, resiliency, control, efficiency, and monitoring
Troubleshooting complex system interactions to find the root cause to problems
Partner with platform lead to design, develop, implement and deploy new software components to investment data platform
Partner with data architect to evaluate and finalize the unified data model
Partner with integration architect to upgrade and integrate data ingestion and data delivery tools with the unified data platform
Upgrade and integrate transformation tool, data validation tool and orchestration tools with the unified data platform to implement data engineering, analytical engineering and data maintenance capabilities.
Provide support during unexpected outages
JOB REQUIREMENTS:
Bachelor’s degree in Computer Science or related disciplines.
Minimum of 5 years of experience in design, development and building data oriented complex applications.
Deep understanding of Agile SDLC, DevOps and Cloud technologies required, in addition to exposure to multiple, diverse technologies, platforms, and processing environments.
Experience in data integration, data warehouse, data modeling and data analytics architecture and design principles. Knowledge of and experience with Snowflake and other cloud native databases is highly preferred.
Knowledge about various architectures, patterns such as unified data management architecture (UDM), data mesh architecture, event-driven architecture, real-time data flows, non-relational repositories, data virtualization, etc.
Experience with building solutions in the financial services domain with an understanding of financial instruments, transactions, and positions, is desired.
Good interpersonal and communication skills with the ability to lead cross-team collaboration and partnerships across a variety of internal and external constituencies.
Not sure you meet 100% of our job requirements? That’s ok. If you believe that you could excel
#MBLI
#LI-HYBRID
At MFS, we are dedicated to building a diverse, inclusive and authentic workplace. If you are excited about this role but your past experience doesn't align perfectly, we encourage you to apply - you might be just the right candidate for this role or others.
What we offer:
Generous time-off provided: including ""Responsible time off"" for many roles, paid company holidays when the US Stock Exchange is closed, plus paid volunteer time
Family Focus: Up to 20 weeks of paid leave for new parents, back-up care program, dependent care flexible spending account, adoption assistance, generous caregiver leave
Health and Welfare: Competitive medical, vision and dental plans, plus tax-free health savings accounts with company contributions
Wellness Programs: Robust wellness webinars, employee assistance program, gym reimbursement through our medical plans, fitness center discounts and more
Life & Disability Benefits: Company-paid basic life insurance and short-term disability
Financial Benefits: 401(k) savings plan, Defined Contribution plan- 15% of base salary invested into the Plan, competitive total compensation programs
MFS is a hybrid work environment (remote/onsite) unless otherwise stated in the job posting.
If any applicant is unable to complete an application or respond to a job opening because of a disability, please contact MFS at 617-954-5000 or email
talent_acquisition@mfs.com
for assistance.
MFS is an Affirmative Action and Equal Opportunity Employer and it is our policy to not discriminate against any employee or applicant for employment because of race, color, religion, sex, national origin, age, marital status, sexual orientation, gender identity, genetic information, disability, veteran status, or any other status protected by federal, state or local laws. Employees and applicants of MFS will not be subject to harassment on the basis of their status. Additionally, retaliation, including intimidation, threats, or coercion, because an employee or applicant has objected to discrimination, engaged or may engage in filing a complaint, assisted in a review, investigation, or hearing or have otherwise sought to obtain their legal rights under any Federal, State, or local EEO law is prohibited. Please see the
Know Your Rights: Workplace Discrimination is Illegal
document and
Pay Transparency Nondiscrimination Provision
, linked for your reference.",1982,Investment & Asset Management,$100 to $500 million (USD),Financial Services,1001 to 5000 Employees,Subsidiary or Business Segment,False
Data Platform Engineer II,"GSK
","Cambridge, MA",$94K - $129K (Glassdoor est.),4.1,"Site Name: USA - California - San Francisco, Cambridge 300 Technology Square, London The Stanley Building, Seattle Sixth Ave, Upper Providence
Posted Date: Nov 20 2023


At GSK, we want to supercharge our data capability to better understand our patients and accelerate our ability to discover vaccines and medicines. The Onyx Research Data Platform organization represents a major investment by GSK R&D and Digital & Tech, designed to deliver a step-change in our ability to leverage data, knowledge, and prediction to find new medicines.

We are a full-stack shop consisting of product and portfolio leadership, data engineering, infrastructure and DevOps, data / metadata / knowledge platforms, and AI/ML and analysis platforms, all geared toward:

Building a next-generation, metadata- and automation-driven data experience for GSK’s scientists, engineers, and decision-makers, increasing productivity and reducing time spent on “data mechanics.”

Providing best-in-class AI/ML and data analysis environments to accelerate our predictive capabilities and attract top-tier talent.

Aggressively engineering our data at scale, as one unified asset, to unlock the value of our unique collection of data and predictions in real-time.

Automation of end-to-end data flows: Faster and reliable ingestion of high throughput data in genetics, genomics and multi-omics, to extract value of investments in new technology (instrument to analysis-ready data in <12h)

Enabling governance by design of external and internal data: with engineered practical solutions for controlled use and monitoring

Innovative disease-specific and domain-expert specific data products: to enable computational scientists and their research unit collaborators to get faster to key insights leading to faster biopharmaceutical development cycles.

Supporting e2e code traceability and data provenance: Increasing assurance of data integrity through automation, integration

Improving engineering efficiency: Extensible, reusable, scalable, updateable, maintainable, virtualized traceable data and code would be driven by data engineering innovation and better resource utilization.

We are looking for a skilled and experienced Data Platform Engineer II to join our growing team. Data Platform Engineers take full ownership of delivering high-performing, high-impact data platform as products, and services, from a description of a problem customer Data Engineers are trying to solve all the way through to final delivery (and ongoing monitoring and operations). They are standard bearers for software engineering and quality coding practices within the team and are expected to mentor more junior engineers; they may even coordinate the work of more junior engineers on a large project. They devise useful metrics ensuring their services are meeting customer demand, having an impact, and iterate to deliver and improve on those metrics in an agile fashion.

The Data Platform team builds and manages reusable components and architectures designed to make it both fast and easy to build robust, scalable, production-grade data products and services in the challenging biomedical data space.

A Data Platform Engineer II is a technical individual contributor, building modern, cloud-native systems for standardizing and templatizing data engineering, such as:

Standardized physical storage and search / indexing systems
Schema management (data + metadata + versioning + provenance + governance)
API semantics and ontology management
Standard API architectures
Kafka + standard streaming semantics
Standard components for publishing data to file-based, relational, and other sorts of data stores
Metadata systems
Tooling for QA / evaluation etc.

A Data Platform Engineer II knows the metrics desired for their tools and services and iterates to deliver and improve on those metrics in an agile fashion.

Additional responsibilities include:

Given a well-specified data framework problem, implement end-to-end solutions using appropriate programming languages (e.g., python, Scala, or go), open-source tools (e.g., Spark, Elasticsearch, ...), and cloud vendor-provided tools (e.g., Amazon S3)

Leverage tools provided by Tech (e.g., infrastructure as code, cloud Ops, DevOps, logging / alerting) in delivery of solutions.

Write proper documentation in code as well as in wikis/other documentation systems.

Write fantastic code along with proper unit, functional, and integration tests for code and services to ensure quality.

Stay up to date with developments in the open-source community around data engineering, data science, and similar tooling.

Why you?

Basic Qualifications:

We are looking for professionals with these required skills to achieve our goals:

Bachelor's degree with 5+ years' experience or Master's degree with 3+ years' experience in computer science with a focus in Data Engineering, DataOps, DevOps, MLOps, Software Engineering

Experience with common distributed data tools in a production setting (Spark, Kafka, Hive, Presto, etc.)

Experience with specialized data architecture (e.g., data lake, lake house, data fabric, data mesh, optimizing physical layout for access patterns)

Experience with public cloud providers like AWS, Azure and GCP

Experience with search / indexing systems (e.g., Elasticsearch)

Preferred Qualifications:

If you have the following characteristics, it would be a plus:

Experience building and designing a DevOps first way of working.

Demonstrated excellence writing production Python, Java, Scala, Go, and/or C#/C++

Practical experience with agile software development and DevOsps-forward ways of working

Demonstrated experience building reusable components on top of the CNCF ecosystem including platforms like Kubernetes (or similar ecosystem)

Metrics-first mindset

#LI-GSK

#GSKOnyx

Why GSK?

Our values and expectations are at the heart of everything we do and form an important part of our culture.

These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance, and trust, the successful candidate will demonstrate the following capabilities:

Agile and distributed decision-making – using evidence and applying judgement to balance pace, rigour and risk.

Managing individual and team performance.

Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.

Implementing change initiatives and leading change.

Sustaining energy and well-being, building resilience in teams.

Continuously looking for opportunities to learn, build skills and share learning both internally and externally.

Developing people and building a talent pipeline.

Translating strategy into action - a compelling narrative, motivating others, setting objectives and delegation.

Building strong relationships and collaboration, managing trusted stakeholder relationships internally and externally.

Budgeting and forecasting, commercial and financial acumen.

The annual base salary for new hires in this position ranges from $115,974 to $156,906 taking into account a number of factors including work location, the candidate’s skills, experience, education level and the market rate for the role. In addition, this position offers an annual bonus and eligibility to participate in our share based long term incentive program which is dependent on the level of the role. Available benefits include health care and other insurance benefits (for employee and family), retirement benefits, paid holidays, vacation, and paid caregiver/parental and medical leave.

Please visit GSK US Benefits Summary to learn more about the comprehensive benefits program GSK offers US employees.

Why Us?

GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.

Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.

If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).

GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK’s compliance to all federal and state US Transparency requirements. For more information, please visit GSK’s Transparency Reporting For the Record site.",1830,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Company - Public,False
"Senior Principal Software Engineer, Data Quality","Red Hat Software
","Boston, MA",$123K - $167K (Glassdoor est.),4.1,"About the job:
The Data Development, Insights & Strategy team is a highly focused effort to lead digital-first execution and transformation at Red Hat, leveraging data strategically for our customers, partners, and associates.

We are looking for a Senior Principal Software Engineer to drive the embodiment of open-source principles, data governance, and data quality best practices by pioneering an innersource paradigm for data product delivery at Red Hat. Within this role, you will help teams transition towards comprehensive automation of insights, ensuring data integrity, consistency, and accuracy across various business domains.

The ideal candidate will be able to work Hybrid in Boston MA, Westford MA or Raleigh NC.
What you will do:
Design and implement comprehensive data quality strategies, ensuring accuracy and consistency in all data assets.
Innovate and design data quality solutions that can be enforced directly at the source, ensuring early interventions and prevention of data inconsistencies
Guide on implementing data quality checks, validations, and integrations, driving the importance of data quality within the development lifecycle.
Diagnose and address software and data quality anomalies, ensuring that software solutions are robust, reliable, and adhere to data quality standards.
Regularly review code on data validation, transformation, and cleaning processes.
Ensure data operations adhere to established quality standards and best practices.
Monitor and optimize software performance, ensuring systems run efficiently and data remains consistent across various data points and modules
Participate and demonstrate expertise in Automation strategy along with contribution in framework development
Able to mentor and guide the team on data quality tools, techniques, and standards, cultivating a culture of continuous improvement and learning
What you will bring:
Bachelor’s or Master’s degree in Computer Science, Software Engineering, or a related field
7+ years of hands-on experience working with Data and Data Quality Engineering
Ability to work Hybrid in Boston MA, Westford MA or Raleigh NC
Proficient in modern testing tools and automation frameworks
Understand data governance and data quality practices
Strong analytical and problem-solving skills, with an unwavering commitment to quality
Experience in developing automation frameworks for API/UI
Support continuous integration and deployment process improvement and innovation
Clear communication skills to work closely with stakeholders on Sprint/Teasing strategy
Demonstrated efficiency of one of the programming languages (Go, Python, Java, and/or JavaScript)
Hands-on technical expertise in relational database systems like SQL Server, Redshift, Oracle, and Big Query. Expert in SQL
Demonstrated experience in building and maintaining data pipelines using Redshift, S3, and/or Snowflake.
Self-motivated with a strong sense of ownership and a proactive team player, working quickly and accurately under pressure and time constraints with minimal supervision.",1993,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,10000+ Employees,Company - Private,False
"Principal Data Engineer, investments Technology","Liberty Mutual
","Boston, MA",$123K - $212K (Employer est.),3.8,"Pay Philosophy

The typical starting salary range for this role is determined by a number of factors including skills, experience, education, certifications and location. The full salary range for this role reflects the competitive labor market value for all employees in these positions across the national market and provides an opportunity to progress as employees grow and develop within the role. Some roles at Liberty Mutual have a corresponding compensation plan which may include commission and/or bonus earnings at rates that vary based on multiple factors set forth in the compensation plan for the role.


Description

Note: This role has a hybrid work arranagement (2 days a week in Boston)


Are you looking for a chance to be part of a high performing team that is passionate about data? Are you intrigued by Investments and Finance? Does the thought of building a modern cloud-based data platform from the ground up excite you? If yes, then join us and be part of a team that's forging the path to data-driven success.


At Liberty Mutual Investments (LMI), we manage a high-quality investment portfolio utilizing a disciplined strategy. We have a large and varied customer base, supported by strategic business units that function as a complete investment firm within our Fortune 100 Company. Our investment professionals are critical to our ability to keep our promises to policyholders, claimants, and their families.

We are an equal opportunity employer and value diversity at our company. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.


We are seeking two highly skilled Principal Data Engineers to join our dynamic team. As a Principal Data Engineer in our Data Engineering Chapter, you will play a pivotal role in shaping the future of data analysis while thriving in a fast-paced environment that encourages personal growth and development.


Key Responsibilities:

Lead the Data and Analytics squad to design, develop, and enhance the data and analytics solutions and pipelines, driving data-driven decision-making processes.
Act as a technical leader, working in tandem with scrum masters, product owners, and engineering teams to iteratively create data and analytics solutions that meet both business and technical requirements.
Collaborate closely with key business and tech stakeholders to identify and deliver high-quality solutions aligned with business needs and technology strategy.
Research, recommend, design, and develop systems and application architecture with a strong focus on software quality, security, and compliance.
Work closely with development team in building Innovative, API first, cloud native solutions using AWS platform, Snowflake, Snaplogic, Python, Rest API etc.
Continuously enhance full delivery pipeline through automation, expanded yet increasingly efficient test coverage, ultimately optimizing time-to-market and overall quality.
Optimize and fine-tune existing data pipelines for performance, scalability, and reliability.
Implement data quality checks and monitoring processes to ensure data accuracy and consistency.
Stay current with industry trends and best practices in data engineering and recommend improvements to existing processes.
Mentor engineers/individual contributors in the team; conduct design and code reviews and champion engineering excellence/best practices.
Collaborate effectively with architecture team and across LMI Tech and Corporate tech team.


Qualifications
A bachelor’s degree in a technical or business discipline, or equivalent experience
8+ years of related data engineering experience with focus on designing and building data pipelines
Strong consultative skills, including the ability to understand and apply customer requirements, including drawing out unforeseen implications and making recommendations for design, the ability to define design reasoning, understanding potential impacts of design requirements
Proficient in SQL and hands on experience with Python
Experience with Data modeling and data warehousing
Experience with public cloud data platforms, Snowflake (preferable), AWS, Azure
Proficiency with AWS Services including but not limited to AWS S3, AWS Glue, AWS Lambda, AWS EC2
Proficient with ETL/ELT data pipelines, patterns for loading Data Warehouses, Lakes
Experience with build/deploy automation & DevOps frameworks (CI/CD, Bamboo, GitHub Actions, pipeline-as-code)
A design thinking and test-driven development mindset
Experience with business intelligence tools and reporting solutions (Power BI, Tableau etc.)

Bonus Skills:

Previous experience in Investments / Asset Management, Finance Data modeling, is highly desirable
Previous Tech Leadership experience desired
Familiarity in building and consuming APIs (REST, API Gateway, etc.)
Cognizance of security concerns, from access control and authentication to secured processes
Knowledge of containerization and orchestration tools (e.g.: Docker, Kubernetes)
A comprehensive understanding of agile environments and the ability to adapt to rapidly changing circumstances
About Us

At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That's why we provide an environment focused on openness, inclusion, trust and respect. Here, you'll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.

Liberty Mutual has proudly been recognized as a ""Great Place to Work"" by Great Place to Work® US for the past several years. We were also selected as one of the ""100 Best Places to Work in IT"" on IDG's Insider Pro and Computerworld's 2020 list. For many years running, we have been named by Forbes as one of America's Best Employers for Women and one of America's Best Employers for New Graduates as well as one of America's Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusion

We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits

Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran's status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.",1912,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Private,False
Principal Data Engineer,"ENGIE INSIGHT SERVICES INC.
","Boston, MA",$120K - $180K (Employer est.),3.9,"Requisition ID: 13676
Location: Boston, US, 2111

SUMMARY: Principal Data Engineer




Leads a scrum team designing, creating, and operating new interactive big data solutions centered on database and data lake technologies in support of Energy services and associated web based applications. Significant big data expertise using Microsoft, AWS, and Snowflake technologies plus familiarity with client facing, critical SaaS applications.




PRIMARY FUNCTIONS AND ESSENTIAL RESPONSIBILITIES:




Lead technical scrum teams constructing OLAP, OLTP, and AI driven cloud software in a cloud environment.
Responsibilities include one or more of the following:
Design, develop, configure and enhance big data systems centered on AWS, PostgresSQL, Redshift, S3, Lamdba, Python, and PowerBI hosted at Azure.
Construct datalake solutions based on AWS or Azure datalake architectures
Create highly scalable and available data software with a focus on data throughput and quality in all software processes
Build data integration capabilities loading large volumes of data reliably enforcing data quality standards and implementing enrichment approaches
Translate Agile software development stories into data software capabilities supporting the needed functionality and performance, estimate level of effort, and track progress on a daily basis
Translate data science deliverables into production software
Document and educate technology partners and peers regarding capabilities of constructed solutions
Partner with DevOps teams to size and design the infrastructure necessary to support our big data computing needs
Support client engagement success driven by data software driving quality answers for platform clients





LOCATION: Boston






QUALIFICATIONS






Education/Certification/

Knowledge




Computer Science BS/MS degree
Non-CS BS/MS degree with other software related training
Big data skill and technology certifications required





Experience:




7+ years of big data engineering experience
5+ years cloud engineering experience with an emphasis on AWS and Azure technologies
Hands on experience with PostgresSQL
Experience creating data repositories support web applications and REST APIs.
Experience with high throughput, big volume, fast response time, scalable systems
Expertise with advanced caching strategies leveraging technologies such as Redis, Memcache, and ElasticSearch.
Energy or financial services experience a plus





Skills/Abilities:




Redshift, Snowflake, Azure Synapse SQL, and/or Redshift
PostgresSQL design and development experience
Strong Python skills in a Lambda environment
Data modelling skills for OLTP and OLAP systems
Data lake construction with parquet
Experience with Python, Hadoop, and Spark helpful
Strong familiarity with AWS and/or Azure cloud environments



The ability to mentor and lead team members focused on technical topics



Good written and verbal English communication skills, client relation skills, and ability to work effectively as a contributor in a technical team environment.



Ability to speak French and/or Spanish a plus



At ENGIE, our goal is to support, promote, and thrive on diversity, equity, and inclusion. We do so for the benefit of our employees, customers, products and services, and community. ENGIE is proud to be an equal opportunity workplace, and we are firmly committed to creating an equitable and inclusive environment for all employees.

We are committed to providing employees with a work environment free of discrimination and harassment. All employment decisions at ENGIE are based on business needs, job requirements, and individual qualifications. ENGIE is committed to providing equal employment opportunities regardless of actual or perceived race, color, creed, religion, national origin, ancestry, citizenship, age, sex or gender (including pregnancy, childbirth, and related medical conditions), gender identity, or gender expression (including transgender status), sexual orientation, marital status, civil union, or domestic partnership status, military service or veteran status, physical or mental disability, protected medical condition, genetic information, or any other legally protected category (referred to as “protected characteristics”) as defined by applicable federal, state or local law in the locations where we operate.

The pay range for this role is: $ 120,000-180,000

Pay range is based on several factors and may vary in addition to a full range of medical, financial, and/or other benefits. Final salary and offer will be determined by the applicant’s background, experience, skills, internal equity, and alignment with geographical market data. This position is eligible for our comprehensive and competitive benefits package including medical, dental, vision, and basic life insurance. Additional ENGIE benefits include a 401k plan, paid time off and annual bonus. ENGIE complies with all federal, state, and local minimum wage laws.






WORK ENVIRONMENT





Hybrid work environment on site in Boston 2-3 days per week







Business Unit: GBU Energy Solutions
Division: ES ENGIE Impact - Americas
Legal Entity: ENGIE INSIGHT SERVICES INC.
Contract Type: Permanent
Job Type: Full - Time
Professional Experience: Skilled ( >3 experience <15 years)
Education Level: Bachelor's Degree",2008,Energy & Utilities,$25 to $100 million (USD),"Energy, Mining & Utilities",10000+ Employees,Company - Public,False
Senior Data Engineer,"Ampion Inc.
","Boston, MA",$108K - $154K (Glassdoor est.),4.1,"Renewable Energy Everywhere, For Everyone

We’re a fast-growing market leader who envisions a world where renewable energy powers our economy and society. Shared and sustainable energy assets, such as solar and wind farms, are the key to this vision, where healthy, inexpensive energy changes the world in which we live. It is a tremendous challenge with huge social benefits, and it is also one of the greatest economic opportunities in the history of business.

Building an industry takes commitment, hard work, and a willingness to work on the messy details. That is where we see our most valuable contribution. Ampion’s platform enables the clean energy revolution by connecting consumers and clean energy providers. We enable consumers to purchase low cost green energy, while providing the customers and revenue for the industry to thrive.

Ampion’s software is a critical differentiator for the company and what allows us to scale efficiently. We deal with lots of different data – from website, ad, search and social data to utility usage and billing and crediting data, to community distributed generation meter data. The Data Engineer will assist Ampion in building our team and technology to make this data into meaningful, actionable insights.

This Data Engineer is a senior position whose responsibilities include line-managing our Data Scientists and Data Wranglers. This is a great opportunity for a senior Data Engineer to move into a management and leadership role and directly contribute to the differentiation of the Ampion product.

We use agile development practices with multi-disciplinary teams that are typically focussed on delighting certain user persona’s. The Data Science team will work with each of the “experience” teams to build comprehensive data-based views of each persona and their journeys (key business processes), by being a consumer of data from these teams, and other sources, and being a provider of insights and data to these teams and their platforms. Our expectation is that the data structures and insights produced by the Data Science team will be embedded into our core product offering and used as one of our major differentiators.

In addition, the Data Science team will also deliver insights to Ampion internal teams and most importantly provide a platform and tools on which functional owners can derive some of their own insights.

The Data Engineer will lead the Data Science team as a coach-player, providing direction, leadership, management and roadblock-busting service so that the team can run as smoothly and efficiently as possible.

The Data Engineer will work with the senior technical team and architecture council to determine best short-term and long-term solutions to pressing Product data needs. The Data Engineer will provide feedback to the Product team on general approach and dependencies for roadmap and company plans.

Core Responsibilities

Identify, design, architect, and implement scalable data engineering platforms with self-service solutions
Act as a subject matter expert to leadership for technical guidance around solution design and best practices
Experience building and shipping highly scalable and distributed systems on cloud platforms such as GCP(preferred) or AWS.
Mentor junior engineers and expose the team to new opportunities.
Keep current with modern data engineering ecosystem technologies.

What you bring to the team

7+ years experience in DBMS, Oracle, Postgres, MySQL, MS-SQL
Experience in data warehousing technologies such as BigQuery, Snowflake, Redshift, ETL/ELT tools, and Information Management design.
2+ years experience with data engineering tools such as pyspark, google airflow. Google dataproc, google cloud storage experience a plus.
Proficient with programming languages such as Python, Golang
Strong project management and organizational skills.

Social justice is at the center of Ampion’s mission to bring renewable energy everywhere, to everyone. We are committed to a diverse and vibrant workforce. If you lack a specific credential for this position but believe that your strengths will propel our mission, we would love to hear from you.

Equal Opportunity

Ampion is an Equal Opportunity Employer and does not discriminate on the basis of race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, protected veteran status, or any status protected by applicable federal, state, or local law. We seek to be an inclusive community and actively encourage applications from candidates of all backgrounds and identities.",-1,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,1 to 50 Employees,Company - Private,False
Senior Software Engineer Data Exchange,"Klaviyo
","Boston, MA",$130K - $167K (Glassdoor est.),4.0,"At Klaviyo, we value the unique backgrounds, experiences and perspectives each Klaviyo (we call ourselves Klaviyos) brings to our workplace each and every day. We believe everyone deserves a fair shot at success and appreciate the experiences each person brings beyond the traditional job requirements. If you're a close but not exact match with the description, we hope you'll still consider applying. Want to learn more about life at Klaviyo? Visit careers.klaviyo.com to see how we empower creators to own their own destiny.

Klaviyo operates a real-time data analytics platform coded primarily in Python that is built for massive scale and hosted on Amazon Web Services (AWS). Engineers come to Klaviyo with experience in a variety of languages and from a number of disciplines.

The Data Exchange team is responsible for designing and building software that enables data transmission in and out of the Klaviyo platform through a variety of protocols and delivery mechanisms. The team collaborates closely with internal stakeholders and has substantial exposure to Klaviyo's customers, including businesses, partners, and third-party developers. Data Exchange operates at the intersection of distributed systems, data pipelining, software architecture, scalability, and reliability.

At Klaviyo, we love tackling tough engineering problems and look for employees who specialize in certain areas but are passionate about building, owning & scaling features end to end from scratch and breaking through any obstacle or technical challenge in their way. We push each other to move out of our comfort zone, learn new technologies, and work hard to ensure each day is better than the last. Klaviyo is growing fast and we have openings for all skill levels across all of our teams. Learn more about our engineering culture at https://klaviyo.tech.

How you'll make an impact

This team is a key contributor to the evolution of Klaviyo into a data platform, enabling hundreds of thousands of Klaviyo customers to effectively leverage and activate their data. Critical components of the data platform include data collection and data distribution, which must be both reliable and scalable as Klaviyo continues to expand its support for various methods of data import and export. As a Senior Software Engineer, you will define and own the core components, tools, and customer-facing features for data collection and distribution. You will contribute to the advancement of our data movement framework and play a key role in enabling our customers and partners to move their data in and out of Klaviyo. You will be contributing to the vision, mission, and strategy of our product area and will work with a team of talented and experienced software engineers who are eager to grow fast and make an impact on the company.

What you'll do
Take ownership of project segments and lead the delivery of new features, including their design, development, and deployment.
Perform independent research, work with domain experts, collect, question, and improve requirements and drill down to core problems for larger features and projects
Take charge of a significant segment within your product domain, becoming its subject matter expert, and overseeing its development and evolution.
Work closely with Product and tech leads to contribute to the roadmap that align with company worldwide growth
Contribute to the technical/architectural evolution of your product area; identify and advocate for scalability, reliability, and maintainability needs
Established expertise in some Klaviyo and industry practices, patterns, tools, languages, and processes; share new insights and contribute beyond the team.
Who you are
Passionate about building software effectively and for the long-term. Have experience building products that matter. Have proven expertise in applying relevant design patterns to implementing highly-scalable multi-tenant systems.
Like working on small, autonomous agile teams. Enjoy shipping code early and often in an agile fashion, pairing with product management, business stakeholders, and other engineers to craft better software.
Have knowledge and experience working with distributed architectures and data processing systems. Have basic understanding of domain-driven design and data management patterns.
Motivated by having ownership, excited about taking the initiative to solve tasks in collaboration with others.
Enjoy mentoring fellow engineers, ensuring their skill development aligns with organizational growth.
Love digging into performance, scalability, and reliability issues to drive breakthrough solutions. You recognize all problems can be solved and are capable of rallying others to address business needs.
Tech Stack

We are looking for a backend-focused engineer, experience with frontend development is preferred but not mandatory. Previous experience with big data stack is desirable. The tech stack you'll be working with:

Python, Django, FastAPI
Apache Kafka, Apache Pulsar, RabbitMQ, and other tech from the big data stack
MySQL, Redis
Graphite, statsd, Grafana
AWS, Terraform, Docker, Kubernetes, Jenkins, and other modern DevOps tools

The pay range for this role is listed below. Sales roles are also eligible for variable compensation and hourly non-exempt roles are eligible for overtime in accordance with applicable law. This role is eligible for benefits, including: medical, dental and vision coverage, health savings accounts, flexible spending accounts, 401(k), flexible paid time off and company-paid holidays and a culture of learning that includes a learning allowance and access to a professional coaching service for all employees.

Pay Range For US Locations:

$156,800—$235,200 USD

Get to Know Klaviyo

We're Klaviyo (pronounced clay-vee-oh). We empower creators to own their destiny by making first-party data accessible and actionable like never before. We see limitless potential for the technology we're developing to nurture personalized experiences in ecommerce and beyond. To reach our goals, we need our own crew of remarkable creators—ambitious and collaborative teammates who stay focused on our north star: delighting our customers. If you're ready to do the best work of your career, where you'll be welcomed as your whole self from day one and supported with generous benefits, we hope you'll join us.

Klaviyo is committed to a policy of equal opportunity and non-discrimination. We do not discriminate on the basis of race, ethnicity, citizenship, national origin, color, religion or religious creed, age, sex (including pregnancy), gender identity, sexual orientation, physical or mental disability, veteran or active military status, marital status, criminal record, genetics, retaliation, sexual harassment or any other characteristic protected by applicable law.

IMPORTANT NOTICE: Our company takes the security and privacy of job applicants very seriously. We will never ask for payment, bank details, or personal financial information as part of the application process. All our legitimate job postings can be found on our official career site. Please be cautious of job offers that come from non-company email addresses (@klaviyo.com), instant messaging platforms, or unsolicited calls. If you suspect a fraudulent job posting or receive suspicious communications that appear to be from our company, please contact us immediately at HR@klaviyo.com.

You can find our Job Applicant Privacy Notice here.",2012,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
"Senior Data Engineer, Data Models Engineering","Arrowstreet Capital
","Boston, MA",$112K - $157K (Glassdoor est.),4.3,"Job Overview
The Associate Director, Data Models Engineering will be a key person in a team that provides the golden data model to the Quantative Investment Research group. As a systematic asset manager, Arrowstreet must identify investable trading strategies and implement them quickly and with the highest quality. The rapid integration of novel data sources is a vital competitive advantage for the Research group and essential to the continued success of the firm, as well as the ability to run compute intensive distributed models to derive financial insights.
We are doing a large multi-year program to rewrite the system that creates the golden data model to further increase the capabilities of the firm and to leverage modern data platforms.
Responsibilities
This is a senior engineering position within the Data Linking team so you will contribute to and support the strategy for all the solutions managed by the Data Linking team.
Provide expert level design and engineering support toward the successful delivery of individual projects
Lead and participate in deep architectural discussions to ensure solutions are designed for successful deployment, security, cost effectiveness and high availability
Provide hands-on delivery on both prototypes as well as project work
Participate in building a data platform that can support batch and real-time data sets using modern data processing frameworks.
Assist the team in investigating potential improvements achieved by adopting new data technologies and frameworks.
Achieve high quality metrics through automated testing, robust operational tooling and reliable designs.
Production support of the platform to avoid disruption to investment processes.
Qualifications
Bachelor’s degree in Computer Science, Computer Engineering or a related discipline; at least 10 years of prior experience, financial services exposure is a plus
Ability to write elegant code, and comfortable with picking up new technologies independently.
Solid experience dealing with large-scale deployments with high degrees of parallelism.
Proven record of building high-performance cloud native solutions on AWS
Proficient in Python and SQL (5+ years)
Experience working with data lakes, data warehousing, and/or database systems, including processing frameworks like Presto (Athena/Glue), Apache Iceberg, RDBMS, NoSQL, Spark/EMR etc.
Experience building microservices using technologies like FastAPI, Swagger
Experience with monitoring technologies like Prometheus/Grafana
Experience with container technologies like Docker, Kubernetes, Helm
Experience with CICD technologies like GitLab

We maintain a friendly, team-oriented environment and place a high value on professionalism, attitude and initiative.
We maintain a friendly, team-oriented environment and place a high value on professionalism, attitude and initiative.",1999,Investment & Asset Management,Unknown / Non-Applicable,Financial Services,Unknown,Company - Private,False
"Lead Software Engineer, Data Engineering","S&P Global
","Boston, MA",$85K - $170K (Employer est.),4.1,"The Role: Data Engineer
Location: Team is in Boston, but is available for remote or on-site throughout CST and EST Time zones
GL (for internal use only): 11

Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.
Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy!
Job Description
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.

You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets.
You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use.
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.

Responsibilities
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers
Optimizing slow-running database queries and data pipelines
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency

Qualifications
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience
7+ years of experience working with data-at-scale in a production environment
Experience designing and implementing large-scale, distributed systems
Experience in multi-threaded software development (or some form of parallelism)
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale
Strong understanding of relational databases and proficiency with SQL
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript)
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go)
Experience developing software on Linux-based operating systems
Experience with distributed version control systems
Nice-to-Haves
Familiarity with relational database internals (especially PostgreSQL)
Proficiency with cloud computing platforms, specifically AWS
Working knowledge of probability & statistics
Contributions to open-source software
Experience building customer-centric products

Compensation/Benefits Information (US Applicants Only):
S&P Global states that the anticipated base salary range for this position is $85,300 - $170,000 . Base salary ranges may vary by geographic location.
In addition to base compensation, this role is eligible for an annual incentive bonus plan.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires .
About S&P Global
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 277527
Posted On: 2023-09-21
Location: Cambridge, Massachusetts, United States",1860,Research & Development,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Sr. Data Engineer,"Archetype
","Boston, MA",$81K - $115K (Glassdoor est.),4.2,"Archetype’s Analytics Insights consulting practice develops insights for our customers through innovative technology solutions. Archetype sees the value in data science and self-service analytics, providing these capabilities to our customers. At Archetype, you will get to work with the best of breed products that include Snowflake, AWS, Azure, GCP Fivetran, dbt, Tableau, ThoughtSpot, Dataiku, DataRobot and partner with our strong growing consulting team.

Job Description

We are seeking a Senior Data Engineer (Architect level) to work with our customers to solve complex problems with well-designed, modern analytical solutions. This role’s responsibilities include:

Working with customers and data analysts, product managers, data architects and engineers to define requirements, design solutions, and build/test/deploy these solutions

Be deep and broad with your technical and functional skill set to support end-to-end analytics across a variety of industries

Stay up to speed on emerging technologies and dynamic in how we evolve our approach for our customers

Support sales processes by participating in scoping calls, solution design workshops, developing estimates and prototyping solutions

Support project management and mentor/manage junior resources.

Research, design and write new software components

Create technical specifications

Maintain systems by monitoring and correcting software defects


Required Qualifications: (Must Have)

5+ years of experience in database and data pipeline development

Proven experience working with both cloud and on-premise DBMSs such as: Snowflake, RedShift, BigQuery, SQL Server, Postgres, and Oracle

Code development in a version control environment

Proven experience with working with structured and semi-structured data

Hands-on experience working with and creating REST web services and APIs

2+ years of experience hands-on experience creating serverless applications on AWS using Lambda or Azure Functions and NodeJS

Top 5% of SQL practitioners


Preferred Qualifications: (Nice-To-Have)

Comfort with scripting languages (JavaScript, Python, or Ruby)

Comfort with Linux and Windows command line functionality

Exposure to multiple cloud providers: AWS, Azure, Google Cloud

Knowledge of common design patterns and how they can be applied to JavaScript.

Experience working with APIs, either integrating a third-party API

Facility with source control, particularly git and Github

Strong independent problem-solving skills

Knowledgeable of best practices, with the ability to convey to non-practitioners

Champions modern, disciplined development process (agile, source control, testing, CI/CD)",2006,Business Consulting,$5 to $25 million (USD),Management & Consulting,51 to 200 Employees,Company - Private,False
Senior Data Engineer,"Extreme Event Solutions
","Boston, MA",$112K - $146K (Glassdoor est.),3.7,"Company Description


We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.



Job Description


Become a member of the growing EES software development team responsible for EES’s flagship SaaS Solution. Our data-rich products deploy a host of cutting-edge technologies to build high-performance and scalable products in AWS Cloud. As an experienced software engineer you will be responsible for designing and building solutions and components using Python, PostgreSQL , AWS technologies (Redshift, Aurora, Glue etc.) and other technologies for enterprise scale multi-user applications.

Responsibilities

Contribute to the distributed database schema design geared for scalability and performance using MPP database engines (Redshift) and relational transactional engines (Aurora)
Strong experience with PostgreSQL (version 4 or higher) including database design, query optimization, and performance tuning.
Proficiency in AWS (Amazon Web Services) with a focus on services like EC2, S3, RDS, and IAM. Experience in deploying and managing applications on AWS.
Excellent programming skills in Python with the ability to develop, maintain, and debug Python-based applications.
Troubleshoot and resolve database-related issues.
Stay up to date with the latest industry trends and technologies related to PostgreSQL, AWS, and Python.
Design and implement risk management business functionality and in-database analytics.
Identify complex data problems and review related information to develop and evaluate options and design and implement solutions.
Design and develop functional and responsive web applications by collaborating with other engineers in the Agile team.
Strong working knowledge of SQL Server 2012/2016 with proficiency in performance tuning, troubleshooting, and writing T-SQL stored procedures in a commercial application centric environment.
Strong understanding of RDBMS concepts
Experience with or good understanding of Big Data concepts
Good knowledge of AWS data platforms like Aurora/Redshift/RDS.
Expertise in object-oriented programming
Strong problem-solving skills Fast learner and keen to learn.
Excellent listening skills Good written and verbal communication skills Enthusiasm, energy, and creativity

#LI-AO1



Qualifications

B.S. in Math, EE, CS or Software Engineering; M.S preferred.
5+ years of hands-on experience in development of commercial-grade software products.
5+ years of SQL Server development, programming with T-SQL
3+ years of Experience with AWS technologies (Redshift, RDS, S3, Glue,)
3+ years of hands-on experience with Strong understanding of AWS services and infrastructure, deploying and managing applications on AWS.
4+ years proven work experience of with PostgreSQL, proving expertise in database design, administration, and performance optimization. ability to troubleshoot and resolve complex database-related issues.
1+ years of proven experience in Python in developing and supporting Python-based applications.
Strong understanding of Agile process and best practices
Strong knowledge of the latest technologies and trends.
Ability to develop use-cases for business requirements.
Ability to collaborate effectively with project stakeholders outside of Dev. group, especially with Product Management on feature requirements and project schedules.
Ability to provide effective technical leadership and oversight to development team on a project, ensuring that software developed is in adherence to established architecture, design, quality standards, as well as delivery schedul

Additional Information


In 2022, Verisk received Great Place to Work® Certification for our outstanding workplace culture for the sixth year in a row and second-time certification in the UK, Spain, and India. We’re also one of the 38 companies on the UK’s Best Workplaces™ list and one of 18 companies on Spain’s Best Workplaces™ list.

For over fifty years and through innovation, interpretation, and professional insight, Verisk has replaced uncertainty with precision to unlock opportunities that deliver significant and demonstrable impact. From our historic roots in risk assessment, we’ve grown to provide analytic insights that help transform industries focused on some of the world’s most critical areas. Today, the insurance industry relies on Verisk to be, and to make the world, more productive, resilient, and sustainable.

Verisk works in collaboration with our customers and at the intersection of people, data, and advanced technologies. Through proprietary platformed analytics, advanced modeling, and interpretation, we deliver immediate and sustained value to our customers and through them, to the individuals and societies they serve, with greater speed, precision, and scale.

We’re 9,000 people strong, committed to translating big data into big ideas. We help others see new possibilities and empower certainty into big decisions that impact individuals and societies. And we relentlessly and ethically pursue innovation to help move our customers, and the world, toward better tomorrows.

Everyone at Verisk—from our chief executive officer to our newest employee—is guided by The Verisk Way, to Be Remarkable, Add Value, and Innovate.

Be Remarkable by doing something better each day in service to our customers and each other
Add Value by delivering immediate and sustained results that drive positive outcomes
Innovate by redefining what’s possible, embracing challenges, and pushing boundaries

Verisk Businesses

Underwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision

Claims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences

Property Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient

Extreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.

Specialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance

Marketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement

Life Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.

Verisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger

At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the 7th consecutive year. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce. Verisk’s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work.

Verisk Analytics is an equal opportunity employer.

All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.

http://www.verisk.com/careers.html

Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

HR CCPA Privacy Notice.pdf",1971,Research & Development,$1 to $5 billion (USD),Management & Consulting,5001 to 10000 Employees,Company - Public,True
Python Engineer - Data Center Hardware Integration (Greater Boston Area),"Canonical
","Boston, MA",$99K - $151K (Glassdoor est.),3.3,"This role is home based in the Boston metropolitan area, and you are expected to be able to visit our Boston lab regularly, 4 - 6 times per month.

This is a Python software engineering opportunity for a computer lab engineer passionate about open source software, Linux, and the latest server and network technologies. Come build a rewarding, meaningful career working with the best and brightest people in technology at Canonical, a growing international software company. If you love hacking in your home lab and are curious about hardware, you will love this opportunity.

As an Python Engineer - Data Center Hardware Integration in Canonical, you will be responsible for the day-to-day management and operations of our lab in the Boston area which serves as a centre point for Ubuntu server certification of US based silicon and server designs. This includes software defined hardware management, working with, and developing data centre automation tooling (MAAS), interacting with vendors, asset tracking and handling deliveries.

What you'll do
Own a fully automated server lab with the latest server and network silicon from leading vendors.
Use your Python development skills to develop the Metal as a Service (MAAS) software to work with a large variety of server and network hardware.
Actively expand MAAS functionality by creating integrations with testing and scheduling software such as Testflinger.
Manage the physical setup of the lab, ensure it is well structured and tidy, and execute changes either self or through remote hands.
Work to standardise processes, configurations, and procedures in cooperation with engineers in our other data centres.
Improve and extend hardware and network monitoring through automation.
Regularly update asset management tools to ensure accuracy and completeness of the lab's hardware.
Update of equipment firmware when appropriate/needed.
Who you are
Bachelor's degree, preferably in Computer Science or Software Engineering
Python programming experience
Linux Administration experience
Mix of Rack and Virtual systems experience
Able to communicate clearly and effectively in English
Strong time management skills
Ability to manage competing priorities
Ability to work with a globally distributed team of passionate engineers

We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.

#LI-Hybrid",2004,Computer Hardware Development,$100 to $500 million (USD),Information Technology,501 to 1000 Employees,Company - Private,False
Data Quality & Platform Lead Engineer,"Takeda Pharmaceutical
","Cambridge, MA",$121K - $165K (Glassdoor est.),4.1,"By clicking the “Apply” button, I understand that my employment application process with Takeda will commence and that the information I provide in my application will be processed in line with Takeda’s Privacy Notice and Terms of Use. I further attest that all information I submit in my employment application is true to the best of my knowledge.

Job Description

Data Quality & Platform Lead Engineer

Takeda Pharmaceutical
Cambridge, MA
About the role:

The position is responsible for ensuring the accuracy, completeness, and reliability of our data. Your primary objective will be to drive data quality initiatives, establish data quality related processes, and collaborate closely with cross-functional teams to enhance decision-making and optimize business operations.

The ideal candidate will possess strong leadership abilities, extensive knowledge of data management best practices, and a deep understanding of the pharmaceutical industry. As a member of Takeda Oncology, your work will contribute to our bold, inspiring vision we aspire to cure cancer. Here, you'll build a career grounded in purpose and be empowered to deliver your best. As part of the Oncology Data Digital and Technology group you will report to Director of Data Execution and Operations, Global Oncology, Data, Digital & Technology and work with key stakeholders.

How you will contribute

Develop and implement strategies to maintain high data quality standards across different data sets within commercial pharmaceutical organizations. Establish data quality KPIs and regularly monitor and report on data accuracy and completeness.

Take the lead in initiatives to cleanse, standardize, and enhance the usability and reliability of existing data. Deploy data validation checks to pinpoint and resolve anomalies in the data.

Identify opportunities for the optimization of data-related processes and implement automation wherever feasible. Collaborate with cross-functional teams to seamlessly integrate data quality considerations into existing workflows.

Institute and enforce data governance policies, standards, and procedures to ensure uniform data practices. Collaborate closely with both IT and business teams to define ownership of data and implement access controls.

Conduct training sessions to raise awareness of data quality issues and promote best practices. Provide guidance and support to teams in improving data quality and its operations.

Work closely with data consumers and stakeholders to understand their data needs and facilitate data-driven decision-making.

Act as a liaison between IT and business units to align data quality initiatives with strategic objectives.

Collaborate with legal and compliance teams to address data privacy concerns.

Minimum Requirements/Qualifications
Bachelor’s Degree in Data Science, Computer Science, Operations Research, or Science-related field.
10+ years of progressive experience in data management and data quality in the pharma industry .
3+ years of leading cross functional teams and/or people management responsibility.
Must have strong knowledge of relevant internal and external data sources within the pharmaceutical data ecosystem.
Deep understanding of data management principles, methodologies, and best practices, including data modeling, data governance, data integration, and data quality management.
Strong knowledge of regulatory requirements, such as HIPAA and GDPR, as they relate to data management in the pharmaceutical industry.
Proven experience in implementing and managing data quality related processes, systems, tools, and technologies.
Having prior experience with the Informatica tool for implementing data quality would be a plus.
Excellent leadership and team management skills, with the ability to motivate, inspire, and develop a high-performing team.
Demonstrated project management skills, with the ability to prioritize and manage multiple initiatives simultaneously.

Travel requirements 10-15%

What Takeda can offer you:

Comprehensive Healthcare: Medical, Dental, and Vision

Financial Planning & Stability: 401(k) with company match and Annual Retirement Contribution Plan

Health & Wellness programs including onsite flu shots and health screenings

Generous time off for vacation and the option to purchase additional vacation days

Community Outreach Programs and company match of charitable contributions

Family Planning Support

Flexible Ways of Working

Tuition reimbursement

More about us:

At Takeda, we are transforming patient care through the development of novel specialty pharmaceuticals and best in class patient support programs. Takeda is a patient-focused company that will inspire and empower you to grow through life-changing work.

Certified as a Global Top Employer, Takeda offers stimulating careers, encourages innovation, and strives for excellence in everything we do. We foster an inclusive, collaborative workplace, in which our teams are united by an unwavering commitment to deliver Better Health and a Brighter Future to people around the world.

This position is currently classified as ""hybrid"" in accordance with Takeda's Hybrid and Remote Work policy.

In accordance with the

EEO Statement

Takeda is proud in its commitment to creating a diverse workforce and providing equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, parental status, national origin, age, disability, citizenship status, genetic information or characteristics, marital status, status as a Vietnam era veteran, special disabled veteran, or other protected veteran in accordance with applicable federal, state and local laws, and any other characteristic protected by law.

Locations

USA - MA - Cambridge - Kendall Square - 500

Worker Type

Employee

Worker Sub-Type

Regular

Time Type

Full time",1781,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Company - Private,False
Lead Data Engineer,"Plymouth Rock Assurance
","Boston, MA",$111K - $146K (Glassdoor est.),3.3,"Overview:

The Plymouth Rock Home Group is an innovative Insurtech start-up within a successful, well-established insurance organization. We quadrupled topline revenue over the past 4 years by revolutionizing the way homeowners insurance is priced, marketed, bought, and sold. Our customers obtain a home insurance quote in seconds using our @Home quoting engine. But the fast quote is not the real innovation. We collect large, detailed data about homes, homeowners and where they are located. The @Home product uses cutting edge techniques from skilled data scientists across machine learning and artificial intelligence to create models that predict loss costs, likelihood to buy, the best service and coverages we can offer, and the best way to provide them. The result is a simplified sales process and a feature-rich coverage package that our distributors want to sell and consumers want to buy.

Here is what you will do:

Work with key leaders across Data Science, IT and Business to spearhead data engineering and infrastructure projects for our rapidly growing @Home business.
Assist with the transition to a Cloud based data lake and help drive new ways of working that capture the benefits of new technology and techniques.
Search for and obtain relevant data that helps us understand and serve all homeowners, even potential customers who do not choose to buy from us.
Make data and the insights generated from it accessible to the entire organization.
Create and manage data infrastructure to design, develop, and enhance the data and analytics solutions and pipelines, enabling data-driven decision-making processes.
Work closely with the IT development team in building Innovative, API first, cloud native solutions using AWS platform, Snowflake, Python, etc.
Enhance full delivery pipeline through automation, expanded yet increasingly efficient test coverage, ultimately optimizing time-to-market and overall quality
Optimize and fine-tune existing data pipelines for performance, scalability, and reliability.
Implement data quality checks and monitoring processes to ensure data accuracy and consistency.
Stay current with industry trends and best practices in data engineering and recommend improvements to existing processes
Mentor analysts across the organization; collaborate in technical documentation; participate in code reviews and adhering to engineering excellence/best practices.
Play a pivotal role in shaping the future of data analysis while thriving in a fast-paced environment that encourages personal growth and development.

Here is what you will bring to the table:


A vision of how to do things differently – better, faster, cheaper, adding more value – than our competitors.
A bachelor’s degree in a technical or business discipline, or equivalent experience.
3+ years of related data engineering experience with focus on designing and building data pipelines.
Expert in Python, proficient in SQL, additional SAS knowledge a bonus for legacy code.
Experience with data modeling and data warehousing.
Experience with cloud data platforms, Snowflake (preferable), AWS.
Proficiency with AWS Services including but not limited to AWS S3, AWS Glue, AWS Lambda, AWS EC2, Sagemaker.
Proficient with ETL/ELT data pipelines, patterns for loading Data Warehouses, Lakes.
Experience with build/deploy automation & DevOps frameworks (CI/CD, Bamboo, GitHub Actions, pipeline-as-code).
A design thinking and test-driven development mindset.
Experience with business intelligence tools and reporting solutions (Tableau etc.).

About the Company
The Plymouth Rock Company and its affiliated group of companies write and manage over $1.8 billion in personal and commercial auto and homeowner’s insurance throughout the Northeast and mid-Atlantic, where we have built an unparalleled reputation for service. We continuously invest in technology, our employees thrive in our empowering environment, and our customers are among the most loyal in the industry. The Plymouth Rock group of companies employs more than 2,000 people and is headquartered in Boston, Massachusetts. Plymouth Rock Assurance Corporation holds an A.M. Best rating of “A-/Excellent”.

#LI-PC1",1982,Insurance Carriers,$5 to $25 million (USD),Insurance,1001 to 5000 Employees,Company - Private,False
R&D Software Engineer – Sensor Data Analysis,"Delsys Incorporated
","Natick, MA",$93K - $126K (Glassdoor est.),4.0,"Full Time

Internship & Co-Op

Natick, MA
Posted 4 months ago
Engineering

Delsys is seeking highly motivated candidates to contribute to our next-generation neural processing systems. Delsys R&D Software Engineers collaborate with engineers and scientists to solve challenges spanning the fields of movement science & human health. The candidate for this position will primarily be involved in developing post-processing data pipelines used to study EMG and other bio-signals from multi-channel array sensors.

Primary Responsibilities

Design and implement machine learning and computer vision pipelines that directly contribute to our core research
Translate proven research algorithms and solutions into commercial products
Collaborate on a team to deliver sound and vetted software
Develop and deploy distributed microservices for real-time applications

Desired Qualifications

Fluent in Python, C, C++, C#
Strong object-oriented design skills
Working knowledge of signal processing
Experience working with time series signals
Be currently enrolled in or have completed an undergraduate or graduate degree in biomedical engineering (signal processing and coding background) computer engineering, computer science, data science (signal processing background) or a similar degree program",1993,Electronics Manufacturing,$1 to $5 million (USD),Manufacturing,1 to 50 Employees,Company - Private,False
Principal Data Engineer,"Exec Office of Technology Services and Security
","Boston, MA",$75K - $140K (Employer est.),3.6,"The Executive Office of Technology Services and Security (EOTSS) places our customers and constituents at the heart of everything we do. We offer responsive digital services and productivity tools to more than 40,000 state employees, who provide essential information and services to the citizens of the Commonwealth. We also serve constituents, providing them with digital services and tools that enable taxpayers, motorists, businesses, visitors, families, and other citizens to do business with the Commonwealth in a way that makes every interaction with government easier, faster, and more secure.



The Massachusetts Data Office (MDO) at EOTSS is hiring a Principal Data Engineer to lead our engineering team. The MDO is the central data office for the Commonwealth. We manage enterprise data programs and initiatives and partner with state agencies to build analytics products that promote data transparency and facilitate evidence-based policy and decision-making.

As a Principal Data Engineer, you’ll lead a team of Engineering professionals to develop and maintain smart, secure data systems and pipelines, enable analytics for data-driven decision-making, and build capacity for innovation in government. As part of the Commonwealth’s central data team, you’ll be on the front lines working to improve the value of our data systems across state government.




A Principal Data Engineer on our team is:

A technical expert leading a high-performance team to develop, construct, test, and maintain sound, secure data architectures that meet business needs.
A team-oriented specialist who works collaboratively with business leaders, project managers, and across technical teams to build the right thing.
A strategic thinker who improves the functionality and value of the Commonwealth’s data system.



This position is a full-time opportunity. The work schedule for this position is Monday through Friday, 9:00AM to 5:00PM EST, in a hybrid remote arrangement with 2-4 days per month spent at the primary work location: One Ashburton Place, Boston, Massachusetts 02108. Applicants should be located within reasonable commuting distance from the primary work location.




Duties and Responsibilities:

Lead and help build a team of high-performing engineers.
Stand up and maintain data infrastructure and data pipelines to process high volumes of complex data.
Work with IT, administrative staff, and business stakeholders to develop and execute on business requirements.
Identify, design, and implement internal process improvements, automate manual processes, optimize data delivery, and re-design infrastructure for greater scalability.
Develop and review data management plans, architecture plans, data transfer plans, and data security and privacy plans, including event monitoring and auditing guidelines, to ensure that systems meet security and technical requirements.
Develop and review standard operating procedures to meet high standards for data organization, quality, and security.
Provide leadership in developing standards and best practices.
Build analytics tools to provide actionable insights into operational efficiency, service delivery, and policy evaluation.
Provide support to other technical staff for issue resolution.
Deliver consistent and reliable processes and high-quality output on independent and team projects.



Preferred Knowledge, Skills & Abilities:

At least seven (7) years of demonstrated experience in data engineering, standing up and managing safe, secure, reliable data architectures, with at least three (3) years in a supervisory or team lead role.
Experience organizing and processing large quantities of data for analysis.
Experience working with business stakeholders to implement new data standards, technologies and systems that meet business needs.
Strong proficiency in Python and SQL.
Experience with current data science tools and methods, including machine learning (ML) and artificial intelligence (AI) frameworks.
Proficiency with Github and version control systems.
Proficiency with the AWS stack.
Working, up-to-date knowledge of best practices for keeping data separated and secure.
Experience with a team software development process: design, testing, coding, and peer reviews.
Experience with continuous integration/continuous development (CI/CD) practices.
Excellent verbal and written communication skills.
Ability to manage multiple priorities and workstreams simultaneously and deliver under tight deadlines.
Experience in an Agile work environment.
Proficiency with Snowflake strongly recommended but not required.



Education and Certifications:

Bachelor’s Degree in computer science, computer engineering, information systems, data science or related field, or equivalent work experience
AWS or other cloud platform certifications a plus; Snowflake certification a plus.



Qualifications


First consideration will be given to those applicants that apply within the first 14 days.

Please see Preferred Qualifications.




Comprehensive Benefits

When you embark on a career with the Commonwealth, you are offered an outstanding suite of employee benefits that add to the overall value of your compensation package. We take pride in providing a work experience that supports you, your loved ones, and your future.

Want the specifics? Explore our Employee Benefits and Rewards!



An Equal Opportunity / Affirmative Action Employer. Females, minorities, veterans, and persons with disabilities are strongly encouraged to apply.


The Commonwealth is an Equal Opportunity Employer and does not discriminate on the basis of race, religion, color, sex, gender identity or expression, sexual orientation, age, disability, national origin, veteran status, or any other basis covered by appropriate law. Research suggests that qualified women, Black, Indigenous, and Persons of Color (BIPOC) may self-select out of opportunities if they don't meet 100% of the job requirements. We encourage individuals who believe they have the skills necessary to thrive to apply for this role.


Official Title: Sys Programmer/Sys Supv, Pdpp
Primary Location: United States-Massachusetts-Boston-1 Ashburton Place
Job: Information Systems and Technology
Agency: Exec Office of Technology Services and Security
Schedule: Full-time
Shift: Day
Job Posting: Oct 23, 2023, 12:56:07 PM
Number of Openings: 1
Salary: 74,658.74 - 140,157.17 Yearly
If you have Diversity, Affirmative Action or Equal Employment Opportunity questions or need a Reasonable Accommodation, please contact Diversity Officer / ADA Coordinator: Emily Hartmann - 6176608300
Bargaining Unit: 06-NAGE - Professional Admin.
Confidential: No
Potentially Eligible for a Hybrid Work Schedule: Yes",-1,State & Regional Agencies,Unknown / Non-Applicable,Government & Public Administration,Unknown,Company - Public,False
Senior Data Scientist/Machine Learning Engineer,SC Group Management INC,"Newton Center, MA",$144K (Employer est.),-1.0,"Position Duties:

-Experience: 3 years of experience in the food industry or related field.

-Primary Responsibilities:

- Analyze large and complex datasets to identify patterns and insights.

- Develop machine learning models and algorithms to solve business problems.

- Design and conduct experiments to test and validate models and algorithms.

- Write efficient and scalable code in Python, Java, SQL, and R.

- Create and maintain APIs for website integration.

- Work with cross-functional teams to identify business requirements and deliver results that meet or exceed expectations.

- Communicate effectively with stakeholders and present findings and recommendations in a clear and concise manner.

- Conduct A/B testing and provide recommendations based on results.

- Manage data architecture and infrastructure on AWS.

Requirements:

- Master's degree in Computer Science, Mathematics, Statistics, or related field.

- Strong verbal and written communication skills in English and Chinese.

- 3 years of experience in the food industry or related field with a strong background in data science and machine learning.

- Proficiency in Python, Java, SQL, and R.

- Experience with API design and implementation.

- Familiarity with A/B testing and algorithm design.

- Extensive experience with AWS, including data architecture and infrastructure management.

Job Type: Full-time

Pay: $144,040.00 per year

Schedule:

Monday to Friday

Experience:

Python: 3 years (Preferred)
SQL: 3 years (Preferred)

Ability to Commute:

Newton Center, MA 02459 (Required)

Ability to Relocate:

Newton Center, MA 02459: Relocate before starting work (Required)

Work Location: In person",-1,-1,-1,-1,-1,-1,True
Data Engineer - GID Boston,"GID Investment Advisers LLC
","Boston, MA",$70K (Employer est.),4.7,"Data Engineer | GID – BOSTON, MA


GID is a leading real estate investment and management firm that operates a diverse portfolio of multifamily, industrial, and mixed-use developments across the United States. With over 60 years of experience across multiple asset classes, GID is an established real estate private equity investor and fiduciary supported by an integrated operating platform with approximately 54,000 multifamily units and over 25M square feet of industrial and commercial space of assets under management. The company also operates a credit platform that aims to provide commercial real estate debt solutions for institutional borrowers.




With corporate offices in Atlanta, Boston, Dallas, New York City, and San Francisco, GID employs over 1,200 real estate professionals and operates an expansive portfolio of existing and under-development properties valued at over $30.11 billion as of June 2023.


DESCRIPTION:

GID is looking for a highly motivated Data Engineer to join our growing Data & Analytics team. The Data and Analytics team is tasked with driving strategic decision making across the investment management and operations platforms through direct collaboration with senior business leaders and by leveraging proprietary and third-party data. The ideal candidate will be instrumental in helping GID make informed strategic decisions by building robust, scalable data pipelines, modeling data for use in BI and ML applications, and enforcing data governance practices. The current data stack includes a Snowflake enterprise data warehouse and ETL/ELT tools including FiveTran, Matillion, Azure Data Factory, and dbt. Power BI is our primary business intelligence tool.




RESPONSIBILITIES:

Design, build, and maintain scalable data pipelines for data ingestion and processing.
Collaborate with business users, data analysts, BI developers, and other stakeholders to identify requirements for data to be processed and used.
Develop queries for ad-hoc requests and data retrieval using SQL.
Use data modeling techniques, including star schema, to support BI and ML applications.
Use Python scripting for data transformation and data modeling tasks.
Apply data governance policies to support data security, privacy, quality, and discoverability.
Conduct troubleshooting, bug fixing, and data quality checks.



REQUIREMENTS:

Minimum of 1-2 years of experience in a data engineering role -or- substitute work experience with Bachelor's degree in Computer Science, Data Science, Engineering, or a related field.
Strong understanding of SQL for complex query writing.
Experience with Python for scripting and data manipulation.
Familiarity with cloud databases such as Snowflake, Azure SQL, or Databricks; and/or relational database management systems (RDBMS) such as PostgreSQL, MySQL, or SQL Server.
Understanding of data modeling techniques, including star schema.
Strong analytical and problem-solving abilities.
Intellectual curiosity and willingness to learn.
Excellent verbal and written communication skills.
Ability to work effectively both independently and as part of a team.
Attention to detail and a commitment to data accuracy.




Drug testing and background checks are an employment requirement. These are required steps in the hiring process.


Our company considers a range of factors including education and experience when determining base compensation.

Total compensation: $70,000 witha a 15% bonus.

This position is also eligible for bonus and benefits. For more information, visit: Benefits!

GID is an Equal Opportunity Employer",1960,Real Estate,Unknown / Non-Applicable,Real Estate,51 to 200 Employees,Company - Private,False
Software Developer & Data Engineer II,"Boston Public Health Commission
","Boston, MA",$80K - $90K (Employer est.),3.4,"Overview
Boston Public Health Commission's (BPHC) position as the leader in public health enables us to develop applications, collect and analyze a trove of data. The Enterprise Applications Department enables BPHC to tell our data story through business intelligence and develop innovative data-driven applications. Our data driven strategy is focused on advancing a new data platform, with a focus in three key areas:
Enable data-driven applications - Our objective is to enable any developer inside BPHC to build data-driven applications, which incorporate descriptive and predictive intelligence into business processes.
Differentiate through data - Differentiated data-driven applications are enabled by engines that encapsulate innovative capabilities, real-time data sharing between applications, and increased adoption of predictive intelligence.
Open up data assets - We will expose all of our key applications and selected platform
capabilities via APIs as part of the City of Boston's Open Data Platform. We will also expose several self-service interfaces and tools to enable internal developers and analysts to access data in the shape and format they desire.
Duties
Under the direction of the Enterprise Applications and Business Intelligence, the qualified candidate will be responsible for the completion, documentation, testing, and rollout of all development tasks for various enterprise-wide applications. In addition, the candidate will also be responsible for custom SQL development including writing stored procedures with extensive use of T-SQL programming and provide technical support to other members of the Enterprise Applications team and end users. This position must participate in an on-call rotation.
Develop enterprise-wide applications and business solutions to support BPHC. Perform
multiple software development tasks following industry standard software engineering
practices and design control processes.
Implement and test new applications, integrations, reports, custom forms and workflows.
Work closely with all applicable cross-functional teams to fully understand all relevant
business requirements, processes, and needs. Conduct systems requirement definition
sessions.
Maintain appropriate coordination and communication with functional owners and users.
Support the creation, execution and documentation of functional and automated tests
necessary to ensure that the delivered product meets requirements.
Prepare and maintain documentation of developed code and system customizations.
Apply project management skills for initiatives to improve business processes. Work with
Bureaus and programs across BPHC to plan, develop and implement enterprise business
solutions.
Ensure effective communication between non-technical and technical teams.
Provide training, management and support for Enterprise applications.
Keep up to date with industry trends and developments.
Manage and monitor systems' operations and resources to research, resolve, and track
problems



Minimum Qualifications

Minimum Qualifications
BS or MS in Computer Science or directly related field (e.g., Information Technology,
Information Science).
3 or more years of software development.
Strong analytical skills, with the ability to independently analyze and document findings and recommend solutions.
Solid experience with data modeling and strong problem-solving skills.
Experience in developing web applications using Python, VB or C#, ASP.NET, Net Framework, CSS, Ajax, JQuery, JavaScript and IIS.
Experience with Object Oriented software development.
Experience using Microsoft Power platform (Power Apps, Power Automate and Power BI)
preferred.
Experience with SQL, PL/SQL and Relational Database queries.
Motivated to explore new technologies and learn new skills.
Able to work independently as well as in a team setting.
Able to communicate effectively, verbally and in writing, and to interact effectively with
internal and external audiences and peers.



Additional Information

City of Boston Residency Required, A Criminal Offenders Records Information request must be completed for this position. However, a record is not an automatic bar to employment but is reviewed in relation to the job applied for., Any position that requires an advanced degree will be subject to education verification, The Boston Public Health Commission is an EEO Employer and all applicants meeting the minimum requirements are eligible to apply",-1,Municipal Agencies,$100 to $500 million (USD),Government & Public Administration,1001 to 5000 Employees,Government,False
"Senior Data Engineer, Investments Technology","Liberty Mutual
","Boston, MA",$110K - $185K (Employer est.),3.8,"Pay Philosophy

The typical starting salary range for this role is determined by a number of factors including skills, experience, education, certifications and location. The full salary range for this role reflects the competitive labor market value for all employees in these positions across the national market and provides an opportunity to progress as employees grow and develop within the role. Some roles at Liberty Mutual have a corresponding compensation plan which may include commission and/or bonus earnings at rates that vary based on multiple factors set forth in the compensation plan for the role.


Description

Note: This role has a hybrid work arrangement (2 days per week in Boston office)


Are you looking for a chance to be part of a high performing team that is passionate about data? Are you intrigued by Investments and Finance? Does the thought of building a modern cloud-based data platform from the ground up excite you? If yes, then join us and be part of a team that's forging the path to data-driven success.


At Liberty Mutual Investments (LMI), we manage a high-quality investment portfolio utilizing a disciplined strategy. We have a large and varied customer base, supported by strategic business units that function as a complete investment firm within our Fortune 100 Company. Our investment professionals are critical to our ability to keep our promises to policyholders, claimants, and their families.

We are an equal opportunity employer and value diversity at our company. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.


At Liberty Mutual Investments Technology, we are seeking two highly skilled Sr. Data Engineers to join our dynamic team. As a Sr. Data Engineer in our Data Engineering Chapter, you will play a pivotal role in shaping the future of data analysis while thriving in a fast-paced environment that encourages personal growth and development.


Key Responsibilities:

Work in Data and Analytics squad to design, develop, and enhance the data and analytics solutions and pipelines, driving data-driven decision-making processes.
Collaborate with scrum masters, product owners, and engineering teams to iteratively create data and analytics solutions that meet both business and technical requirements.
Work closely with development team in building Innovative, API first, cloud native solutions using AWS platform, Snowflake, Snaplogic, Python, Rest API etc.
Continuously enhance full delivery pipeline through automation, expanded yet increasingly efficient test coverage, ultimately optimizing time-to-market and overall quality.
Optimize and fine-tune existing data pipelines for performance, scalability, and reliability.
Implement data quality checks and monitoring processes to ensure data accuracy and consistency.
Stay current with industry trends and best practices in data engineering and recommend improvements to existing processes.
Mentor junior engineers in the team; collaborate in technical documentation; participate in code reviews and adhering to engineering excellence/best practices.


Qualifications


A bachelor’s degree in a technical or business discipline, or equivalent experience
5+ years of related data engineering experience with focus on designing and building data pipelines
Proficient in SQL and hands on experience with Python
Experience with Data modeling and data warehousing
Experience with public cloud data platforms, Snowflake (preferable), AWS, Azure
Proficiency with AWS Services including but not limited to AWS S3, AWS Glue, AWS Lambda, AWS EC2
Proficient with ETL/ELT data pipelines, patterns for loading Data Warehouses, Lakes
Experience with build/deploy automation & DevOps frameworks (CI/CD, Bamboo, GitHub Actions, pipeline-as-code)
A design thinking and test-driven development mindset
Experience with business intelligence tools and reporting solutions (Power BI, Tableau etc.)

Preferred Skills:

Previous experience in Investments / Asset Management, Finance Data modeling, is highly desirable
Familiarity in building and consuming APIs (REST, API Gateway, etc.)
Cognizance of security concerns, from access control and authentication to secured processes
Knowledge of containerization and orchestration tools (e.g.: Docker, Kubernetes)
A comprehensive understanding of agile environments and the ability to adapt to rapidly changing circumstances.
About Us

At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That's why we provide an environment focused on openness, inclusion, trust and respect. Here, you'll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.

Liberty Mutual has proudly been recognized as a ""Great Place to Work"" by Great Place to Work® US for the past several years. We were also selected as one of the ""100 Best Places to Work in IT"" on IDG's Insider Pro and Computerworld's 2020 list. For many years running, we have been named by Forbes as one of America's Best Employers for Women and one of America's Best Employers for New Graduates as well as one of America's Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusion

We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits

Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran's status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.",1912,Insurance Carriers,$10+ billion (USD),Insurance,10000+ Employees,Company - Private,False
Senior Data Engineer,"PlatformQ Health
","Needham, MA",$108K - $151K (Glassdoor est.),3.7,"PlatformQ Health is a leading digital medical education provider, producing live and enduring online Continuing Medical Education (CME) activities in a convenient and engaging interactive format. This pioneering approach to online education makes it time efficient and cost-effective for healthcare professionals to stay current with the latest clinical developments and treatment options. PlatformQ Health currently designs, develops and provides education in over 13 therapeutic areas, including oncology, neurology, rare diseases, cardiology, infectious disease and immunology. The Company has strategic partnerships with leading medical societies, associations, advocacy groups and foundations. Examples include ASGCT, NORD, KDIGO and AAFA.

The Senior Data Engineer will be responsible for designing and developing data pipelines and services using Python and AWS. The Senior Data Engineer will join a team of data engineers and will be responsible for designing, monitoring, and maintaining data pipelines and integrations. They will work to ensure data accuracy and integrity within the system and will be responsible for monitoring the stack for proactive resolutions. The Senior Data Engineer will also be responsible for providing technical guidance, documentation, and mentorship to other members of the engineering team.

The ideal candidate should have a strong background in data engineering, data warehousing, ETL/ELT pipelines, and architecting creative data solutions. The candidate should be a self-starter and also have a desire to learn about ML ops in order to support future-looking machine learning initiatives.

Responsibilities:
Design, develop and maintain ETL/ELT pipelines using AWS cloud
Mentorship of the data engineering team in the form of code reviews, guidance, and upskilling
Collaborate with software engineers, product managers, and business stakeholders to understand requirements and data needs
Develop and maintain PlatformQ’s data warehouse and reporting architectures
Proactively monitor, troubleshoot, and optimize data pipelines
Design and develop data applications and services that enable self-service reporting and analysis
Ensure data integrity and accuracy
Stay current with emerging technologies and industry trends related to data engineering
Basic data privacy and security principles
Requirements:
5+ years of experience in data engineering.
Demonstrated team mentorship or leadership experience
Extensive experience in the design, development, and maintenance of data ETL pipelines.
Extensive knowledge of coding in Python with a focus on data processing.
Experience implementing the AWS technology stack (S3, Redshift, Lambda).
Experience with data and entity relationship modeling to support data warehouses and analytics solutions including downstream reporting solutions.
Experience with relational and non-relational databases (SQL/NOSQL).
Comfortable working with unstructured and semi-structured data as well as working with APIs
Experience working in a professional software environment using source control (git), an issue tracker (JIRA, Confluence, etc.), code reviews, and agile development process.
Nice to Have:
Experience with machine learning workflows and data requirements for use with ML frameworks
Experience with containerization using Docker
Experience with open-source tools like Apache Airflow and Superset
Experience with AWS services like Step Functions, Glue, and Sagemaker
Experience with AWS IaC services like SAM or CloudFormation
Location:
Remote

Please send your resume to sfreedman@platformq.com",-1,Advertising & Public Relations,$1 to $5 million (USD),Media & Communication,1 to 50 Employees,Company - Private,False
Senior Data Engineer - Remote,"Watts Water Technologies
","North Andover, MA",$93K - $129K (Glassdoor est.),3.8,"The Watts Water Technologies family of companies designs and manufactures valves and drains and related products that promote the comfort and safety of people and the quality, conservation and control of water used in commercial, residential, industrial, and municipal applications. Everything we design is made to keep the Earth's most precious resource safer, cleaner, and more useful for our customers.
We are looking for a Data Engineer to join the Watts Digital team. In this role, you will have the opportunity to build a next generation data platform that serves digital solutions and other teams within Watts. You will be responsible for designing, developing, and maintaining our data architecture, ensuring the availability and reliability of data for various business functions. You will work with key stakeholders to apply data analytics, models, and techniques to assist in realizing the value of data. You will architect and implement scalable ETL pipelines that contribute to a centralized data repository leveraging data lake architecture. As a valued technical leader, you will be responsible for ensuring our technology decisions align and scale with our architectural north star. You will directly contribute to a culture of excellence in Watts Digital’s growing engineering organization and be a pivotal member in enhancing our engineering standards and processes.
You Will:
Technical Implementation and Architecture
Design, implement, and own ETL pipelines and data lakehouse architecture across Watts digital solutions
Build large-scale batch and real-time data pipelines with data processing frameworks like Spark and Databricks
Utilize optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources into a central Watts data repository that supports varying use-cases
Work closely with Watts business units and engineering teams to develop a strategy for long term data platform architecture which will be efficient, reliable and scalable
Lead and contribute to technical architecture discussions and driving technical decisions across engineering teams
Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
Communicate technology decisions and outcomes to key stakeholders (e.g. sponsors, partners, product teams)
Determine and implement a security model based on privacy requirements; addressing data quality issues, and evolving governance processes within allocated areas of ownership
Ensure that the systems we develop and maintain result in highly scalable, feature-rich solutions that minimize support costs and deliver value to customers
Develop and maintain solution architecture diagrams and documentation
Advise and support the team on selection and implementation of modern technologies including languages, open-source and third-party tools to increase efficiency and improve technology and product offerings
Execution, Product Delivery and Results
Lead the architecture and delivery of scalable ETL pipelines and data stores
Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
Enable streamlining our data science workflows, adding value to our product offerings and building out the customer lifecycle and retention models
Clean, prepare and optimize data at scale for ingestion and consumption
Working closely with other Engineers, Quality Assurance, Operations, and 3rd party vendors to successfully deliver and deploy solutions to production
Define and manage SLA for all data sets
Identify and implement the right analytical libraries, programming languages, and frameworks for each task
Advocate a continuous improvement mindset regarding our development process, with a focus on how we can automate regular, high-quality, releases in an agile environment
Continuously rebalancing features, which maximize value and minimize effort to focus on the highest returning initiatives for business and customer
Champion a culture of learning, measurement, accountability, and quality via code reviews, paired programming, and other collaboration opportunities with the team
Collaborate with Product Owners on the backlog and providing high level effort estimation to plan feature prioritization more accurately and development
BUs, Operations, IT, Information Security and Infrastructure
Partner with hardware BUs to understand their needs and deliver platform-oriented solutions
Continuing to evolve security practices and controls to meet the needs of protecting customer data
Champion a culture of compliance as it pertains to data to meet legal, regulatory, and operational data requirements
Partner with IT and operations in support of enterprise IT strategy
Ensure we are building necessary observability into our systems that provide transparency across the entire data architecture stack
Work with engineering teams and assisting Customer Success and Operations team in triaging and resolving production issues
You Have:
Bachelor’s degree in computer science, information technology, engineering, or related discipline
5+ years of experience with ETL technologies
5+ years of experience with Databricks, specifically within Azure
5+ years of experience with Python, Scala, .NET, Java or similar languages
7+ years of SQL experience (No-SQL experience is a plus)
5+ years of experience with schema design and dimensional data modeling
Excellent product strategic thinking and communication to influence product and cross-functional teams by identifying data opportunities that drive impact
Proven ability around managing and communicating data roadmap plans to internal stakeholders
Experience designing, building and maintaining data processing systems
Deep understanding of software engineering practices (e.g. Agile software development, test driven development, unit testing, code reviews, design documentation, etc.)
An entrepreneurial spirit that is flexible, experimental, and resourceful
What’s In It For You:
People-First Culture – Enriching and caring for people is at the core of who we are; this includes our Diversity, Equity, and Inclusion (DEI) strategy, and providing our employees with meaningful career growth opportunities, a positive and safe work environment, and affirmation that they are heard, valued, and respected.
401K Plan
Flexible PTO & Generous Paid Holidays
Educational Assistance
Variety of Medical plan options – choose the one that is right for you!
Sustainability – One of Newsweek’s Top 400 of “America’s Most Responsible Companies” for sustainability performance, three years running.
PHYSICAL REQUIREMENTS:
While performing the responsibilities of this job, the employee is frequently required to walk, talk, and/or hear. The employee is occasionally required to stand, sit, and use hands to finger, handle, or feel. You must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include: close vision, color vision, peripheral vision, depth perception and ability to adjust focus.
WORK ENVIRONMENT:
Work in both office and manufacturing environment. May occasionally be required to perform job responsibilities outside the typical office setting.
#LI-Remote
Watts is committed to equal employment opportunity. We follow a policy of administering all employment decisions and personnel actions without regard to race, color, religion, creed, sex, pregnancy, national origin, sexual orientation, age, physical or mental disability, genetic disposition or carrier status, marital status, military or veteran status, minorities, or any other category protected under applicable federal, state, or local law. Consistent with the obligations of state and federal law, Watts will make reasonable accommodations for qualified individuals with disabilities. Any employee who needs a reasonable accommodation should contact Human Resources.
#LI-Remote",1874,Machinery Manufacturing,$1 to $5 billion (USD),Manufacturing,5001 to 10000 Employees,Company - Public,False
Software Engineer - Data Center Networking,"Facebook App
","Boston, MA",$143K - $204K (Employer est.),3.9,"The DC Networking team is responsible for developing, deploying, and operating Meta's global data center networks. Our work covers the entire network lifecycle, including hardware development, capacity planning, distributed and centralized control systems, modeling/provisioning/automation, monitoring/troubleshooting/analytics, and simulation/design/failure analysis. We are actively seeking Software Engineers to help build and scale our rapidly evolving network infrastructure. We are looking for Software Engineers with a passion for networking and aptitude for building scalable distributed systems. Do you want to work on one of the most dynamic, fast-paced networks in the world? Do you want to develop innovative solutions to our challenges and ship them into production? Then a role on one of our network engineering teams is for you!



Software Engineer - Data Center Networking Responsibilities:

Design and implement drivers (and/or Firmware) for (network) ethernet adapter functions, Transport stack for RDMA, control functions with the host/accelerators.
Design and implement Platform services such as programming, monitoring, and controlling system components (Optics, PHY, FPGAs, sensors, fan control, power etc).
Develop and enhance HPC collective communication and parallel computing libraries such as NCCL, RCCL, OneCCL, and MPI
Debug complex, system-level, multi-component issues that typically span across multiple layers from Kernel, and user-mode applications.




Minimum Qualifications:

Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
Proficient in programming in C/C++/Python
Hands on experience with debugging large scale systems




Preferred Qualifications:

Experience in one of the following areas -
Experience with Linux Kernel, especially drivers and network stack
Working knowledge of transport stack particularly RDMA (RoCEv2)
Experience with parallel computing platforms such as CUDA, RoCM and OpenCL
Platform services (program, control, and monitor Optics, PHY, FPGAs, sensors, fan control, power etc), BSP/Board Support Package, Operating Systems, Kernel, Bootloader, Power Management, RTOS, Linux.
Experience with Qemu, FPGA Emulation environment is a plus




About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.



Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",2004,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Principal Data Platform Engineer,"CarGurus
","Cambridge, MA",$130K - $179K (Glassdoor est.),4.4,"Who we are
At CarGurus (NASDAQ: CARG), our mission is to give people the power to reach their destination. We started as a small team of developers determined to bring trust and transparency to car shopping. Since then, our history of innovation and go-to-market acceleration has driven industry-leading growth. In fact, we're the largest and fastest-growing automotive marketplace, and we've been profitable for over 15 years.

What we do
The market is evolving, and we are too, moving the entire automotive journey online and guiding our customers through every step. That includes everything from the sale of an old car to the financing, purchase, and delivery of a new one. Today, tens of millions of consumers visit CarGurus.com each month, and ~30,000 dealerships use our products. But they're not the only ones who love CarGurus—our employees do, too. We have a people-first culture that fosters kindness, collaboration, and innovation, and empowers our Gurus with tools to fuel their career growth. Disrupting a trillion-dollar industry requires fresh and diverse perspectives. Come join us for the ride!

Role overview

The Data Engineering team is looking for a highly motivated Principal Data Pipeline Engineer to evolve our modern data warehousing platform to world-class levels! As CarGurus enters the next phase of dramatic growth with new data sources, new business lines, and business acquisitions, we are looking for a candidate who is interested in revamping how we do data at the company. You will act as a technical mentor for the other data engineers in the team.

What you'll do
Gain a deep understanding of our evolving data and analytics stack and provide guidance in enhancing those
Define and drive tactical decisions around Data Platform domain while providing input into larger strategic decisions around data infrastructure, data quality, data observability, and data governance
Build robust and scalable data integration (ETL/ELT) pipelines using Python, SQL and Airflow
Build and deliver high quality data architecture to support our team of Analytics Engineers, Data Analysts, Data Scientists, and various stakeholders throughout the company
Be a technical mentor to other data and sr data engineers and expose the team to new technologies and techniques
Maintain the data infrastructure layer using IaaS and keep enhancing the framework.
What you'll bring
7+ years of experience in data engineering, designing and building scalable and reliable data pipelines and infrastructure
Extensive knowledge in programming languages like Python
Advanced knowledge of SQL, Snowflake preferred
Expert in system architecture – with the ability to understand the context of a business need and build a system that addresses it
3+ years experience with cloud-based data platforms like AWS or GCP
Excellent problem-solving and communication skills, and ability to work collaboratively with cross-functional teams including product managers, data scientists, and software engineers
Proficient with data streaming frameworks like Kafka or Kinesis
Extensive knowledge of working with workflow management tools like Airflow.
Proficiency in performance tuning the ETLs/ELTs and database solutions for large data sets
Extensive knowledge in data governance.
Proficiency with modern Agile development methodologies.
Extensive experience in requirement gathering, analysis, design, code review, and unit and integration testing
Deliver maintenance and improvements for existing applications.
The ability to be an exceptional team player, act as a technical mentor, interested in sharing knowledge with other team members, and passionate about learning new technologies
Experience on managing and maintaining the data infrastructure with the use of Terraform, Cloudform, Ansible or other tools.
Experience in building monitoring and alerting techniques.
Nice to have
Experience in managing and maintaining warehouses in Snowflake.
Experience working with NoSQL databases.
Worked building event driven streaming pipelines.
Familiarity with dbt.

Working at CarGurus
We reward our Gurus' curiosity and passion with best-in-class benefits and compensation, including equity for all employees, both when they start and as they continue to grow with us. Our career development and corporate giving programs, as well as our employee resource groups (ERGs) and communities, help people build connections while making an impact in personally meaningful ways. A flexible hybrid model and robust time off policies encourage work-life balance and individual well-being. Thoughtful perks like daily free lunch, a new car discount, meditation and fitness apps, commuting cost coverage, and more help our people create space for what matters most in their personal and professional lives.

We welcome all
CarGurus strives to be a place to which people can bring the ultimate expression of themselves and their potential—starting with our hiring process. We do not discriminate based on race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, or sexual orientation. We foster an inclusive environment that values people for their skills, experiences, and unique perspectives. That's why we hope you'll apply even if you don't check every box listed in the job description. We want to know what only you can bring to CarGurus. #LI-Hybrid",2006,Internet & Web Services,$500 million to $1 billion (USD),Information Technology,501 to 1000 Employees,Company - Public,True
Lead Software Engineer - Data Exchange,"Klaviyo
","Boston, MA",$129K - $167K (Glassdoor est.),4.0,"At Klaviyo, we value the unique backgrounds, experiences and perspectives each Klaviyo (we call ourselves Klaviyos) brings to our workplace each and every day. We believe everyone deserves a fair shot at success and appreciate the experiences each person brings beyond the traditional job requirements. If you're a close but not exact match with the description, we hope you'll still consider applying. Want to learn more about life at Klaviyo? Visit careers.klaviyo.com to see how we empower creators to own their own destiny.

Klaviyo operates a real-time data analytics platform coded primarily in Python that is built for massive scale and hosted on Amazon Web Services (AWS). Engineers come to Klaviyo with experience in a variety of languages and from a number of disciplines.

The Data Exchange team is responsible for designing and building software that enables data transmission in and out of the Klaviyo platform through a variety of protocols and delivery mechanisms. The team collaborates closely with internal stakeholders and has substantial exposure to Klaviyo's customers, including businesses, partners, and third-party developers. Data Exchange operates at the intersection of distributed systems, data pipelining, software architecture, scalability, and reliability.

At Klaviyo, we love tackling tough engineering problems and look for employees who specialize in certain areas but are passionate about building, owning & scaling features end to end from scratch and breaking through any obstacle or technical challenge in their way. We push each other to move out of our comfort zone, learn new technologies, and work hard to ensure each day is better than the last. Klaviyo is growing fast and we have openings for all skill levels across all of our teams. Learn more about our engineering culture at https://klaviyo.tech.

How you'll make an impact

This team is a key contributor to the evolution of Klaviyo into a data platform, enabling hundreds of thousands of Klaviyo customers to effectively leverage and activate their data. Critical components of the data platform include data collection and data distribution, which must be both reliable and scalable as Klaviyo continues to expand its support for various methods of data import and export. As a Lead Software Engineer, you will define and own the architecture for data collection and distribution. You will contribute to the advancement of our data movement framework and play a key role in shaping Klaviyo's data platform evolution, aligning with our vision, mission, and strategy. You'll work with a team of talented and experienced software engineers who are eager to grow fast and make an impact on the company.

What you'll do
Be independently responsible for the entire lifecycle of projects or features including design, development, and deployment, providing direction for others
Work closely with Product and other Engineering leads to refine the strategy and make valuable contributions to the roadmap that align with company worldwide growth
Be responsible for the technical/architectural evolution of your product area; identify and advocate for scalability, reliability, and maintainability needs
Be responsible for technical quality, teach others technical expertise and help them develop skills they need to improve within the organization
Establish expertise in multiple internal and industry practices, patterns, tools, languages, and processes; Contributes beyond the team to share new patterns, tools, etc.
Master diverse internal and industry practices, tools, and processes. Share new insights and contribute beyond the team.
Who you are
Passionate about building software effectively and for the long-term. Have experience building products that matter. Have proven expertise in applying relevant design patterns to implementing highly-scalable multi-tenant systems.
Like working on small, autonomous agile teams. Enjoy shipping code early and often in an agile fashion, pairing with product management, business stakeholders, and other engineers to craft better software.
Have in-depth knowledge and extensive experience working with distributed architectures, data processing systems, big data stack, and process control systems. Have understanding of domain-driven design and data management patterns.
Motivated by having ownership and leading others, excited about taking the initiative to solve tasks in collaboration with others. Have experience leading projects and groups of engineers.
Have expertise assessing risks and alternatives. Have solid understanding of prioritizing organizational, technical, and product needs.
Promote shared understanding among leadership and considers others when making decisions. Regularly mentor fellow engineers, ensuring their skill development aligns with organizational growth.
Love digging into performance, scalability, and reliability issues to drive breakthrough solutions. You recognize all problems can be solved and are capable of rallying others to address business needs.
Tech Stack

We are looking for a backend-focused engineer, experience with frontend development is preferred but not mandatory. Previous experience with Python is desirable. The tech stack you'll be working with:

Python, Django
Apache Kafka, Apache Pulsar, RabbitMQ, and other tech from the big data stack
MySQL, Redis
Graphite, statsd, Grafana
AWS, Terraform, Docker, Kubernetes, Jenkins, and other modern DevOps tools

The pay range for this role is listed below. Sales roles are also eligible for variable compensation and hourly non-exempt roles are eligible for overtime in accordance with applicable law. This role is eligible for benefits, including: medical, dental and vision coverage, health savings accounts, flexible spending accounts, 401(k), flexible paid time off and company-paid holidays and a culture of learning that includes a learning allowance and access to a professional coaching service for all employees.

Pay Range For US Locations:

$183,200—$274,800 USD

Get to Know Klaviyo

We're Klaviyo (pronounced clay-vee-oh). We empower creators to own their destiny by making first-party data accessible and actionable like never before. We see limitless potential for the technology we're developing to nurture personalized experiences in ecommerce and beyond. To reach our goals, we need our own crew of remarkable creators—ambitious and collaborative teammates who stay focused on our north star: delighting our customers. If you're ready to do the best work of your career, where you'll be welcomed as your whole self from day one and supported with generous benefits, we hope you'll join us.

Klaviyo is committed to a policy of equal opportunity and non-discrimination. We do not discriminate on the basis of race, ethnicity, citizenship, national origin, color, religion or religious creed, age, sex (including pregnancy), gender identity, sexual orientation, physical or mental disability, veteran or active military status, marital status, criminal record, genetics, retaliation, sexual harassment or any other characteristic protected by applicable law.

IMPORTANT NOTICE: Our company takes the security and privacy of job applicants very seriously. We will never ask for payment, bank details, or personal financial information as part of the application process. All our legitimate job postings can be found on our official career site. Please be cautious of job offers that come from non-company email addresses (@klaviyo.com), instant messaging platforms, or unsolicited calls. If you suspect a fraudulent job posting or receive suspicious communications that appear to be from our company, please contact us immediately at HR@klaviyo.com.

You can find our Job Applicant Privacy Notice here.",2012,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
"Lead/Principle Data Analytics Engineer, Advanced Analytics","SharkNinja Operating LLC
","Needham, MA",$107K - $145K (Glassdoor est.),3.2,"Our purpose is to positively impact people's lives every day in every home around the world! We work very hard to provide our consumers with high-quality, exciting 5-star products that make life easier. We thrive on passion and innovation and are looking for great people, with great ideas, who want to build the next big thing and develop while they do.

The Company

Today we operate in 7 countries across 27 categories in cooking, cleaning, and beauty – and we're just getting started. Our purpose is to positively impact people's lives every day in every home around the world! We work hard to provide our consumers with high-quality, exciting 5-star products that make life easier. We thrive on passion and innovation and are looking for great people, with great ideas, who want to build the next big thing and develop while they do.

Summary of Position

We are building a world-class global customer data & analytics organization to support teams like marketing, ecommerce, and post-purchase. SharkNinja is rich with data sources and a data-driven culture; we need data experts (like you!) to centralize, transform, and wrangle our data to enable end users to derive meaningful insights and impact the business. The successful candidate understands the balance between speed and scale, is self-driven to be an expert in their space, and can both set the strategy and hands-on execute on it.

Responsibilities

Be an owner of your workstream. Identify opportunities to streamline or enhance how we operate today to improve efficiency and efficacy. Balance long term solutions with short term demands.
Partner closely with the other members of the Consumer Data & Analytics team to understand the analytics strategy and inform the data roadmap. Build and maintain close relationships with IT to ensure the data analytics strategy aligns and is complimentary to the enterprise-wide IT strategy.
Build and own infrastructure to centralize our analytics data with robust, reliable data pipelines.
Create user-friendly semantic layer designed for ad hoc analysis, routine reporting, and/or data science modeling to enable end users to quickly and easily analyze the data. Includes friendly naming conventions, well defined metrics, and optimized for performance.
Set up best-in-class alerting and anamoly detection for proactive identification of data integrity errors or business performance shifts to be root caused.
Contribute to the team culture; includes collaborating, upskilling teammates, and knowledge sharing.

Skills & Experience

5-8 years of relevant work experience; experience in the retail industry or CPG preferred
Bachelors degree in relevant field such as software engineering or computer science; Masters degree preferred
Expert knowledge of data engineering / analytics engineering technologies; SnowFlake, FiveTran, DBT, GBQ and/or Domo preferred
Expert knowledge of ETL / ELT
Expert knowledge of data connections such as out-of-the-box APIs, custom APIs, and Excel database connectors
Expert knowledge of data modeling techniques including database structures (eg relational database)
Expert knowledge of data wrangling techniques such as flattening nested data and automated outlier detection
Expert knowledge of database performance optimization techniques such as indexing
Expert knowledge of data alert best practices
Expert knowledge of clickstream data and data structures, Google Analytics 4 (GA4) experience preferred
Advanced knowledge of marketing, transactional, call center, and customer data and data structures
Expert critical thinking skills for analysis set up and zero-defect delivery
Incredible attention to detail, and innate passion for root causing and resolving discrepancies
Self-motivated with the ability to influence decisions based on data and insights
Effectively handle multiple projects in a fast-paced work environment
Consistently challenge the status quo to uncover new and improved ways of operating

Location: Needham, MA - Hybrid

#LI-Hybrid


At SharkNinja, Diversity, Equity, and Inclusion are vital to our global success. Valuing each unique voice and blending all of our diverse skills strengthens SharkNinja's innovation every day. We support ALL associates in bringing their authentic selves to work, making an impact, and having the opportunity for career acceleration. With help from our leadership, associates, and our community, we aim to have equity be a key component of the SharkNinja DNA.
YOUR ROLE in leading our SUCCESS DRIVERS & representing our UNIQUE MINDSET
Lead us to be ""RARELY SATISFIED""
Make things better each day; ""PROGRESS OVER PERFECTION""
Use your knowledge of our consumer, understand that ""DETAILS MAKE THE DIFFERENCE""
Deliver something great; ""WINNING IS A TEAM SPORT""
Be clear and honest, ""COMMUNICATING FOR IMPACT""
Explore SharkNinja on our social channels:
Instagram
LinkedIn
SharkNinja's Candidate Privacy Notice can be found here: https://www.sharkninja.com/candidate-privacy-notice/



We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, disability, or any other class protected by state or federal law. SharkNinja will consider reasonable accommodations consistent with federal, state, and local law. If you require a reasonable accommodation to participate in the job application or interview process, please contact SharkNinja People & Culture.",1994,Consumer Product Manufacturing,$1 to $5 billion (USD),Manufacturing,1001 to 5000 Employees,Company - Public,True
Principal Data Engineer,"Fidelity Investments
","Boston, MA",$118K - $154K (Glassdoor est.),4.3,"Job Description:

Principal Data Engineer

The Role

Fidelity’s Asset Management Technology (AMT) provides worldwide technology and support to all the Investment Management, Research, Trading, and Investment Operations functions. We are seeking a Principal Quant Data Engineer to join our Quantitative Research & Investing Technology organization. This role will be part of our Quantitative Data Engineering team, which is responsible for architecting, developing, and maintaining a high-quality data platform that is optimized for quant consumption.

If you are a highly motivated and expert data engineer with a strong agile mindset, who’s looking for a new challenge, we have an exciting opportunity for you to join our fast paced and highly collaborative group. This role will be involved in the full end-to-end process through planning, design, development, quality and implementation of solutions.

Primary Location: Merrimack, NH

Additional Locations: Boston, MA

The Expertise and Skills You Bring

7 or more years of industry experience as a Database engineer and developer.
B.S. degree in math, statistics, computer science, or equivalent technical field.
Experience in building and designing solutions for data warehouse and experience in working with large data sets
Strong database knowledge and proven experience with data analysis and database design for operational, transactional systems.
Experience in building solutions using Python and experience in working with large data sets
Experience with Cloud data storage and access using Snowflake / S3
Strong software engineering skills, preferably PLSQL, Python, shell scripting, SQL, and Linux.
Validated knowledge ETL tools and data warehouse concepts.
Expertise in native AWS services such as EMR, EC2 and Cloud formation will be a plus

The Team


Quantitative Data Platform team is part of Asset Management’s Quantitative Research & Investment Technology group that partners with the Quantitative Research & Investment teams on various projects including portfolio construction, risk management, and alpha research. We build high quality, robust, and efficient high-responsive solutions that are used to improve efficiency and decision making.


Certifications:

Company Overview

Fidelity Investments is a privately held company with a mission to strengthen the financial well-being of our clients. We help people invest and plan for their future. We assist companies and non-profit organizations in delivering benefits to their employees. And we provide institutions and independent advisors with investment and technology solutions to help invest their own clients' money.


Join Us

At Fidelity, you'll find endless opportunities to build a meaningful career that positively impacts peoples' lives, including yours. You can take advantage of flexible benefits that support you through every stage of your career, empowering you to thrive at work and at home. Honored with a Glassdoor Employees' Choice Award, we have been recognized by our employees as a Best Place to Work in 2023. And you don't need a finance background to succeed at Fidelity—we offer a range of opportunities for learning so you can build the career you've always imagined.

At Fidelity, our goal is for most people to work flexibly in a way that balances both personal and business needs with time onsite and offsite through what we’re calling “Dynamic Working”. Most associates will have a hybrid schedule with a requirement to work onsite at a Fidelity work location for at least one week, 5 consecutive days, every four weeks. These requirements are subject to change.

We invite you to Find Your Fidelity at fidelitycareers.com.


Fidelity Investments is an equal opportunity employer. We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging.

Fidelity will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, contact the HR Accommodation Team by sending an email to accommodations @fmr.com, or by calling 800-835-5099, prompt 2, option 3.

At Fidelity, we value honesty, integrity, and the safety of our associates and customers within a heavily regulated industry. Certain roles may require candidates to go through a preliminary credit check during the screening process. Candidates who are presented with a Fidelity offer will need to go through a background investigation and may be asked to provide additional documentation as requested. This investigation includes but is not limited to a criminal, civil litigations and regulatory review, employment, education, and credit review (role dependent). These investigations will account for 7 years or more of history, depending on the role. Where permitted by federal or state law, Fidelity will also conduct a pre-employment drug screen, which will review for the following substances: Amphetamines, THC (marijuana), cocaine, opiates, phencyclidine.",1946,Investment & Asset Management,$10+ billion (USD),Financial Services,10000+ Employees,Company - Private,False
Data Analytics Engineer / Senior Data Analytics Engineer,"American Student Assistance
","Boston, MA",$99K - $134K (Glassdoor est.),3.9,"As ASA expands its digital transformation to drive its mission of creating resources and solutions for teenagers’ exploring their options for post-High School planning, it is seeking new and talented data analysts and engineers. Under the direction of the Senior Director of Strategic Insights & Program Outcomes, the Data Analytics Engineer is responsible for designing and building reliable data models and pipelines to provide large-scale data ingestion, aggregation, analysis and visualization projects for strategy and innovation insights, marketing and operations effectiveness, and outcomes measurement and reporting.

What’s ASA all about?

American Student Assistance (ASA) is a pioneer of student-led career learning helping millions of middle and high schoolers plan their futures – on their terms. Our mission is to radically transform the way careers are planned and pursued, and we’re doing this by creating digital tools that empower students to explore education and careers that align with their goals.

Since our founding in 1956, ASA has been at the forefront of educational innovation for middle and high school students nationwide. Our work has consistently adapted to meet their needs in a changing education landscape, and today, we’re focused on developing resources and opportunities that support students during the transition from high school into their careers.

ASA is a hybrid workplace with 2 required in office workdays per week on Tuesdays and Wednesdays.

As ASA expands its digital transformation to drive its mission of creating resources and solutions for teenagers’ exploring their options for post-High School planning, it is seeking new and talented data analysts and engineers. Under the direction of the Senior Director of Strategic Insights & Program Outcomes, the Data Analytics Engineer is responsible for designing and building reliable data models and pipelines to provide large-scale data ingestion, aggregation, analysis and visualization projects for strategy and innovation insights, marketing and operations effectiveness, and outcomes measurement and reporting.

The senior data analytics engineer’s responsibilities are to:

1) Drive business impact by identifying and acquiring or mining data from multiple and diverse sources for actionable insights (including digital session web data, Salesforce and other CRM/CDP/IAM platforms, Google Analytics and Google BigQuery, etc.).

2) Manage the inflow and governance of that data as we warehouse it for staging, processing, and reporting, while building proper data quality detection to identify data issues in the transformation stages and fix problems to meet pipelines/table health SLAs, etc.

3) Deliver timely and high-quality analytics to internal and external stakeholders across product management, operations, marketing, partnerships, innovation and executive teams as they make data-informed decisions

4) Provide oversight/quality control direction to internal and external engineers/analysts, including development of talent, management of key 3rd party development and support services, etc.

Essential Functions:

Develop, validate, monitor, and improve analytics and advanced modeling initiatives used to determine operational effectiveness, program outcomes, targeting initiatives and customer analysis to support insights development and strategic initiatives
Translate business requirements into technical specifications; establish and define details, definitions, and requirements of applications, components and enhancements
Explore, find, and strategize new uses from multiple, existing data sources to gain maximum insight
Design, build, and implement data pipelines and automated processes to enhance or create new data sets for use in analyzing trends and patterns, and production of custom reports and dashboards
Identify opportunities to collect and supplement analysis with external data, data partnerships, etc.
Present and communicate data findings, i.e., discover “stories” hidden in the data to Insights & Outcomes and other business leaders to help the organization understand operational outcomes performance, challenges, goals and provide recommendations on use of this information
Research external outcomes studies and reconstruct methodologies to develop comparable metrics
Maintain awareness of evolving analytical techniques, software and data sources to bring innovative approaches into the organization that drives higher quality results;
Contribute towards a robust best practices and governance program with respect to data discoverability, observability, lineage, stewardship and security strategies for protecting sensitive information and content
All other duties as assigned

Education & Experience:

Computer Science, Math, Statistics, Engineering or other quantitative field or equivalent experience,

6+ years in a data analyst, business analytics engineer, business intelligence analyst or data analyst or related role with SQL experience and object oriented programming/scripting such as Python
Expertise in business intelligence, data visualization and dashboarding platforms (e.g., Tableau, Dataiku, Looker, etc.)
Strong knowledge of data management and modern data warehouse (Snowflake, Big Query) and ELT data acquisition/model building tools (Rivery, Fivetran), as well as dbt
Experience in dimensional data modeling and schema design, statistics and predictive modeling
Experience working with agile development methodologies such as Sprint and Scrum
Not required, but would be ideal if also had experience in providing leadership or mentorship to other engineers that fosters collaboration, knowledge sharing and high quality expectations

Skills:

Strong critical thinking skills and ability to relate them to the services the company is providing
Ability to think and research creatively, possesses strong exploratory analysis and problem-solving skills, and is detail oriented
Extensive knowledge of industry practices
Demonstrated excellent verbal and written communication skills as well as the ability to bridge the gap between data and business by translating data results to strategic advice
Entrepreneurial spirit; ability to take the initiative to accomplish tough tasks and identify alternative solutions
Able to use deep breadth of analytics and market knowledge to guide strategy decisions by brand directors and provide support for those decisions in discussions with senior executives
Demonstrated excellent code writing abilities in programming languages like SQL (Structured Query Language), SAS, and SPSS (must pass a proficiency exam)
Proficient with Microsoft Office applications required; including SSRS reporting tool
Experience with digital and web analytics, and direct marketing a plus
Must provide examples of output related to described skill

Does a career at ASA align with your professional goals? Great! We look forward to reading your application.",1956,Civic & Social Services,$25 to $100 million (USD),Nonprofit & NGO,51 to 200 Employees,Nonprofit Organization,True
"Data Scientist/Research Software Engineer, Department of Research and Faculty Development","Harvard University
","Boston, MA",-1,4.3,"Position Description

Harvard Business School, whose mission is to educate leaders who make a difference in the world, is seeking a Data Scientist/Research Software Engineer to join its Research Computing Services (RCS) group within the Division of Research and Faculty Development (DRFD).

The Data Scientist/Research Software Engineer contributes to the school’s research community and RCS team through his/her knowledge of data science and research software engineering. The ideal candidate has experience with multiple steps in the data life cycle, including data acquisition, data processing, data management, analysis, and visualization, preferably in a research environment; and brings technical programming expertise developing and maintaining research software packages using advanced cyberinfrastructure. You will have a history of successful collaborations, particularly in a service delivery environment, and exhibits a high level of independence, judgment, and intellectual curiosity.

Reporting to the Sr. Director of Research Computing Services, the Data Scientist/Research Software Engineer’s primary responsibilities include:
Managing and contributing to faculty data science projects, including those that involve large/complex data sets, optimizing/enhancing code, developing algorithms, and machine learning.
Developing and supporting new research software along with optimizing and enhancing the performance of existing software and libraries.
Leveraging cluster and cloud computing capabilities including advanced research computing in the cloud, to meet faculty research computing needs.
Resolving short-term research-related questions and problems, including those related to optimizing code and enhancing performance.
Identifying and applying cutting-edge techniques and computational tools, and advising and training researchers in the use of these tools.
Working with RCS partners to coordinate and collaborate on faculty project work; scoping projects; and assessing the skill level of their job candidates.
Collaborating with other team members through knowledge-sharing and promotion of best practices (e.g., code review, technology showcase).
Working independently with sound judgment, directly accountable for accuracy of methods and results.
Working on multiple projects simultaneously, balancing short and long-term projects to meet deadlines and faculty needs.
Ensuring adherence to policies related to the use of data from external sources.
Ability to perform the essential duties of the position with or without reasonable accommodation
This role is responsible for other duties as assigned

Basic Qualifications

Minimum of five years’ post-secondary education or relevant work experience

Additional Qualifications and Skills

Required Qualifications:
BA in quantitative (or related) field + 5-7 years of related experience, OR; MA in quantitative (or related) field + 3-5 years of related experience, OR; PhD + 0-2 years of related experience.
Applied use of multiple programming packages such as R, Python, C++, and/or Stata for statistics, data science and/or research software engineering
Additional Preferred Qualifications:
Meticulous attention to detail and demonstrated ability to produce consistently high-quality work product. Experience with (or openness to training on) Machine Learning.
Exemplary customer service orientation, initiative, and the ability to anticipate and plan for customer needs.
Strong written and oral communication skills; ability to communicate complex technical topics to lay audiences as well as knowledgeable individuals.
Ability to work independently and collaboratively on an academic research team.
Demonstrated ability and desire to develop and maintain expertise in emerging research methods and technologies.
Flexibility and capacity to multi-task and meet competing deadlines.

Additional Information

This role is offered as a hybrid (some combination of onsite and remote) where you are required to be onsite at our Boston, MA based campus 3 days per week. Specific days and schedule will be determined between you and your manager.

We may conduct candidate interviews virtually (phone and/or via Zoom) and/or in-person for this role.

A cover letter is required to be considered for this opportunity.

Harvard Business School will not offer visa sponsorship for this opportunity.

Culture of Inclusion: The work and well-being of HBS is profoundly strengthened by the diversity of our network and our differences in background, culture, national origin, religion, sexual orientation, and life experiences. Explore more about HBS work culture here https://www.hbs.edu/employment.

Benefits

We invite you to visit Harvard's Total Rewards website (https://hr.harvard.edu/totalrewards) to learn more about our outstanding benefits package, which may include:

Paid Time Off: 3-4 weeks of accrued vacation time per year (3 weeks for support staff and 4 weeks for administrative/professional staff), 12 accrued sick days per year, 12.5 holidays plus a Winter Recess in December/January, 3 personal days per year (prorated based on date of hire), and up to 12 weeks of paid leave for new parents who are primary care givers.
Health and Welfare: Comprehensive medical, dental, and vision benefits, disability and life insurance programs, along with voluntary benefits. Most coverage begins as of your start date.
Work/Life and Wellness: Child and elder/adult care resources including on campus childcare centers, Employee Assistance Program, and wellness programs related to stress management, nutrition, meditation, and more.
Retirement: University-funded retirement plan with contributions from 5% to 15% of eligible compensation, based on age and earnings with full vesting after 3 years of service.
Tuition Assistance Program: Competitive program including $40 per class at the Harvard Extension School and reduced tuition through other participating Harvard graduate schools.
Tuition Reimbursement: Program that provides 75% to 90% reimbursement up to $5,250 per calendar year for eligible courses taken at other accredited institutions.
Professional Development: Programs and classes at little or no cost, including through the Harvard Center for Workplace Development and LinkedIn Learning.
Commuting and Transportation: Various commuter options handled through the Parking Office, including discounted parking, half-priced public transportation passes and pre-tax transit passes, biking benefits, and more.
Harvard Facilities Access, Discounts and Perks: Access to Harvard athletic and fitness facilities, libraries, campus events, credit union, and more, as well as discounts to various types of services (legal, financial, etc.) and cultural and leisure activities throughout metro-Boston.

Job Function

Information Technology

Department Office Location

USA - MA - Boston

Job Code

I1157P IT RC Facilitation Prof III

Work Format

Hybrid (partially on-site, partially remote)

Sub-Unit

-

Salary Grade

057

Department

Division of Research and Faculty Development

Union

00 - Non Union, Exempt or Temporary

Time Status

Full-time

Pre-Employment Screening

Education, Identity

Commitment to Equity, Diversity, Inclusion, and Belonging

Harvard University views equity, diversity, inclusion, and belonging as the pathway to achieving inclusive excellence and fostering a campus culture where everyone can thrive. We strive to create a community that draws upon the widest possible pool of talent to unify excellence and diversity while fully embracing individuals from varied backgrounds, cultures, races, identities, life experiences, perspectives, beliefs, and values.

EEO Statement

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation, pregnancy and pregnancy-related conditions, or any other characteristic protected by law.",1636,Colleges & Universities,$10+ billion (USD),Education,10000+ Employees,College / University,False
Principal Data Engineer,"Geode Capital Management
","Boston, MA",$116K - $156K (Glassdoor est.),3.5,"Geode Capital Management is actively searching for a full-time Principal Data Engineer to become an integral part of our Data team. The Principal Data Engineer will play a very critical role within our data team by providing technical leadership, implementation expertise, design best practices and guiding other highly skilled and motivated data engineers. In this capacity, you will work closely with the analytics team, architecture, and data analysts to gather requirements and contribute to the development of a best-in-class analytics platform centered around Snowflake and Tableau.

This is a hybrid work environment with a weekly in-office schedule of Tuesdays, Wednesdays, and Thursdays with remote work availability on Mondays and Fridays.

Responsibilities:
Build best in class analytics platform for our business teams to gain insights from our data
Collaborate with Product owners, Analytics Lead, Scrum Master, and Development teams to build effective data integration pipelines and Rest APIs on hosted data
Mentor new or junior team members and participate in code reviews
Collaborate in design, development, and implementation of software and data solutions
Collaborate with development team in building innovative, event driven, API-first cloud native solutions using AWS platform, Snowflake, Snaplogic, Tableau, Python and Rest APIs
iteratively deliver high quality products to enable our investment business, operations, analytics, and Client reporting
Skills You Bring:
A Bachelor’s or Master’s degree in computer science or a similar field
5+ years of software and or data engineering experience
Strong implementation experience with snowflake ecosystem, knowledge of Snowflake architecture and concepts
Strong background in modeling and building data warehouses
Strong working experience in Snowflake using warehouses, stored procedures, streams, snow pipes, tasks, stages, storage integration, ingestion frameworks and tools etc.
Ability to develop ELT/ETL pipelines to move data to and from Snowflake data store using combination of Python, dbt and SnowSQL
Strong experience in ETL/ELT technologies such as informatica, Snaplogic etc.
Hands on experience building cloud native applications using AWS or Azure
Good hands-on experience with scheduling tools such as Airflow, Control M, Autosys
Excellent SQL skills, writing SQL stored procedures and functions
Experience in leading teams, propose design, establish best practices and engineering discipline
Experience building reports, dashboards, and visualizations with business intelligence tools such as Tableau or Power BI is preferred
Experience with build/deploy automation & DevOps frameworks
Familiarity in building and consuming APIs (REST, API Gateway, etc.)
Possessing outstanding technical and analytical skills with strong business knowledge in the financial services domain
Good project management, experience in Agile methodologies (Kanban and SCRUM), communication, and interpersonal skills
Strong hands-on experience with requirements gathering analysis, coding, testing, implementation, maintenance, and review.
Company Overview:
Founded in 2001, Geode is headquartered in Boston’s financial district, the center of one of the world’s most vibrant finance and technology hubs and employs approximately 170 employees.

Geode is a systematic asset manager providing core beta exposures across a range of equity and niche asset classes, with over $1 trillion in AUM as of September 30, 2023. With a robust infrastructure and experienced investment professionals, Geode offers the scale of a large asset management firm with the benefits of a smaller organization.

Geode is proud to be an equal opportunity employer and support a diversified work environment. Learn more about Geode at www.geodecapital.com/careers.",2001,Investment & Asset Management,Unknown / Non-Applicable,Financial Services,51 to 200 Employees,Company - Private,True
Senior Data Engineer,"GSK
","Cambridge, MA",$121K - $160K (Glassdoor est.),4.1,"The Onyx Research Data Platform organization represents a major investment by GSK R&D and Digital & Tech, designed to deliver a step-change in our ability to leverage data, knowledge, and prediction to find new medicines. We are a full-stack shop consisting of product and portfolio leadership, data engineering, infrastructure and DevOps, data / metadata / knowledge platforms, and AI/ML and analysis platforms, all geared toward:

Building a next-generation data experience for GSK’s scientists, engineers, and decision-makers, increasing productivity, and reducing time spent on “data mechanics”
Providing best-in-class AI/ML and data analysis environments to accelerate our predictive capabilities and attract top-tier talent
Aggressively engineering our data at scale to unlock the value of our combined data assets and predictions in real-time

Data Engineering is responsible for the design, delivery, support, and maintenance of industrialised automated end to end data services and pipelines. They apply standardised data models and mapping to ensure data is accessible for end users in end-to-end user tools through use of APIs. They define and embed best practices and ensure compliance with Quality Management practices and alignment to automated data governance. They also acquire and process internal and external, structure and unstructured data in line with Product requirements.

A Senior Data Engineer is a leading technical contributor who can consistently take a poorly defined business or technical problem, work it to a well-defined data problem / specification, and execute on it at a high level. They have a strong focus on metrics, both for the impact of their work and for its inner workings / operations. They are a model for the team on best practice for software development in general (and data engineering in particular), including code quality, documentation, DevOps practices, and testing, and consistently mentor junior members of the team. They ensure robustness of our services and serve as an escalation point in the operation of existing services, pipelines, and workflows.

A Senior Data Engineer should be deeply familiar with the tools of modern data engineering (e.g. Spark, Kafka, Storm) and of their customers, and engaged with the open source community surrounding them – potentially, even to the level of contributing pull requests.

Key responsibilities for the Senior Data Engineer include:

Designs, builds, and operates data tools, services, workflows, etc that deliver high value through the solution to key business problems by leveraging modern data engineering tools (e.g. Spark, Kafka, Storm, …) and orchestration tools (e.g. Google Workflow, AirFlow Composer)
Confidently optimizes design and execution of complex solutions in data ingestion and data transformation
Produces well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Diverse problem solver who surfaces opportunities to reuse modular code and develop microservices to drive efficiencies
Provides input into the roadmaps of upstream teams (e.g. Data Platforms, DataOps, DevOps) to help improve the overall program of work
Ensure consistent application of platform abstractions to ensure quality and consistency with respect to logging and lineage
Fully versed in coding best practices and ways of working, and participates in code reviews and partnering to improve the team’s standards
Adhere to QMS framework and CI/CD best practices and helps to guide improvements to them that improve ways of working
Provide leadership to team members to help others get the job done right

Please view this video to get a better understanding of this role-

Why you?

Basic Qualifications:

We are looking for professionals with these required skills to achieve our goals:

Bachelor’s Degree in Data Engineering, Computer Science, Software engineering or related field
5+ years of data engineering experience
Experience with at least one common programming language: e.g., Python, Scala, Java, including toolchains for documentation, testing, and operations / observability
Cloud experience (e.g., AWS, Google Cloud, Azure, Kubernetes)
Experience in automated testing and design
Experience with DevOps-forward ways of working

Preferred Qualifications:

If you have the following characteristics, it would be a plus:

Deep expertise in modern software development tools / ways of working (e.g. git/GitHub, devops tools, metrics / monitoring, …)
Extensive cloud experience (e.g., AWS, Google Cloud, Azure, Kubernetes), including infrastructure-as-a-code
Application experience of CI/CD implementations using git and a common CI/CD stack (e.g. Jenkins, CircleCI, GitLab, Azure DevOps)
Demonstrated excellence with agile software development environments using tools like Jira and Confluence
Deep familiarity with the tools, techniques, etc of modern data engineering (e.g. Spark, Kafka, Storm, …) and orchestration (e.g. Google Workflow, AirFlow Composer), including engagement with the open source community (and potentially making contributions to such tools)
Strong experience in data modelling, database concepts and SQL
Familiarity with orchestrating tooling

Why GSK?

Our values and expectations are at the heart of everything we do and form an important part of our culture.

These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance, and trust, the successful candidate will demonstrate the following capabilities:

Agile and distributed decision-making – using evidence and applying judgement to balance pace, rigour and risk
Managing individual and team performance. Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.
Implementing change initiatives and leading change.
Sustaining energy and well-being, building resilience in teams.
Continuously looking for opportunities to learn, build skills and share learning both internally and externally.
Developing people and building a talent pipeline.
Translating strategy into action - a compelling narrative, motivating others, setting objectives and delegation.
Building strong relationships and collaboration, managing trusted stakeholder relationships internally and externally.
Budgeting and forecasting, commercial and financial acumen.

#LI-GSK

#GSKOnyx

The annual base salary for new hires in this position ranges from $145,877 to $197,363 taking into account a number of factors including work location, the candidate’s skills, experience, education level and the market rate for the role. In addition, this position offers an annual bonus and eligibility to participate in our share based long term incentive program which is dependent on the level of the role. Available benefits include health care and other insurance benefits (for employee and family), retirement benefits, paid holidays, vacation, and paid caregiver/parental and medical leave.

Please visit GSK US Benefits Summary to learn more about the comprehensive benefits program GSK offers US employees.

Why Us?

GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.

Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.

If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).

GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK’s compliance to all federal and state US Transparency requirements. For more information, please visit GSK’s Transparency Reporting For the Record site.",1830,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Company - Public,False
Principal Software Engineer- Storage and Data Management,"Oracle
",Massachusetts,-1,3.8,"Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc. As a member of the software engineering division, you will take an active role in the definition and evolution of standard practices and procedures. You will be responsible for defining and developing software for tasks associated with the developing, designing and debugging of software applications or operating systems. Work is non-routine and very complex, involving the application of advanced technical/business skills in area of specialization. Leading contributor individually and as a team member, providing direction and mentoring to others. BS or MS degree or equivalent experience relevant to functional area. 7-10 years of software engineering or related experience.




We are looking for proven technical architect and/or technical lead who has built and delivered high-scale intelligent services and experiences. You will work in a team of highly capable developers and applied scientists who are responsible for all stages of development life cycle. You are expected to own/drive platform architecture, design and implementations to deliver high-quality features and services. You are expected to work across teams in a highly collaborative environment. You will be responsible for providing technical leadership, deliver high quality code, set high standards through design/code reviews and mentor others on the team.

Required Qualifications

Bachelor’s in computer science and Engineering or related engineering fields.

10+ years experiences delivering and operating large scale, highly available distributed systems.

Preferred Qualifications

Proven development experience in Java, C#, C++
Proven experience in building and operating large-scale distributed storage and data management systems
Familiarity with database concepts (ACID properties) and relational and non-relational databases such as Postgres, Oracle DB, Cassandra, DynamoDB, Spanner, etc.
Familiarity with consensus protocols such as Paxos and Raft.
Experience delivering highly scalable REST or Micro services
Ability to learn quickly, strong analytic skills, passion for driving for results and strong customer empathy
Deep understanding of data structures, designing algorithms, data models, programming patterns and solving complex issues

Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will take an active role in the definition and evolution of standard practices and procedures. Define specifications for significant new projects and specify, design and develop software according to those specifications. You will perform professional software development tasks associated with the developing, designing and debugging of software applications or operating systems.

Provide leadership and expertise in the development of new products/services/processes, frequently operating at the leading edge of technology. Recommends and justifies major changes to existing products/services/processes. BS or MS degree or equivalent experience relevant to functional area. 8 or more years of software engineering or related experience.",1977,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Senior Data Engineer,"Labviva, Inc.
","Boston, MA",$107K - $145K (Glassdoor est.),2.5,"Senior Data Engineer
Location: Boston, MA
Category: Data/Analytics
Type: Full-time, Hybrid Boston Office


About the Role

As a Senior Data Engineer at Labviva, you will be charting the blueprint of data infrastructure for a leading marketplace in life science. You will be the first hire in the data engineering function and will join our growing team of analytics and data professionals, reporting to the VP Analytics and Data Science. You would be a great fit for the role if you are a data engineering expert knowledgeable of data architecture in Big Data. You have worked in a scaled e-commerce platform, preferably having experienced its growth stages. You are a self-starter who thrives in an ambiguous, fast-paced p environment. Success in this position will mature Labviva's approach to data to meet standards that are high quality (accurate, complete, consistent), comprehensive to meaningful business activity, easy to use properly and difficult to use incorrectly to drive the business forward.


How You Will Contribute

Work with internal/external resources to design and build a centralized business intelligence environment
Develop and implement data pipelines to ETL/ELT data from multiple sources into a data warehouse or data lake and monitor for data accuracy
Maintain data infrastructure in production and development environments
Provide data engineering support throughout product/solution lifecycle from research, development, testing to production
Improve operational efficiency by automating and streamlining data processes
Collaborate with stakeholders to develop and implement data governance procedures to ensure data security, privacy and compliance



What You Bring to the Team

Bachelor's degree in computer science, engineering or a related field
5+ years of experience with database design, data modeling, data pipelines, data warehousing/data lake
Retail/ecommerce data management expertise; e-Marketplace, supply chain management and/or data platform experience is a plus
Data governance and compliance experience in regulated industries are preferred
Public cloud experience; AWS preferred
Event driven architecture and microservices
Big Data technologies such as Kafka, Spark, Hadoop
Excellent working knowledge of SQL; proven ability to debug and optimize queries & procedures
PostgreSQL, MySQL, Microsoft SQL Server
NoSQL DBs such as MongoDB
Python, Java
Exposure to scaled enterprises andp mentality
Strong intellectual curiosity and self-motivation



About the Company

Labviva is on a mission to accelerate the pace of life science research. We connect researchers with suppliers of reagents, chemicals and instrumentation in an intuitive user-friendly platform that supports the priorities of scientists while staying compliant with purchasing rules.

We are a venture-funded start-up that acknowledges that the unique contributions of each team member drive our success. We commit to creating a diverse and inclusive workspace where people can make a positive impact. At Labviva, we invest in our employees and strongly believe that a culture of respect and support drives success for all involved.

We provide a competitive set of benefits including but not limited to a hybrid – office/remote work option, health benefits, flexible time off, parental leave, competitive salary and equity, and Thursday company lunches.

We are an equal opportunity employer and building a diverse team is our top priority. At Labviva, we celebrate all. Help us build an inclusive community that will transform the life sciences industry. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics as outlined by federal, state or local laws, regulations, or ordinances.",-1,Biotechnology,Unknown / Non-Applicable,Pharmaceutical & Biotechnology,Unknown,Company - Private,True
Lead Software Data Performance Engineer,"Klaviyo
","Boston, MA",$111K - $148K (Glassdoor est.),4.0,"At Klaviyo, we value the unique backgrounds, experiences and perspectives each Klaviyo (we call ourselves Klaviyos) brings to our workplace each and every day. We believe everyone deserves a fair shot at success and appreciate the experiences each person brings beyond the traditional job requirements. If you're a close but not exact match with the description, we hope you'll still consider applying. Want to learn more about life at Klaviyo? Visit careers.klaviyo.com to see how we empower creators to own their own destiny.

Klaviyo is growing fast and we have openings for all skill levels across all of our teams. Learn more about our engineering culture at https://klaviyo.tech

We love tackling tough engineering problems and look for Engineers who specialize in certain areas but are passionate about building, owning & scaling features end to end from scratch and breaking through any obstacle or technical challenge in their way. We push each other to move out of our comfort zone, learn new technologies and work hard to ensure each day is better than the last.

Klaviyo operates a real-time data platform built for massive scale on Amazon Web Services (AWS). Engineers come to Klaviyo with experience in a variety of languages and from a number of disciplines.

Team Overview:

The data platform team facilitates the storage and interactions with billions of data points per day. These data points power core, Klaviyo functionality and are leveraged by internal application teams to generate data-driven insights for our customers.

Responsibilities:

This team manages the foundation of Klaviyo analytics. You will have ownership over defining the evolutionary, technical vision of analytical data management at Klaviyo. As a lead engineer on this team, you will be responsible for coaching engineers, managing/reviewing technical documentation and articulating a phased approach to achieving the team's overall technical vision.

Team Tech Stack: Hudi, Clickhouse, MySQL, EMR, Airflow, Parquet, Kubernetes, Terraform, Spark, Kafka, Python

Required Skills:

Bachelor's degree or equivalent practical experience
8 years of experience in software development, and strong knowledge of computer science fundamentals
5 years of experience testing, developing, and launching software products, and 3 years of experience with software design and architecture
Hands-on experience designing reliable, fault-tolerant, and high performance distributed systems
Proven ability to come up to speed quickly
Experience applying multi-dimensional data models to analytical data for optimal storage and retrieval
Star Schema
Snowflake Schema
Data Vault
Knowledge of data algorithms and database internals. Examples include:
Building stream/batch processing applications
Understanding of search, range or probabilistic indices
Knowledge of B / LSM Trees
2+ years of professional experience using:
Hudi or Delta Lake
Clickhouse, Druid, Pinot or similar.
Cloud-based DFS (eg. AWS S3, Google Storage Buckets, Azure Blob Storage)

Preferred Skills:

3 years of experience in an architectural role leading project teams and setting technical vision
3 years of experience working in an organization involving cross-functional teams
2+ years of experience applying multi-dimensional data modeling for optimal storage and retrieval
Star Schema
Snowflake Schema
Data Vault
4+ years of experience designing systems leveraging:
Hudi or Delta Lake
Clickhouse, Druid, Pinot or similar.
Cloud-based DFS (eg. AWS S3, Google Storage Buckets, Azure Blob Storage)

The pay range for this role is listed below. Sales roles are also eligible for variable compensation and hourly non-exempt roles are eligible for overtime in accordance with applicable law. This role is eligible for benefits, including: medical, dental and vision coverage, health savings accounts, flexible spending accounts, 401(k), flexible paid time off and company-paid holidays and a culture of learning that includes a learning allowance and access to a professional coaching service for all employees.

Pay Range For US Locations:

$192,000—$288,000 USD

Get to Know Klaviyo

We're Klaviyo (pronounced clay-vee-oh). We empower creators to own their destiny by making first-party data accessible and actionable like never before. We see limitless potential for the technology we're developing to nurture personalized experiences in ecommerce and beyond. To reach our goals, we need our own crew of remarkable creators—ambitious and collaborative teammates who stay focused on our north star: delighting our customers. If you're ready to do the best work of your career, where you'll be welcomed as your whole self from day one and supported with generous benefits, we hope you'll join us.

Klaviyo is committed to a policy of equal opportunity and non-discrimination. We do not discriminate on the basis of race, ethnicity, citizenship, national origin, color, religion or religious creed, age, sex (including pregnancy), gender identity, sexual orientation, physical or mental disability, veteran or active military status, marital status, criminal record, genetics, retaliation, sexual harassment or any other characteristic protected by applicable law.

IMPORTANT NOTICE: Our company takes the security and privacy of job applicants very seriously. We will never ask for payment, bank details, or personal financial information as part of the application process. All our legitimate job postings can be found on our official career site. Please be cautious of job offers that come from non-company email addresses (@klaviyo.com), instant messaging platforms, or unsolicited calls. If you suspect a fraudulent job posting or receive suspicious communications that appear to be from our company, please contact us immediately at HR@klaviyo.com.

You can find our Job Applicant Privacy Notice here.",2012,Internet & Web Services,Unknown / Non-Applicable,Information Technology,1001 to 5000 Employees,Company - Private,False
"Sr. Software Dev Engineer, Data Producer eXperience (DPX)","Amazon.com Services LLC
","Boston, MA",$114K - $166K (Glassdoor est.),3.7,"5+ years of non-internship professional software development experience
5+ years of programming with at least one software programming language experience
5+ years of leading design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience as a mentor, tech lead or leading an engineering team
Are you interested in working with the latest technology in the cloud computing space?

The Amazon Foundational People Data Services (FPDS) organization is building cutting-edge solutions to enable employees and managers to self-serve changes across all human resource processes.

Join us in building an innovative technology using Amazon Web Services to meet the complex and unique demands of managing nearly 3,000,000 employees globally. We dive deep to insist on the highest standards in architecture, coding, testing, deploying, and maintaining every aspect of our offerings.

Mentorship & Career Growth: Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship.

Work/Life Balance: Our team also maintains an inclusive team culture, and we put a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success.

We are looking for developers with solid computer science fundamentals, including data structures, object-oriented design, algorithm design, problem-solving, and complexity analysis. We want to talk to you if you have a track record of designing and building scalable, complex solutions across distributed systems in an agile environment.

Key job responsibilities

Architect and build highly available software components in a distributed architecture
Collaborate with cross-functional teams
Define and drive software best practices, including coding standards, code reviews, source control management, agile development, build processes, and testing
Coach and mentor engineers on the team to foster a supportive culture of collaboration, scalability, and performance
A day in the life
You'll work on cutting-edge projects at the forefront of innovation, pushing boundaries and creating solutions that are shaping the future. You'll be surrounded by a team of talented individuals who are passionate about what they do. In this role, you'll have the unique ability to influence software architecture on a global scale. Your expertise and insights will have a direct impact on how our products are developed and implemented worldwide. You'll be working on projects that directly impact our customers and contribute to their success. And while you're making a difference, you'll also have continuous learning and professional growth opportunities.

About the team
The Data Producer eXperience (DPX) organization’s primary mission is to enable data producers to securely and efficiently store, describe, and vend data to downstream data consumers at Amazon scale, providing a seamless experience with greater visibility, security and privacy built into all of our services. We strive to empower data producers to get their data to market faster with improved time to value.
Our teams provide access and storage of human capital information to an extensive ecosystem across Amazon and its associated vendors as we build new systems to take us into the future. Data from our platform is vital to calculate compensation, payroll, benefits, hiring, onboarding and separation activities, security and access controls, fulfillment center operations, and provide many other low-friction business processes and world-class experiences for everyone at Amazon who innovates on behalf of our customers.
Our engineers continuously strive to build and run an infrastructure that can process billions of queries, provide data consistency and availability-related solutions in a distributed systems architecture, functional data materialization for unique business use cases, data visualization and analytics products, and set up data privacy controls. We are building a one-of-a-kind cloud-native platform uniquely positioned to accelerate delivering customer value across Amazon!

We are open to hiring candidates to work out of one of the following locations:

Boston, MA, USA


5+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",1994,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Data Systems Architect / Data Engineer,"M/A Com Technolgy Solutions
","Lowell, MA",$83K - $121K (Glassdoor est.),3.6,"MACOM designs and manufactures semiconductor products for Data Center, Telecommunication and Industrial and Defense applications. Headquartered in Lowell, Massachusetts, MACOM has design centers and sales offices throughout North America, Europe and Asia. MACOM is certified to the ISO9001 international quality standard and ISO14001 environmental management standard.

MACOM has more than 65 years of application expertise with multiple design centers, Si, GaAs and InP fabrication, manufacturing, assembly and test, and operational facilities throughout North America, Europe, and Asia. Click here to view our facilities. In addition, MACOM offers foundry services that represents a key core competency within our business.
MACOM sells and distributes products globally via a sales channel comprised of a direct field sales force, authorized sales representatives and leading industry distributors. Our sales team is trained across all of our products to give our customers insights into our entire portfolio.


Data Systems Architect / Data Engineer

Responsible for investigating existing systems and providing architectural guidance, technological recommendations, and transitions strategies for the MACOM engineering data system and manufacturing execution system. The Data Systems Architect will improve and maintain large-scale data solutions that make use of on-premises databases and cloud solutions which organize disparate real time data streams from globally deployed test systems for future analysis. This work is the foundation for data access and querying according to the business needs. Must be passionate about data and have a strong understanding of the related initiatives such as data governance, quality, security, and processes. Must have a hands-on approach to database warehouse and cloud data lake technologies. A strong understand of the benefits and tradeoffs of technical stack and design decisions in support of manufacturing and engineering stakeholders is important. Will work with a highly collaborative team focused on building and supporting systems and solutions from the ground up.

Responsibilities:



Individual in this role will be working with the data team to improve data accessibility within the organization
Support various teams across MACOM with their data needs
Develop and deploy data pipeline to collect data from various sources and store in cloud
Assist in development of tools that allow users to access data stored in cloud and on-prem databases
Collaborate with other members of the team to enable creative problem solving.

Job Qualifications:

3+ years’ experience in a data engineering, architecture, or data analysis role

Bachelor’s Degree in Computer Science or related field required (Master’s degree preferred)

Proven ability to work in distributed systems

Must be able to develop creative solutions to problems

Strong analytical and creative thinking skills for effective and timely decision-making.

Strong communication skills – oral, written, and presentation.

Strong inter-personal skills and ability to motivate team members.

Ability to make work fun and contribute to the collaborative environment of the team

Work Authorization: Because this position will work with ITAR restricted data, qualified candidates must be a U.S. Citizen or U.S. Permanent Resident.

Preferred Skills:

Hands on experience with AWS platforms and tools (including but not limited to S3, QuickSight, Lambda, Athena, SAM)
Fluent in SQL and at scripting languages (Python, Java preferred)
Experience with building data pipeline and ETL
Strong understanding of relational and no-SQL databases
Knowledge of data ingestion using spark for supporting various file types like Json, Xml, Csv and databases
Able to architect high availability, high performance systems with zero risk of data loss
Knowledge of development methodologies like Agile, Scrum, DevOps and test-driven development.
Knowledge of API, Apache Spark, Grafana, Loki, Git, Docker, Linux
Experience uniting disparate legacy data sources into a unified platform for analysis and operations
AWS certifications a plus
Data Engineer certification a plus
Experience in the semiconductor industry is a plus

EEO:

MACOM is an Equal Opportunity Employer committed to a diverse workforce. MACOM will not discriminate against any worker or job applicant on the basis of race, color, religion, gender, gender identity, gender expression, national origin, ancestry, age, sexual orientation, marital or civil partnership status, pregnancy, disability, genetic information, veteran status, military obligations, or membership in any other category protected under applicable law.

Reasonable Accommodation:

Reasonable Accommodation. MACOM is committed to working with and providing reasonable accommodations to qualified individuals with physical and mental disabilities. If you have a disability and are in need of a reasonable accommodation with respect to any part of the application process please call +1-978-656-2500 or email HR_Ops@MACOM.com. Provide your name, phone number and the position title and location in which you are interested, and nature of accommodation needed, and we will get back to you. We also work with current employees who request or need reasonable accommodation in order to perform the essential functions of their jobs.",1950,Electronics Manufacturing,$100 to $500 million (USD),Manufacturing,1001 to 5000 Employees,Company - Public,False
SaaS Data Engineer and Architect,"Edenred
","Waltham, MA",$94K - $139K (Glassdoor est.),4.0,"Take a step forward and let Edenred surprise you.
Every day, we deliver innovative solutions to improve the life of millions of people, connecting employees, companies, and merchants all around the world.
We know there are hundred ways for you to grow. With us, you will expand your skills in a multicultural, challenging, and dynamic environment.
Dare to join Edenred and get ready to thrive in a global company that will offer you endless opportunities.
Are you interested in joining a remarkable company where your contributions truly matter? Edenred offers a fast-paced, high-energy, innovative, global, and team-oriented culture with a flexible and exciting work environment, as well as plenty of opportunities for you to grow as a professional and as an individual.
We are currently seeking a SaaS Data Engineer and Architect who is passionate about delivering data warehousing platform at scale and designing data storage, processing, and analytics capabilities for our rapidly expanding Fleet and Mobility business unit in North America. As part of our flexible working arrangements, we are offering a hybrid office environment in which team members work from the office two days a week.
Essential Functions: Duties and Responsibilities:
Design and architect data services and data infrastructure in Azure to deliver a reliable, scalable, secure, and performant SaaS platform.
Propose, develop, and deliver disruptive features to Edenred Fleet and Mobility offering
Take charge of strategic and tactical responsibilities related to data strategy and data roadmap in the team and bring them to completion
Contribute towards leading and influencing experienced and accomplished software engineers inside and outside of the Fleet and Mobility development team.
Drive results with clearly defined priorities, effective resource allocation, and communication of goals.
Work with customer support to address escalations, participate in the on-call rotation for production issues and escalations, and identify the root cause for escalated issues
Perform other duties as assigned.
Required Skills/Abilities:
10+ years of practical experience with cloud-based data warehousing platforms and databases, such as Snowflake, Azure Cosmos DB, Azure SQL, or others; and hands-on enterprise software development experience at scale
5+ years of practical experience with Cloud based development – Azure, AWS or GCP and data services provided through one of these Cloud vendors.
Hands-on experience with establishing data governance and capabilities to expose data safely in a multi-tenant Cloud environment
5+ years of practical query and database performance tuning experience through changes in SQL, database schema and cloud vendor infrastructure
Champion data analytics roadmap and mentality to drive every decision with data in the business unit
Excellent understanding of observability principles and technologies, e.g., experience integrating DataDog or others to properly manage and monitor the data warehousing platform
Excellent written & oral communication and interpersonal skills and ability to create and maintain technical documentation
Strong creative logical problem-solving skills required.
Strong planning, organizing, and coordinating skills required.
It is a bonus if you have…
Experience with machine learning data products
Experience with data engineering ecosystem design and implementation
Experience with payment (i.e., commercial cards), fintech, or B2B services or compliance requirements such as PCI, SOC2, etc.
Education:
Bachelor’s degree in a related field. Equivalent combination of education and experience will be considered.
Affirmative Action/EEO Statement:

Edenred is an equal opportunity organization. We recruit, employ, train, compensate, and promote without regard to race, religion, color, national origin, age, gender, sexual orientation, gender identity, marital status, disability, protected veteran status, or any other basis protected by applicable federal, state, or local law. Edenred is committed to providing access, equal opportunity, and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, contact
humanresources@edenredusa.com
.
Apply now and Vibe with Us!",2010,Financial Transaction Processing,$1 to $5 million (USD),Financial Services,5001 to 10000 Employees,Company - Public,False
Google Cloud Platform Data Engineer,"Publicis Sapient
","Boston, MA",$115K - $150K (Employer est.),3.7,"Google Cloud Platform Data Engineer
Full-time

Company Description

Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value.

Job Description

This position requires in-depth knowledge and expertise in GCP services, architecture, and best practices. Will work closely with clients to understand their business objectives and develop strategies to leverage GCP to meet their needs. They will collaborate with cross-functional teams to design, implement, and manage scalable and reliable cloud solutions. They will also be responsible for driving innovation and staying up-to-date with the latest GCP technologies and trends to provide industry-leading solutions.

Your Impact:

Collaborate with clients to understand their business requirements and design GCP architecture to meet their needs.
Develop and implement cloud strategies, best practices, and standards to ensure efficient and effective cloud utilization.
Work with cross-functional teams to design, implement, and manage scalable and reliable cloud solutions on GCP.
Provide technical guidance and mentorship to the team to develop their skills and expertise in GCP.
Stay up-to-date with the latest GCP technologies, trends, and best practices and assess their applicability to client solutions.
Drive innovation and continuous improvement in GCP offerings and services to provide industry-leading solutions.
Collaborate with sales and business development teams to identify and pursue new business opportunities related to GCP.
Ensure compliance with security, compliance, and governance requirements in GCP solutions.
Develop and maintain strong relationships with clients, vendors, and internal stakeholders to promote the adoption and success of GCP solutions.

Qualifications
Must have good implementation experience on various GCP’s Data Storage and Processing services such as BigQuery, Dataflow, Bigtable, Dataform, Data fusion, cloud spanner, Cloud SQL
Must have programmatic experience with tools like Javascript, Python, Apache Spark.
Experience in building advance Bigquery SQL and Bigquery modelling is required
Experience in orchestrating end-end data pipelines with tools like cloud composer, Dataform is highly desired.
Experience in managing complex and reusable dataflow pipelines is highly desired.

What sets you apart:

Experience in complex migrations from legacy data warehousing solutions or on-prem datalakes to GCP
Experience in maneuvering resources in delivering tight projects
Experience in building real-time ingestion and processing frameworks on GCP.
Adaptability to learn new technologies and products as the job demands.
Experience in implementing Data-governance solutions
Knowledge in AI, ML and GEN-AI use cases
Multi-cloud & hybrid cloud experience
Any cloud certification

Additional Information
Flexible vacation policy; Time is not limited, allocated, or accrued
16 paid holidays throughout the year
Generous parental leave and new parent transition program
Tuition reimbursement
Corporate gift matching program

Career Level: Senior Associate

Base Salary Range for the Role: 115,000-150,000 (varies depending on experience)

The range shown represents a grouping of relevant ranges currently in use at Publicis Sapient. Actual range for this position may differ, depending on location and specific skillset required for the work itself.

Learn more about us at www.publicissapient.com or explore other career opportunities careers.publicissapient.com.

As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at [email protected] or you may call us at +1-617-621-0200.",1990,Business Consulting,Unknown / Non-Applicable,Management & Consulting,10000+ Employees,Company - Public,False
Traffic Data Collection Field Operations Engineer,"Mass Dept of Transportation
","Concord, MA",$83K - $117K (Employer est.),3.6,"Position Summary

Incumbents of positions in this series prepare or review plans, designs, specifications and cost estimates for engineering projects; prepare and/or review reports, studies and analytical data; perform calculations relating to engineering problems; perform engineering surveys; inspect construction and/or maintenance work; and perform professional engineering duties in such areas as highways, bridges, buildings and facilities all in accordance with sound engineering principles, applicable laws, regulations and standards. The basic purpose of this work is to perform professional engineering duties in such areas as highways, bridges, buildings, and facilities all in accordance with sound engineering principles, applicable laws, regulations, and standards. The Traffic Data Collection Field Operations Engineer will have full oversight of all field traffic data counting equipment across all 6 Districts within the MassDOT Highway Division.

The incumbent shall be responsible for traffic data collection equipment specifications, construction means and methods and defining calibration and testing requirements. This includes working with MassDOT Project Delivery to ensure adherence to all specifications for the design of new, replacement and maintenance of all field traffic data collection equipment. The incumbent will work directly with District Construction, including area construction engineer, resident engineer, and construction inspectors to ensure contractor compliance with traffic data collection equipment installation, replacement and maintenance in the field, and the validation of equipment calibration and operation before acceptance. The Field Operations Engineer will have direct oversight of the field data collection crews to ensure compliance with standard operating procedures, and the safe and efficient installation/removal of field data collection equipment.

Construction Experience and knowledge of plans, specifications and estimates is preferred.

Duties and Responsibilities

Supervise and manage the daily functions of maintaining the Statewide Traffic Data Collection Program in accordance with the FHWA's Traffic Monitoring Guide. Which includes the detailed scheduling and implementation of the coverage, ramp, and special counting programs.
Designs and implements the yearly Traffic data Collection Program in accordance with management guidance and information.
Responsible for coordinating work activity necessary to complete project related requests for traffic data, including analysis and finalization of data.
Coordinate with other MassDOT Districts and Units as necessary to further the goals of the TDC Unit.
Coordinate with MassDOT Toll Maintenance Group for repair of TDC count stations as needed.
Assist in the coordination with state police for support for traffic count installation, as required.
Prepares plans, specifications and estimates for the installation of traffic data collection stations, working with numerous Sections (Construction, Design, ITS, etc.) of MassDOT (highway) staff and Contractors to ensure adherence to established specifications and standard practices (This includes the Traffic Section’s Telemetry Upgrade).
Coordinates and processes all special count data, this includes site studies, correspondence, processing, editing and all aspects of work.
Recommends and approves equipment needs and new systems.
Ensures field staff are properly trained on work zone safety and proper traffic data collection installation and removal procedures in accordance with state and federal requirements.
Performs EPRS reviews and resolves all personnel matters where they arise.
Interacts with other Department Sections on Traffic and Transportation issues to make sure all needs are met.
Interacts with vendors on the procurement, testing, and evaluation of products to ensure that desired results are being achieved.
Acts as database manager for WEB based traffic count database MS2.
Acts as database manager for WEB based turning movement count database Miovision.

The position of Traffic Data Collection Field Operations Engineer may be required to work weekend shifts on overtime to support the MassDOT Traffic Data Collection operational needs.

This position is eligible for a five-thousand dollar ($5,000) signing bonus (“Signing Bonus”) if you are newly hired into the Unit E collective bargaining unit at MassDOT. The Signing Bonus will be paid in two parts: 1) $3,000 (less applicable taxes) included in the employee's first paycheck. 2) $2,000 (less applicable taxes) after the successful completion of the employee’s probationary period. Only candidates external to the Massachusetts Department of Transportation are eligible for the sign-on bonus.

About MassDOT

The 4,000+ employees of Massachusetts Department of Transportation (MassDOT) take great pride in connecting the Commonwealth’s residents and communities. MassDOT is responsible for developing, implementing, and coordinating transportation policies and projects for the Commonwealth of Massachusetts and to efficiently plan, design, construct, and maintain a safe statewide transportation system which effectively meets the transportation needs of the Commonwealth. Information about MassDOT’s inclusive culture and career opportunities can be found at mass.gov/massdot-careers.

MassDOT’s divisions include Highway, Registry of Motor Vehicles, Aeronautics, and Rail & Transit. Headquarters (Planning & Enterprise Services) provides business and administrative support and policy leadership for each of the four (4) divisions.



Qualifications


Minimum Entrance Requirements

This requisition will remain open until filled; however, first consideration will be given to those applicants that apply within the first 14 days.

All job applications must be submitted online through MassCareers to be considered.

Please provide a complete, accurate and current resume / application for MassDOT to review in order to determine if your submitted materials meet the minimum entrance requirements for the position.

Applicants must have at least (A) four years of full-time, or equivalent part-time, technical or professional experience in civil engineering work in such areas as construction, survey, design, transportation, hydraulics, structural, sanitary, drafting, environmental, highway, architectural, airport, soils and materials, of which (B) at least two years must have been in a professional capacity, or (C) any equivalent combination of the required experience and the substitutions below.

Substitutions:

An Associate's degree with a major in civil engineering** or civil engineering technology** may be substituted for a maximum of one year of the required (A) experience. *

A Bachelor's degree with a major in civil engineering** or civil engineering technology**, may be substituted for a maximum of two years of the required (A) experience. *

A Graduate degree with a major in civil engineering**, may be substituted for a maximum of three years of the required (A) experience and one year of the required (B) experience. *

**NOTE: The terms civil engineering and civil engineering technology include related engineering disciplines such as construction, survey, design, transportation, hydraulics, structural, soils, sanitary, environmental, drafting, highway, architectural, mining, airport, and materials.

Education toward such a degree will be prorated on the basis of the proportion of the requirements actually completed.

NOTE: Educational substitutions will only be permitted for a maximum of one year of the required (B) experience.

SPECIAL REQUIREMENT: Based on assignment, possession of a current and valid Massachusetts Class D Motor Vehicle Operator's License may be required.

FOR NON-MassDOT APPLICANTS:

Applicants for this position must possess a Bachelor’s Degree in an appropriate engineering discipline.

FOR MassDOT EMPLOYEES:

Applicants for this position must possess a Bachelor’s Degree in an appropriate engineering discipline or hold a position in the Department in one of the next two lower titles than the position applied for, in the same or similar career ladder.

Comprehensive Benefits

When you embark on a career with the Commonwealth, you are offered an outstanding suite of employee benefits that add to the overall value of your compensation package. We take pride in providing a work experience that supports you, your loved ones, and your future.

Want the specifics? Explore our Employee Benefits and Rewards!

For questions regarding the job posting, please email LaTanya Wood at latanya.wood@dot.state.ma.us.
For general questions regarding MassDOT, call the Human Resources Service Center at 857-368-4722.
For a disability-related reasonable accommodation or alternative application method, call The Diversity Officer, Derrick Mann 857-368-8541.

An Equal Opportunity / Affirmative Action Employer. Females, minorities, veterans, and persons with disabilities are strongly encouraged to apply.

The Commonwealth is an Equal Opportunity Employer and does not discriminate on the basis of race, religion, color, sex, gender identity or expression, sexual orientation, age, disability, national origin, veteran status, or any other basis covered by appropriate law. Research suggests that qualified women, Black, Indigenous, and Persons of Color (BIPOC) may self-select out of opportunities if they don't meet 100% of the job requirements. We encourage individuals who believe they have the skills necessary to thrive to apply for this role.



Official Title: Civil Engineer III
Primary Location: United States-Massachusetts-Concord-936 Elm Street
Job: Engineering
Agency: Massachusetts Department of Transportation
Schedule: Full-time
Shift: Day
Job Posting: Oct 27, 2023, 1:27:22 PM
Number of Openings: 1
Salary: 82,737.98 - 116,847.12 Yearly
If you have Diversity, Affirmative Action or Equal Employment Opportunity questions or need a Reasonable Accommodation, please contact Diversity Officer / ADA Coordinator: Derrick Mann, Diversity Officer 857-368-8541 - 8573688541
Bargaining Unit: DOT
Confidential: No
Potentially Eligible for a Hybrid Work Schedule: Yes",-1,State & Regional Agencies,Unknown / Non-Applicable,Government & Public Administration,Unknown,Company - Public,False
"Senior Software Engineer, Data Science","Motional
","Boston, MA",$159K - $207K (Employer est.),4.1,"Mission Summary:

The Metrics Engine team oversees the extraction of data to evaluate the behavior of our av-stack, all the way from devising the metric formulation based on traffic laws, ethics and safety, to extracting the information necessary to compute these metrics from the logs. Beyond evaluating system-level behavior, we also derive metrics to evaluate subsystems that collectively participate to AV system behavior.

As we are outputting a growing amount of metrics at various stages of the development process, our team is looking for a Senior Engineer to analyze the progression of our av-stack performance with respect to those metrics, and surface key trends. This person will get to make reports and recommendations that are of direct interest to many different teams across the organization, including leadership.

The Motional global headquarters are located at 100 Northern Avenue in Boston, MA. Nestled in the bustling Seaport district with sweeping views of Boston Harbor and downtown Boston, the offices are located close to major transit lines and a quick walk to various restaurants and popular attractions.

What you'll be doing:

Analyze the output of our metric evaluator to provide high-level insights on the progress of our stack
Communicate with the Testing, Operations, and Autonomy teams to understand their day-to-day analysis needs
Provide recommendations on how to design experiments to get a stronger signal from the metrics
Question the results of certain metrics, dig into their formulations and contribute to improving them regularly

What we're looking for:

Strong Python coding experience
MSc in Statistics, Math, Physics, Computer Science or equivalent + 3 years of experience in data science in a tech-heavy industry
Python/Julia experience in statistical analysis
Commitment to rigorous analysis - if assumptions need to be made to infer results, they should be spelled out
Ability to communicate clearly to non-domain experts about potentially complex behaviors
An interest in contributing to the metric formulation and implementation

Bonus points:

Experience in evaluating human or autonomous driving behavior
Experience in robotics


The salary range for this role is an estimate based on a wide range of compensation factors including but not limited to specific skills, experience and expertise, role location, certifications, licenses, and business needs. The estimated compensation range listed in this job posting reflects base salary only. This role may include additional forms of compensation such as a bonus or company equity. The recruiter assigned to this role can share more information about the specific compensation and benefit details associated with this role during the hiring process.

Candidates for certain positions are eligible to participate in Motional's benefits program. Motional's benefits include but are not limited to medical, dental, vision, 401k with a company match, health saving accounts, life insurance, pet insurance, and more.

Salary Range

$159,000—$207,000 USD

Motional is a driverless technology company making autonomous vehicles a safe, reliable, and accessible reality. We're driven by something more.

Our journey is always people first.

We aren't just developing driverless cars; we're creating safer roadways, more equitable transportation options, and making our communities better places to live, work, and connect. Our team is made up of engineers, researchers, innovators, dreamers and doers, who are creating a technology with the potential to transform the way we move.

Higher purpose, greater impact.

We're creating first-of-its-kind technology that will transform transportation. To do so successfully, we must design for everyone in our cities and on our roads. We believe in building a great place to work through a progressive, global culture that is diverse, inclusive, and ensures people feel valued at every level of the organization. Diversity helps us to see the world differently; it's not only good for our business, it's the right thing to do.

Scale up, not starting up.

Our team is behind some of the industry's largest leaps forward, including the first fully-autonomous cross-country drive in the U.S, the launch of the world's first robotaxi pilot, and operation of the world's longest-standing public robotaxi fleet. We're driven to scale; we're moving towards commercialization of our technology, and we need team members who are ready to embrace change and challenges.

Formed as a joint venture between Hyundai Motor Group and Aptiv, Motional is fundamentally changing how people move through their lives. Headquartered in Boston, Motional has operations in the U.S and Asia. For more information, visit www.Motional.com and follow us on Twitter, LinkedIn, Facebook, Instagram and YouTube.




Motional AD Inc. is an EOE. We celebrate diversity and are committed to creating an inclusive environment for all employees. To comply with Federal Law, we participate in E-Verify. All newly-hired employees are queried through this electronic system established by the DHS and the SSA to verify their identity and employment eligibility.",2020,Computer Hardware Development,Unknown / Non-Applicable,Information Technology,501 to 1000 Employees,Company - Private,True
Sr. Data Engineer,"Deloitte
","Boston, MA",$100K - $138K (Glassdoor est.),4.0,"In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

Work you'll do

As a Senior Data Engineer you work cross-functionally with data scientists, machine learning engineers, project managers, and industry experts to develop robust AI infrastructure and deployment services for our novel machine learning applications. Key to this role is the ability to demonstrate expertise in cloud deployment, DevOps, MLOps, data engineering, and streamlining IT infrastructure processes for organizations across a wide variety of industries.

In our consultative approach, we are platform agnostic and are committed to providing the best technical solutions for each client and solution. Our engineering team leverages emerging technologies across cloud, HPC, DevOps, and MLOps to create solutions and products that address complex issues and business problems faced by global organizations to include cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, and renewable energy. Join us to expand your technical career through the lens of consulting and work on many novel projects and use cases to expand your data science & AI skills.

Work with clients to design, develop, and deploy new architectures for machine learning & automation applications such as ELT functions, HPC/compute infrastructure, AWS/Azure solutions, database solutions, and optimization of DevOps procedures
Leverage skills in modern data architecture, cloud engineering, data transformation, and management of structured and unstructured data sources
Support and enhance data architecture, and data pipelines, and define database schemas (Graph DB, SQL, NoSQL) to support algorithm scalability and deployment based on agile business priorities and technology initiatives
Participate in architectural discussions to ensure solutions are designed for successful deployment, security, and high availability in the cloud or on-prem
Adopt and maintain best engineering practices in automation, HPC, CI/CD, and AIOps



The Team

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications

Required:


Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future


Must be able to obtain and maintain the required clearance for this role


Bachelor's degree in a STEM field or equivalent experience (Computer Science, Engineering, Physics etc.); Master's degree preferred


4+ years' experience in data engineering, cloud engineering, MLOps, while building highly scalable and secure solutions


Proficient in Python, SQL, Shell scripting


Experience with distributed computing frameworks (e.g., Spark, Dask), cloud platforms (e.g. AWS, Azure), containerization, and supporting analytics libraries


Expertise with code management and DevOps tools (e.g., Docker, Kubernetes, Jenkins, etc.)


Experience with workflow and data management solutions such as Airflow, Kafka, Glue, etc.


Experience designing data architectures and understanding of different types of databases or platforms (relational, NoSQL, graph, etc.)


Strong analytical and problem-solving skills with the ability to develop novel and efficient solutions


Live within commuting distance to one of Deloitte's consulting offices


Travel up to 5%

Preferred:

Master's or Ph.D. degree in Computer Science, Information Technology, or related STEM field
AWS/Azure Certifications (AWS/Azure Certified: SysOps Administrator, DevOps Engineer, Solutions Architect).
Expertise in designing and scaling IT architectures, data lakes, & database schemas (Graph, SQL, NoSQL), etc.
Demonstrated experience launching AI/ML solutions into production environments, such as into cloud or HPC/GPU environments
Active Security Clearance

#LI-MM4",1850,Accounting & Tax,$10+ billion (USD),Financial Services,10000+ Employees,Company - Private,False
Sr. Data Engineer,"Cognizant Technology Solutions
","Quincy, MA",$87K - $115K (Glassdoor est.),3.8,"WE ARE COGNIZANT ARTIFICIAL INTELLIGENCE

Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. But clients need new business models built from analyzing customers and business operations in every angle to really understand them.

With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate and scale the most desirable products and delivery models to enterprise scale within weeks.

You must be legally authorized to work in the United States without the need for employer sponsorship / visa transfer now or at any time in the future.



Location Onsite – Quincy, MA (remote)




Strong Oracle/PLSQL position with exposure to AWS/Postgress.

Skillset – Oracle, Postgresql, Informatica , IICS (Optional), AWS , AWS RDS, Redshift




Skills – Function as the lead at onsite to oversee the maintenance and support of customer facing member portal and mobile application. Knowledge of Data model, data quality and data integration. Knowledge on cloud and data synchronization will be helpful. Healthcare knowledge is preferred.




Employee Status : Full Time Employee

Shift : Day Job

Travel : No

Job Posting : Nov 03 2021

About Cognizant
Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.

Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",1994,Information Technology Support Services,$10+ billion (USD),Information Technology,1001 to 5000 Employees,Company - Public,False
Senior Data Engineer,"Publicis Sapient
","Boston, MA",$103K - $154K (Employer est.),3.7,"Senior Data Engineer
Full-time

Company Description

Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers.We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity.United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across truly value

Job Description

Publicis Sapient is looking for a Senior Associate Data Engineer to be part of our team of top-notch technologists. You will lead and deliver technical solutions for large-scale digital transformation projects. Working with the latest data technologies in the industry, you will be instrumental in helping our clients evolve for a more digital future.

Your Impact:

Combine your technical expertise and problem-solving passion to work closely with clients, turning complex ideas into end-to-end solutions that transform our client's business
Translate client's requirements to system design and develop a solution that delivers business value
Lead, designed, develop, and deliver large-scale data systems, data processing, and data transformation projects
Automate data platform operations and manage the post-production system and processes
Conduct technical feasibility assessments and provide project estimates for the design and development of the solution
Mentor, help and grow junior team members

Your Technical Skills & Experience:

Demonstrable experience in data platforms involving implementation of end to end data pipelines
Hands-on experience with at least one of the leading public cloud data platforms (Azure, AWS or Google Cloud)
Implementation experience with column-oriented database technologies (i.e., Big Query, Redshift, Vertica), NoSQL database technologies (i.e., DynamoDB, BigTable, Cosmos DB, etc.) and traditional database systems (i.e., SQL Server, Oracle, MySQL)
Experience in implementing data pipelines for both streaming and batch integrations using tools/frameworks like Azure Data Factory, Glue ETL, Lambda, Spark, Spark Streaming, etc.
Ability to handle module or track level responsibilities and contributing to tasks “hands-on”
Experience in data modeling, warehouse design and fact/dimension implementations
Experience working with code repositories and continuous integration
Data modeling, querying, and optimization for relational, NoSQL, timeseries, and graph databases and data warehouses and data lakes
Data processing programming using SQL, DBT, Python, and similar tools
Logical programming in Python, Spark, PySpark, Java, Javascript, and/or Scala
Data ingest, validation, and enrichment pipeline design and implementation
Cloud-native data platform design with a focus on streaming and event-driven architectures
Test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks
Metadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, DataHub, Alation, AWS Glue Catalog, Google Data Catalog, and similar
Code review and mentorship
Bachelor’s degree in Computer Science, Engineering or related field.

Set Yourself Apart With:

Developer certifications for any of the cloud services like AWS, Google Cloud or Azure
Understanding of development and project methodologies
Willingness to travel

Additional Information

Pay Range:$103,000 -$154,000

The range shown represents a grouping of relevant ranges currently in use at Publicis Sapient. Actual range for this position may differ, depending on location and the specific skillset required for the work itself.

Benefits of Working Here:

Flexible vacation policy; time is not limited, allocated, or accrued
16 paid holidays throughout the year
Generous parental leave and new parent transition program
Tuition reimbursement
Corporate gift matching program

As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at hirin[email protected] or you may call us at +1-617-621-0200",1990,Business Consulting,Unknown / Non-Applicable,Management & Consulting,10000+ Employees,Company - Public,False
Sr. Security Engineer (Data Governance),"SimpliSafe
","Boston, MA",$117K - $166K (Glassdoor est.),3.5,"About SimpliSafe

We're a high-tech home security company that's passionate about protecting the life you've built and our mission of keeping Every Home Secure. And we've created a culture here that cares just as deeply about the career you're building. Ours is a no ego culture of collaboration and innovation where those seeking their next challenge can find big opportunities and make a huge impact on the lives of all those who we protect. We don't just want you to work here. We want you to grow and thrive here.

We're embracing a hybrid work model that enables our teams to split their time between office and home. Hybrid for us means we expect our teams to come together in our state-of-the-art office on two core days, typically Tuesday and Wednesday, working together in person and choose where they work for the remainder of the week. We all benefit from flexibility and get to use the best of both worlds to get our work done.

Why are we hiring?

Well, we're growing and thriving. So, we need smart, talented, and humble people who share our values to join us as we disrupt the home security space and relentlessly pursue our mission of keeping Every Home Secure.

What You'll Do

Working with our Privacy and Legal teams, our Security team is responsible for securing sensitive data across the organization. We are looking for an experienced data security professional who can strategically create, organize, and enforce data security policies and practices to secure SimpliSafe data while enabling the business to innovate and grow.

Primary Responsibilities Include
Developing and maintaining relevant data security policies and procedures
Establishing secure guidelines and standards to protect all sensitive data collected, generated, and used by the organization
Collaborating with the Privacy team to set up and maintain automated data mapping processes
Maintaining and administering data security software
Working with various Engineering teams to understand individual data security needs and developing security plans for each
Minimizing sensitive data access across a variety of data platforms
Analyze and monitor evolving industry data security standards for relevancy and possible implementation
Auditing user roles and permissions in existing data stores to minimize data access.
What You'll Bring
2+ years of experience with a specific focus in data security, with a desired 5 years in the general field of information security
An update to date knowledge of data encryption, hashing, tokenization, and integrity tools
A practitioner's understanding of data privacy and protection regulations
Knowledge of data platforms, data science, and data analytics principles
What Values You'll Share
Customer Obsessed - Building deep empathy for our customers, putting them at the core of our work, and developing strong, long-term relationships with them.
Aim High - Always challenging ourselves and others to raise the bar.
No Ego - Maintaining a ""no job too small"" attitude, and an open, inclusive and humble style.
One Team - Taking a highly collaborative approach to achieving success.
Lift As We Climb - Investing in developing others and helping others around us succeed.
Lean & Nimble - Working with agility and efficiency to experiment in an often ambiguous environment.

We wholeheartedly embrace and actively seek applications from all individuals, no matter how they identify. We are committed to cultivating a diverse and inclusive workplace, and we believe our work is enriched when we incorporate a multitude of perspectives, backgrounds, and experiences. We want everyone who works here to thrive and contribute to not only our mission of keeping every home secure, but also to making our workplace safe and supportive for others. If a reasonable accommodation may be needed to fully participate in the job application or interview process, to perform the essential functions of a position, or to receive other benefits and privileges of employment, please contact careers@simplisafe.com.",2006,Computer Hardware Development,$100 to $500 million (USD),Information Technology,1001 to 5000 Employees,Company - Private,True
Data Engineer IV - Max Digital (Data Engineering),"ACV Auctions
",Massachusetts,-1,3.7,"If you are looking for a career at a dynamic company with a people-first mindset and a deep culture of growth and autonomy, ACV is the right place for you! Competitive compensation packages and learning and development opportunities, ACV has what you need to advance to the next level in your career. We will continue to raise the bar every day by investing in our people and technology to help our customers succeed. We hire people who share our passion, bring innovative ideas to the table, and enjoy a collaborative atmosphere.

Who we are:
ACV is a technology company that has revolutionized how dealers buy and sell cars online. We are transforming the automotive industry. ACV Auctions Inc. (ACV), has applied innovation and user-designed, data driven applications and solutions. We are building the most trusted and efficient digital marketplace with data solutions for sourcing, selling and managing used vehicles with transparency and comprehensive insights that were once unimaginable. We are disruptors of the industry and we want you to join us on our journey. ACV’s network of brands includes ACV Auctions, ACV Transportation, ClearCar, MAX Digital and ACV Capital within its Marketplace Products, as well as, True360 and Data Services.
At ACV we focus on the Health, Physical, Financial, Social and Emotional Wellness of our Teammates and to support this we offer:

Multiple medical plans including a high deductible health plan that costs $0 out of your paycheck
Company-sponsored (paid) Short-Term Disability, Long-Term Disability, and Life Insurance
Comprehensive optional benefits such as Dental, Vision, Supplemental Life/AD&D, Legal/ID Protection, and Accident and Critical Illness Insurance
Generous paid time off options, including vacation time, sick days, Company holidays, floating holidays, parental leave, bereavement leave, jury duty leave, voting leave, and other forms of paid leave as required by applicable law or regulation
Employee Stock Purchase Program with additional opportunities to earn stock in the Company
Retirement planning through the Company’s 401(k)
Who we are looking for:
We are seeking a highly skilled Engineer IV in Data Engineering with a strong foundation in computer science and excellent problem-solving skills. You will be responsible for maintaining and extending our database operations, optimizing SQL queries, and designing scalable data services.

What you will do:

Actively and consistently support all efforts to simplify and enhance the customer experience.
Maintain and extend (as required) existing database operations solution for backups, index defragmentation, data retention, etc.
Troubleshoot any SQL Server or ETL stack outages during our operational support window.
Triage any issues with data stack (SSIS, C#, Web APIs).
Support development, integration, and stage SQL Server environments for application development and data science teams.
Ensure that new database development meets company standards for readability, reliability, and performance. Work with internal teams on transactional and analytical schema design.
Collaborate with software and DevOps engineers to design scalable services, plan feature roll-out, and ensure high reliability and performance of our products.
Architect and build entire services including but not limited to; data modeling, storage, message brokers, protocols and interfaces.
Design, build and maintain complex systems that can scale rapidly with little maintenance.
Conduct code reviews, develop high-quality documentation, and build robust test suites.
Own the overall performance of products and services within a defined area of focus.
Be empowered to lead and complete software projects with minimal guidance from managers.
Lead team discussions to define technical requirements on new and current products.
Respond-to and troubleshoot highly complex problems quickly, efficiently, and effectively.
Mentor junior engineers.
Perform additional duties as assigned.
What you will need:

Bachelor's degree in Computer Science, Information Technology, Computer Information Systems, Management Information Systems, or similar
5 years' building & supporting the database-tier of SaaS web applications.
Ability to read, write, speak, and understand English.
Expert understanding of SQL query execution fundamentals and query optimization principles.
Experience maintaining and extending an existing codebase, adapting to pre-existing patterns and tracing the code’s path of execution.
ETL workflow implementation (SSIS, Airflow, C#, Python)
Experience working with Cloud Services (AWS RDS, S3, SQS, SNS)
Experience working with NoSQL data stores (MongoDB)
Experience writing unit and integration testing (DBT, C#)
Expert SQL and data-layer development experience; OLTP schema design.
Experience integrating 3rd-party APIs, implementing authentication & authorization and developing asynchronous data flows.
Nice to Have
OLAP schema design experience.
Experience with Airflow, Snowflake, etc.
Experience with DBT
Our Values
Trust & Transparency | People First | Positive Experiences | Calm Persistence | Never Settling

At ACV, we are committed to an inclusive culture in which every individual is welcomed and empowered to celebrate their true selves. We achieve this by fostering a work environment of acceptance and understanding that is free from discrimination. ACV is committed to being an equal opportunity employer regardless of sex, race, creed, color, religion, marital status, national origin, age, pregnancy, sexual orientation, gender, gender identity, gender expression, genetic information, disability, military status, status as a veteran, or any other protected characteristic. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires reasonable accommodation, please let us know.

For information on our collection and use of your personal information, please see our Privacy Notice.",2014,Wholesale,Unknown / Non-Applicable,Retail & Wholesale,1001 to 5000 Employees,Company - Public,True
AWS and Databricks Data Engineer / Architect,"Wipro Limited
","Boston, MA",$93K - $136K (Glassdoor est.),3.1,"Overview:
About Wipro:
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.
A PROUD HISTORY OF OVER 75 YEARS
FY22 REVENUE 10.4 BN USD
WE’RE PRESENT IN 66 COUNTRIES
OVER 1,400 ACTIVE GLOBAL CLIENTS
Role – AWS and Databricks Data Engineer/Architect
Location – Boston, MA (or) Princeton, NJ (Onsite - Day 1)
Yrs. of experience – 10+ Years
Mode of employment – Full-Time

Job Description:
We are seeking a skilled and experienced Databricks Architect with expertise in working with Databricks on the AWS cloud platform.
Comprehensive knowledge and hands on experience with Databricks pipelines, Unity Catalog and Medallion architecture
Proficiency in programming languages Python, Scala, or Java for data processing and application development
Experience in implementing data solutions on AWS cloud using cloud storage, compute and network resources
Expertise in data engineering principles, ETL processes, data modeling and data integration techniques
Experience in end-end qualification and performance tuning of the data models and pipelines
Strong problem solving and analytic skills to handle data engineering challenges and troubleshoot issues
Experience with agile development methodologies

Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.

#LI-AK2",1945,Information Technology Support Services,$5 to $10 billion (USD),Information Technology,10000+ Employees,Company - Public,False
Senior Electrical Engineer - Data Center Team,"HED
","Boston, MA",-1,3.7,"PRIMARY FUNCTION

Primary responsibilities include providing for the design and technical systems for large, complex projects from schematics through construction administration.

TYPICAL DUTIES

Responsible for building system concepts and documentation process from schematics through construction administration phases within the discipline.
It is expected that the Electrical Engineer in regular coordination with Supervisor in project development and performance.
Electrical Engineer shall have a proficient knowledge of primary sectors of design including:
Power Distribution
Lighting and Controls
Fire Alarm
Specification writing and editing.
Energy conservation and sustainability/report technical writing.
Function as Project Discipline Team Leader on large, complex projects when assigned.
Responsible for directing and overseeing project team members within their own discipline. Level 4 is responsible for monitoring and executing team compliance with project budget.
Prepare and monitor project status reports.
Coordinate with Electrical Engineering Discipline Leader in preparing project Man-hour Estimates.
Prepare and document required code research for project.
Participate in the development of the project cost model and design to it.
Develop and maintain Electrical Basis of Design Journal throughout the life of the project.
Conduct material and product research as required for project development.
Attend project meetings as necessary.
Interface with other Project Discipline Team Leaders.
Respond to client questions/requests within 24 hours.
Document interpretation and submittal reviews during bidding and construction administration.
Monitor and mentor staff to produce quality architectural and engineering services within a project team concept.
Perform other duties as assigned by the supervisor.

TYPICAL DUTIES - NON-PROJECT RELATED

Mentor support engineers to help prepare them for greater project responsibilities.
Provide regular feedback to the Electrical Engineering Discipline Leader on performance of support engineers.
Identify opportunities to improve quality and services, and participate in the implementation.
Participate in in-house training activities.
Participate in related professional organizations and activities.
Contribute to department discussions on field feedback, lessons learned, new technology or developments encountered.
Offer recognition to those staff members observed doing excellent work and/or things beyond their job expectations.

SKILL, KNOWLEDGE, EDUCATION AND EXPERIENCE

Proven experience working on mission critical/data center projects.
Bachelor's degree in Electrical Engineering and PE licensure required.
LEED Accredited preferred.
Minimum six years' experience in A/E industry preferred.
Extensive knowledge of all aspects of professional services from schematic design through project close-out, including design and technical expertise.
A comprehensive understanding of the coordination aspects and related requirements of all design disciplines.
Proficiency in short circuit and selective coordination calculation. Utilization of EDSA, SKM or other analytical modeling software preferred.
Excellent written/ verbal communication and strong organizational skills.
Possess the ability to motivate and mentor staff, and delegate work assignments.
Computer and CADD/Revit literate.
Very detail-oriented, self-motivated, enthusiastic and flexible.
Ability to work well with others under deadline situations.

PHYSICAL REQUIREMENTS

Capable of traveling to and from project sites for attending client, project and construction meetings.
Ability to access existing and new project sites for observation, investigation and evaluation purposes.
Ability to use equipment for communication and documentation purposes.
Visual acuity to perform responsibilities.

#LI-JK1",1908,Architectural & Engineering Services,$25 to $100 million (USD),"Construction, Repair & Maintenance Services",201 to 500 Employees,Company - Private,True
Senior Data Engineer,"Quantexa
","Boston, MA",$130K - $142K (Employer est.),4.8,"Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 7 years, and 600+ employees later we still believe that today. We connect the dots within our Customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data. Quantexa empowers organisations to drive better decisions from their data. Using the latest advancements in big data and AI, Quantexa uncovers hidden customer connections and behaviours to solve major challenges in financial crime, customer insight and data analytics.

Quantexa has accomplished rapid global expansion and achieved a valuation of $1.8 billion in April 2023 making us the first UK Unicorn business for 2023. Due to our continuous success and high demand from our customers, we are looking for a Senior Data Engineer with a proven track record to join the Quantexa family.




What does a Senior Data Engineer role at Quantexa look like?

In order to be a successful data Engineer at Quantexa, you’ll need to be comfortable dealing with both internal and external stakeholders You will be managing, transforming and cleansing high volume data, helping our Tier 1 clients solve business problems in the area of fraud, compliance and financial crime.

Being Agile is an integral part to the success we have at Quantexa and having regular team sprints and Scrum meetings with your Projects team is essential. You’ll be working closely with Data Scientists, Business Analysts, Technical Leads, Project Managers and Solutions Architects, with everyone following the same goal of meeting our Clients expectations and delivering a first-class service.

We want our employees to use the latest and leading open source big-data technology possible. You will be using tools such as Spark, Hadoop, Scala, Data Fusion and Elasticsearch, with our platform being hosted on Google cloud (GCP). Our primary language is written in Scala, but don’t worry If that’s not your strongest language or if you haven’t used it before, we make sure that every Quantexan goes through our training academy so they’re comfortable and confident with using our platform.

Requirements

We’re looking for individuals who have proven big data experience, either from an implementation or a data science prospective.
The desire to learn and code in Scala
Experience in working in an Agile environment
Expert knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch.
A strong coding background in either Java, Python or Scala
Good experience with testing libraries of common programming languages and can talk about how they used them – for example scalatest (or equivalent packages for other languages)
Knows the difference between different test types ( unit test vs integration test for example) – can provide specific examples of one they have written themselves or oversaw when asked
Can explain unit testing and how they have been automated – can provide specific examples relevant to their own code or project when asked
Experience of building data processing pipelines for use in production “hands off” batch systems, including either traditional ETL pipelines and/or analytics pipelines.
Passion and drive to grow within one of the UK’s fastest growing scale-ups.
Consulting or business facing skills and a desire to work with customers.

Benefits

Why join Quantexa?

We know that just having an excellent glass door rating isn’t enough, so we’ve put together a competitive package as a way of saying thank you for all your hard work and dedication.

We offer:

Competitive Salary range of $130-141k
Company Bonus
401(k) match up to 5%
Competitive PTO Allowance + Paid US Federal Holidays + Your Birthday Off!
Medical, Dental, and Vision coverage
Short-term and Long-term Disability, Life, and AD&D insurance
Access to One Medical - primary care practice that offers 24/7 on-demand virtual care
Access to Teladoc - on-demand healthcare via phone or video
Access to Health Advocate - the nation’s leading healthcare advocacy and assistance company
Access to Calm App Subscription - the #1 app for meditation, relaxation, and sleep
Access to Talk Space - the #1 rated, HIPAA-compliant app for online counseling and therapy services
Continuous Training and Development, including access to Udemy Business
Access to WeWork offices & Company-wide socials






Our mission

We have one mission. To help businesses grow. To make data easier. And to make the world a better place. We’re not a start-up. Not anymore. But we’ve not been around that long either. What we are is a collection of bright, passionate minds harnessing complexities and helping our clients and their communities. One culture, made of many. Heading in one direction – the future.

It's all about you

Quantexa is proud to be an Equal Opportunity Employer. We’re dedicated to creating an inclusive and diverse work environment, where everyone feels welcome, valued, and respected. We want to hear from people who are passionate about their work and align with our values. Qualified applications will receive consideration for employment without regard to their race, colour, ancestry, religion, national origin, sex, sexual orientation, gender identity, age, citizenship, marital, disability, or veteran status. Whoever you are, if you’re a curious, caring, and authentic human being who wants to help push the boundaries of what’s possible, we want to hear from you.

Internal pay equity across departments is crucial to our global compensation philosophy. Grade level and salary ranges are determined through interviews and a review of experience, education, training, knowledge, skills, and abilities of the applicant, equity with other team members, and alignment with market data.

Quantexa is committed to providing reasonable accommodations in our talent acquisition processes. If you require support, please inform our Talent Acquisition Team.

Applicants must be authorized to work for any employer in the United States. We are unable to sponsor or take over the sponsorship of an employment visa at this time.",2016,Enterprise Software & Network Solutions,Unknown / Non-Applicable,Information Technology,501 to 1000 Employees,Company - Private,True
Data Engineer,"Contact Government Services, LLC
","Worcester, MA",$81K - $123K (Glassdoor est.),4.7,"Data Engineer
Employment Type: Full-Time, Mid-level
Department: Business Intelligence
CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.
Skills and attributes for success:
Complete development efforts across data pipeline to store, manage, store, and provision to data consumers.
Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices.
Write code to ensure the performance and reliability of data extraction and processing.
Support continuous process automation for data ingest.
Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing.
Work with program management and engineers to implement and document complex and evolving requirements.
Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork.
Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists.

Qualifications:
Must be a US Citizen.
Must be able to obtain a Public Trust Clearance.
7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.
Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats.
Proficiency in developing ETL processes, and performing test and validation steps.
Proficiency to manipulate data (Python, R, SQL, SAS).
Strong knowledge of big data analysis and storage tools and technologies.
Strong understanding of the agile principles and ability to apply them.
Strong understanding of the CI/CD pipelines and ability to apply them.
Experience with relational database, such as, PostgreSQL.
Work comfortably in version control systems, such as, Git Repositories.

Ideally, you will also have:
Experience creating and consuming APIs.
Experience with DHS and knowledge of DHS standards a plus.
Candidates will be given special consideration for extensive experience with Python.
Ability to develop visualizations utilizing Tableau or PowerBI.
Experience in developing Shell scripts on Linux.
Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions.
Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences.
Our Commitment:
Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:
Health, Dental, and Vision
Life Insurance
401k
Flexible Spending Account (Health, Dependent Care, and Commuter)
Paid Time Off and Observance of State/Federal Holidays

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:
https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:
Email: info@cgsfederal.com",-1,-1,Unknown / Non-Applicable,-1,1 to 50 Employees,Company - Public,True
Staff Python + Data Engineer (AI SaaS),"EvolutionIQ
","Boston, MA",$95K - $136K (Glassdoor est.),4.7,"About Us: EvolutionIQ's mission is to improve the lives of injured and disabled workers and enable them to return to the workforce, saving billions of dollars in avoidable costs and lost productivity to the US and global economies and make insurance more affordable for everyone. We are currently experiencing massive growth and to accomplish our goals, we are hiring world-class talent who want to help build and scale internally, and transform the insurance space. We're backed by First Round Capital, FirstMark Capital, Foundation Capital, Brewer Lane Ventures, and have been named as Inc.'s top places to work!

Our Team: We are founded by a senior Google AI expert and a Bridgewater Associates Algorithmic Investor & Stanford MBA. We're not looking for employees. We're looking for partners in work, partners in culture-building, and partners in the future of data-driven insurance. The development team consists of world class engineers and leaders from companies like Google and Bloomberg. Each individual has had great success building large scale enterprise software and is now excited to try their hand at transforming the insurance industry.

Job Summary: We are looking for a Lead Engineer for our Workers Comp Engineering team who will play an integral role in securing, architecting, and managing our highly sensitive insurance data. This position is tasked with overseeing our foundational datasets, data models, general software architecture, and analytics. The ideal candidate will have considerable experience in creating and managing secure data platforms, a strong engineering background, and a demonstrated record of technical leadership and effective communication.

In this critical role, you will not only ensure the robustness and reliability of our data systems, but also their security and compliance with stringent industry regulations. You will navigate the complexities of insurance data, bringing technical excellence and a security-first approach to safeguard our information assets. Your keen eye for security will be instrumental in protecting our company, customers, and stakeholders, while your technical expertise will shape the future of our data platform architecture.

Key Responsibilities:

Architect, design, and implement robust, secure, scalable, and high-quality data platforms, ensuring the availability, integrity, and confidentiality of the information.
Lead the development and maintenance of data pipelines, including personally coding and building the most critical components.
Work closely with product engineers, data scientists, analysts, and other stakeholders to understand data needs and deliver on those needs.
Define, design, and improve foundational data models to be used across the company to enable feature development and analytics.
Continuously improve our data quality toolkit
Provide guidance and technical leadership to the data engineering team, promoting continual team growth and individual team member skill development.
Be a role model for all engineers and provide mentorship as needed
Drive proof of concepts and experiments to explore new technologies that can level up the entire organization

Requirements:

7+ years of industry experience, holding staff/principal/lead level roles in Software Engineer or Data Engineer, with a focus in building scalable, mission critical, data platforms
Strong written and verbal communication skills
Extensive Python development experience
Experience with distributed data/computing tools, such as: Spark, Airflow, dbt
Proven track record of establishing engineering best practices for both coding and architecture
Experience building out systems and processes to enable secure handling of highly sensitive data
Experience using modern big data storage technologies such as Apache Parquet or Avro
Strong familiarity with modern data warehouse such as BigQuery or Snowflake
Ambitious, collaborative, and empathetic values

Even Better if You Have:

You have at least 3+ years experience in deploying systems on GCP or AWS
Experience with MLOps, such as feature engineering and model serving
You have worked with Dagster/Airflow, BigQuery, GCP, Terraform, Kubernetes, sklearn, keras/TensorFlow/pytorch, dbt, data modeling, Python/Pandas data frameworks, and scalable technical concepts/solutions

Work-life, Culture & Perks:

Compensation: The range is $210-240K depending on a candidate's background and experience.
Well-Being: Full medical, dental, vision, short- & long-term disability, 401k matching. 100% of the employee contribution up to 3% and 50% of the next 2%
Work/Life Balance: For this role we are hoping this person can work out of the NYC office regularly with much of our leadership with flexibility. We also have a flexible vacation policy.
Home & Family: 100% paid parental leave (4 months for primary caregivers and 3 months for secondary caregivers), sick days, paid time off. For new parents returning to work we offer a flexible schedule. We also offer sleep training to help you and your family navigate life schedules with a newborn
Office Life: Catered lunches, happy hours, and pet-friendly office space. $500 for your in home office setup and $200/year for upgrades every year after your initial setup
Growth & Training: $1,000/year for each employee for professional development, as well as upskilling opportunities internally
Sponsorship: We are open to sponsoring candidates currently in the U.S. who need to transfer their active H1-B visa

EvolutionIQ appreciates your interest in our company as a place of employment. EvolutionIQ is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees",2019,Enterprise Software & Network Solutions,$25 to $100 million (USD),Information Technology,51 to 200 Employees,Company - Private,True
Data Center ACI-Arista Fabric Network Engineer IV,"Retail Business Services
","Quincy, MA",$59K - $92K (Glassdoor est.),3.8,"Address: USA-MA-Quincy-1385 Hancock Street
Store Code: Infrastructure-Network (5118718)




Retail Business Services, ranked No. 25 on Fast Company’s 2022 100 Best Workplaces for Innovators, is the services company of leading grocery retail group Ahold Delhaize USA, which includes Food Lion, Giant Food, The GIANT Company, Hannaford and Stop & Shop.


Primary Purpose:

A Sr Data Center ACI-Arista Fabric Network Engineer will provide expertise and leadership in the design, configuration, and management of all corporate, distribution center and retail digital media devices and associated supporting services. They are expected to work in a fast-paced and challenging environment leveraging forward-thinking technical engineering expertise in the media device and services area of the enterprise.

Duties and Responsibilities:

Lead the overall design and implementation of the technology stack within the RBS Data Centers.

Develop process, procedures, and maintain documentation for RBS managed data centers.

Document network infrastructure and environment design and keep updated with changes to the environment.

Report on the health of the RBS data centers by performing capacity planning and proactively provide recommendations for future growth.

Manage day to day activities and provide guidance of Managed Service Provider engineers.

Provide escalated technical support for Managed Service Providers.

Manage vendor relationship.

Provide subject matter expertise in the analysis, design and preparation of technology solutions to meet business needs

Recommends components for solutions that will work well together across business domains, partner with domain architect or act as the domain architect to ensure adherence to the architectural roadmap

Accountable for projects/applications/infrastructure meeting business needs are delivered in a timely, cost-effective manner considering all budget aspects including total cost of ownership.

Ensures project artifacts are developed as required, this includes working with support organizations and suppliers to ensure proper documentation is created and stored in the procedure’s manual or document repository.

Facilitates/completes the creation of communication plans, ensuring that appropriate information is exchanged among key stakeholders.

Develops complete and robust test plans, cases, and scripts, ensures defects are properly resolved and user acceptance is obtained. Ensures the test scripts and defects are entered and tracked in our department tools.

Acts as communication point keeping the supplier and business partners informed of infrastructure changes, application changes, data changes or upcoming implementations and ensures business specific impacts are addressed.

Ensures integration and consideration of assigned business areas against critical business processing, freeze periods, schedule changes, weather events and significant refresh activities.

Review’s business processes to understand capability gaps and opportunities

Recommends Innovations and business processes /systems simplifications

Builds close relationships with the function heads and their teams. Advise these teams on how technology can be used to match or outpace competitor performance.

Works as 3rd level support to help resolve issues within area of responsibility

Maintains a high level of individual contribution, professional growth, and ability to function effectively and independently, challenges others to do the same

Qualifications:

Bachelor's Degree in Computer Science or Technical field and master's degree in Technology and/or Business-related field equivalent trainings/certifications/experience equivalency will be considered

5 or more years of equivalent experience in relevant job or field of technology.

2 or more years of equivalent experience in an advanced role or technical capacity, leading teams directly or indirectly.

2 or more years' experience directly responsible for guiding, training or onboarding team members in relevant technologies, capabilities or skills

Preferred Qualifications:

Post graduate degree advanced training and or certifications in relevant field/s of study preferred.

3 or more years experience in Agile teams and Product/Platform based operating model.

3 or more years of experience in leading teams or advancing technical capability in teams.

Experience in retail or grocery preferred.

#LI-RV1 #DiceJobs #LI-Hybrid


Retail Business Services currently provides services to five omnichannel grocery brands, including Food Lion, Giant Food, The GIANT Company, Hannaford and Stop & Shop. Retail Business Services leverages the scale of the local brands to drive synergies and provide industry-leading expertise, insights and analytics to local brands to support their strategies. We are committed to diversity, equity and inclusion and we foster a community of belonging where everyone is valued.

Retail Business Services is an equal opportunity employer. We comply with all applicable federal, state and local laws. Qualified applicants are considered without regard to sex, race, color, ancestry, national origin, citizenship status, religion, age, marital status (including civil unions), military service, veteran status, pregnancy (including childbirth and related medical conditions), genetic information, sexual orientation, gender identity, legally recognized disability, domestic violence victim status or any other characteristic protected by law. We provide reasonable accommodations to applicants and employees with disabilities. As important as what we do is how we do it. Our team embodies our values of Courage, Care, Teamwork, Integrity and Humor in everything that they do. We have a culture of care that values and celebrates the qualities and perspectives that make us all unique.

If you have a disability and require assistance in the application process, please contact our Talent Acquisition Department at tad@retailbusinessservices.com.

For more information, visit https://www.retailbusinessservices.com.


Job Requisition: 313850_external_USA-MA-Quincy_9172023",-1,Food & Beverage Stores,$25 to $100 million (USD),Retail & Wholesale,1001 to 5000 Employees,Company - Public,False
Sr. Machine Learning / Data Science Engineer,"Seceon
","Westford, MA",$103K - $157K (Glassdoor est.),3.8,"Do you want to solve complex problems, roll up your sleeves and innovate?

Do you see yourself having fun building, brain-storming and positioning cutting-edge cybersecurity products in front of partners and customers?

Do you enjoy working in cutting-edge technologies that involve Big/Fast Data, powerful GUI, AI and Machine Learning?

If the answer to any of the questions above is yes, then we would love to hear from you! Our team has built a state-of-the-art comprehensive cybersecurity solution that has won 165+ awards in industry. Come join one of the hottest startups around where diligence, aspiration and customer centricity is highly valued.




Benefits:

Handsome Compensation Package
Comprehensive Medical Benefits
401K Plan (US Employees)
Passionate Team
Chance to wear Multiple Hats
Stocked Kitchen (Snacks & Beverages)
Flexible Work Environment



Please email your resume or cv to HR-USA (hrusa@seceon.com), HR-India (hrindia@seceon.com)




Sr. Machine Learning / Data Science Engineer



Do you want to innovate, stand out amongst your peers, and see your work protect largest Enterprises and Data Centers across the world from cyber security threats? All of this while working on cutting-edge Big and Fast data technologies, advanced machine learning techniques with great group of experienced engineers at one of the hottest startup companies around? Come work at a place where agility, developer productivity and continuous improvement are valued, and architectural and product roadmaps are downright awesome!

Here at Seceon, we believe that if you offer challenging projects to smart people, and give them the freedom to invent, you can create powerful products while being part of a fun, collaborative environment.

In this role you’ll:

Architect and build very highly scalable data-center security solution based on big and fast data analytics solution with supervised and unsupervised machine learning algorithms.
Work with small group of highly talented and experienced engineers with lots of opportunity to learn and contribute in all facets of the product.
Create clean, high quality code that leverages the best/latest thinking on design patterns and architectures like Spark ML, Functional programming.
Positively collaborate with other top-notch engineers, product managers and customers.
Continually drive improvement of process and product
Learn and grow, a LOT
Have fun, make friends, and contribute to our culture

About Us:

Seceon is a startup company focused on creating and reimaging Data Center Security solutions using latest innovations from industry and its own innovations to create highly scalable solute which has global view of applications, users and contexts but high-precisions to stop cyber attacks and breaches.

About You:

In depth knowledge of Machine Learning algorithms and techniques applied to network security
2-5+ years working experience applying Machine Learning methods to network security models and software packages
Strong math, analytical and problem solving skills
Solid experience in at least one of the Python, R and Scala with machine learning libraries and frameworks
Working Knowledge of big data frameworks such as Spark and databases such as Cassandra and Elasticsearch
Self-driven, passionate and team-oriented
Track record and working experience on Deep Learning real time response models with NGFW, SIEM, UEBA or Incident Response

Your technical buzzwords include some combination of (what we use in parentheses)

Experience with Big Data Technologies (Hadoop, Cassandra)
Knowledge of Real-time stream processing (Spark Streaming)
Realtime Messaging and Search Databases (Kafka, Elasticsearch)
Developer tools (Eclipse, Git, JIRA, Sonar)
Continuous Integration tools (Jenkins, Selenium)
Micro-service containers (Docker)
Service Oriented Architectures (RESTful APIs, JSON)
Relational and NoSQL database knowledge
Linux (Redhat, CentOS)

Education

Minimum BS in Computer Science, Statistics, Computer Engineering or related areas",-1,Security & Protective,Unknown / Non-Applicable,Management & Consulting,Unknown,Company - Private,False
"Principal Data Engineer, MS&T Robustness & Digital Strategies","Bristol Myers Squibb
","Devens, MA",$106K - $143K (Glassdoor est.),3.8,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.

Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.

Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.

Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us


Position Summary

At BMS, digital innovation and Information Technology are central to our vision of transforming patients’ lives through science. To accelerate our ability to innovate and guarantee supply to our patients around the world, we must unleash the power of technology. We are committed to being at the forefront of transforming the way medicine is made by harnessing the power of computer and data science, artificial intelligence, and other technologies to promote robust products and processes, faster decision making, and more efficient manufacturing and supply.

We are seeking an experienced and highly motivated data engineer to join the Robustness & Digital Strategies team within the Manufacturing Sciences & Technology (MS&T) organization. In this role, the Principal Data Engineer will be responsible for designing, building, and maintaining manufacturing data assets and data products to enable rapid investigation resolution and advanced multivariate model development for real-time process monitoring and control.

The ideal candidate will have exceptional background in data engineering, data systems, and data governance and will be comfortable working with both structured and unstructured data. Experience in Biopharma manufacturing processes and data types is a plus, but not required.

If you want an exciting and rewarding career that is meaningful and directly helps deliver lifesaving medicines to patients, consider joining our diverse team!

Key Responsibilities

Work as a member of the MS&T Robustness & Digital Strategies team to develop and implement data engineering solutions that deliver high-quality, contextualized datasets as an enabler of advanced process modelling and other analytics

Design and establish a scalable framework for engineering new features and processing modular datasets across different subject areas into modelling-ready data

Collaborate with Data & Supply Technology Excellence (DSTE) team within GPS IT to shape data and technology strategy and drive towards synergistic outcomes

Optimize or redesign existing data engineering solutions to improve efficiency or scalability

Devise and implement data engineering best practices across the team with a focus on short-term deliverables and strategic capabilities

Partner with and guide offshore data partner team who provides support in implementing, maintaining, and supporting data engineering pipeline

Mentor provide guidance to fellow Data Engineers where required

Leverage the latest advances in data engineering and analytics to design innovative solutions

Learn new technologies and lead proof-of-concepts to further innovate and optimize data engineering approaches

Acquire and maintain thorough understanding of internal and external manufacturing data landscape, including enterprise and site systems, data warehouses, and data lakes


Qualifications & Experience

Expected 9 years, 4 years with Ph.D., of experience in data engineering or DevOps environment

Minimum Bachelor’s degree in computer science, information systems, computer engineering, or equivalent experience

Advanced knowledge of Python or similar data engineering focused programming language

Hands-on experience implementing and operating cloud-based data ingestion, integration, transformation, storage, and virtualization solutions using company approved technologies such as AWS (Amazon Web Services) native services (S3, Glue, Athena, Redshift, RDS, Aurora, Lambda, etc.), Cloudera Data Platform (CDP), and Domino

In-depth experience with distributed processing systems like Apache Spark

Experience in DataOps workflow orchestration tools such as Apache Airflow, dbt, etc.

Deep experience and knowledge of:

Software engineering principles: testing (definition of unit tests, integration tests), setting up CI/CD pipelines in collaboration with DevOps teams, experience with Docker containers and kubernetes, experience developing or interacting with APIs

Data quality and validation principles: experience with libraries like great-expectations, pandera, pydantic, pandas profiler

Data architecture principles: data modeling, SQL query optimization, data warehouse design patterns

Security principles: data encryption, access control, authentication and authorization

Team management skills: strong track record of leading teams in the technical development of analytical solutions

Experience integrating with Spotfire or other visual analytics platforms like Tableau

Deep experience in definition and implementation of feature engineering

Good experience with agile/scrum development processes and concepts and with leveraging project management tools like Jira and Confluence

Experience managing multiple priorities and working in fast-paced, constantly evolving environment with a variety of cross-functional teams

Evaluates complex issues through analytical thinking and previous experience to consider short- and long-term implications and interdependencies

Excellent interpersonal, collaborative, team building, and communication skills to ensure effective collaborations within matrix teams. Demonstrated performance against cooperation principles and enterprise mindset.

Experience working in life sciences/biopharmaceutical industry is a plus

If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.

Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.

On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.

BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.

BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.

BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.

Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.

If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.

Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.

On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.

BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.

BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.

BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.

Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",1858,Biotech & Pharmaceuticals,$10+ billion (USD),Pharmaceutical & Biotechnology,10000+ Employees,Company - Public,False
"Senior Data Engineer, Public Company","Recruiting From Scratch
","Andover, MA",$100K - $200K (Employer est.),4.0,"This is for a client of Recruiting from Scratch.
Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Our Client:

Our next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we’re blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.

With a track record of strong financial performance and plans for continued headcount growth, we’re looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us.

What’s so interesting about this role?

Our client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .

In this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.

What’s the job?

Design, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.
Moving implementation to ownership of real-time and batch processing and data governance and policies.
Maintain and enforce the business contracts on how data should be represented and stored.
Stay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users
Implementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.
Work closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.

What we’ll love about you

5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.
7+ years experience using Python,
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )
Significant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.
Experience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Experience with dimensional data modeling and schema design in Data Warehouses
Familiar with ETL (managing high-quality reliable ETL pipelines)
Be familiar with legal compliance (with data management tools) data classification, and retention.

Salary Range: $165,000-$210,000 USD base. Equity. Medical, Dental, Vision.
https://www.recruitingfromscratch.com/",2019,Staffing & Subcontracting,$1 to $5 million (USD),Human Resources & Staffing,1 to 50 Employees,Company - Private,True
"Society of Hispanic Professional Engineers Convention (SHPE 2023) -Manager, Finance & Data Analytics","Novanta
","Bedford, MA",$68K - $100K (Glassdoor est.),2.7,"Build a career powered by innovations that matter! At Novanta, our innovations power technology products that are transforming healthcare and advanced manufacturing—improving productivity, enhancing people’s lives and redefining what’s possible. We create for our global customers engineered components and sub-systems that deliver extreme precision and performance for a range of mission-critical applications—from minimally invasive surgery to robotics to 3D metal printing.
Novanta is one global team with over 26 offices located in The Americas, Europe and Asia-Pacific. Looking for a great place to work? You have found it with a culture that embraces teamwork, collaboration and empowerment. Come explore Novanta.
This position is part of Novanta’s Corporate and Shared Services global team. Novanta’s Corporate and Shared Services teams play an important role in executing the company’s strategic mission and operations. Included in Corporate and Shared Services are the business functions including Finance, Accounting, Human Resources, Information Technology, Legal, Compliance, Corporate Development and Corporate Marketing. The Corporate and Shared Services teams work closely with all Novanta business units to support operating initiatives contributing to the organization’s financial success.
Job Summary
The role is responsible for leading data analytics processes and projects, both financial and operational, which are aligned to overall Company priorities and initiatives. This role requires strong data analytics design, business analysis and project management skills to help drive multiple data analysis projects designed to improve Novanta’s financial management and business operations. This individual is expected to heavily support the business requirements, analytics design, project management, and process management. This role is also expected to analyze data and provide insights and information to help the team make better financial and business decisions. The candidate must be a “hand’s on” contributor; who enjoys challenges and thrives in a demanding and sometimes under-developed environment.
Primary Responsibilities
Support special projects to drive Novanta’s digital transformation, including financial and data design support for projects in Business Intelligence, Customer Resource Management (CRM), Enterprise Resource Planning (ERP), and other projects
Recommend and drive process improvements across global FP&A and Finance processes, with a focus on data and reporting, driving efficiencies and improving decision making
Create and improve data analytics to Company leadership in relevant areas such as sales, backlog, margins, inventory, pricing, quality, purchasing, etc.
Synthesize financial planning and analysis processes company-wide, including budgets, forecasts, and management presentations
Lead and manage other Corporate Finance processes as needed
Required Experience, Education, Skills and Competencies
Bachelor’s degree in Finance, Accounting, Data Analytics, or similar
Approximately 5 years experience in some of the following areas: data analytics, project management, financial planning and analysis
Very strong financial, analytical, and modeling skills
Knowledge of good data governance practices, such as master data management, data quality, data architecture
Demonstrated success in project management, including scoping, resource management, working cross-functionally, hitting deadlines
Demonstrated success in process improvement initiatives, including problem identification & mitigation
Ideally experience in industrial manufacturing market
Experience using Business Intelligence tools (PowerBI, Tableau, etc.) is required. Experience with other database systems (middleware, data lakes) is optional but preferred
Advanced MS Excel and EPM tools (HFM, Oracle EPM, etc.)
Ability to handle multiple tasks concurrently; hand’s on individual contributor
Excellent written, verbal, analytical skills; strong interpersonal skills
Self-starter with the demonstrated ability to work in a fast-paced unstructured atmosphere with minimal supervision
Travel Requirements
Occasional travel is required to Novanta global locations.
Less than 20%
Novanta is proud to be an equal employment opportunity and affirmative action workplace. We consider all qualified applicants without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity or expression, national origin, military and veteran status, disability, genetics, or any other category protected by federal law or Novanta policy.
Please call +1 781-266-5700 if you need a disability accommodation for any part of the employment process.",1968,Health Care Products Manufacturing,$500 million to $1 billion (USD),Manufacturing,1001 to 5000 Employees,Company - Public,False
Principal Software Engineer - Data Migration,"Veeva Systems
","Boston, MA",$180K - $300K (Employer est.),3.9,"Veeva Systems is a mission-driven organization and pioneer in industry cloud, helping life sciences companies bring therapies to patients faster. As one of the fastest-growing SaaS companies in history, we surpassed $2B in revenue in our last fiscal year with extensive growth potential ahead.
At the heart of Veeva are our values: Do the Right Thing, Customer Success, Employee Success, and Speed. We’re not just any public company – we made history in 2021 by becoming a public benefit corporation (PBC), legally bound to balancing the interests of customers, employees, society, and investors.
As a Work Anywhere company, we support your flexibility to work from home or in the office, so you can thrive in your ideal environment.
Join us in transforming the life sciences industry, committed to making a positive impact on its customers, employees, and communities.
The Role
We are seeking an exceptional Principal Software Engineer to lead the development of a migration tool that will help us move our critical Salesforce data into Veeva Vault. This role will require deep expertise in AWS, Java, DevOps practices, and cloud architecture. The successful candidate will be responsible for end-to-end implementation, including designing, coding, testing, and maintaining the tool.
What You’ll Do

Architect, design, and implement scalable, reliable solutions leveraging AWS services and tools
Design and develop ETL data pipelines to facilitate the migration of data from Salesforce to Veeva Vault
Develop security protocols and best practices for IAM, VPC, and data encryption
Collaborate with cross-functional teams, including DevOps, to establish an effective CI/CD pipeline

Requirements

12+ years of software development experience
Extensive experience in Java stack service development, particularly with the Spring Boot library, is essential
Experience in architecting/implementing solutions using the AWS platform, services, and tools
Experience in designing and implementing solutions across various Cloud services such as Lambda, ECS, Fargate, RDS, S3, SQS, Glue, and Redshift
Understanding of network and security concepts, such as TCP/IP and DNS, including security best practices like IAM policies, VPC security groups, and encryption
Experience with Engineering/DevOps practices, agile methodologies, and container orchestration such as Docker or Kubernetes
Experience with ETL(Extract, Transform, Load) Data Pipeline
Knowledge of database and data storage technologies
Must be willing to work in PST hours
We are looking for strong mentors with a proven record of making your team better
Applicants must have the unrestricted right to work in the United States. Veeva will not provide sponsorship at this time

Learn More

Engineer Perspective: 3 Reasons to Consider Veeva
Engineering at Veeva

Perks & Benefits

Medical, dental, vision, and basic life insurance
Flexible PTO and company paid holidays
Retirement programs
1% charitable giving program

Compensation

Base pay: $180,000 – $300,000
The salary range listed here has been provided to comply with local regulations and represents a potential base salary range for this role. Please note that actual salaries may vary within the range above or below, depending on experience and location. We look at compensation for each individual and base our offer on your unique qualifications, experience, and expected contributions. This position may also be eligible for other types of compensation in addition to base salary, such as variable bonus and/or stock bonus.

#LI-RemoteUS
Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.
Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances. If you need assistance or accommodation due to a disability or special need when applying for a role or in our recruitment process, please contact us at talent_accommodations@veeva.com.",2007,Enterprise Software & Network Solutions,$1 to $5 billion (USD),Information Technology,5001 to 10000 Employees,Company - Public,False
Principal Data Driven Model Development Engineer,"Extreme Event Solutions
","Boston, MA",$99K - $143K (Glassdoor est.),3.7,"Company Description


We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.



Job Description


This opening is for a Principal Engineer at Extreme Event Solutions, a Verisk business in Boston, MA. This role will report to the Assistant Vice President of Operations for the Research and Model Development Department. This department consists of many engineers, scientists, economists, analysts, and mathematicians who develop and maintain a global suite of probabilistic risk models for natural hazards and emerging perils. These risk models are implemented into commercial software products that support the quantification and transfer of risk across the globe.

As a Principal Engineer, you will be uniquely situated between researchers who develop probabilistic risk models and software engineers who develop our commercial software products. This role will be primarily responsible for developing and maintaining a unified simulation platform that natural catastrophe models will leverage for performing risk calculations. The architecture of this platform should be compatible with the structure of the commercial software product while providing researchers the functionality and flexibility that is required to explore new and innovative modeling techniques. We are looking for someone who has an interest in developing natural catastrophe models in addition to being an excellent software developer. This person should be able to comprehend the physical concepts that underpin models of different perils as well as understand the flow of large datasets through a series of complex processing algorithms.

To be successful in this role, you will need to:

Learn how the existing suite of risk models is developed by researchers
Collect feedback from modeling and development teams on challenges and inefficiencies
Understand the implementation of these models within the commercial software product
Standardize a simulation platform that can accommodate a diverse portfolio of peril models
Imagine new approaches for efficiently handling vast amounts of simulation data
Ensure that deliverables satisfy the requirements of our researchers and downstream development partners

Day to Day Responsibilities (including but not limited to)

Meet with researchers to understand the flow of data through the loss simulation models
Optimize the way data is stored and processed to increase computational efficiency
Understand the capabilities and features that are required for conducting research
Develop and maintain code to support a standardized yet flexible research platform
Perform unit testing on the platform to ensure consistency and reproducibility of the results
Work with implementation engineers to integrate models with our commercial software
Design and administer the source control management system for the Research Department

#LI-SM1



Qualifications


Education and Experience

Degree in engineering, computer science, or a related field
Bachelor's degree required; Master’s degree preferred
Preference for candidates with a Civil Engineering background
5+ years of experience developing code to support risk modeling
Demonstrated track-record of efficient programming in C++, C#, or similar high-level language
Experience working in a collaborative program design environment
Experience developing computationally efficient applications
Preference for experience leveraging multi-threading and parallel computing
Comfortable developing in a Source Control Management System
Preference for experience administering TFS, Azure DevOps, and/or GitHub Enterprise environments
Preference for candidates with:
Working knowledge of SQL, C#, and .NET framework
Experience developing on Amazon Web Services (AWS)
Experience developing geospatial software and working with geospatial file formats

Skills

Works independently and with minimal supervision
Multi-tasks and stays organized in a dynamic environment
Manages a geospatially distributed team of developers
Brings enthusiasm, energy, and creativity to motivate and inspire your colleagues
Listens with empathy and provides communication tailored to your audience
Considers the Voice of the Customer to analyze and solve multi-faceted problems

Additional Information


At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.

Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.

But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.

It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.

At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.

At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the 7th consecutive year. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce. Verisk’s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work.

Verisk Analytics is an equal opportunity employer.

All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.

http://www.verisk.com/careers.html

Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Consumer Privacy Notice",1971,Research & Development,$1 to $5 billion (USD),Management & Consulting,5001 to 10000 Employees,Company - Public,True
