Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply
Data Engineer - 5050304,"Accenture
","Carmel, IN",-1,3.9,"Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.

As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.

You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.

Utilize strong SQL Python skills to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features.

Build reporting dashboards and visualizations to design, create and track campaign program KPIs.

Perform analyses on large data sets to understand drivers of operational efficiency.

Manage end to end process of analytic tooling feature development, including request intake, requirements evaluation, cross functional team alignment, feature execution, QA testing, and stakeholder communication.

Consult with business analysts, technical data SMEs, and cross functional partners to understand their reporting and data needs, serving as the point of contact for requests, inquiries, and actions.

Interface with other data engineering, product, and data science teams to implement client needs and initiatives.




Basic Qualifications:

Minimum 2 years experience with Python.

Minimum 3 years experience SQL.

Minimum 3 years experience Big Data Analytics.

High School Diploma or GED.

Preferred Qualifications:

Experience with large enterprise data sets.

Bachelors Degree

Compensation at Accenture varies depending on a wide array of factors, which may include but are not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York, or Washington as set forth below.

Information on benefits is here.

Role Location

California: $61.53 to $71.53/hour

Colorado: $61.53 to $71.53/hour

New York: $61.53 to $71.53/hour

Washington: $61.53 to $71.53/hour


What We Believe


We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.


Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here


Equal Employment Opportunity Statement


Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.


All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.


Accenture is committed to providing veteran employment opportunities to our service men and women.


For details, view a copy of the Accenture Equal Employment Opportunity and Affirmative Action Policy Statement.


Requesting An Accommodation


Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.


If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.


Other Employment Statements


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.


Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.


Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.


The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",1989,Business Consulting,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Engineer,"CSpring
","Indianapolis, IN",$86K - $116K (Glassdoor est.),4.4,"Description:

This is a great time to join our team at CSpring! Our team is looking for a full-time Data Engineer. If the idea of working on challenging assignments with a team who is passionate about serving others and creating insights sounds exciting, this may just be the role you’ve been looking for!

Summary

As a CSpring Consultant, you will be a true partner to our clients, dedicated to making each client a raving fan. In this role, you will work with a team to develop state of the art solutions to business problems. You will interact with our clients and project teams, leverage your business and technical skills, discuss solutions with team members, and analyze client needs to develop important solutions.

CSpring Data Engineers are responsible for engaging in the design, development and maintenance of data platforms and solutions. This includes the platform hosting data sets that support various business operations and enable data-driven decisions as well as the analytical solutions that provide visibility and decision support using data technologies. You will be responsible for administering data tooling, developing ETL/ELT pipelines, developing data integration solutions, resolving technical issues, and working with data scientists, business analysts, system administrators and data architects to ensure the platform meets business demands. This team member also ensures that solutions are scalable, include necessary monitoring, and adheres to best practices and guidelines.

Responsibilities

Develop ETL pipelines from various data repositories to load into various stages of the data platform
Develop data lake and warehouse architectures that support business objectives
Integrate platforms into the existing enterprise data warehouse and various operational systems
Develop administration processes to monitor pipeline performance, resource usage, and failure
Address performance and scalability issues in a large-scale data lake environment
Provide data platform support and issue resolution
Requirements:
Proven experience as a Data Engineer, with a strong track record of building and maintaining data pipelines
Experience with Azure solutions such as functions, Synapse Data Warehousing, Data Factory, and Databricks
Proficiency in developing batch and/or streaming ETL/ELT processes
Strong development skills in languages such as Python, Java, or Scala
Experience with data modeling and database design (SQL and NoSQL)
Experience with visualization platforms, such as Tableau or Power BI
Familiarity with data integration tools and technologies
Excellent problem-solving skills and attention to detail
Strong communication and teamwork skills

Preferred Qualifications

Bachelor’s degree in computer science, software engineering or a closely related field
Experience working on a development team including teams running an agile methodology
Prior experience working in State, Health and Human Services

About CSpring

CSpring is a growing, Indianapolis-based technology consulting firm focused on data-driven solutions. Our team aligns business goals with technology to make information accessible, reliable, and engaging via custom and integrated software, data platforms, and advanced analytics.

If you are committed, collaborative, consultative, and caring – you will fit right in with our team. We pride ourselves in working together and understand that the whole is stronger than any one of us individually. When you join CSpring, you become part of our family - our Ohana. When you're part of our Ohana, we promise to communicate well, provide opportunities for growth, and most importantly, celebrate our successes together. Being part of CSpring’s Ohana means you will be informed, recognized, rewarded, and respected. You will also have lots of opportunity to develop strong relationships with our team at quarterly company update events, monthly outings, community service opportunities, learning lunches, and more.

CSpring offers a comprehensive compensation, training, and benefits package; including Paid Time Off, Medical/Dental/Vision/Life/Disability insurance on day one, and 401(k) with company match.",1996,Information Technology Support Services,Unknown / Non-Applicable,Information Technology,51 to 200 Employees,Company - Private,True
Data Center Chief Engineer,"Amazon Data Services, Inc.
","Portage, IN",$69K - $120K (Glassdoor est.),3.7,"Technical (Military/Trade School) training or degree in a relevant field (for example: electrical, mechanical).
5+ years of electrical or mechanical experience.
4+ years of data center or mission critical facilities (example: hospital, military facility, public safety facility, etc.) experience.
5+ years of experience MS Office Suite experience.
How would you like to be a part of Earth’s most customer-centric company? You would work with teams of front-line responders who support the operations of some of the world’s most powerful data centers. Our Data Center Engineering Operations team maintain and operate our critical infrastructure systems so that they are prepared to stand up against any situation.

AWS has the world’s largest cloud computing portfolio. As an Amazonian you will work in some of the most sophisticated, safe, and secure data centers in the world. Our Chief Engineers help keep them that way by working with the brightest minds from around the globe to help test and implement the newest technology and work practices to meet the demands of a changing market.

We have a passion for learning and evolving, it’s how we have helped define ourselves as leaders in the industry. Let’s work hard, have fun, and make history!

Key job responsibilities
This position requires you to be an energetic self-starter who will be provided an overall direction the facility needs to be heading. It is expected that, with that provided direction, you are able to ensure all work is scheduled and performed to help meet our goals. This job also requires a strong mechanical and electrical background and the ability to create strong working relationships with internal and external groups.

A day in the life

Each day you will look at the schedule of current and upcoming work, check on the progress of the maintenance work orders being ready to work, assign tasks to the EOTs, ensure PMs are being performed and completed in the tracking tool, and escalate any issues to the Facility Manager. All of this includes major evolutions which could impact customer load to minor evolutions such as office repairs. It is expected that you are the owner of the work going on in your building and work with the FM to ensure our success.

Day in the Life of a Chief Engineer

Operate independently with limited direct management.
Act as an escalation point for all facilities-related issues.
Oversee operation and management of routine and emergency services on a variety of critical systems such as: switchgear, generators, UPS systems, power distribution equipment, chillers, cooling towers, computer room air handlers, building monitoring systems, etc.
Drive projects with moderate complexity.
Perform root cause analysis of equipment failures.
Provide training and guidance to Engineering Operations Technicians and responsible for working with Facility Manager (FM) to set team culture.
Responsible for drills that are building specific and identifying team/individual areas for improvement. Also responsible for working with FM to help improve on the identified weakness.
Create and deploy ensure compliance for new standard practices for Engineering Operations Technicians, and vendor support teams.
Establish building performance benchmarks, conduct analyses, and prepare reports on all aspects of the critical facility operations and maintenance.
Communicate complex technical information to a non-technical audience.
May assist in the design and build out of new facilities.
Work with IT managers and other business leaders to coordinate projects, manage capacity, and optimize plant safety, performance, reliability and efficiency.
Respond to out of hours emergency calls – second level escalation point for Data Center facilities related issues / failures.
Working outside of normal business hours for routine maintenance as required.
Some travel may be required.
Walk job sites in uneven terrain. Maintain balance and perform construction tasks while on a ladder.
Regularly lift and/or move up to 39 pounds independently and participate in group lifts for 40+ pounds.
Regularly walk, use hands and fingers, handle or touch, reach with hands and arms, stoop, kneel, crouch or crawl
We are open to hiring candidates to work out of one of the following locations:

Portage, IN, USA


4+ years of Data Center Engineering Experience.
Associates or Bachelor’s Degree.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",1994,Internet & Web Services,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Senior Data Engineer,"Do it Best Corp.
","Fort Wayne, IN",$96K - $132K (Glassdoor est.),3.3,"Senior Data Engineer


Do you love data? Looking to grow your development career? We are looking for a motivated and positive individual to join our team and do just that!
Based in Fort Wayne, Ind., Do it Best Corp. proudly serves thousands of member-owned home improvement businesses throughout the US and all around the world. We provide everything independent hardware stores, home centers, lumberyards, industrial/commercial distributors, and e-tailers need to grow their businesses and achieve their dreams. With annual sales of $5.2 billion, Do it Best Corp. serves member-owned stores in the United States and 50 foreign countries and prides itself on offering opportunities for advancement and benefits, such as tuition reimbursement.
Description
Our data engineers are focused on improving business decisions by making available clean, reliable, and well-understood data. We leverage agile frameworks for delivery and are focused on highest-value capabilities, data quality, security, and solution economics. As part of the Analytics team we develop actionable insights for the enterprise.
Responsibilities
Design and build data warehouse solutions
Build ETL processes for batch and real-time analytics
Leverage agile software development frameworks for product delivery and write clean, scalable code
Partner with peers, scrum masters, product owners, and other stakeholders on product delivery
Create high-quality analytics solutions that delight users, are aligned with standards and guiding principles, and are maintainable and easy to support
Ensure solution economics and total cost of ownership are considered during design and development
Collaborate with Architecture & Engineering team on creation of new data architecture or enhancements to existing solutions
Partner with IT operational teams and other stakeholders resolving issues and providing technical support
Education, Experience, and Skills
Two-year degree in Computer Science / related discipline or equivalent training / experience
Experience or training with agile frameworks
Experience or training with cloud, web, integration, and data development in a business environment
Knowledge of and experience with IT security and data privacy best-practices
Strong analytical and problem-solving skills
Disciplined, focused, and self-motivated
Strong planning and organizational skills
Strong interpersonal, written, and verbal communication skills
Advantages
Knowledge of retail and distribution business processes
Experience with Test Driven Development (TDD) and writing automated tests
Experience with Scrum or Kanban
Experience with Azure DevOps
Experience with SQL development
Experience with building/designing Data Warehouses
Experience with cloud technologies and open source technologies",-1,Home Furniture & Housewares Stores,$1 to $5 billion (USD),Retail & Wholesale,1001 to 5000 Employees,Company - Private,True
Data Engineer,"Resultant
","Indianapolis, IN",$72K - $103K (Glassdoor est.),3.8,"Company Description


Resultant is a modern consulting firm with a radically different approach to solving problems.

We don’t solve problems for our clients. We solve problems with them.

Through outcomes driven by data analytics, technology solutions, digital transformation, and beyond, our team works with clients in both the public and private sectors to solve their most complex challenges. We start by learning as much as we can about who they are, how they work, and what they’re striving for so we can feel their problems as our own. Partnering with our clients means their desired outcomes are always top of mind, their challenges and strengths guiding our efforts. We build client-focused relationships before we build unique solutions that blaze past expectations.

Originally founded in Indianapolis in 2008, Resultant now employs more than 400 team members who operate from offices around the United States including Indianapolis and Fort Wayne, Indiana; Columbus, Ohio; Lansing, Michigan; Denver, Colorado; Dallas, Texas and Atlanta, Georgia.

We’re Resultant. Clients partner with us to see a difference. People join us to make one.



Job Description


At Resultant we are fearless problem solvers. We are passionate about helping our clients solve their toughest problems. Data analytics is a core component of how we do this.

We are looking for Data Engineers to join our talented data analytics team. As a Data Engineer, you will work closely with many teams across our company on complex, advanced analytical projects to perform data sourcing, data profiling, and other data manipulation functions.

You will be directly responsible for the solutions we build for our clients, addressing their business needs through requirements gathering and collaborating on solution reviews. We are looking for self-starters with the skills necessary to empathize with the clients’ needs, translate technical complexities, develop appropriate solutions, and contribute to the growth of our technology and data-driven company.

Consider your day-to-day responsibilities in this role:

Work closely with the solution leads, project managers, data architects, and data scientists on solution design, architecture, and implementation
Performing extraction, transformation, and loading of data from a wide variety of data sources using various data engineering tools and methods.
Querying and processing large data sets and perform data quality checks.
Designing and implementing data solutions for operational and secure integration across systems.
Assist in creating database models and architecture design and documentation
Conduct research and development as well as contribute to the long-term positioning of and emerging technologies related to data sourcing, cleansing, and integration
Documenting and demonstrating solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code.
Improving operations by conducting systems analysis; recommending changes in policies and procedures.
Involvement in client-facing project activities such as requirements gathering, solution reviews, and explaining technical complexities and business benefits in layperson terms.


Qualifications


Some of the qualifications and skills we are expecting include the following:

Bachelor’s degree in Computer Science, Engineering or a similar field is required
3+ years of data engineering, software engineer, or similar experience
3+ years od data warehouse integration experience using tools such as Wherescape, Matillion, Fivetran, etc.
2+ hands-on industry experience working with SQL on various relational database platforms (Microsoft, Oracle, Hana, Postgres, etc.)
2+ hands-on industry experience working with enterprise ETL/DW tools like Azure Data Factory, Snowflake, Redshift, Informatica, etc.
Hands-on experience with aspects of data engineering design and implementation including data sourcing, data modeling of warehouses/marts/repositories, data integration/transformation/ETL, APIs, reporting, business intelligence and analytics
Hands-on experience with modern programing languages like Python, C#, JavaScript, etc.
Hands-on experience with cloud platforms like AWS, Azure, GCP, etc.
Hands-on experience with NoSQL databases like MongoDB (preferred), CouchDB, Cosmos, etc. a plus
Hands-on experience with Graph databases like Neo4j (preferred), Cosmos DB, Neptune, etc. a plus
Experience with Docker for containerization and Kubernetes for orchestration a plus
Experience with “big data” and distributed tools like Hadoop, Spark, Cloudera, etc. a plus
Collaborative team player who is detailed oriented, focused on solution quality and execution
Progressive mindset particularly around deployment models and emerging technologies
Comfortable working across a wide range of project sizes and industries

Additional Information


What you should know about us:

We are humble, hungry, and smart. We solve big problems, serve lots of clients, and are entirely committed to delivering transformative outcomes.
We are team players, deeply dedicated to the mission of the organization, and to helping everyone around us be successful.
We compensate well, rewarding performance that delivers positive outcomes for our clients.
Our leaders work hard, serving as shining examples of what it means to live out our values. They are servant leaders, helping their teams to be successful in all possible ways.
We offer several opportunities to develop yourself.
We pride ourselves in having the best talent in the industry and hope that you're up for the challenge!

What our team members say about us:

""I love our true empathy and concern for our clients, it's very rare and appreciated. It is a pleasure to be a part of an organization like this.""
""I learn something new every single day, and I feel like I'm a part of building an organization that has legs. I appreciate that I'm consistently humbled by the talent and caliber of our team.""
""The culture of the company is amazing, and the climate of my team is great. The benefits that employees are offered are better than competitors, and the one-on-one presence that my team lead gives is extremely beneficial to me.""

All qualified applicants will receive consideration for employment without regard to age, color, sex, disability, national origin, race, religion, or veteran status.

Equal Opportunity Employer",2008,Business Consulting,Unknown / Non-Applicable,Management & Consulting,201 to 500 Employees,Company - Private,False
Data Engineer,"Community Health Network
","Indianapolis, IN",$76K - $100K (Glassdoor est.),4.0,"Hours
8:00am - 5:00pm, Monday - Friday


Schedule
Full-time



Join Community

Community Health Network was created by our neighbors, for our neighbors. Over 60 years later, “community” is still the heart of our organization. It means providing our neighbors with the best care possible, backed by state-of-the-art technology. It means getting involved in the communities we serve through volunteer opportunities and benefits initiatives. It means ensuring our dedicated caregivers can learn and grow to stay at the top of their fields and to better serve our patients. And above all, it means exceptional care, simply delivered — and we couldn’t do it without you.

Make a Difference

We are looking for an experienced and talented Data Engineer to join our team! The Data Engineer will be responsible for developing solutions to manage and optimize data in a way that empowers analysts and end users with relevant data to help in the decision-making process. The Data Engineer will be expected to collaborate with data scientists, data analysts, and other data consumers throughout the network. The Data Engineer will be expected to use industry-standard practices and cloud-based tools such as Azure Data Factory, Azure Data Lake, DataBricks, and Azure SQL database to build and develop data-focused initiatives across the Network.

Exceptional Skills and Qualifications

Applicants for this position should be able to collaborate with others in a team setting, have excellent communication skills, and attention to detail.



Bachelor’s degree preferred.
In lieu of above education requirements, a combination of experience and education will be considered.
Must obtain DP-203 Data Engineering on Microsoft Azure certification within 12 months of hire.
Three (3) years of professional experience with relational databases using Microsoft Server technology stack required.
Developing Reporting Services (SSRS), Power BI or Qlik View reports. -Designing tables, writing SQL queries, Stored Procedures, and developing data models required.
Ability in working with large, heterogeneous datasets, building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies as well as Azure Data Factory, Synapse, and Databricks platforms using Python and SQL languages required.
Must also have a strong ability with SQL language. Azure Cosmos, Azure FIHR, Scala, and R Language, Databricks, Databricks Delta Lake, Azure SQL, Synapse, Microsoft Power BI
Ability to communicate effectively through public speaking, power point, dashboards, visualizations, and/or other presentations formats.

Why Community?

At Community Health Network, we build teams that deliver exceptional care through empathy, communication and collaboration. We consider ALL an integral part of the exceptional patient experience. We PRIIDE ourselves on not having employees but Caregivers. Join our Community as we make a difference in your community.

Caring people apply here.

Apply Today!",1956,Health Care Services & Hospitals,$1 to $5 billion (USD),Healthcare,10000+ Employees,Nonprofit Organization,False
Data Engineer 2,"Cook Group
","Bloomington, IN",$86K - $116K (Glassdoor est.),3.6,"Overview:
The Data Engineer develops, implements and documents data systems that provide the technical solutions to meet specifications and business requirements defined by company objectives to promote effective, efficient, and compliant operations. Experience with Azure preferrable. Experience with relational SQL and NoSQL databases; experience with SQL Server, Azure, Oracle, and/or MongoDB preferred.

**Hybird or Remote position with expectation of Eastern Time Zone Hours.
Responsibilities:
Work as part of a project team to define and document data and data pipelines for a variety of solutions.
Technical responsibility for data and data pipelines to ensure compliance with data standards, architectural standards, and achievement of documented requirements.
Develop and maintain current state documentation and deliverables for data solutions.
Maintain existing and new data solutions to ensure that they continue to meet user needs.
Provide assistance to operational teams to ensure continuity of service.
Work with the Data Engineering community of practice to identify and implement continuous improvement opportunities.
Must have excellent analytical and problem solving skills
Performs other duties as assigned
Possesses solid working knowledge of subject matter.
May provide leadership, coaching, and/or mentoring to a subordinate group.
Ability to manage tasks independently and take ownership of responsibilities
Performs work under minimal supervision.
Demonstrated organizational, analytical and interpersonal skills
Must work and interact effectively and professionally with and for others throughout various levels of the global organization
Must have effective communication skills and ability to work in a collaborative and independent work situations and environments with minimal supervision
Ability to remain calm and receptive in fast paced situations
Ability to manage tasks independently; take ownership of responsibilities
Qualifications:
Bachelors Degree in Computer Science or other related degree; or experience of such kind and amount as to provide a comparable background.
Experience with relational SQL and NoSQL databases; experience with SQL Server, Oracle, and/or MongoDB preferred.
Preferrable 4-6 years of experience as Data Engineer
Experience building data transformations, data structures, and data pipelines.
Experience with data integration tools.
Experience with object-oriented/object function scripting languages.
Demonstrated organizational, analytical and interpersonal skills
Ability to manage tasks independently; take ownership of responsibilities

Physical Requirements:

Works under general office environment conditions
Sitting for extended periods, utilizes close visual acuity for working with computers, equipment, etc.
Must be able to perform the essential functions of the job, subject to reasonable accommodation requirements under the ADA
Requires occasional early morning or late evening teleconferences
International and domestic travel as required

**For this position, qualified candidates must be legally authorized to be employed in the United States. Cook does not intend to provide sponsorship for employment visa status (e.g., H-1B or TN status) for this employment position.",1963,Health Care Products Manufacturing,$1 to $5 billion (USD),Manufacturing,10000+ Employees,Company - Private,False
Senior Data Engineer I,"Allegion
","Carmel, IN",$88K - $114K (Glassdoor est.),4.1,"Creating Peace of Mind by Pioneering Safety and Security
At Allegion, we help keep the people you know and love safe and secure where they live, work and visit. With more than 30 brands, 11,000+ employees globally and products sold in 130 countries, we specialize in security around the doorway and beyond.
Summary:
This position functions within Allegion’s Global Data & Analytics Team and will support Data Warehouse initiatives of the Data Engineering Team. This role is strategically designed to support existing Analytical Solutions as well as implement ETL solutions within Azure Data Factory. This role will be responsible for collaborating with the Global Data Team, designing and rolling out technical solutions within Allegion’s Global Data Architecture and Best Practice.
Major Job Duties and Responsibilities:
Collaborate with Global Data Team Members to review requirements & translate to ETL design and implementation.
Understand Extract Transform and Load technical approaches and designs
Understand the agile approach, leveraging best practices and implementing/documenting repeatable processes
Coordinate with all source-system, and IT teams to ensure integration points are managed and involved
Perform technical validation of extracted data
Follow Allegion code management processes and utilize specified tools.
Support & Maintain Allegion’s Global Data Assets
Skills and Competencies
Ability to execute and deliver to milestones
5+ Years’ experience in data warehousing.
Be self-motivated and highly organized with good time management skills.
Execute and deliver with agile / iterative approach.
Work well in teams that may be globally co-located.
Flexibility and adaptability in responsibilities as required
Experience working with Azure Data Factory or Extract-Transform-Load Tool equivalent
Experience working with SQL Server Databases
Bachelor’s degree (preferred in an IT-related discipline)
Preferred Education/ Experience.
Basic Python Data Transformation Skills
Basic PowerBI or Analysis Services Knowledge for Data Analysis
Working Knowledge of Event Hub, Azure Function Apps, & IoT Hub
We Celebrate Who We Are!
Allegion is committed to building and maintaining a diverse and inclusive workplace. Together, we embrace all differences and similarities among colleagues, as well as the differences and similarities within the relationships that we foster with customers, suppliers and the communities where we live and work. Whatever your background, experience, race, color, national origin, religion, age, gender, gender identity, disability status, sexual orientation, protected veteran status, or any other characteristic protected by law, we will make sure that you have every opportunity to impress us in your application and the opportunity to give your best at work, not because we’re required to, but because it’s the right thing to do. We are also committed to providing accommodations for persons with disabilities. If for any reason you cannot apply through our career site and require an accommodation or assistance, please
contact our Talent Acquisition Team.
© Allegion plc, 2020 | Block D, Iveagh Court, Harcourt Road, Dublin 2, Co. Dublin, Ireland
REGISTERED IN IRELAND WITH LIMITED LIABILITY REGISTERED NUMBER 527370
Allegion is an
equal opportunity and affirmative action employer",2013,Consumer Product Manufacturing,$1 to $5 billion (USD),Manufacturing,10000+ Employees,Company - Public,False
Data Engineer LMTS - Pricing,"Salesforce
","Indianapolis, IN",$91K - $134K (Glassdoor est.),4.0,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Software Engineering

Job Details

About Salesforce

We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.

Org Overview

The Data and Analytics Organization is Salesforce's cornerstone for fostering growth and margins through unparalleled data insights. From robust governance to strategic execution, we support data pioneers with an unbiased approach. Our Enterprise Data Strategy builds a solid data foundation, fostering a culture of data-driven decisions. We ensure end-to-end quality through a cohesive data supply chain. By deploying and integration platform tools, we enable seamless data access and automated data management driving efficiency and growth with actionable insights. As a steadfast partner, we shape a data ecosystem that fuels innovation. Our commitment to integrity and accessibility propels informed decision-making, propelling Salesforce to new heights of excellence.

Team Overview

Data Strategy and Management Engineering team brings Data to life, partnering with data producers and platform engineers to empower data consumers (data scientists, data analysts and visualization engineers) who consume data for business analytics and AI augmented solutions. We do this by delivering trusted data, in an agile way and make it accessible for a variety of use cases. We pride ourselves in being data curious (one who has an intrinsic need to understand a data point). We architect, automate, and scale our data curation frameworks, services, and processes to rapidly integrate disconnected and disparate raw data into a business-relevant asset and work towards one common theme - Customer Success.

Responsibilities:

Design efficient and scalable data pipelines for collecting, transforming, and loading data from various sources.
Implement error handling and monitoring mechanisms to ensure data quality and pipeline reliability.
Partner with data producers in understanding data sources, enable data contracts and define the data model that drives analytical use cases
Optimize data storage solutions while implementing strategies for query performance, cost and scalability
Monitor and enhance data pipelines' performance, availability and scalability, addressing bottlenecks and latency.
Ensure data security and compliance with relevant regulations (e.g., GDPR,) implements data masking, access control and other data protection measures
SME of the solution, able to connect work with the business impact
Collaborate with cross-functional teams, provide technical guidance, and mentor junior engineers.
Evaluate various technologies and platforms in open source and internal solutions. Execute proof of concept on new technology and tools to pick the best tools and solutions as needed



Requirements

B.S/M.S. in Computer Sciences or equivalent experience in big data engineering, data acquisition and integration projects.
5+ years experience designing, implementing and maintaining relational / data warehousing environments (custom or structured ETL, preferably working with large data environments)
Strong background in Data Warehousing concepts and schema design.
Strong proficiency in programming languages commonly used in data engineering, such as Python, SQL and big data technologies such as Hadoop, Spark, Kafka, and distributed computing frameworks.
In-depth understanding of data modeling, lakehouse/data mesh technologies, proficiency in building frameworks and data pipelines. Experience in using test driven frameworks, version control, conducting efficient code reviews, deployment strategies
Strong problem-solving skills and the ability to troubleshoot complex data-related issues with prime focus on data quality and management
Excellent communication skills to collaborate with technical and non-technical stakeholders, laser focus on the impact, curious, team player
A beginner and continuous improvement mindset, always seeking opportunities for automation, process enhancement, and reusable tool creation.





Preferred:

Salesforce products knowledge, working with Salesforce metadata is a plus
Experience working with Public Cloud platforms like GCP, AWS, Snowflake
Familiar with production debugging techniques such as thread dump analysis and GC performance tuning

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .

Posting Statement

At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .

Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce . ﻿

Salesforce welcomes all.",1999,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
Senior Data Engineer,"Burns & McDonnell
",Indiana,-1,4.1,"Description

1.Designing and building data pipelines that move data from various sources into a centralized data warehouse or data lake. 2.Design, develop, and maintain SQL scripts and procedures for data extraction, transformation, and loading (ETL) processes. 3.Implement scalable and optimized data processing solutions using Spark, Delta Lake, and other big data technologies. 4.Building and maintaining the infrastructure required to support data processing and analysis, including databases, data warehouses, and data lakes. 5.Developing ETL processes to transform raw data into a usable format for analysis. 6.Creating and maintaining data models that provide a clear and consistent view of the data. 7.Ensuring data quality and consistency across various data sources. 8.Optimizing the performance of data processing and analysis infrastructure to ensure fast and efficient data retrieval. 9.Keeping up-to-date with the latest trends and technologies in data engineering and applying them to improve the data infrastructure. 10.Troubleshooting data-related issues and working with the IT team to resolve any technical problems. 11.Ensuring that data privacy and security protocols are in place and adhered to.

Qualifications

Bachelor's degree in Computer Science, Information Technology, Management Information Systems (MIS), Data Science or related field. Applicable years of experience may be substituted for the degree requirement.
Up to 4 years of experience in software engineering
Experience with large-scale data warehousing tools like Databricks/synapse/snowflake.
Worked with Cloud-based architecture such as Azure Cloud/AWS/GCP
Experience on working with ETL/ELT tools like Airflow/ADF/Glue/DLT/DBT(Preferred).
Experience implementing streaming use cases using Kafka/EventHub/Kinesis.
Working knowledge on Relational/No-Sql databases like Postgres/Sql/Oracle/MongoDb.
Expert in SQL and high-level languages such as Python, Java or Scala preferred
Experience in infrastructure as code / CICD development environment, Terraform knowledge preferred.
Proven ability to build, manage and foster a team-oriented environment
Excellent communication (written and oral) and interpersonal skills
Excellent organizational, multi-tasking, and time-management skills

Job Information Technology

Primary Location India-Maharashtra-Mumbai

Schedule: Full-time

Travel: No

Req ID: 224959 Job Hire Type Experienced

Not Applicable #BMI N/A",1898,Construction,$5 to $10 billion (USD),"Construction, Repair & Maintenance Services",10000+ Employees,Company - Private,False
Senior Data Engineer,"Purdue University
","West Lafayette, IN",$104K - $136K (Glassdoor est.),4.3,"Job Summary

The Senior Data Engineer will be an integral part of our data science team at the Regenstrief Center for Healthcare Engineering (RCHE) .This role will architect and develop data engineering solutions to support strategic partnerships, faculty research, operations, education, and outreach needs. This position will be responsible for designing, building, and maintaining data pipelines and tools to assemble and prepare complex datasets for downstream analysis. The position will work independently and within a team environment to gather requirements, review designs, implement and/or integrate new functionality, maintain systems, and assist with quality assurance; create and maintain system documentation to help train operational staff and user guides to train end users and provide some level of direct support to end users; and collaborate with research groups through participation in project meetings and assistance in outreach activities. This position will participate in national computing activities by attending workshops, conferences, presenting projects and contribute to writing conference and journal papers and grant proposals.




Who We Are at Purdue:
The Regenstrief Center for Healthcare Engineering (RCHE) conducts research to improve the quality, accessibility, and affordability of healthcare delivery through collaboration, partnerships, and engagement. RCHE’s team is comprised of researchers, staff, and outreach advisors that collaborate with the healthcare community to develop science-based approaches to personalized care, match health resources with community needs, and improve access to care among rural communities in Indiana and around the world. The RCHE is committed to promoting and advancing all forms of diversity, equity, inclusion, and access (DEIA) to create an environment and culture where the uniqueness of individuals is celebrated, and persons from all backgrounds can thrive.




Duties & Responsibilities

Design, develop, deploy, and maintain data pipelines and data infrastructure tools.
Define, design, and implement data governance platform strategies for operational, privacy, data quality, and security components.
Build data models including robust data definitions, entity-relationship-attribute models, as well as relational and/or dimensional models.
Design technical strategies and roadmaps for Data Integration, Data Warehousing, Analytics, Reporting, and Data Science.
Validate the data quality and integration of all Data Architecture Components deemed to be cross-domain or enterprise in scope
Responsible for collection of necessary Data Architecture metrics to support quality of processes and related artifacts.
Maintain, propose changes, and verify compliance to Data Architecture Standards and Best Practices.
Collaborate with research groups to gather requirements, review priorities, and plan development tasks with timelines.
Collaborate with the data science team to support the successful delivery of data initiatives. Participate in design and code reviews.
Work independently and collaborate in a team environment

Qualifications




Required:

Bachelor’s degree in Computer Science, Computer Engineering, or Computer information related field
Four (4) years of experience in one or more of the following:
Working as a Data Architect, Database Developer, or in a similar capacity involving data management
Architecting data-driven solutions involving relational and non-relational data stores, Data Warehousing platforms (OLAP and OLTP) and Data Lake concepts and architecture
Designing, implementing, and migration cloud-based data platforms such as AWS, Azure
Equivalent combinations of education and experience may be considered.
Common programing language such Shell and Python, Java, and Scale
Knowledge in technologies such as Hadoop, Spark, and other tools from the open-source big data ecosystem
Knowledge of version control software, i.e. GIT
Ability to work as part of a high performing team in a collaborative environment
Ability to plan, organize and prioritize tasks, and complete projects with minimal supervision
Demonstrated skills in data/pipeline design and development and standard data engineering and access management best practices
Knowledge of common data engineering software, languages, and packages
Excellent oral, written, and computer communication skills with strong analytical and troubleshooting skills



Preferred:

Experience with health care related data such as electronic health records, PACS medical imaging, or wearable devices
Knowledge of HIPAA rules and data security.



Additional Information:

To learn more about Purdue’s benefits summary https://bit.ly/3t7vcRd
A background check will be required for employment in this position
FLSA: Exempt (Not Eligible For Overtime)
Retirement Eligibility: Defined Contribution Waiting Period
Purdue University is an EOE/AA employer. All individuals, including minorities, women, individuals with disabilities, and veterans are encouraged to apply",1869,Colleges & Universities,Unknown / Non-Applicable,Education,10000+ Employees,College / University,False
"Senior AI Data Engineer (UK must reside in England, Scotland, or Northern Ireland) 100% REMOTE","PlagScan
","Scotland, IN",$108K - $181K (Employer est.),4.0,"Your role as a Senior Data Engineer entails a range of responsibilities, necessitating a balanced skillset:

AI Data Engineering: Design, build, operate and deploy real-time data pipelines at scale using AI techniques and best practices. Support Turnitin's AI R&D efforts by applying advanced data warehousing, data science, and data engineering technologies. Aim for automation to enable a faster time-to-market and better reusability of new AI initiatives.
Collaboration: Work in tandem with the AI R&D teams and the Data Platform Team to collect, create, curate and maintain high-quality AI datasets. Ensure alignment of data architecture and data models across different products and platforms.
Innovation: Unearth insights from Turnitin's rich data resources through innovative research and development.
Hands-on Involvement: Engage in data engineering and data science tasks as required to support the team and the projects. Conduct and own external data collection efforts - including state of the art prompt engineering techniques - to support the construction of state of the art AI models.
Communication: Foster clear communication within the team and the organization, and ensure understanding of the company's vision and mission.
Continuous Learning: Keep abreast of new tools and development strategies, bringing innovative recommendations to leadership.

Qualifications
At least 4 years of experience in data engineering, ideally focused on enabling and accelerating AI R&D.
Strong proficiency in Python, Java, and SQL.
Proficiency with Redshift, Hadoop, Elasticsearch, and cloud platforms (AWS, Azure, GCP).
Familiarity interacting with AI frameworks including PyTorch and TensorFlow and AI libraries such as Huggingface and Scikit-Learn.
Experience with Large Language Models (LLMs) and LLM APIs.
Strong problem-solving, analytical, and communication skills, along with the ability to thrive in a fast-paced, collaborative environment.

Desired Qualifications

6+ years of experience in data engineering with a focus on AI and machine learning projects.
Experience in a technical leadership role.
Familiarity with natural language processing (NLP) techniques and tools.
Experience in the education or education technology sectors.
Experience with data visualization and data communications.

Characteristics for Success

As a Senior Data Engineer, you should possess:
A passion for creatively solving complex data problems.
The ability to work collaboratively and cross-functionally.
A continuous learning mindset, always striving to improve your skills and knowledge.
A proven track record of delivering results and ensuring a high level of quality.
Strong written and verbal communication skills.
Curiosity about the problems at hand, the field at large, and the best solutions.
Strong system-level problem-solving skills.

Additional Information

The expected annual base salary range for this position is: $108,308/year to $180,514/year. This position is bonus eligible / commission-based. As a Remote-First company, actual compensation will be provided in writing at the time of offer, if extended, and is determined by work location and a range of other relevant factors, including but not limited to: experience, skills, degrees, licensures, certifications, and other job-related factors. Internal equity, market and organizational factors are also considered.

Total Rewards @ Turnitin

Turnitin maintains a Total Rewards package that is competitive within the local job market. People tend to think about their Total Rewards monetarily – solely as regular pay plus bonus or commission. This what they earn in exchange for what they do. However, Turnitin delivers more than just these components. Beyond the intrinsic rewards of making a difference in the lives of educators, administrators, learners and researchers around the world, and thriving in an organization that is free of politics and full of humble, inclusive and collaborative teammates, the extrinsic rewards at Turnitin include generous time off and health and wellness programs that offer choice and flexibility and provide a safety net for the challenges that life presents from time to time. In our Remote-First approach to collaborating, you are also able to work the way that best fits your style and situation – whether that be remote, in one of our offices/rented spaces or hybrid.

Our Mission is to ensure the integrity of global education and meaningfully improve learning outcomes.

Our Values underpin everything we do.

Customer Centric - We realize our mission to ensure integrity and improve learning outcomes by putting educators and learners at the center of everything we do.

Passion for Learning - We seek out teammates that are constantly learning and growing and build a workplace which enables them to do so.

Integrity - We believe integrity is the heartbeat of ExamSoft. It shapes our products, the way we treat each other, and how we work with our customers and vendors.

Action & Ownership - We have a bias toward action and empower teammates to make decisions.

One Team - We strive to break down silos, collaborate effectively, and celebrate each other’s successes.

Global Mindset - We respect local cultures and embrace diversity. We think globally and act locally to maximize our impact on education.

Global Benefits

Flexible/hybrid working
Remote First Culture
Health Care Coverage*
Tuition Reimbursement*
Competitive Paid Time Off
4 Self-Care Days per year
National Holidays*
3 all-company global holidays (Juneteenth + 2 Founder’s Days)
Paid Volunteer Time*
Charitable cContribution Match*
Monthly Wellness Reimbursement/Home Office Equipment*
Access to Modern Health (mental health platform)
Parental Leave*
Retirement Plan with match/contribution*
varies by country

Turnitin, LLC is committed to the policy that all persons have equal access to its programs, facilities and employment. We strongly encourage applications from people of color, persons with disabilities, women, and the LGBTQ+ community, regardless of age, gender, religion, marital or veterans status.",1998,Primary & Secondary Schools,Unknown / Non-Applicable,Education,501 to 1000 Employees,Company - Private,False
"Consulting Systems Engineer - Data Center, Indiana","World Wide Technology Holding, LLC
","Indianapolis, IN",$70K - $102K (Glassdoor est.),4.0,"Qualifications:

Candidates must live in Indiana/Kentucky region
8+ years of technical enterprise and 2+ years of Pre-Sales experience.
Bachelor's Degree or equivalent experience
Excellent communication skills and interpersonal skills.
Excellent presentation skills and technical sales skills.
Must have passion driving networking/storage/server/virtualization solution strategies.
Strong personality with leadership skills working in a complex matrix organization.
Strong presence and credibility to be proven at client site and internally.
Knowledge of the technical aspects of networking, storage, server, backup and virtualization hardware, software and architecture(s).
Cisco, Dell/EMC, NetApp, HP TSG and/or VMware certifications highly desired.

Want to learn more about Global Enterprise Sales? Check out the Solutions and Services we provide on the platform:https://wwt.com

The well-being of WWT employees is essential. So, when it comes to our benefits package, WWT has one of the best. We offer the following benefits to all full-time employees:

Health and Wellbeing: Heath, Dental, and Vision Care, Onsite Health Centers, Employee Assistance Program, Wellness program
Financial Benefits: Competitive pay, Profit Sharing, 401k Plan with Company Matching, Life and Disability Insurance, Tuition Reimbursement
Paid Time Off: PTO & Holidays, Parental Leave, Sick Leave, Military Leave, Bereavement
Additional Perks: Nursing Mothers Benefits, Voluntary Legal, Pet Insurance, Employee Discount Program

World Wide Technology, Inc. offers excellent benefits and competitive compensation. Visit our company web page atwww.wwt.comfor more information.

Equal Opportunity Employer Minorities/Women/Veterans/Differently Abled

Requirements:

Why WWT?

Fueled by creativity and ideation, World Wide Technology strives to accelerate our growth and nurture future innovation. From our world class culture, to our generous benefits, to developing cutting edge technology solutions, WWT constantly works towards its mission of creating a profitable growth company that is a great place to work. We encourage our employees to embrace collaboration, get creative and think outside the box when it comes to delivering some of the most advanced technology solutions for our customers.

At a glance, WWT was founded in 1990 in St. Louis, Missouri. We employ over 10,000 individuals and closed nearly $17.5 Billion in revenue. We have an inclusive culture and believe our core values are the key to company and employee success. WWT is proud to announce that it has been named on the FORTUNE ""100 Best Places to Work For®"" list for the twelfth consecutive year!

Want to work with highly motivated individuals that come together to form high performance team? Come join WWT today! We are looking for a Consulting Systems Engineer to join our Global Enterprise Sales team.

Why should you join Global Enterprise Sales?

As a Consulting Systems Engineer (CSE), you will be partnering with Client Managers to provide the technical Pre-Sales work for our Fortune 500 customers across all verticals. No two days will be the same as our broad offerings include Infrastructure Modernization, Multicloud Architecture, Security Transformation and Digital Strategy among others. With our Advanced Technology Center (https://www.wwt.com/atc) at your fingertips for briefings, training, workshops, demos and POC's you'll be delivering best in class results for your customers.

What will you be doing?

The Consulting Systems Engineer (CSE) role will bring technical Pre-Sales experience to our customers within the Indiana region. Day to day responsibilities will include participation in customer sales meetings, presentations, white board sessions and custom technical design work. The CSE will team with local Client Managers to build customer relationships, partner with multiple OEM's and take part in technical training to provide continued value to the customers. Technical expertise expansion is highly encouraged as you look to learn about new areas of interest and be on the forefront of cutting-edge technologies. This position will require the ability to travel up to 25%.

Responsibilities:

Aligns with WWT Sales team to represent WWT's Networking and Data Center (Hyper-Converged, Storage, Servers, Compute, Virtualization, Backups, Fabric, etc.) expertise to all assigned accounts.
Uses knowledge of technology, products and services to build Data Center solutions (and solution options) for the customer.
Works with clients and WWT Sales team to obtain technical priorities, challenges, and initiatives that can be translated into WWT Networking and Data Center opportunities.
Responsible for the coordination, delivery, and quality of presales technology solution deliverables within the domain of the opportunity which may include items such as configurations, architectural diagrams, and proposals.
Manages and achieves a sales gross profit number.
Develops and fosters relationships with strategic original equipment manufacturers (OEMs) and key data center partners who are local to your region and/or territory.
Assists in Statement of Work and Proof of Concept review and development.
Ensures that proposed solutions, when implemented, meet the needs and functional requirements of the customer.",1990,Computer Hardware Development,$10+ billion (USD),Information Technology,5001 to 10000 Employees,Company - Private,True
Staff Data Engineer,"Teladoc Health
",Indiana,-1,3.6,"Teladoc Health is a global, whole person care company made up of a diverse community of people dedicated to transforming the healthcare experience. As an employee, you’re empowered to show up every day as your most authentic self and be a part of something bigger – thriving both personally and professionally. Together, let’s empower people everywhere to live their healthiest lives.

The Opportunity

Teladoc Health is transforming how people access and experience healthcare. Recognized as the world leader in virtual care, we are partnering with over a thousand clients to serve millions! of people around the globe every day. Teladoc Health offers a whole person virtual care platform that empowers all people everywhere to live their healthiest lives by transforming the healthcare experience, from acute and primary care to chronic care, mental health, and specialty care.

Our team of data engineers aggregate and transform substantial amounts of health data and information to support actionable, personalized, and timely health signals for our members. This approach delivers better clinical and financial outcomes while creating a different and better healthcare experience for people everywhere. The applicant should have a strong interest in the interface between real-time and reporting systems, pulling data from multiple sources into central data storage, and collaborating with internal teams to help provide for their data needs.

About You

You flourish in a fast paced and highly collaborative team environment. You are a quick

learner and have the expert ability to prioritize tasks efficiently, while delivering high quality work. You understand that solutions provided by a Data Engineer, support in empowering an organization’s business in decision making. You will be part of a great working atmosphere, performing complex work in a collaborative team of amazing people, with forward-thinking managers. You will have the opportunity to make an impact.

Responsibilities
Data is significant at Teladoc and our data engineers design and develop data pipelines to integrate data across disparate systems and create tools and data sets to support data science
Work with Python, Spark SQL, Scala, TensorFlow, Keras, SKL (or Scala/DL4J) to build production-grade machine learning (ML) pipelines and tools
Perform continuous integration to ensure that every step of a data pipeline is testable and automated
Collaborate closely with Teladoc Health’s ML experts, Data Scientists, Product Managers, and clinical researchers to define, analyze, and provide data that contributes to our mission of total health for our members
Document code, provide progress reports, and perform code review and peer feedback
Track milestones, activities and inter-dependencies across projects and tasks, with frequent status updates to stakeholders
Continuously evaluate and identify improvements in the system processes and architecture
Assist in maintaining data quality and fidelity in production systems
Participate in Agile planning around data feature requests and advocate for the best data engineering projects in priority planning.
Candidate Profile
BS degree in Engineering, Computer Science, or a related field
10+ years’ experience in software development/engineering
10+ years’ experience in a data engineering role
2+ years working in health care industry
Strong experience with big data technologies, and skills in data processing using Spark
Expertise in creating and maintaining production data pipelines using Airflow
Strong SQL development experience (Postgres /MySQL/SQL Server/Oracle)
Expertise in Python(preferred), Scala, or Java
3+ years of experience working in Azure cloud
Expertise in performance tuning and query optimization
Expertise in Cloud data engineering in Azure stack. Azure certification is a plus.
Streaming data flow experience is desirable (Kafka).
Expertise in deploying production pipelines in CI/CD environment
Excellent communication skills, supporting recommendations, design ideas, and analysis to team and stake holders
Experience in leading and guiding other data engineers

People and culture are Teladoc Health’s greatest and most valued assets! We’ve built a culture we are proud of that reflects our values of diversity and inclusion where everyone’s voice is equally important.

#LI-RK1 #LI-Hybrid

Why Join Teladoc Health?



A New Category in Healthcare: Teladoc Health is transforming the healthcare experience and empowering people everywhere to live healthier lives.

Our Work Truly Matters: Recognized as the world leader in whole-person virtual care, Teladoc Health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a person’s health journey.

Make an Impact: In more than 175 countries and ranked Best in KLAS for Virtual Care Platforms in 2020, Teladoc Health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals.

Focus on PEOPLE: Teladoc Health has been recognized as a top employer by numerous media and professional organizations. Talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment.

Diversity and Inclusion: At Teladoc Health we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.

Growth and Innovation: We’ve already made healthcare yet remain on the threshold of very big things. Come grow with us and support our mission to make a tangible difference in the lives of our Members.


As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy.",2002,Health Care Services & Hospitals,$1 to $5 billion (USD),Healthcare,1001 to 5000 Employees,Company - Public,False
Data Engineer/Software Developer,"General Dynamics Information Technology
",Indiana,$100K - $150K (Employer est.),4.0,"Clearance Level None Category Software Development Location Remote, Working from the USA

Requisition Type: Regular
Your Impact

Own your opportunity to work alongside federal civilian agencies. Make an impact by providing services that help the government ensure the well being of U.S. citizens.

Job Description

GDIT MAINES contract has a requirement for an experienced Data Engineer to join our Business Intelligence & Analytics Center (BIAC) team on the ITS-EPA IV Managed Application, Infrastructure, Networking, Enterprise, and Security Services (MAINES) Contract in support of the Environmental Protection Agency.

Researches, designs, develops, tests, and/or modifies enterprise-wide systems and/or applications software.

Task Responsibilities:

Responsibilities include, but are not limited to:

Hands on experience leading data warehousing and analytics projects
Excellent SQL and strong hands-on data warehousing design, tuning and ETL process development on Prem and in Cloud.
The design, development, testing and support of new capabilities and ongoing changes within the various application data marts
Collaborate with other IT specialists to rapidly develop and deliver solutions that meet changing business needs.
Perform all necessary discovery and fact finding to fully understand business problems and opportunities and execute all assignments with limited supervision
Effectively communicate development and production issues to the project team, applicable vendors and/or the manager in a timely manner
Work with data owners to document data mappings and transformations to support effective downstream analytics and alerts
Research and stay abreast of technology trends and IT best practices, with a focus on continuous learning.
Develop test data as necessary to support testing
Make recommendations and advise on data refresh, optimization of data, data storage, and data integration among two or more systems
Attend various meetings as Subject Matter Expert for ETL
Understanding of Business Intelligence Reporting and dashboard development
Knowledge of Salesforce data integration
Monitoring daily workflows for errors and performance. Debugging issues, analyzing data flow logic, and correcting defects
Working knowledge of Unix and Shell scripting

Qualifications:

Required Qualifications:

Bachelor’s Degree in Computer Science or related technical discipline with 5+ years' experience, or a Master’s Degree in Computer Application and 3+ years' experience
Demonstrated experience using Informatica PowerCenter v10, PL/SQL, SQL, Oracle 11g/12c/18c/19c, XML, JSON, Java, web services, Git, JIRA, Linux (Red Hat)
Hands-on experience with Oracle Relational Database Management System. An understanding of how to design and develop an Oracle DataMart/data warehouse
Demonstrated experience working with and transforming XML, JSON, or CSV
Demonstrated experiencing working with and or authoring XML and JSON Schemas. Excellent communication skills, the ability to be proactive in communication (email, chat, phone)
Knowledge of Salesforce for data integration
Ability to work East Coast business hours
Must be able to obtain and retain a Public Trust
Must be able to work independently
Must be able to work 100% remotely

Additional Preferred qualifications but not required:

Experience developing in an Agile environment, including Scrum and user stories
Demonstrated experience participating in Agile development teams. 5+ years of experience in IT platform implementation in a technical role, designing data base and date warehouse environments, analyzing production deployments, recommendations to optimize performance, and ETL development using Informatica
Experience with Business Intelligence and reporting
Experience with other technologies, such as Java, Python, .NET, Node.js, Salesforce, and Oracle APEX
AWS Services for Data Analytics",1996,Information Technology Support Services,$10+ billion (USD),Information Technology,10000+ Employees,Subsidiary or Business Segment,False
Metering Data Engineer,"The AES Corporation
","Indianapolis, IN",$74K - $99K (Glassdoor est.),4.2,"At AES, we raise the quality of life around the world by changing the way energy works. Everyone makes an impact every day in our small, global teams. Apply here to start an extraordinary career today.
Metering Data Engineer
The Metering Data Engineer position is to be AES Indiana’s meter data expert. This position will become the in-house subject matter expert on our existing metering reports and how to improve and automate them. This position will also be responsible for learning our meter programs and working with our business partner on updating and maintaining those programs. Will need to work with co-works to learn existing as well as future applications including but not limited to: MDM, CIS, OMS, ADMS, SAP, AMI Head-End System, Field Service Management application.
Role and responsibilities
You will manage operational reports, ensuring updated and correct data.
You develop quality reports to monitor the performance of meters and personnel so that data can translate into actionable insights.
You are able to translate internal department requests into concrete requirements.
Collaborate across departments to define, develop, and implement structural reporting that supports long-term business objectives.
Provide data-driven analysis and be able to present to peers and upper management on your findings.
Providing technical assistance and guidance on, but not limited to, computer systems, network environments, AMI Infrastructure, MDM, MV90, SAP and metering.
Assist with metering programs, software product specifications, development, testing and training.
Participate in and contribute to product training.
There is always space for creative and unique points of view. You will have the flexibility and trust to choose how best to tackle tasks and solve problems.
Work closely with our metering P.E energy
Education and experience
BS degree in Electrical Engineering, Data Science, Analytics, Computer Science, required.
1-3 years of working experience as an Electrical Engineer/Data Analyst.
Excellent written and oral communication skills.
Experience with utilities at an internship or co-op desired, but not required.
Attention to detail and analytical.
Proficient with Microsoft Suite programs and Google Cloud
Skills
Can observe and respond to people and situations and interact with others encountered in the course of work.
Can learn and apply new information or skills.
Must be able to read and interpret data, information, and documents.
Ability to complete assignments with attention to detail and high degree of accuracy.
Result driven-demonstrate ownership and accountability.
Identifies bottlenecks and drives improvements.
Work independently or as part of a team and follow through on assignments with minimal supervision.
Demonstrate open, clear, concise, and professional communication.
Ability to establish and maintain cooperative working relationships with manager, co-workers, and customers.
Strong analytical skills and ambition to keep developing these.
Self-starter that shows high drive, creativity, ambition, and accountability.
Growth mindset: you believe in continuous learning by dedication of time, effort, and energy.
Outstanding interpersonal and relationship management skills with the ability to effectively collaborate with varying levels of the organization as needed.
Emerging partnership and teamwork skills and ability to learn from and share knowledge with co-workers in a fast-paced environment.
Desire to learn and grow and improve themselves and the company.
Network with other utilities and L&G customers to implement best practices.
Attend conferences and training classes.
This is on-site Monday through Friday!
AES is an Equal Opportunity Employer who is committed to building strength and delivering long-term sustainability through diversity and inclusion. Respecting all backgrounds, differences and perspectives enables us to improve the lives of our people, customers, suppliers, contractors, and the communities in which we live and work. All qualified applicants will receive consideration for employment without regard to sex, sexual orientation, gender, gender identity and/or expression, race, national origin, ethnicity, age, religion, marital status, physical or mental disability, pregnancy, childbirth, or related medical condition, military or veteran status, or any other characteristic protected under applicable law. E-Verify Notice: AES will provide the Social Security Administration (SSA) and if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.",1981,Energy & Utilities,$10+ billion (USD),"Energy, Mining & Utilities",5001 to 10000 Employees,Company - Public,False
Senior Data Integration Engineer (AWS),"Republic Airways
","Indianapolis, IN",$83K - $115K (Glassdoor est.),3.7,"POSITION PURPOSE:

Responsible for design, development, testing, documentation, deployment and support of APIs & Integrations leveraging an Any-Point platform. As a Data Integration Engineer (AWS), you will be responsible for following enterprise integration patterns, and developing reusable, endpoint APIs leveraged by our internal and external partners. You will ensure the APIs & Integrations follow standards for Requirements, Architecture, Design, Code, Test, Deployment and Operational Lifecycle. Support the integration platform and the implementation of real-time data streaming pipeline for various applications.




ESSENTIAL DUTIES

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.

Implementing service transformation, routing, enrichment and orchestration in AWS integration platforms
Drive end-to-end technical planning and development of 3rd party integrations, from high-level architecture down to code implementation in a fast-paced, innovation-focused environment.
Perform deep-dive analysis to understand and solve integration needs between data sources and applications.
Perform data analysis of input, transformation process, and output message data.
Design, build and maintain interfaces between different messaging structures and related applications.
Develop new application integrations and provide daily operational support.
Serve as the primary coordinator for internal engineering resources.
Prepare technical documents such as test procedures, performance specifications and assist in product manual creation.
Record, track, and report integration performance and software quality metrics.
Collaborate with the team and the lines of business to identify system improvements and enhancements and recommend and implement solutions.
Gather and analyze requirements and design solutions to meet business needs.
Responsible for the overall technical aspects of integration projects.
Provide production support for incident management and integration monitoring.
Provides production support including on-call. Performs regular application, systems and data administration tasks, monitors results, recommends and implements automated solutions.
Identify and communicate product and project risk and opportunities.
Assess current processes to suggest improvements to the team.
Document and demonstrate solutions by develop documentation, flowcharts, layouts, diagrams, charts, code comments and clear code.
Define and build-level test plan documents and procedures.
May coach other team members in AWS.
Performs other duties as assigned.


REQUIRED KNOWLEDGE, SKILLS AND ABILITIES

The requirements listed below are representative of the knowledge, skill, and/or ability necessary to perform this job.


EDUCATION and/or EXPERIENCE

Bachelor’s degree (B.A. / B.S.) in Information Technology or related field or the equivalent combination of education and experience.
3+ years of experience in data integration space
3+ years of experience with AWS data integration platform
3+ years of experience with real-time data streaming pipeline, message broker and applications that adapt to the data stream.
3+ years of hands-on experience in designing and developing high volume web services using API Protocols and Data Formats (REST, JSON, SOAP & XML).
Serverless Architecture and AWS Services such as Step Functions, Lambda and, DynamoDB
Data Integration Using SQS (Message Queuing), SNS (Pub/Sub Service), EventBridge (SNS, SQS)
Build a Real-Time Data Pipeline and Real-Time Streaming Application (AWS MSK)
DevOps Release Automation
Python
Experience in API development and API management products
Experience with Atlassian tools like JIRA, Confluence, and etc.
Experience developing in agile & with CICD tools like GitHub.
Demonstrated knowledge of software design and development, database design, report writing, and testing procedures.
Experience with technology such as SQL server, ETL tools and SSIS




LANGUAGE SKILLS

Ability to read, analyze, and interpret general business periodicals, professional journals, technical procedures, or governmental regulations. Ability to write reports, business correspondence, and procedure manuals. Ability to effectively present information and respond to questions from groups of managers, clients, customers, and the general public.

REASONING/PROBLEM SOLVING ABILITY

Ability to define problems, collect data, establish facts, and draw valid conclusions. Ability to interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.

DECISION MAKING

Makes day to day decisions used to support strategic direction. Decisions often require some thought and are somewhat structured. Decisions tend to be short term and usually moderate cost.


PHYSICAL DEMANDS

The physical demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job.

Able to move about the work environment.

Frequently required to stand, walk, sit, talk and hear.


WORK ENVIRONMENT

The work environment characteristics described here are representative of those an associate encounter while performing the essential functions of this job.

Typically, not exposed to extreme environmental conditions.


TRAVEL REQUIREMENTS

Travel up to 10% of the time, including overnight stays.",1974,"Airlines, Airports & Air Transportation",Unknown / Non-Applicable,Transportation & Logistics,5001 to 10000 Employees,Company - Public,False
"C# Software Engineer, Marketing Cloud Data Platform (Lead/Principal)","Salesforce
","Indianapolis, IN",$173K - $280K (Employer est.),4.0,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Software Engineering

Job Details

About Salesforce

We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.

The Salesforce Marketing Cloud Data Recoverability, High Availability, and Movement (DRHAM) team consists of smart and tenacious engineers dedicated to excellence through platform expertise and uncompromising integrity. While we understand that delivery is important, it is always balanced against business needs and engineering excellence. The code we deliver must be secure, perform well at scale, and provide the functionality promised to our customers.

Our team is responsible for the recoverability, availability, and movement of the Marketing Cloud data platform. As our platform grows in size, complexity, and diversity - we must consistently provide the uptime and recoverability from disaster that our customers demand. We are looking to grow our team to develop and manage our next generation of systems designed to maintain our world-class data platform that supports record breaking activity year after year.

Responsibilities:

Design and develop high-quality code to improve platform reliability, availability, and scalability.

Influence and drive end-to-end solutions that help a cloud-scale data platform service remain highly available and operating with predictable performance.

Lead, collaborate, communicate, and mentor others on the team and in the company.

Work closely with multi-functional teams across geographies to deliver a roadmap to meet shared business goals.

Develop test strategies, design automation frameworks, and write unit/functional tests to drive up code coverage and automation metrics.

Contribute to the success of the scrum team through code reviews, documentation, and refinement, planning, and retros.

Solve issues with the applications and services that our team develops and owns.

Participate in the team’s on-call rotation to address complex problems in real-time and keep services operational and highly available.

Required Qualifications:

6+ years of relevant work experience.

Demonstrable experience and technical proficiency with C# and .NET, developing and supporting Cloud-Scale Platform services, and complex problem solving.

Working knowledge of API Security and Authentication principles, SDLC concepts and technologies, and SCRUM methodology.

Basic understanding of how to interact with and manage both Relational and Non-Relational Data Stores, Docker Containerization, Kubernetes Orchestration, and multi-substrate Public Cloud Infrastructure.

LI-Y

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .

Posting Statement

At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .

Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce . ﻿

Salesforce welcomes all.

For Washington-based roles, the base salary hiring range for this position is $172,500 to $280,200.

Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.",1999,Enterprise Software & Network Solutions,$10+ billion (USD),Information Technology,10000+ Employees,Company - Public,False
"Lead Software Engineer, Data Engineering","S&P Global
","Zionsville, IN",$85K - $170K (Employer est.),4.1,"The Role: Data Engineer
Location: Team is in Boston, but is available for remote or on-site throughout CST and EST Time zones
GL (for internal use only): 11

Panjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualization of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.
Recognizing Panjiva’s cutting-edge technology, S&P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans. People are Panjiva’s greatest strength – join our engineering team as we map out a key part of the world economy!
Job Description
As a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva’s world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.

You’ll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for machine learning applications at production scale over ever-growing datasets.
You’ll design and leverage distributed computing technologies, data schemas, and APIs to construct data science pipelines. In addition, you’ll be expected to participate in augmenting our infrastructure to seamlessly integrate new data sets through constant R&D of the technologies and systems we use.
Join us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.

Responsibilities
Architect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets
Develop processes to monitor and automate detection of quality regressions in raw data or in the output of Panjiva’s machine learning models
Working with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers
Optimizing slow-running database queries and data pipelines
Helping enhance our search engine, capable of running sophisticated user queries quickly and efficiently
Building internal tools and backend services to enable our data scientists and product engineers to improve efficiency

Qualifications
B.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience
7+ years of experience working with data-at-scale in a production environment
Experience designing and implementing large-scale, distributed systems
Experience in multi-threaded software development (or some form of parallelism)
Significant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)
Solid understanding of core algorithms and data structures, including the ability to select (and apply) the optimal ones to computationally expensive operations over data-at-scale
Strong understanding of relational databases and proficiency with SQL
Deep knowledge of at least one scripting language (e.g., Python, Ruby, JavaScript)
Deep knowledge of at least one compiled language (e.g., Scala, C++, Java, Go)
Experience developing software on Linux-based operating systems
Experience with distributed version control systems
Nice-to-Haves
Familiarity with relational database internals (especially PostgreSQL)
Proficiency with cloud computing platforms, specifically AWS
Working knowledge of probability & statistics
Contributions to open-source software
Experience building customer-centric products

Compensation/Benefits Information (US Applicants Only):
S&P Global states that the anticipated base salary range for this position is $85,300 - $170,000 . Base salary ranges may vary by geographic location.
In addition to base compensation, this role is eligible for an annual incentive bonus plan.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://www.spgbenefitessentials.com/newhires .
About S&P Global
S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

S&P Global Market Intelligence partners with customers to broaden their perspective and operate with confidence by bringing them leading data sources and technologies that embed insight in their daily work.
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 277527
Posted On: 2023-09-21
Location: Cambridge, Massachusetts, United States",1860,Research & Development,$10+ billion (USD),Management & Consulting,10000+ Employees,Company - Public,False
Data Engineer IV - Max Digital (Data Engineering),"ACV Auctions
",Indiana,-1,3.7,"If you are looking for a career at a dynamic company with a people-first mindset and a deep culture of growth and autonomy, ACV is the right place for you! Competitive compensation packages and learning and development opportunities, ACV has what you need to advance to the next level in your career. We will continue to raise the bar every day by investing in our people and technology to help our customers succeed. We hire people who share our passion, bring innovative ideas to the table, and enjoy a collaborative atmosphere.

Who we are:
ACV is a technology company that has revolutionized how dealers buy and sell cars online. We are transforming the automotive industry. ACV Auctions Inc. (ACV), has applied innovation and user-designed, data driven applications and solutions. We are building the most trusted and efficient digital marketplace with data solutions for sourcing, selling and managing used vehicles with transparency and comprehensive insights that were once unimaginable. We are disruptors of the industry and we want you to join us on our journey. ACV’s network of brands includes ACV Auctions, ACV Transportation, ClearCar, MAX Digital and ACV Capital within its Marketplace Products, as well as, True360 and Data Services.
At ACV we focus on the Health, Physical, Financial, Social and Emotional Wellness of our Teammates and to support this we offer:

Multiple medical plans including a high deductible health plan that costs $0 out of your paycheck
Company-sponsored (paid) Short-Term Disability, Long-Term Disability, and Life Insurance
Comprehensive optional benefits such as Dental, Vision, Supplemental Life/AD&D, Legal/ID Protection, and Accident and Critical Illness Insurance
Generous paid time off options, including vacation time, sick days, Company holidays, floating holidays, parental leave, bereavement leave, jury duty leave, voting leave, and other forms of paid leave as required by applicable law or regulation
Employee Stock Purchase Program with additional opportunities to earn stock in the Company
Retirement planning through the Company’s 401(k)
Who we are looking for:
We are seeking a highly skilled Engineer IV in Data Engineering with a strong foundation in computer science and excellent problem-solving skills. You will be responsible for maintaining and extending our database operations, optimizing SQL queries, and designing scalable data services.

What you will do:

Actively and consistently support all efforts to simplify and enhance the customer experience.
Maintain and extend (as required) existing database operations solution for backups, index defragmentation, data retention, etc.
Troubleshoot any SQL Server or ETL stack outages during our operational support window.
Triage any issues with data stack (SSIS, C#, Web APIs).
Support development, integration, and stage SQL Server environments for application development and data science teams.
Ensure that new database development meets company standards for readability, reliability, and performance. Work with internal teams on transactional and analytical schema design.
Collaborate with software and DevOps engineers to design scalable services, plan feature roll-out, and ensure high reliability and performance of our products.
Architect and build entire services including but not limited to; data modeling, storage, message brokers, protocols and interfaces.
Design, build and maintain complex systems that can scale rapidly with little maintenance.
Conduct code reviews, develop high-quality documentation, and build robust test suites.
Own the overall performance of products and services within a defined area of focus.
Be empowered to lead and complete software projects with minimal guidance from managers.
Lead team discussions to define technical requirements on new and current products.
Respond-to and troubleshoot highly complex problems quickly, efficiently, and effectively.
Mentor junior engineers.
Perform additional duties as assigned.
What you will need:

Bachelor's degree in Computer Science, Information Technology, Computer Information Systems, Management Information Systems, or similar
5 years' building & supporting the database-tier of SaaS web applications.
Ability to read, write, speak, and understand English.
Expert understanding of SQL query execution fundamentals and query optimization principles.
Experience maintaining and extending an existing codebase, adapting to pre-existing patterns and tracing the code’s path of execution.
ETL workflow implementation (SSIS, Airflow, C#, Python)
Experience working with Cloud Services (AWS RDS, S3, SQS, SNS)
Experience working with NoSQL data stores (MongoDB)
Experience writing unit and integration testing (DBT, C#)
Expert SQL and data-layer development experience; OLTP schema design.
Experience integrating 3rd-party APIs, implementing authentication & authorization and developing asynchronous data flows.
Nice to Have
OLAP schema design experience.
Experience with Airflow, Snowflake, etc.
Experience with DBT
Our Values
Trust & Transparency | People First | Positive Experiences | Calm Persistence | Never Settling

At ACV, we are committed to an inclusive culture in which every individual is welcomed and empowered to celebrate their true selves. We achieve this by fostering a work environment of acceptance and understanding that is free from discrimination. ACV is committed to being an equal opportunity employer regardless of sex, race, creed, color, religion, marital status, national origin, age, pregnancy, sexual orientation, gender, gender identity, gender expression, genetic information, disability, military status, status as a veteran, or any other protected characteristic. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires reasonable accommodation, please let us know.

For information on our collection and use of your personal information, please see our Privacy Notice.",2014,Wholesale,Unknown / Non-Applicable,Retail & Wholesale,1001 to 5000 Employees,Company - Public,True
"Lead Data Engineer, AI","Recruiting From Scratch
","West Lafayette, IN",$160K - $280K (Employer est.),4.0,"This is for a client of Recruiting from Scratch.
Who is Recruiting from Scratch:
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
Our Client:

This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays.

What’s the job?

Our client is looking for an exceptional data engineer who is passionate about data for AI. This candidate loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.

In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.

Responsibilities:

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn’t always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams
Build data processing streams for cleaning and modeling text data for LLMs
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure

What we’ll love about you

Bachelors in Computer Science, Mathematics, Physics, or a related fields
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Experience in statistical analysis & visualization on datasets using Pandas or R
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines)

We’ll really swoon if you have

2+ years of experience of technical leadership in building data engineering pipelines for AI
Previous experience in building data pipeline for conversational AI APIs and recommender systems
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Strong understanding of applied machine learning topics
Be familiar with legal compliance (with data management tools) data classification, and retention
Consistent track record of managing and implementing complex data projects

Location : We are looking to hire someone in the San Francisco, Palo Alto, or Chicago Area.

Salary Range: $160,000-$280,000 USD base. Equity. Medical, Dental, Vision.
https://www.recruitingfromscratch.com/",2019,Staffing & Subcontracting,$1 to $5 million (USD),Human Resources & Staffing,1 to 50 Employees,Company - Private,True
Senior Staff AI Data Engineer,"Recruiting From Scratch
","West Lafayette, IN",$160K (Employer est.),4.0,"Who is Recruiting from Scratch :
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
https://www.recruitingfromscratch.com/

This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays.

What’s so interesting about this role?

We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety.

What’s the job?

We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.

In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.

Responsibilities:

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn’t always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams
Build data processing streams for cleaning and modeling text data for LLMs
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure

What we’ll love about you

Bachelors in Computer Science, Mathematics, Physics, or a related fields
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Experience in statistical analysis & visualization on datasets using Pandas or R
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines)

We’ll really swoon if you have

2+ years of experience of technical leadership in building data engineering pipelines for AI
Previous experience in building data pipeline for conversational AI APIs and recommender systems
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Strong understanding of applied machine learning topics
Be familiar with legal compliance (with data management tools) data classification, and retention
Consistent track record of managing and implementing complex data projects

What you'll love about us

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events
Base Pay Range
$160,000—$280,000 USD
https://www.recruitingfromscratch.com/",2019,Staffing & Subcontracting,$1 to $5 million (USD),Human Resources & Staffing,1 to 50 Employees,Company - Private,True
Lead Sales Engineer - Data Center Vertical,"Eaton
","Indianapolis, IN",$84K - $123K (Employer est.),3.9,"Eaton’s ES AMER NAS division is currently seeking a Lead Sales Engineer - Data Center Vertical. This is a hybrid-based position and candidates must reside within 50 miles of our Indianapolis, IN location. Relocation assistance will be offered.

What you’ll do:

Position Overview:

The primary function of the Lead Sales Engineer is to sell assigned product lines to targeted customers in targeted market areas. This position will be responsible to achieve the assigned sales goal consistent with the expectations of a thoroughly seasoned professional sales engineer for the assigned product categories while under little supervision. It will be an expectation to optimize sales volume, product mix and profit margin, while increasing sales in the marketplace. This position will need to coordinate sales for the assigned customer and distributor base. It has the responsibility to manage all aspects of the customer relationship, providing sales and technical assistance through all customer channels: end customers, distributors, consulting engineers and contractors.

Making what matters work at Eaton takes the passion of every employee around the world. We create an environment where creativity, invention and discovery become reality, each and every day. It’s where bold, bright professionals like you can reach your full potential—and where you can help us reach ours.

In this function you will:

Develop and execute sales plans to meet performance expectations and requirements
Quote projects and negotiate correct required pricing
Prepare sales presentations to create product understanding and awareness
Build relationships with key customers to enhance long-term business prospects
Work with factories to resolve technical issues
Canvas the market to gain insight and adjust to ever changing pricing and delivery requirements
Assist the team to develop a coordinated sales effort while keeping management informed of market conditions
Obtain ongoing training on both functional and technical skills

When we embrace the different ideas, perspectives and backgrounds that make each of us unique, we — as individuals and as a company — are stronger.

Qualifications:

Required (Basic) Qualifications:

Bachelor’s degree from an accredited institution
Minimum five (5) years of electrical industry sales/marketing and/or engineering experience
Possess and maintain a valid and unrestricted driver’s license
Must be able to work in the United States without corporate sponsorship now and within the future

Preferred Qualifications:

Bachelor’s degree in Engineering
Knowledgeable of Eaton electrical products, services and competitors
Design/build knowledge in the data center marketplace
Ability to recognize and offer value-added value engineering (VAVE) options and suggestions/recommendations to our mission critical customers
Experience or exposure to a manufacturing organization
Skills:

Position Criteria:

Possess excellent communication skills
Ability to respond to a variety of circumstances while continuing to demonstrate superior selling skills for important customer services and applications
Electrical product knowledge
Ability to provide technical solutions built around customer needs
Skilled in time management
Possess negotiating skills while understanding and using techniques needed to close orders
Experience with preparing sales proposals that meet customer expectations
Robust presentation & training skills
Experience utilizing value added selling techniques
Strong work ethic, communications skills, competitiveness, willingness to learn and adept at building relationships
Experience working with quotation software
Ability to travel up to 25%

The compensation range for this full-time position includes base pay and sales incentive. This position has a total compensation range of $108,750 - $159,500.


Please note the salary information shown above is a general guideline only. Salaries are based upon candidate skills, experience, and qualifications, as well as market and business considerations.


We are committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law.


Eaton considers qualified applicants regardless of criminal histories, consistent with local laws. To request a disability-related reasonable accommodation to assist you in your job search, application or interview process, please call us at 1-800-836-6345 to discuss your specific need. Only accommodation requests will be accepted by this phone number.


We know that good benefit programs are important to employees and their families. Eaton provides various Health and Welfare benefits as well as Retirement benefits, and several programs that provide for paid and unpaid time away from work. Click here for more detail: Eaton Benefits Overview. Please note that specific programs and options available to an employee may depend on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.",1911,Electronics Manufacturing,$10+ billion (USD),Manufacturing,10000+ Employees,Company - Public,False
