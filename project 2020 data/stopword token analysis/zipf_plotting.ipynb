{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine sim for all datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df:pd.DataFrame, exclude=None):\n",
    "    subset_columns = ['Job Title', 'Company Name', 'Location', 'Salary Estimate', 'Rating', 'Job Description']\n",
    "    if exclude:\n",
    "        if isinstance(exclude, list):\n",
    "            subset_columns = [a for a in subset_columns if a not in exclude]\n",
    "        else:\n",
    "            subset_columns.remove(exclude)\n",
    "    \n",
    "    df.sort_values(subset_columns, inplace=True)\n",
    "\n",
    "    df['Duplicate Count'] = df.groupby(subset_columns)['Job Title'].transform('count')\n",
    "    print(df['Duplicate Count'].value_counts())\n",
    "    df.drop_duplicates(subset=subset_columns, inplace=True, keep='last')\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Count\n",
      "1.0     10704\n",
      "2.0      2288\n",
      "3.0       990\n",
      "4.0       192\n",
      "5.0        75\n",
      "8.0        56\n",
      "6.0        54\n",
      "47.0       47\n",
      "7.0        42\n",
      "26.0       26\n",
      "11.0       22\n",
      "9.0        18\n",
      "15.0       15\n",
      "14.0       14\n",
      "10.0       10\n",
      "Name: count, dtype: int64\n",
      "role\n",
      "Data Analyst        4691\n",
      "Business Analyst    3485\n",
      "Data Scientist      3114\n",
      "Data Engineer       2322\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Sector</th>\n",
       "      <th>...</th>\n",
       "      <th>Easy Apply</th>\n",
       "      <th>Duplicate Count</th>\n",
       "      <th>Salary Type</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>State</th>\n",
       "      <th>job_description_cleaned</th>\n",
       "      <th>Job Title clean</th>\n",
       "      <th>Years Experience</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!!100% Remote!!! Sr. Data and Integration Eng...</td>\n",
       "      <td>Amerit Consulting</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>74-134</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Job Description\\nOur client is an American for...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>State &amp; Regional Agencies</td>\n",
       "      <td>$5 to $10 million (USD)</td>\n",
       "      <td>Government</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>74.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>job description our client is an american for ...</td>\n",
       "      <td>remote senior data and integration engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Business Analyst/ Data Analyst with experienc...</td>\n",
       "      <td>ESolutions Inc</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>62-113</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Job Title: Business Analyst/ Data Analyst with...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>IT Services</td>\n",
       "      <td>$50 to $100 million (USD)</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>62.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>job title business analyst data analyst with e...</td>\n",
       "      <td>business analyst data analyst experience on an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#104252 Division Data and Financial Analyst</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>34-61</td>\n",
       "      <td>4.3</td>\n",
       "      <td>This position will remain open until filled.\\n...</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>34.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>this position will remain open until filled uc...</td>\n",
       "      <td>division data and financial analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#104293 Business Tech Support Analyst</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>31-61</td>\n",
       "      <td>4.3</td>\n",
       "      <td>UCSD Layoff from Career Appointment: Apply by ...</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>31.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>ucsd layoff from career appointment apply by f...</td>\n",
       "      <td>business tech support analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#104733 HPC Systems and Data Engineer</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>46-92</td>\n",
       "      <td>4.3</td>\n",
       "      <td>The effects of the COVID-19 pandemic have impa...</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Colleges &amp; Universities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>46.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>the effect of the covid pandemic have impacted...</td>\n",
       "      <td>hpc system and data engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>senior data systems analyst</td>\n",
       "      <td>Citi</td>\n",
       "      <td>Texas</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Position Summary: The Senior Data Systems anal...</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>Investment Banking &amp; Asset Management</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>Finance</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>position summary the senior data system analys...</td>\n",
       "      <td>senior data system analyst</td>\n",
       "      <td>14</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>senior data systems analyst</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Texas</td>\n",
       "      <td>85-153</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Position Summary: The Senior Data Systems anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lending</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finance</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>85.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>position summary the senior data system analys...</td>\n",
       "      <td>senior data system analyst</td>\n",
       "      <td>14</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>systems Analyst 1596 (d)</td>\n",
       "      <td>The City of Los Angeles</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>48-100</td>\n",
       "      <td>3.6</td>\n",
       "      <td>DUTIESANNUAL SALARY$70,156 to $102,562The sala...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Municipal Governments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Government</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>48.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>dutiesannual salary to salary in the departmen...</td>\n",
       "      <td>system analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>{\"title\":\"GAO Analyst (Data Analysis)\",\"extend...</td>\n",
       "      <td>Legislative Branch</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>61-108</td>\n",
       "      <td>4.3</td>\n",
       "      <td>DutiesHelpDutiesSummaryThis position is locate...</td>\n",
       "      <td>1789.0</td>\n",
       "      <td>State &amp; Regional Agencies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Government</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>61.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dutieshelpdutiessummarythis position is locate...</td>\n",
       "      <td>title gao analyst extended opening_type null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13611</th>\n",
       "      <td>【1yr OPT+Intern】Data Analyst 保实习保就业</td>\n",
       "      <td>Easyfind Company</td>\n",
       "      <td>Arcadia, CA</td>\n",
       "      <td>42-66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>现在就在微信 wuyuzhou0907\\n现在就在微信 wuyuzhou0907\\n现在就在...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Annual (K)</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>现在就在微信 现在就在微信 现在就在微信 保实习保就业 无offer退全额 在美留学生独家一...</td>\n",
       "      <td>opt intern data analyst 保实习保就业</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13612 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Job Title  \\\n",
       "0      !!!100% Remote!!! Sr. Data and Integration Eng...   \n",
       "1      \"Business Analyst/ Data Analyst with experienc...   \n",
       "2            #104252 Division Data and Financial Analyst   \n",
       "3                  #104293 Business Tech Support Analyst   \n",
       "4                  #104733 HPC Systems and Data Engineer   \n",
       "...                                                  ...   \n",
       "13607                        senior data systems analyst   \n",
       "13608                        senior data systems analyst   \n",
       "13609                           systems Analyst 1596 (d)   \n",
       "13610  {\"title\":\"GAO Analyst (Data Analysis)\",\"extend...   \n",
       "13611                【1yr OPT+Intern】Data Analyst 保实习保就业   \n",
       "\n",
       "                  Company Name         Location Salary Estimate  Rating  \\\n",
       "0            Amerit Consulting       Dallas, TX          74-134     3.5   \n",
       "1               ESolutions Inc        Tampa, FL          62-113     4.0   \n",
       "2                 UC San Diego    San Diego, CA           34-61     4.3   \n",
       "3                 UC San Diego    San Diego, CA           31-61     4.3   \n",
       "4                 UC San Diego    San Diego, CA           46-92     4.3   \n",
       "...                        ...              ...             ...     ...   \n",
       "13607                     Citi            Texas              -1     3.7   \n",
       "13608                 Citibank            Texas          85-153     3.8   \n",
       "13609  The City of Los Angeles  Los Angeles, CA          48-100     3.6   \n",
       "13610       Legislative Branch   Washington, DC          61-108     4.3   \n",
       "13611         Easyfind Company      Arcadia, CA           42-66     NaN   \n",
       "\n",
       "                                         Job Description  Founded  \\\n",
       "0      Job Description\\nOur client is an American for...   2002.0   \n",
       "1      Job Title: Business Analyst/ Data Analyst with...   1999.0   \n",
       "2      This position will remain open until filled.\\n...   1960.0   \n",
       "3      UCSD Layoff from Career Appointment: Apply by ...   1960.0   \n",
       "4      The effects of the COVID-19 pandemic have impa...   1960.0   \n",
       "...                                                  ...      ...   \n",
       "13607  Position Summary: The Senior Data Systems anal...   1812.0   \n",
       "13608  Position Summary: The Senior Data Systems anal...      NaN   \n",
       "13609  DUTIESANNUAL SALARY$70,156 to $102,562The sala...      NaN   \n",
       "13610  DutiesHelpDutiesSummaryThis position is locate...   1789.0   \n",
       "13611  现在就在微信 wuyuzhou0907\\n现在就在微信 wuyuzhou0907\\n现在就在...      NaN   \n",
       "\n",
       "                                    Industry                    Revenue  \\\n",
       "0                  State & Regional Agencies    $5 to $10 million (USD)   \n",
       "1                                IT Services  $50 to $100 million (USD)   \n",
       "2                    Colleges & Universities                        NaN   \n",
       "3                    Colleges & Universities                        NaN   \n",
       "4                    Colleges & Universities                        NaN   \n",
       "...                                      ...                        ...   \n",
       "13607  Investment Banking & Asset Management         $10+ billion (USD)   \n",
       "13608                                Lending                        NaN   \n",
       "13609                  Municipal Governments                        NaN   \n",
       "13610              State & Regional Agencies                        NaN   \n",
       "13611                                     -1                        NaN   \n",
       "\n",
       "                       Sector  ... Easy Apply Duplicate Count  Salary Type  \\\n",
       "0                  Government  ...      False             1.0   Annual (K)   \n",
       "1      Information Technology  ...      False             1.0   Annual (K)   \n",
       "2                   Education  ...      False             1.0   Annual (K)   \n",
       "3                   Education  ...      False             1.0   Annual (K)   \n",
       "4                   Education  ...      False             2.0   Annual (K)   \n",
       "...                       ...  ...        ...             ...          ...   \n",
       "13607                 Finance  ...      False             1.0   Annual (K)   \n",
       "13608                 Finance  ...      False             1.0   Annual (K)   \n",
       "13609              Government  ...      False             1.0   Annual (K)   \n",
       "13610              Government  ...      False             3.0   Annual (K)   \n",
       "13611                     NaN  ...      False             NaN   Annual (K)   \n",
       "\n",
       "       min_salary max_salary  State  \\\n",
       "0            74.0      134.0     TX   \n",
       "1            62.0      113.0     FL   \n",
       "2            34.0       61.0     CA   \n",
       "3            31.0       61.0     CA   \n",
       "4            46.0       92.0     CA   \n",
       "...           ...        ...    ...   \n",
       "13607         NaN        NaN     TX   \n",
       "13608        85.0      153.0     TX   \n",
       "13609        48.0      100.0     CA   \n",
       "13610        61.0      108.0    NaN   \n",
       "13611        42.0       66.0     CA   \n",
       "\n",
       "                                 job_description_cleaned  \\\n",
       "0      job description our client is an american for ...   \n",
       "1      job title business analyst data analyst with e...   \n",
       "2      this position will remain open until filled uc...   \n",
       "3      ucsd layoff from career appointment apply by f...   \n",
       "4      the effect of the covid pandemic have impacted...   \n",
       "...                                                  ...   \n",
       "13607  position summary the senior data system analys...   \n",
       "13608  position summary the senior data system analys...   \n",
       "13609  dutiesannual salary to salary in the departmen...   \n",
       "13610  dutieshelpdutiessummarythis position is locate...   \n",
       "13611  现在就在微信 现在就在微信 现在就在微信 保实习保就业 无offer退全额 在美留学生独家一...   \n",
       "\n",
       "                                         Job Title clean Years Experience  \\\n",
       "0            remote senior data and integration engineer              NaN   \n",
       "1      business analyst data analyst experience on an...              NaN   \n",
       "2                    division data and financial analyst              NaN   \n",
       "3                          business tech support analyst              NaN   \n",
       "4                           hpc system and data engineer              NaN   \n",
       "...                                                  ...              ...   \n",
       "13607                         senior data system analyst               14   \n",
       "13608                         senior data system analyst               14   \n",
       "13609                                     system analyst              NaN   \n",
       "13610       title gao analyst extended opening_type null              NaN   \n",
       "13611                     opt intern data analyst 保实习保就业                1   \n",
       "\n",
       "                   role  \n",
       "0         Data Engineer  \n",
       "1          Data Analyst  \n",
       "2          Data Analyst  \n",
       "3      Business Analyst  \n",
       "4         Data Engineer  \n",
       "...                 ...  \n",
       "13607      Data Analyst  \n",
       "13608      Data Analyst  \n",
       "13609  Business Analyst  \n",
       "13610      Data Analyst  \n",
       "13611      Data Analyst  \n",
       "\n",
       "[13612 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_business_analyst = pd.read_csv('../data_jobs_data/data/BusinessAnalyst clean.csv')\n",
    "df_data_analyst = pd.read_csv('../data_jobs_data/data/DataAnalyst clean.csv')\n",
    "df_data_engineer = pd.read_csv('../data_jobs_data/data/DataEngineer clean.csv')\n",
    "df_data_scientist = pd.read_csv('../data_jobs_data/data/DataScientist clean.csv')\n",
    "\n",
    "# Combine data for TF-IDF analysis\n",
    "combined_data = pd.concat([\n",
    "    df_business_analyst.assign(role=\"Business Analyst\"),\n",
    "    df_data_analyst.assign(role=\"Data Analyst\"),\n",
    "    df_data_scientist.assign(role=\"Data Scientist\"),\n",
    "    df_data_engineer.assign(role=\"Data Engineer\"),\n",
    "])\n",
    "# print(combined_data.role.value_counts())\n",
    "# combined_data\n",
    "remove_duplicates(combined_data, exclude=['Location','Salary Estimate']) # sometimes salary is location-dependent. we are only analyzing job descriptions so this is fine.\n",
    "print(combined_data.role.value_counts())\n",
    "\n",
    "# Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply,Duplicate Count,\n",
    "# Job Title clean,Salary Type,min_salary,max_salary,job_description_cleaned,Years Experience\n",
    "\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
    "\n",
    "# Counting the number of stopwords in each set\n",
    "nltk_stopwords = set(nltk_stopwords.words('english'))\n",
    "sklearn_stopwords = set(sklearn_stop_words)\n",
    "\n",
    "nltk_stopwords_count = len(nltk_stopwords)\n",
    "sklearn_stopwords_count = len(sklearn_stopwords)\n",
    "\n",
    "stopword_sets = dict()\n",
    "stopword_sets['no'] = None\n",
    "stopword_sets['nltk'] = list(nltk_stopwords)\n",
    "stopword_sets['sklearn'] = list(sklearn_stopwords)\n",
    "stopword_sets['nltk sklearn union'] = list(nltk_stopwords.union(sklearn_stopwords))\n",
    "stopword_sets['nltk sklearn intersect'] = list(nltk_stopwords.intersection(sklearn_stopwords))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zipf(df, column, vectorizer, stopwords_name, ax=None, rank_lim=1e7, count_lim=1e6):\n",
    "    # Fit and transform the data\n",
    "    if vectorizer.stop_words is not None and isinstance(vectorizer.stop_words, list):\n",
    "        print(f'removing {len(vectorizer.stop_words)} stopwords')\n",
    "    count_matrix = vectorizer.fit_transform(df[column].fillna(''))\n",
    "    ng_ = vectorizer.ngram_range\n",
    "    print(ng_, '-', count_matrix.shape[1], 'tokens detected')\n",
    "\n",
    "    # Sum the counts for each term in the corpus\n",
    "    count_sum = np.array(count_matrix.sum(axis=0)).flatten()\n",
    "\n",
    "    # Sort the counts in descending order\n",
    "    sorted_count_sum = np.sort(count_sum)[::-1]\n",
    "\n",
    "    # Check if axes are provided, if not, create new ones\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(7 * 1.4, 6 * 1.4))\n",
    "\n",
    "    # Plotting on the provided or new axes\n",
    "    ax.loglog(sorted_count_sum, label=f'{ng_[0]}-{ng_[1]} grams stopwords {stopwords_name}', lw=2)\n",
    "\n",
    "    # Setting labels, limits, and title only if new axes were created\n",
    "    if ax is None:\n",
    "        ax.set_xlabel('Rank')\n",
    "        ax.set_ylabel('Counts')\n",
    "        ax.set_xlim([0, rank_lim])\n",
    "        ax.set_ylim([0, count_lim])\n",
    "        ax.set_title(f'{column}: Word Freq, {count_matrix.shape[1]} tokens, {stopwords_name} stopwords removed')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        plt.show()\n",
    "# Job Title,Company Name,Location,Salary Estimate,Rating,Job Description,Founded,Industry,Revenue,Sector,Size,Type,Easy Apply,Duplicate Count,\n",
    "# Job Title clean,Salary Type,min_salary,max_salary,job_description_cleaned,Years Experience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data = {}\n",
    "for col in ['job_description_cleaned']:\n",
    "    for sw in stopword_sets:\n",
    "        for j in range(1, 4):\n",
    "            vectorizer = CountVectorizer(ngram_range=(1, j), stop_words=stopword_sets[sw])\n",
    "            count_matrix = vectorizer.fit_transform(combined_data[col].fillna(''))\n",
    "            count_sum = np.array(count_matrix.sum(axis=0)).flatten()\n",
    "            sorted_count_sum = np.sort(count_sum)[::-1]\n",
    "            count_data[(col, sw, j)] = sorted_count_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['job_description_cleaned']:\n",
    "    for sw in stopword_sets:\n",
    "        fig, ax = plt.subplots(figsize=(6*1.4, 6*1.4))\n",
    "        for j in range(1, 4):\n",
    "            sorted_count_sum = count_data[(col, sw, j)]\n",
    "            ax.loglog(sorted_count_sum, label=f'N-gram range (1, {j})')\n",
    "\n",
    "        ax.set_xlabel('Rank')\n",
    "        ax.set_ylabel('Counts')\n",
    "        ax.set_xlim([0, 1e7])\n",
    "        ax.set_ylim([0, 1e6])\n",
    "        ax.set_title(f'{col}: Word Freq, stopwords {sw}')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'zipf plots combined/zipf {col} stopwords {sw}.png', dpi=300)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['job_description_cleaned']:\n",
    "    for j in range(1, 4):\n",
    "        fig, ax = plt.subplots(figsize=(6*1.4, 6*1.4))\n",
    "        for sw in ['no','nltk sklearn union']:\n",
    "            sorted_count_sum = count_data[(col, sw, j)]\n",
    "            ax.loglog(sorted_count_sum, label=f'Stopwords {sw}')\n",
    "\n",
    "        ax.set_xlabel('Rank')\n",
    "        ax.set_ylabel('Counts')\n",
    "        ax.set_xlim([0, 1e7])\n",
    "        ax.set_ylim([0, 1e6])\n",
    "        ax.set_title(f'{col}: Word Freq, ngram range (1, {j})')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'zipf plots combined/zipf {col} ngrams 1-{j}.png', dpi=300)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['job_description_cleaned']:\n",
    "    fig, ax = plt.subplots(figsize=(11*1.4, 6*1.4))\n",
    "    for sw in ['no','nltk sklearn union']:\n",
    "        for j in range(1, 4):\n",
    "            sorted_count_sum = count_data[(col, sw, j)]\n",
    "            ax.loglog(sorted_count_sum, label=f'Stopwords {sw}, N-gram (1, {j})')\n",
    "\n",
    "    ax.set_xlabel('Rank')\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.set_xlim([0, 1e7])\n",
    "    ax.set_ylim([0, 1e6])\n",
    "    ax.set_title(f'{col}: Combined Word Freq Analysis')\n",
    "    ax.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    ax.grid(True)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'zipf plots combined/zipf {col} combined.png', dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Job Description','job_description_cleaned','Job Title','Job Title clean']:\n",
    "    for i in range(1,4):\n",
    "        for j in range(i,4):\n",
    "            for sw in stopword_sets:\n",
    "                print(col, (i,j), '- stopwords:', sw)\n",
    "                plot_zipf(combined_data, col, CountVectorizer(ngram_range=(i,j), stop_words=stopword_sets[sw]), stopwords_name=sw)\n",
    "                plt.savefig(f'zipf plots/zipf {col} ngrams {i}-{j} stopwords {sw}', dpi=300)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Job Title','Job Title clean']:\n",
    "    for i in range(1,4):\n",
    "        for j in range(i,4):\n",
    "            for sw in stopword_sets:\n",
    "                print(col, (i,j), '- stopwords:', sw)\n",
    "                plot_zipf(combined_data, col, CountVectorizer(ngram_range=(i,j), stop_words=stopword_sets[sw]), stopwords_name=sw)\n",
    "                plt.savefig(f'zipf plots/zipf {col} ngrams {i}-{j} stopwords {sw}', dpi=300)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for col in ['Job Description','job_description_cleaned','Job Title','Job Title clean']:\n",
    "    with open(f'{col}.txt', 'r') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    lines = file_content.split('\\n')\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "\n",
    "        if col in line:\n",
    "            # Extracting the N-gram and stopwords information\n",
    "            n_gram_info, stopwords_info = line.split(' - ')\n",
    "            n_gram = n_gram_info.split('(')[-1].split(')')[0]  # Extracting the N-gram range\n",
    "            n0,n1 = n_gram.split(', ')\n",
    "            stopwords = stopwords_info.split(': ')[-1]\n",
    "\n",
    "            if stopwords == 'no':\n",
    "                # If stopwords are 'no', the token count is in the next line\n",
    "                token_count = int(lines[i + 1].split(' - ')[-1].split()[0])\n",
    "                i += 2  # Incrementing by 2 to skip the next line\n",
    "            else:\n",
    "                # If stopwords are specified, the token count is in the line after the next\n",
    "                token_count = int(lines[i + 2].split(' - ')[-1].split()[0])\n",
    "                i += 3  # Incrementing by 3 to skip the next two lines\n",
    "\n",
    "            temp_df = pd.DataFrame({'ngram range': [n_gram], 'ngram min': [int(n0)], 'ngram max': [int(n1)], 'stopwords': [stopwords], 'num tokens': [token_count]})\n",
    "            df = pd.concat([df, temp_df], ignore_index=True)\n",
    "        else:\n",
    "            i += 1  # Incrementing to check the next line\n",
    "\n",
    "    # print(df)\n",
    "    df['column'] = col\n",
    "    df = df[['column','ngram range','ngram min', 'ngram max', 'stopwords', 'num tokens']]\n",
    "    dfs.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>ngram range</th>\n",
       "      <th>ngram min</th>\n",
       "      <th>ngram max</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>num tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>67695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk</td>\n",
       "      <td>67557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>67400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>67378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>67579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>1586888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk</td>\n",
       "      <td>1924770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1885504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>1881728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>1928322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>6233896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk</td>\n",
       "      <td>6603039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>6435895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>6423429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>6614995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>1519193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk</td>\n",
       "      <td>1857213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1818104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>1814350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>1860743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>6166201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk</td>\n",
       "      <td>6535482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>6368495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>6356051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>2, 3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>6547416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>4647008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk</td>\n",
       "      <td>4678269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>4550391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>4541701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>4686673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column ngram range  ngram min  ngram max               stopwords  \\\n",
       "0   Job Description        1, 1          1          1                      no   \n",
       "1   Job Description        1, 1          1          1                    nltk   \n",
       "2   Job Description        1, 1          1          1                 sklearn   \n",
       "3   Job Description        1, 1          1          1      nltk sklearn union   \n",
       "4   Job Description        1, 1          1          1  nltk sklearn intersect   \n",
       "5   Job Description        1, 2          1          2                      no   \n",
       "6   Job Description        1, 2          1          2                    nltk   \n",
       "7   Job Description        1, 2          1          2                 sklearn   \n",
       "8   Job Description        1, 2          1          2      nltk sklearn union   \n",
       "9   Job Description        1, 2          1          2  nltk sklearn intersect   \n",
       "10  Job Description        1, 3          1          3                      no   \n",
       "11  Job Description        1, 3          1          3                    nltk   \n",
       "12  Job Description        1, 3          1          3                 sklearn   \n",
       "13  Job Description        1, 3          1          3      nltk sklearn union   \n",
       "14  Job Description        1, 3          1          3  nltk sklearn intersect   \n",
       "15  Job Description        2, 2          2          2                      no   \n",
       "16  Job Description        2, 2          2          2                    nltk   \n",
       "17  Job Description        2, 2          2          2                 sklearn   \n",
       "18  Job Description        2, 2          2          2      nltk sklearn union   \n",
       "19  Job Description        2, 2          2          2  nltk sklearn intersect   \n",
       "20  Job Description        2, 3          2          3                      no   \n",
       "21  Job Description        2, 3          2          3                    nltk   \n",
       "22  Job Description        2, 3          2          3                 sklearn   \n",
       "23  Job Description        2, 3          2          3      nltk sklearn union   \n",
       "24  Job Description        2, 3          2          3  nltk sklearn intersect   \n",
       "25  Job Description        3, 3          3          3                      no   \n",
       "26  Job Description        3, 3          3          3                    nltk   \n",
       "27  Job Description        3, 3          3          3                 sklearn   \n",
       "28  Job Description        3, 3          3          3      nltk sklearn union   \n",
       "29  Job Description        3, 3          3          3  nltk sklearn intersect   \n",
       "\n",
       "    num tokens  \n",
       "0        67695  \n",
       "1        67557  \n",
       "2        67400  \n",
       "3        67378  \n",
       "4        67579  \n",
       "5      1586888  \n",
       "6      1924770  \n",
       "7      1885504  \n",
       "8      1881728  \n",
       "9      1928322  \n",
       "10     6233896  \n",
       "11     6603039  \n",
       "12     6435895  \n",
       "13     6423429  \n",
       "14     6614995  \n",
       "15     1519193  \n",
       "16     1857213  \n",
       "17     1818104  \n",
       "18     1814350  \n",
       "19     1860743  \n",
       "20     6166201  \n",
       "21     6535482  \n",
       "22     6368495  \n",
       "23     6356051  \n",
       "24     6547416  \n",
       "25     4647008  \n",
       "26     4678269  \n",
       "27     4550391  \n",
       "28     4541701  \n",
       "29     4686673  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>ngram range</th>\n",
       "      <th>ngram min</th>\n",
       "      <th>ngram max</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>num tokens detected by vectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>67695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk</td>\n",
       "      <td>67557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>67400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>67378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job Description</td>\n",
       "      <td>1, 1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>67579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>23952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk</td>\n",
       "      <td>22413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>21753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn union</td>\n",
       "      <td>21742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Job Title clean</td>\n",
       "      <td>3, 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nltk sklearn intersect</td>\n",
       "      <td>22424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             column ngram range  ngram min  ngram max               stopwords  \\\n",
       "0   Job Description        1, 1          1          1                      no   \n",
       "1   Job Description        1, 1          1          1                    nltk   \n",
       "2   Job Description        1, 1          1          1                 sklearn   \n",
       "3   Job Description        1, 1          1          1      nltk sklearn union   \n",
       "4   Job Description        1, 1          1          1  nltk sklearn intersect   \n",
       "..              ...         ...        ...        ...                     ...   \n",
       "25  Job Title clean        3, 3          3          3                      no   \n",
       "26  Job Title clean        3, 3          3          3                    nltk   \n",
       "27  Job Title clean        3, 3          3          3                 sklearn   \n",
       "28  Job Title clean        3, 3          3          3      nltk sklearn union   \n",
       "29  Job Title clean        3, 3          3          3  nltk sklearn intersect   \n",
       "\n",
       "    num tokens detected by vectorizer  \n",
       "0                               67695  \n",
       "1                               67557  \n",
       "2                               67400  \n",
       "3                               67378  \n",
       "4                               67579  \n",
       "..                                ...  \n",
       "25                              23952  \n",
       "26                              22413  \n",
       "27                              21753  \n",
       "28                              21742  \n",
       "29                              22424  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = pd.concat(dfs)\n",
    "ret.rename(columns={'num tokens':'num tokens detected by vectorizer'},inplace=True)\n",
    "ret.to_csv('stopword token analysis.csv',index=False)\n",
    "ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si671",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
